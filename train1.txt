Total train examples: 3000
Loss at batch 10 : 0.3968190550804138
Loss at batch 20 : 0.33031466603279114
Loss at batch 30 : 0.3370526432991028
Loss at batch 40 : 0.28823691606521606
Loss at batch 50 : 0.3118042051792145
Loss at batch 60 : 0.32966408133506775
Loss at batch 70 : 0.2855934500694275
Loss at batch 80 : 0.3121996819972992
Loss at batch 90 : 0.25807350873947144
Loss at batch 100 : 0.29914259910583496
Loss at batch 110 : 0.2614184617996216
Loss at batch 120 : 0.2815748453140259
Loss at batch 130 : 0.31586337089538574
Loss at batch 140 : 0.2726467251777649
Loss at batch 150 : 0.278689444065094
Loss at batch 160 : 0.24268098175525665
Loss at batch 170 : 0.2660820484161377
Loss at batch 180 : 0.2802983224391937
Loss at batch 190 : 0.288379043340683
Loss at batch 200 : 0.26807844638824463
Loss at batch 210 : 0.2742847204208374
Loss at batch 220 : 0.2525712251663208
Loss at batch 230 : 0.244988352060318
Loss at batch 240 : 0.26016202569007874
Loss at batch 250 : 0.23380917310714722
Loss at batch 260 : 0.29285961389541626
Loss at batch 270 : 0.24538859724998474
Loss at batch 280 : 0.30295807123184204
Loss at batch 290 : 0.2482164204120636
Loss at batch 300 : 0.19384482502937317
Loss at batch 310 : 0.13971136510372162
Loss at batch 320 : 0.1309889405965805
Loss at batch 330 : 0.08080043643712997
Loss at batch 340 : 0.03718681260943413
Loss at batch 350 : 0.011911233887076378
Loss at batch 360 : 0.019364021718502045
Loss at batch 370 : 0.016639240086078644
epoch0 finished!
Loss at batch 10 : 0.018461573868989944
Loss at batch 20 : 0.013784428127110004
Loss at batch 30 : 0.012276336550712585
Loss at batch 40 : 0.01811266876757145
Loss at batch 50 : 0.01518330443650484
Loss at batch 60 : 0.02147977612912655
Loss at batch 70 : 0.019599512219429016
Loss at batch 80 : 0.020405739545822144
Loss at batch 90 : 0.02265579253435135
Loss at batch 100 : 0.014731106348335743
Loss at batch 110 : 0.010657579638063908
Loss at batch 120 : 0.021067237481474876
Loss at batch 130 : 0.016127491369843483
Loss at batch 140 : 0.019398873671889305
Loss at batch 150 : 0.030710000544786453
Loss at batch 160 : 0.019959338009357452
Loss at batch 170 : 0.012012026272714138
Loss at batch 180 : 0.011283639818429947
Loss at batch 190 : 0.009742097929120064
Loss at batch 200 : 0.015441350638866425
Loss at batch 210 : 0.01307394914329052
Loss at batch 220 : 0.01350751705467701
Loss at batch 230 : 0.013318468816578388
Loss at batch 240 : 0.026799168437719345
Loss at batch 250 : 0.02374517358839512
Loss at batch 260 : 0.014238331466913223
Loss at batch 270 : 0.015902861952781677
Loss at batch 280 : 0.01268509216606617
Loss at batch 290 : 0.008342457003891468
Loss at batch 300 : 0.02187645435333252
Loss at batch 310 : 0.01896022818982601
Loss at batch 320 : 0.007861459627747536
Loss at batch 330 : 0.013252438977360725
Loss at batch 340 : 0.019254541024565697
Loss at batch 350 : 0.018920274451375008
Loss at batch 360 : 0.014579967595636845
Loss at batch 370 : 0.014567147009074688
epoch1 finished!
Loss at batch 10 : 0.028384553268551826
Loss at batch 20 : 0.017067594453692436
Loss at batch 30 : 0.010951898992061615
Loss at batch 40 : 0.02597823366522789
Loss at batch 50 : 0.011430063284933567
Loss at batch 60 : 0.01831701770424843
Loss at batch 70 : 0.0059135365299880505
Loss at batch 80 : 0.012824391946196556
Loss at batch 90 : 0.014072916470468044
Loss at batch 100 : 0.008099628612399101
Loss at batch 110 : 0.013742955401539803
Loss at batch 120 : 0.01099475473165512
Loss at batch 130 : 0.014301899820566177
Loss at batch 140 : 0.0223662368953228
Loss at batch 150 : 0.016421033069491386
Loss at batch 160 : 0.017927663400769234
Loss at batch 170 : 0.015824897214770317
Loss at batch 180 : 0.011668427847325802
Loss at batch 190 : 0.024080650880932808
Loss at batch 200 : 0.01593671925365925
Loss at batch 210 : 0.011284716427326202
Loss at batch 220 : 0.01254189945757389
Loss at batch 230 : 0.010309016332030296
Loss at batch 240 : 0.006813887506723404
Loss at batch 250 : 0.012217625975608826
Loss at batch 260 : 0.01688159629702568
Loss at batch 270 : 0.015880703926086426
Loss at batch 280 : 0.01854698173701763
Loss at batch 290 : 0.01245571207255125
Loss at batch 300 : 0.00954358372837305
Loss at batch 310 : 0.015905123203992844
Loss at batch 320 : 0.01242597121745348
Loss at batch 330 : 0.021089257672429085
Loss at batch 340 : 0.017696166411042213
Loss at batch 350 : 0.009501485154032707
Loss at batch 360 : 0.01816239207983017
Loss at batch 370 : 0.012662031687796116
epoch2 finished!
Loss at batch 10 : 0.03227611258625984
Loss at batch 20 : 0.018036074936389923
Loss at batch 30 : 0.011123203672468662
Loss at batch 40 : 0.010180272161960602
Loss at batch 50 : 0.012996405363082886
Loss at batch 60 : 0.009197324514389038
Loss at batch 70 : 0.020161328837275505
Loss at batch 80 : 0.017626633867621422
Loss at batch 90 : 0.024789277464151382
Loss at batch 100 : 0.022451302036643028
Loss at batch 110 : 0.017098110169172287
Loss at batch 120 : 0.015627965331077576
Loss at batch 130 : 0.015130235813558102
Loss at batch 140 : 0.008030817843973637
Loss at batch 150 : 0.018937163054943085
Loss at batch 160 : 0.022258244454860687
Loss at batch 170 : 0.018303129822015762
Loss at batch 180 : 0.02406120114028454
Loss at batch 190 : 0.010271381586790085
Loss at batch 200 : 0.014985235407948494
Loss at batch 210 : 0.019136982038617134
Loss at batch 220 : 0.012308995239436626
Loss at batch 230 : 0.01741691492497921
Loss at batch 240 : 0.01268936786800623
Loss at batch 250 : 0.016892388463020325
Loss at batch 260 : 0.022229406982660294
Loss at batch 270 : 0.02389408089220524
Loss at batch 280 : 0.01642500050365925
Loss at batch 290 : 0.009445619769394398
Loss at batch 300 : 0.022857259958982468
Loss at batch 310 : 0.011611910536885262
Loss at batch 320 : 0.010945507325232029
Loss at batch 330 : 0.007096078712493181
Loss at batch 340 : 0.02137652039527893
Loss at batch 350 : 0.01747291162610054
Loss at batch 360 : 0.017724422737956047
Loss at batch 370 : 0.018489019945263863
epoch3 finished!
Loss at batch 10 : 0.020201468840241432
Loss at batch 20 : 0.01833350770175457
Loss at batch 30 : 0.016046496108174324
Loss at batch 40 : 0.017794331535696983
Loss at batch 50 : 0.021442871540784836
Loss at batch 60 : 0.011603178456425667
Loss at batch 70 : 0.02099425531923771
Loss at batch 80 : 0.013265001587569714
Loss at batch 90 : 0.011258409358561039
Loss at batch 100 : 0.023159794509410858
Loss at batch 110 : 0.011176491156220436
Loss at batch 120 : 0.013682616874575615
Loss at batch 130 : 0.013336115516722202
Loss at batch 140 : 0.013834978453814983
Loss at batch 150 : 0.0110251409932971
Loss at batch 160 : 0.01719393953680992
Loss at batch 170 : 0.008178669959306717
Loss at batch 180 : 0.01669144444167614
Loss at batch 190 : 0.010282582603394985
Loss at batch 200 : 0.019136173650622368
Loss at batch 210 : 0.010936513543128967
Loss at batch 220 : 0.00800254289060831
Loss at batch 230 : 0.016887273639440536
Loss at batch 240 : 0.011559569276869297
Loss at batch 250 : 0.008180143311619759
Loss at batch 260 : 0.01485832966864109
Loss at batch 270 : 0.016905395314097404
Loss at batch 280 : 0.016178073361516
Loss at batch 290 : 0.02513519860804081
Loss at batch 300 : 0.012410781346261501
Loss at batch 310 : 0.018017305061221123
Loss at batch 320 : 0.02119576372206211
Loss at batch 330 : 0.013330690562725067
Loss at batch 340 : 0.020227301865816116
Loss at batch 350 : 0.012153803370893002
Loss at batch 360 : 0.009982508607208729
Loss at batch 370 : 0.016464978456497192
epoch4 finished!
Loss at batch 10 : 0.016511308029294014
Loss at batch 20 : 0.020879853516817093
Loss at batch 30 : 0.014627475291490555
Loss at batch 40 : 0.012385022826492786
Loss at batch 50 : 0.011832699179649353
Loss at batch 60 : 0.01422896608710289
Loss at batch 70 : 0.013799273408949375
Loss at batch 80 : 0.017521552741527557
Loss at batch 90 : 0.012046365067362785
Loss at batch 100 : 0.012140870094299316
Loss at batch 110 : 0.014383798465132713
Loss at batch 120 : 0.017820099368691444
Loss at batch 130 : 0.020890453830361366
Loss at batch 140 : 0.013881752267479897
Loss at batch 150 : 0.02035224623978138
Loss at batch 160 : 0.02082974836230278
Loss at batch 170 : 0.007484213914722204
Loss at batch 180 : 0.012078490108251572
Loss at batch 190 : 0.015881268307566643
Loss at batch 200 : 0.013870250433683395
Loss at batch 210 : 0.011598017066717148
Loss at batch 220 : 0.02014673314988613
Loss at batch 230 : 0.011474722065031528
Loss at batch 240 : 0.014322488568723202
Loss at batch 250 : 0.018461264669895172
Loss at batch 260 : 0.010180138982832432
Loss at batch 270 : 0.017885388806462288
Loss at batch 280 : 0.02963060326874256
Loss at batch 290 : 0.018879184499382973
Loss at batch 300 : 0.013287489302456379
Loss at batch 310 : 0.015205356292426586
Loss at batch 320 : 0.018865231424570084
Loss at batch 330 : 0.024411721155047417
Loss at batch 340 : 0.015496491454541683
Loss at batch 350 : 0.022016877308487892
Loss at batch 360 : 0.01477980986237526
Loss at batch 370 : 0.013515915721654892
epoch5 finished!
Loss at batch 10 : 0.0151179488748312
Loss at batch 20 : 0.01947586052119732
Loss at batch 30 : 0.01072380319237709
Loss at batch 40 : 0.011726687662303448
Loss at batch 50 : 0.011364856734871864
Loss at batch 60 : 0.014461921527981758
Loss at batch 70 : 0.015884779393672943
Loss at batch 80 : 0.008536430075764656
Loss at batch 90 : 0.012515132315456867
Loss at batch 100 : 0.022468317300081253
Loss at batch 110 : 0.01929740607738495
Loss at batch 120 : 0.017891298979520798
Loss at batch 130 : 0.011953041888773441
Loss at batch 140 : 0.012651112861931324
Loss at batch 150 : 0.020340684801340103
Loss at batch 160 : 0.01023145392537117
Loss at batch 170 : 0.021450571715831757
Loss at batch 180 : 0.015622179955244064
Loss at batch 190 : 0.024460619315505028
Loss at batch 200 : 0.022337112575769424
Loss at batch 210 : 0.016215013340115547
Loss at batch 220 : 0.012357344850897789
Loss at batch 230 : 0.013168683275580406
Loss at batch 240 : 0.01068696565926075
Loss at batch 250 : 0.010252038016915321
Loss at batch 260 : 0.01601768098771572
Loss at batch 270 : 0.012212198227643967
Loss at batch 280 : 0.011539742350578308
Loss at batch 290 : 0.017652709037065506
Loss at batch 300 : 0.014574138447642326
Loss at batch 310 : 0.011983485892415047
Loss at batch 320 : 0.012084271758794785
Loss at batch 330 : 0.012110221199691296
Loss at batch 340 : 0.014966992661356926
Loss at batch 350 : 0.019849225878715515
Loss at batch 360 : 0.017951074987649918
Loss at batch 370 : 0.014277946203947067
epoch6 finished!
Loss at batch 10 : 0.009305892512202263
Loss at batch 20 : 0.015977824106812477
Loss at batch 30 : 0.01059659756720066
Loss at batch 40 : 0.02501286379992962
Loss at batch 50 : 0.007964438758790493
Loss at batch 60 : 0.020083673298358917
Loss at batch 70 : 0.019984720274806023
Loss at batch 80 : 0.009839441627264023
Loss at batch 90 : 0.016037307679653168
Loss at batch 100 : 0.011864766478538513
Loss at batch 110 : 0.013863284140825272
Loss at batch 120 : 0.02613680623471737
Loss at batch 130 : 0.016802333295345306
Loss at batch 140 : 0.008450720459222794
Loss at batch 150 : 0.016960259526968002
Loss at batch 160 : 0.014829045161604881
Loss at batch 170 : 0.01765730418264866
Loss at batch 180 : 0.01372759509831667
Loss at batch 190 : 0.0241151861846447
Loss at batch 200 : 0.014445249922573566
Loss at batch 210 : 0.017836619168519974
Loss at batch 220 : 0.01384634431451559
Loss at batch 230 : 0.010561703704297543
Loss at batch 240 : 0.015220832079648972
Loss at batch 250 : 0.013641690835356712
Loss at batch 260 : 0.016724342480301857
Loss at batch 270 : 0.010467306710779667
Loss at batch 280 : 0.02567293867468834
Loss at batch 290 : 0.01141318492591381
Loss at batch 300 : 0.01845276728272438
Loss at batch 310 : 0.020517010241746902
Loss at batch 320 : 0.01714290678501129
Loss at batch 330 : 0.021779216825962067
Loss at batch 340 : 0.012448162771761417
Loss at batch 350 : 0.019806133583188057
Loss at batch 360 : 0.024729928001761436
Loss at batch 370 : 0.02301066555082798
epoch7 finished!
Loss at batch 10 : 0.03457342088222504
Loss at batch 20 : 0.015799984335899353
Loss at batch 30 : 0.012090404517948627
Loss at batch 40 : 0.02627716213464737
Loss at batch 50 : 0.013468657620251179
Loss at batch 60 : 0.014088807627558708
Loss at batch 70 : 0.02468055859208107
Loss at batch 80 : 0.020526695996522903
Loss at batch 90 : 0.021383514627814293
Loss at batch 100 : 0.018472231924533844
Loss at batch 110 : 0.016284266486763954
Loss at batch 120 : 0.016578324139118195
Loss at batch 130 : 0.013508176431059837
Loss at batch 140 : 0.018213871866464615
Loss at batch 150 : 0.013951628468930721
Loss at batch 160 : 0.02276805229485035
Loss at batch 170 : 0.0174099188297987
Loss at batch 180 : 0.012659486383199692
Loss at batch 190 : 0.01822383515536785
Loss at batch 200 : 0.011456087231636047
Loss at batch 210 : 0.016363846138119698
Loss at batch 220 : 0.03413483500480652
Loss at batch 230 : 0.021122153848409653
Loss at batch 240 : 0.008980832062661648
Loss at batch 250 : 0.0074709560722112656
Loss at batch 260 : 0.01577889733016491
Loss at batch 270 : 0.013683014549314976
Loss at batch 280 : 0.007390079088509083
Loss at batch 290 : 0.011329448781907558
Loss at batch 300 : 0.01765577308833599
Loss at batch 310 : 0.008313448168337345
Loss at batch 320 : 0.012928836047649384
Loss at batch 330 : 0.018703371286392212
Loss at batch 340 : 0.020875554531812668
Loss at batch 350 : 0.009726363234221935
Loss at batch 360 : 0.015730837360024452
Loss at batch 370 : 0.013368352316319942
epoch8 finished!
Loss at batch 10 : 0.008149492554366589
Loss at batch 20 : 0.01705394871532917
Loss at batch 30 : 0.014515792019665241
Loss at batch 40 : 0.011106944642961025
Loss at batch 50 : 0.009146396070718765
Loss at batch 60 : 0.01258130557835102
Loss at batch 70 : 0.015925513580441475
Loss at batch 80 : 0.014587108977138996
Loss at batch 90 : 0.012230080552399158
Loss at batch 100 : 0.013942530378699303
Loss at batch 110 : 0.018491234630346298
Loss at batch 120 : 0.01394351664930582
Loss at batch 130 : 0.014502923004329205
Loss at batch 140 : 0.009537076577544212
Loss at batch 150 : 0.012989738956093788
Loss at batch 160 : 0.016130860894918442
Loss at batch 170 : 0.011285554617643356
Loss at batch 180 : 0.014967232011258602
Loss at batch 190 : 0.01495094783604145
Loss at batch 200 : 0.009870432317256927
Loss at batch 210 : 0.020489150658249855
Loss at batch 220 : 0.012919594533741474
Loss at batch 230 : 0.017422841861844063
Loss at batch 240 : 0.016739465296268463
Loss at batch 250 : 0.009584539569914341
Loss at batch 260 : 0.01301802322268486
Loss at batch 270 : 0.025828013196587563
Loss at batch 280 : 0.015538361854851246
Loss at batch 290 : 0.012013961561024189
Loss at batch 300 : 0.008730638772249222
Loss at batch 310 : 0.011632796376943588
Loss at batch 320 : 0.010473603382706642
Loss at batch 330 : 0.017434433102607727
Loss at batch 340 : 0.016288165003061295
Loss at batch 350 : 0.019865894690155983
Loss at batch 360 : 0.01754913292825222
Loss at batch 370 : 0.0102009242400527
epoch9 finished!
Loss at batch 10 : 0.009249117225408554
Loss at batch 20 : 0.015113627538084984
Loss at batch 30 : 0.013484552502632141
Loss at batch 40 : 0.02131509967148304
Loss at batch 50 : 0.017843162640929222
Loss at batch 60 : 0.013860007748007774
Loss at batch 70 : 0.018404876813292503
Loss at batch 80 : 0.018464921042323112
Loss at batch 90 : 0.0077764554880559444
Loss at batch 100 : 0.011016990058124065
Loss at batch 110 : 0.016355279833078384
Loss at batch 120 : 0.01078475546091795
Loss at batch 130 : 0.011968547478318214
Loss at batch 140 : 0.01819072850048542
Loss at batch 150 : 0.016508664935827255
Loss at batch 160 : 0.014790873974561691
Loss at batch 170 : 0.02573002316057682
Loss at batch 180 : 0.01744377613067627
Loss at batch 190 : 0.01718953065574169
Loss at batch 200 : 0.009454097598791122
Loss at batch 210 : 0.015760697424411774
Loss at batch 220 : 0.0218595452606678
Loss at batch 230 : 0.009586429223418236
Loss at batch 240 : 0.020693235099315643
Loss at batch 250 : 0.014516404829919338
Loss at batch 260 : 0.020764024928212166
Loss at batch 270 : 0.02906346693634987
Loss at batch 280 : 0.014167270623147488
Loss at batch 290 : 0.026182692497968674
Loss at batch 300 : 0.012429004535079002
Loss at batch 310 : 0.011391235515475273
Loss at batch 320 : 0.01848074048757553
Loss at batch 330 : 0.013444285839796066
Loss at batch 340 : 0.007075836416333914
Loss at batch 350 : 0.015750827267766
Loss at batch 360 : 0.014094533398747444
Loss at batch 370 : 0.01213479321449995
epoch10 finished!
Loss at batch 10 : 0.017994020134210587
Loss at batch 20 : 0.01329270750284195
Loss at batch 30 : 0.012430241331458092
Loss at batch 40 : 0.01592416875064373
Loss at batch 50 : 0.013356314972043037
Loss at batch 60 : 0.015776963904500008
Loss at batch 70 : 0.012826492078602314
Loss at batch 80 : 0.013984646648168564
Loss at batch 90 : 0.01679222658276558
Loss at batch 100 : 0.01994054578244686
Loss at batch 110 : 0.017302926629781723
Loss at batch 120 : 0.013667422346770763
Loss at batch 130 : 0.011081776581704617
Loss at batch 140 : 0.022736648097634315
Loss at batch 150 : 0.02081347070634365
Loss at batch 160 : 0.011335095390677452
Loss at batch 170 : 0.010202032513916492
Loss at batch 180 : 0.024445317685604095
Loss at batch 190 : 0.026154836639761925
Loss at batch 200 : 0.013148723170161247
Loss at batch 210 : 0.02005300112068653
Loss at batch 220 : 0.018814750015735626
Loss at batch 230 : 0.008264821954071522
Loss at batch 240 : 0.009315380826592445
Loss at batch 250 : 0.015435151755809784
Loss at batch 260 : 0.011870194226503372
Loss at batch 270 : 0.010170224122703075
Loss at batch 280 : 0.017856255173683167
Loss at batch 290 : 0.018979759886860847
Loss at batch 300 : 0.023771772161126137
Loss at batch 310 : 0.02409120462834835
Loss at batch 320 : 0.01380226667970419
Loss at batch 330 : 0.01749999076128006
Loss at batch 340 : 0.015516201965510845
Loss at batch 350 : 0.009065750986337662
Loss at batch 360 : 0.014023988507688046
Loss at batch 370 : 0.009987053461372852
epoch11 finished!
Loss at batch 10 : 0.013504592701792717
Loss at batch 20 : 0.01417108066380024
Loss at batch 30 : 0.016466785222291946
Loss at batch 40 : 0.025448307394981384
Loss at batch 50 : 0.014732151292264462
Loss at batch 60 : 0.01277628168463707
Loss at batch 70 : 0.01543586514890194
Loss at batch 80 : 0.00780065543949604
Loss at batch 90 : 0.018321385607123375
Loss at batch 100 : 0.013230355456471443
Loss at batch 110 : 0.008420505560934544
Loss at batch 120 : 0.012572439387440681
Loss at batch 130 : 0.01225225254893303
Loss at batch 140 : 0.0307918731123209
Loss at batch 150 : 0.010729656554758549
Loss at batch 160 : 0.023534970358014107
Loss at batch 170 : 0.010806337930262089
Loss at batch 180 : 0.014786415733397007
Loss at batch 190 : 0.012082594446837902
Loss at batch 200 : 0.012185454368591309
Loss at batch 210 : 0.020847361534833908
Loss at batch 220 : 0.02486511319875717
Loss at batch 230 : 0.01329830102622509
Loss at batch 240 : 0.019764240831136703
Loss at batch 250 : 0.027536850422620773
Loss at batch 260 : 0.010893953032791615
Loss at batch 270 : 0.014815617352724075
Loss at batch 280 : 0.01078807469457388
Loss at batch 290 : 0.012884457595646381
Loss at batch 300 : 0.007757590617984533
Loss at batch 310 : 0.017033491283655167
Loss at batch 320 : 0.013582545332610607
Loss at batch 330 : 0.00965268723666668
Loss at batch 340 : 0.009616918861865997
Loss at batch 350 : 0.012469002045691013
Loss at batch 360 : 0.021330831572413445
Loss at batch 370 : 0.014226815663278103
epoch12 finished!
Loss at batch 10 : 0.01603909768164158
Loss at batch 20 : 0.01208956353366375
Loss at batch 30 : 0.013319028541445732
Loss at batch 40 : 0.01591075025498867
Loss at batch 50 : 0.012746285647153854
Loss at batch 60 : 0.017605431377887726
Loss at batch 70 : 0.015967948362231255
Loss at batch 80 : 0.014720111154019833
Loss at batch 90 : 0.012298458255827427
Loss at batch 100 : 0.008019364438951015
Loss at batch 110 : 0.00813854020088911
Loss at batch 120 : 0.012532368302345276
Loss at batch 130 : 0.013375803828239441
Loss at batch 140 : 0.014104231260716915
Loss at batch 150 : 0.015384615398943424
Loss at batch 160 : 0.010675258934497833
Loss at batch 170 : 0.017075901851058006
Loss at batch 180 : 0.0260466355830431
Loss at batch 190 : 0.030209610238671303
Loss at batch 200 : 0.01942623220384121
Loss at batch 210 : 0.012204134836792946
Loss at batch 220 : 0.014853901229798794
Loss at batch 230 : 0.013774434104561806
Loss at batch 240 : 0.011837798170745373
Loss at batch 250 : 0.01424314919859171
Loss at batch 260 : 0.020059064030647278
Loss at batch 270 : 0.012026903219521046
Loss at batch 280 : 0.01974133402109146
Loss at batch 290 : 0.011764252558350563
Loss at batch 300 : 0.009085001423954964
Loss at batch 310 : 0.02686765044927597
Loss at batch 320 : 0.013149469159543514
Loss at batch 330 : 0.008486970327794552
Loss at batch 340 : 0.01822515018284321
Loss at batch 350 : 0.014718991704285145
Loss at batch 360 : 0.019558364525437355
Loss at batch 370 : 0.012126019224524498
epoch13 finished!
Loss at batch 10 : 0.016556499525904655
Loss at batch 20 : 0.015832901000976562
Loss at batch 30 : 0.010778062045574188
Loss at batch 40 : 0.015794260427355766
Loss at batch 50 : 0.015988267958164215
Loss at batch 60 : 0.019317274913191795
Loss at batch 70 : 0.018286727368831635
Loss at batch 80 : 0.01712021604180336
Loss at batch 90 : 0.0186017956584692
Loss at batch 100 : 0.01613745652139187
Loss at batch 110 : 0.01949990913271904
Loss at batch 120 : 0.016890089958906174
Loss at batch 130 : 0.007473406381905079
Loss at batch 140 : 0.006923965644091368
Loss at batch 150 : 0.01807978004217148
Loss at batch 160 : 0.010427127592265606
Loss at batch 170 : 0.009981269016861916
Loss at batch 180 : 0.010843014344573021
Loss at batch 190 : 0.01332168374210596
Loss at batch 200 : 0.011388879269361496
Loss at batch 210 : 0.018913958221673965
Loss at batch 220 : 0.019666535779833794
Loss at batch 230 : 0.015405485406517982
Loss at batch 240 : 0.0124988853931427
Loss at batch 250 : 0.022519785910844803
Loss at batch 260 : 0.011618686839938164
Loss at batch 270 : 0.010642697103321552
Loss at batch 280 : 0.01195268053561449
Loss at batch 290 : 0.02043990232050419
Loss at batch 300 : 0.012371212244033813
Loss at batch 310 : 0.019535254687070847
Loss at batch 320 : 0.014753122813999653
Loss at batch 330 : 0.013181756250560284
Loss at batch 340 : 0.011470867320895195
Loss at batch 350 : 0.015976399183273315
Loss at batch 360 : 0.015197273343801498
Loss at batch 370 : 0.025331944227218628
epoch14 finished!
Loss at batch 10 : 0.011552075855433941
Loss at batch 20 : 0.012656403705477715
Loss at batch 30 : 0.030578263103961945
Loss at batch 40 : 0.010274560190737247
Loss at batch 50 : 0.0077805547043681145
Loss at batch 60 : 0.01134438905864954
Loss at batch 70 : 0.01271151751279831
Loss at batch 80 : 0.017839830368757248
Loss at batch 90 : 0.009903405793011189
Loss at batch 100 : 0.01637113280594349
Loss at batch 110 : 0.020385866984725
Loss at batch 120 : 0.01110219955444336
Loss at batch 130 : 0.011845606379210949
Loss at batch 140 : 0.019302112981677055
Loss at batch 150 : 0.014990663155913353
Loss at batch 160 : 0.015633748844265938
Loss at batch 170 : 0.015947382897138596
Loss at batch 180 : 0.02369324304163456
Loss at batch 190 : 0.014613786712288857
Loss at batch 200 : 0.008498325943946838
Loss at batch 210 : 0.014469354413449764
Loss at batch 220 : 0.02498798817396164
Loss at batch 230 : 0.026556160300970078
Loss at batch 240 : 0.010625947266817093
Loss at batch 250 : 0.01949031464755535
Loss at batch 260 : 0.01510042417794466
Loss at batch 270 : 0.02554967813193798
Loss at batch 280 : 0.03442494943737984
Loss at batch 290 : 0.022863537073135376
Loss at batch 300 : 0.013929473236203194
Loss at batch 310 : 0.018350761383771896
Loss at batch 320 : 0.030857345089316368
Loss at batch 330 : 0.020069707185029984
Loss at batch 340 : 0.01316759455949068
Loss at batch 350 : 0.01585332304239273
Loss at batch 360 : 0.019679540768265724
Loss at batch 370 : 0.015328553505241871
epoch15 finished!
Loss at batch 10 : 0.01518958155065775
Loss at batch 20 : 0.011915945447981358
Loss at batch 30 : 0.01220618560910225
Loss at batch 40 : 0.013783654198050499
Loss at batch 50 : 0.010160536505281925
Loss at batch 60 : 0.01348311360925436
Loss at batch 70 : 0.014904933050274849
Loss at batch 80 : 0.014617507345974445
Loss at batch 90 : 0.016680512577295303
Loss at batch 100 : 0.012499915435910225
Loss at batch 110 : 0.026925163343548775
Loss at batch 120 : 0.00843501091003418
Loss at batch 130 : 0.01994887925684452
Loss at batch 140 : 0.021262476220726967
Loss at batch 150 : 0.017565568909049034
Loss at batch 160 : 0.01510897558182478
Loss at batch 170 : 0.011991696432232857
Loss at batch 180 : 0.01203947700560093
Loss at batch 190 : 0.01606130413711071
Loss at batch 200 : 0.022386860102415085
Loss at batch 210 : 0.02154822275042534
Loss at batch 220 : 0.01537204161286354
Loss at batch 230 : 0.016077524051070213
Loss at batch 240 : 0.008875117637217045
Loss at batch 250 : 0.018135711550712585
Loss at batch 260 : 0.02288898453116417
Loss at batch 270 : 0.021892162039875984
Loss at batch 280 : 0.011995568871498108
Loss at batch 290 : 0.02304767444729805
Loss at batch 300 : 0.01605495810508728
Loss at batch 310 : 0.018437646329402924
Loss at batch 320 : 0.019162502139806747
Loss at batch 330 : 0.021947477012872696
Loss at batch 340 : 0.016237391158938408
Loss at batch 350 : 0.01158036570996046
Loss at batch 360 : 0.01585151068866253
Loss at batch 370 : 0.01250859722495079
epoch16 finished!
Loss at batch 10 : 0.014424589462578297
Loss at batch 20 : 0.0076436190865933895
Loss at batch 30 : 0.01646716333925724
Loss at batch 40 : 0.0075610848143696785
Loss at batch 50 : 0.006160280201584101
Loss at batch 60 : 0.01648278348147869
Loss at batch 70 : 0.015631822869181633
Loss at batch 80 : 0.010627055540680885
Loss at batch 90 : 0.010574483312666416
Loss at batch 100 : 0.01819688268005848
Loss at batch 110 : 0.011674434877932072
Loss at batch 120 : 0.013659183867275715
Loss at batch 130 : 0.012922675348818302
Loss at batch 140 : 0.017934231087565422
Loss at batch 150 : 0.010150733403861523
Loss at batch 160 : 0.016715703532099724
Loss at batch 170 : 0.02375055104494095
Loss at batch 180 : 0.015151411294937134
Loss at batch 190 : 0.0071329050697386265
Loss at batch 200 : 0.008068453520536423
Loss at batch 210 : 0.010803275741636753
Loss at batch 220 : 0.01546571310609579
Loss at batch 230 : 0.015216066502034664
Loss at batch 240 : 0.012334039434790611
Loss at batch 250 : 0.008244827389717102
Loss at batch 260 : 0.01726720668375492
Loss at batch 270 : 0.014788012951612473
Loss at batch 280 : 0.019201431423425674
Loss at batch 290 : 0.018573056906461716
Loss at batch 300 : 0.029867012053728104
Loss at batch 310 : 0.024320358410477638
Loss at batch 320 : 0.023399243131279945
Loss at batch 330 : 0.019010081887245178
Loss at batch 340 : 0.010330336168408394
Loss at batch 350 : 0.022335443645715714
Loss at batch 360 : 0.009713377803564072
Loss at batch 370 : 0.016979292035102844
epoch17 finished!
Loss at batch 10 : 0.019401071593165398
Loss at batch 20 : 0.017779240384697914
Loss at batch 30 : 0.008860884234309196
Loss at batch 40 : 0.02392931655049324
Loss at batch 50 : 0.01520620845258236
Loss at batch 60 : 0.01613016240298748
Loss at batch 70 : 0.010036981664597988
Loss at batch 80 : 0.017280539497733116
Loss at batch 90 : 0.016176745295524597
Loss at batch 100 : 0.0195031575858593
Loss at batch 110 : 0.030735915526747704
Loss at batch 120 : 0.021964751183986664
Loss at batch 130 : 0.01932731457054615
Loss at batch 140 : 0.030821606516838074
Loss at batch 150 : 0.017759233713150024
Loss at batch 160 : 0.011067871935665607
Loss at batch 170 : 0.013219230808317661
Loss at batch 180 : 0.014774319715797901
Loss at batch 190 : 0.014601665548980236
Loss at batch 200 : 0.01579032465815544
Loss at batch 210 : 0.025110311806201935
Loss at batch 220 : 0.017180226743221283
Loss at batch 230 : 0.009856411255896091
Loss at batch 240 : 0.012420508079230785
Loss at batch 250 : 0.012313514947891235
Loss at batch 260 : 0.02059338055551052
Loss at batch 270 : 0.00862098764628172
Loss at batch 280 : 0.014429671689867973
Loss at batch 290 : 0.0132630979642272
Loss at batch 300 : 0.01879231631755829
Loss at batch 310 : 0.011602465994656086
Loss at batch 320 : 0.01584828831255436
Loss at batch 330 : 0.01045248657464981
Loss at batch 340 : 0.011941324919462204
Loss at batch 350 : 0.0138627327978611
Loss at batch 360 : 0.018890036270022392
Loss at batch 370 : 0.02526966854929924
epoch18 finished!
Loss at batch 10 : 0.017719071358442307
Loss at batch 20 : 0.017832670360803604
Loss at batch 30 : 0.01853502169251442
Loss at batch 40 : 0.011556044220924377
Loss at batch 50 : 0.01065981574356556
Loss at batch 60 : 0.01451767235994339
Loss at batch 70 : 0.00937325693666935
Loss at batch 80 : 0.02408147230744362
Loss at batch 90 : 0.011837683618068695
Loss at batch 100 : 0.017559535801410675
Loss at batch 110 : 0.012604902498424053
Loss at batch 120 : 0.013755613937973976
Loss at batch 130 : 0.009072261862456799
Loss at batch 140 : 0.012432774528861046
Loss at batch 150 : 0.01788216456770897
Loss at batch 160 : 0.014134664088487625
Loss at batch 170 : 0.02039625495672226
Loss at batch 180 : 0.02099805325269699
Loss at batch 190 : 0.009447244927287102
Loss at batch 200 : 0.02613218128681183
Loss at batch 210 : 0.01679418794810772
Loss at batch 220 : 0.01345356460660696
Loss at batch 230 : 0.01236871350556612
Loss at batch 240 : 0.01648023910820484
Loss at batch 250 : 0.011901188641786575
Loss at batch 260 : 0.017078770324587822
Loss at batch 270 : 0.020124360918998718
Loss at batch 280 : 0.008184520527720451
Loss at batch 290 : 0.019251590594649315
Loss at batch 300 : 0.013650224544107914
Loss at batch 310 : 0.015172471292316914
Loss at batch 320 : 0.013495302759110928
Loss at batch 330 : 0.020351359620690346
Loss at batch 340 : 0.014525189064443111
Loss at batch 350 : 0.02438419871032238
Loss at batch 360 : 0.030356712639331818
Loss at batch 370 : 0.031715523451566696
epoch19 finished!
Loss at batch 10 : 0.015910329297184944
Loss at batch 20 : 0.00969690177589655
Loss at batch 30 : 0.01876826025545597
Loss at batch 40 : 0.02445184998214245
Loss at batch 50 : 0.01796438917517662
Loss at batch 60 : 0.008824406191706657
Loss at batch 70 : 0.013996194116771221
Loss at batch 80 : 0.0192073006182909
Loss at batch 90 : 0.017834562808275223
Loss at batch 100 : 0.01528962142765522
Loss at batch 110 : 0.020381340757012367
Loss at batch 120 : 0.00888699758797884
Loss at batch 130 : 0.016858506947755814
Loss at batch 140 : 0.01645176112651825
Loss at batch 150 : 0.019762733951210976
Loss at batch 160 : 0.018440259620547295
Loss at batch 170 : 0.016124302521348
Loss at batch 180 : 0.01426469162106514
Loss at batch 190 : 0.018655506893992424
Loss at batch 200 : 0.027318930253386497
Loss at batch 210 : 0.01286142785102129
Loss at batch 220 : 0.027833133935928345
Loss at batch 230 : 0.012117677368223667
Loss at batch 240 : 0.01086194533854723
Loss at batch 250 : 0.012512451969087124
Loss at batch 260 : 0.018601680174469948
Loss at batch 270 : 0.023173738270998
Loss at batch 280 : 0.015320850536227226
Loss at batch 290 : 0.013566385954618454
Loss at batch 300 : 0.014362085610628128
Loss at batch 310 : 0.014107045717537403
Loss at batch 320 : 0.013195141218602657
Loss at batch 330 : 0.01937389373779297
Loss at batch 340 : 0.017277821898460388
Loss at batch 350 : 0.018837470561265945
Loss at batch 360 : 0.015096238814294338
Loss at batch 370 : 0.006950758397579193
epoch20 finished!
Loss at batch 10 : 0.016535289585590363
Loss at batch 20 : 0.01959889754652977
Loss at batch 30 : 0.01822168193757534
Loss at batch 40 : 0.014872497878968716
Loss at batch 50 : 0.009819122031331062
Loss at batch 60 : 0.012742532417178154
Loss at batch 70 : 0.01697395183146
Loss at batch 80 : 0.019665226340293884
Loss at batch 90 : 0.014264281839132309
Loss at batch 100 : 0.0146996034309268
Loss at batch 110 : 0.023428963497281075
Loss at batch 120 : 0.0104377381503582
Loss at batch 130 : 0.010960397310554981
Loss at batch 140 : 0.02046177349984646
Loss at batch 150 : 0.014174374751746655
Loss at batch 160 : 0.011770712211728096
Loss at batch 170 : 0.021316545084118843
Loss at batch 180 : 0.015963947400450706
Loss at batch 190 : 0.012463079765439034
Loss at batch 200 : 0.016544073820114136
Loss at batch 210 : 0.01918455772101879
Loss at batch 220 : 0.014429988339543343
Loss at batch 230 : 0.009889031760394573
Loss at batch 240 : 0.020901324227452278
Loss at batch 250 : 0.009533155709505081
Loss at batch 260 : 0.01670394279062748
Loss at batch 270 : 0.008667301386594772
Loss at batch 280 : 0.013753917999565601
Loss at batch 290 : 0.01461169682443142
Loss at batch 300 : 0.020264646038413048
Loss at batch 310 : 0.020114166662096977
Loss at batch 320 : 0.010298818349838257
Loss at batch 330 : 0.017488308250904083
Loss at batch 340 : 0.025026682764291763
Loss at batch 350 : 0.021385274827480316
Loss at batch 360 : 0.02081054449081421
Loss at batch 370 : 0.014481805264949799
epoch21 finished!
Loss at batch 10 : 0.02284647338092327
Loss at batch 20 : 0.019673194736242294
Loss at batch 30 : 0.012060683220624924
Loss at batch 40 : 0.015317150391638279
Loss at batch 50 : 0.011181816458702087
Loss at batch 60 : 0.018206199631094933
Loss at batch 70 : 0.015579457394778728
Loss at batch 80 : 0.009900735691189766
Loss at batch 90 : 0.008011884987354279
Loss at batch 100 : 0.017885809764266014
Loss at batch 110 : 0.02289782650768757
Loss at batch 120 : 0.02282276563346386
Loss at batch 130 : 0.009329158812761307
Loss at batch 140 : 0.014691149815917015
Loss at batch 150 : 0.010827876627445221
Loss at batch 160 : 0.012843921780586243
Loss at batch 170 : 0.014228797517716885
Loss at batch 180 : 0.02006935328245163
Loss at batch 190 : 0.01674540713429451
Loss at batch 200 : 0.007651236839592457
Loss at batch 210 : 0.014664131216704845
Loss at batch 220 : 0.022719666361808777
Loss at batch 230 : 0.01000465452671051
Loss at batch 240 : 0.016642773523926735
Loss at batch 250 : 0.017902523279190063
Loss at batch 260 : 0.01712643913924694
Loss at batch 270 : 0.013510686345398426
Loss at batch 280 : 0.013007061555981636
Loss at batch 290 : 0.014005656354129314
Loss at batch 300 : 0.013275792822241783
Loss at batch 310 : 0.010622547939419746
Loss at batch 320 : 0.013189664110541344
Loss at batch 330 : 0.007609361782670021
Loss at batch 340 : 0.01037885807454586
Loss at batch 350 : 0.017227502539753914
Loss at batch 360 : 0.013176084496080875
Loss at batch 370 : 0.011319451034069061
epoch22 finished!
Loss at batch 10 : 0.017888911068439484
Loss at batch 20 : 0.016037380322813988
Loss at batch 30 : 0.010329297743737698
Loss at batch 40 : 0.016331803053617477
Loss at batch 50 : 0.01809670589864254
Loss at batch 60 : 0.015134171582758427
Loss at batch 70 : 0.03137930482625961
Loss at batch 80 : 0.019968660548329353
Loss at batch 90 : 0.023215586319565773
Loss at batch 100 : 0.013058527372777462
Loss at batch 110 : 0.02201213873922825
Loss at batch 120 : 0.02011839672923088
Loss at batch 130 : 0.01514224149286747
Loss at batch 140 : 0.016004325821995735
Loss at batch 150 : 0.00943024829030037
Loss at batch 160 : 0.01392257958650589
Loss at batch 170 : 0.013803535141050816
Loss at batch 180 : 0.01914846897125244
Loss at batch 190 : 0.016128990799188614
Loss at batch 200 : 0.011669778265058994
Loss at batch 210 : 0.017860841006040573
Loss at batch 220 : 0.008014414459466934
Loss at batch 230 : 0.02690238133072853
Loss at batch 240 : 0.0080499779433012
Loss at batch 250 : 0.01527623925358057
Loss at batch 260 : 0.00824371911585331
Loss at batch 270 : 0.013445802964270115
Loss at batch 280 : 0.013011869043111801
Loss at batch 290 : 0.017323065549135208
Loss at batch 300 : 0.015789546072483063
Loss at batch 310 : 0.015474044717848301
Loss at batch 320 : 0.0165085531771183
Loss at batch 330 : 0.01081835851073265
Loss at batch 340 : 0.008634780533611774
Loss at batch 350 : 0.017969811335206032
Loss at batch 360 : 0.02568734809756279
Loss at batch 370 : 0.01400179322808981
epoch23 finished!
Loss at batch 10 : 0.023022038862109184
Loss at batch 20 : 0.014133114367723465
Loss at batch 30 : 0.01889677345752716
Loss at batch 40 : 0.011885715648531914
Loss at batch 50 : 0.013357516378164291
Loss at batch 60 : 0.018064219504594803
Loss at batch 70 : 0.014122361317276955
Loss at batch 80 : 0.022610321640968323
Loss at batch 90 : 0.018836751580238342
Loss at batch 100 : 0.010041103698313236
Loss at batch 110 : 0.009793435223400593
Loss at batch 120 : 0.013430259190499783
Loss at batch 130 : 0.016489828005433083
Loss at batch 140 : 0.008822294883430004
Loss at batch 150 : 0.015940269455313683
Loss at batch 160 : 0.014528184197843075
Loss at batch 170 : 0.010164686478674412
Loss at batch 180 : 0.008794296532869339
Loss at batch 190 : 0.020474819466471672
Loss at batch 200 : 0.012457524426281452
Loss at batch 210 : 0.015944676473736763
Loss at batch 220 : 0.01264200545847416
Loss at batch 230 : 0.02062683366239071
Loss at batch 240 : 0.017232948914170265
Loss at batch 250 : 0.012605623342096806
Loss at batch 260 : 0.015118696726858616
Loss at batch 270 : 0.010437700897455215
Loss at batch 280 : 0.028827019035816193
Loss at batch 290 : 0.014101510867476463
Loss at batch 300 : 0.022374674677848816
Loss at batch 310 : 0.015641506761312485
Loss at batch 320 : 0.012232079170644283
Loss at batch 330 : 0.009947864338755608
Loss at batch 340 : 0.01856916956603527
Loss at batch 350 : 0.01892830803990364
Loss at batch 360 : 0.014541085809469223
Loss at batch 370 : 0.008861533366143703
epoch24 finished!
Loss at batch 10 : 0.011478286236524582
Loss at batch 20 : 0.008951464667916298
Loss at batch 30 : 0.01357437763363123
Loss at batch 40 : 0.011590614914894104
Loss at batch 50 : 0.013559666462242603
Loss at batch 60 : 0.012068952433764935
Loss at batch 70 : 0.012733878567814827
Loss at batch 80 : 0.008426818996667862
Loss at batch 90 : 0.01397000439465046
Loss at batch 100 : 0.010792228393256664
Loss at batch 110 : 0.009224653244018555
Loss at batch 120 : 0.014921953901648521
Loss at batch 130 : 0.012529655359685421
Loss at batch 140 : 0.02179187349975109
Loss at batch 150 : 0.016779137775301933
Loss at batch 160 : 0.01585972309112549
Loss at batch 170 : 0.013545628637075424
Loss at batch 180 : 0.01170952059328556
Loss at batch 190 : 0.010301765985786915
Loss at batch 200 : 0.020589353516697884
Loss at batch 210 : 0.01311559323221445
Loss at batch 220 : 0.01752096600830555
Loss at batch 230 : 0.022737205028533936
Loss at batch 240 : 0.012570410035550594
Loss at batch 250 : 0.012543996796011925
Loss at batch 260 : 0.007108776364475489
Loss at batch 270 : 0.013554524630308151
Loss at batch 280 : 0.016903134062886238
Loss at batch 290 : 0.02396143041551113
Loss at batch 300 : 0.010671854950487614
Loss at batch 310 : 0.00883249007165432
Loss at batch 320 : 0.02230719104409218
Loss at batch 330 : 0.011751475743949413
Loss at batch 340 : 0.008551307022571564
Loss at batch 350 : 0.011955369263887405
Loss at batch 360 : 0.03763158246874809
Loss at batch 370 : 0.016408195719122887
epoch25 finished!
Loss at batch 10 : 0.010899551212787628
Loss at batch 20 : 0.016417566686868668
Loss at batch 30 : 0.017110001295804977
Loss at batch 40 : 0.014181106351315975
Loss at batch 50 : 0.018938597291707993
Loss at batch 60 : 0.02160143107175827
Loss at batch 70 : 0.02016492187976837
Loss at batch 80 : 0.011454270221292973
Loss at batch 90 : 0.009883571416139603
Loss at batch 100 : 0.016754118725657463
Loss at batch 110 : 0.019193997606635094
Loss at batch 120 : 0.016990739852190018
Loss at batch 130 : 0.009942214004695415
Loss at batch 140 : 0.0127422995865345
Loss at batch 150 : 0.031598325818777084
Loss at batch 160 : 0.012237656861543655
Loss at batch 170 : 0.016007624566555023
Loss at batch 180 : 0.016563838347792625
Loss at batch 190 : 0.012669139541685581
Loss at batch 200 : 0.011158515699207783
Loss at batch 210 : 0.01560442429035902
Loss at batch 220 : 0.0121645862236619
Loss at batch 230 : 0.020709514617919922
Loss at batch 240 : 0.020261408761143684
Loss at batch 250 : 0.012383252382278442
Loss at batch 260 : 0.01791870780289173
Loss at batch 270 : 0.010517556220293045
Loss at batch 280 : 0.015906717628240585
Loss at batch 290 : 0.01476928312331438
Loss at batch 300 : 0.01335727795958519
Loss at batch 310 : 0.01615491509437561
Loss at batch 320 : 0.0134944012388587
Loss at batch 330 : 0.018880920484662056
Loss at batch 340 : 0.01308237574994564
Loss at batch 350 : 0.008642240427434444
Loss at batch 360 : 0.018659435212612152
Loss at batch 370 : 0.015194927342236042
epoch26 finished!
Loss at batch 10 : 0.019006608054041862
Loss at batch 20 : 0.025869159027934074
Loss at batch 30 : 0.014159675687551498
Loss at batch 40 : 0.019782667979598045
Loss at batch 50 : 0.00883339624851942
Loss at batch 60 : 0.014815506525337696
Loss at batch 70 : 0.01568256877362728
Loss at batch 80 : 0.01838498003780842
Loss at batch 90 : 0.015937449410557747
Loss at batch 100 : 0.01576165482401848
Loss at batch 110 : 0.016902610659599304
Loss at batch 120 : 0.01788965053856373
Loss at batch 130 : 0.009649336338043213
Loss at batch 140 : 0.011775481514632702
Loss at batch 150 : 0.018512168899178505
Loss at batch 160 : 0.016195695847272873
Loss at batch 170 : 0.016514768823981285
Loss at batch 180 : 0.01918286271393299
Loss at batch 190 : 0.01964213140308857
Loss at batch 200 : 0.00736972177401185
Loss at batch 210 : 0.008698562160134315
Loss at batch 220 : 0.005697342567145824
Loss at batch 230 : 0.01809713989496231
Loss at batch 240 : 0.011778488755226135
Loss at batch 250 : 0.010974124073982239
Loss at batch 260 : 0.011929435655474663
Loss at batch 270 : 0.016212057322263718
Loss at batch 280 : 0.014661219902336597
Loss at batch 290 : 0.007900272496044636
Loss at batch 300 : 0.018214959651231766
Loss at batch 310 : 0.017587125301361084
Loss at batch 320 : 0.008584822528064251
Loss at batch 330 : 0.012011951766908169
Loss at batch 340 : 0.014103857800364494
Loss at batch 350 : 0.009521503932774067
Loss at batch 360 : 0.014223605394363403
Loss at batch 370 : 0.015596702694892883
epoch27 finished!
Loss at batch 10 : 0.01959647610783577
Loss at batch 20 : 0.01774638146162033
Loss at batch 30 : 0.011370431631803513
Loss at batch 40 : 0.010947139002382755
Loss at batch 50 : 0.02006601355969906
Loss at batch 60 : 0.02769721858203411
Loss at batch 70 : 0.010728390887379646
Loss at batch 80 : 0.017131807282567024
Loss at batch 90 : 0.02072608657181263
Loss at batch 100 : 0.01682574488222599
Loss at batch 110 : 0.015628447756171227
Loss at batch 120 : 0.012182600796222687
Loss at batch 130 : 0.013464801013469696
Loss at batch 140 : 0.018172651529312134
Loss at batch 150 : 0.02538704313337803
Loss at batch 160 : 0.012806282378733158
Loss at batch 170 : 0.026960289105772972
Loss at batch 180 : 0.025776494294404984
Loss at batch 190 : 0.016093410551548004
Loss at batch 200 : 0.015586013905704021
Loss at batch 210 : 0.012214788235723972
Loss at batch 220 : 0.01723899506032467
Loss at batch 230 : 0.017431842163205147
Loss at batch 240 : 0.023695500567555428
Loss at batch 250 : 0.015681052580475807
Loss at batch 260 : 0.01415602583438158
Loss at batch 270 : 0.010241290554404259
Loss at batch 280 : 0.012126774527132511
Loss at batch 290 : 0.015325900167226791
Loss at batch 300 : 0.017004340887069702
Loss at batch 310 : 0.022481093183159828
Loss at batch 320 : 0.011610188521444798
Loss at batch 330 : 0.015941323712468147
Loss at batch 340 : 0.02284223958849907
Loss at batch 350 : 0.017316702753305435
Loss at batch 360 : 0.009911537170410156
Loss at batch 370 : 0.010582041926681995
epoch28 finished!
Loss at batch 10 : 0.015987729653716087
Loss at batch 20 : 0.017259931191802025
Loss at batch 30 : 0.015907805413007736
Loss at batch 40 : 0.011580771766602993
Loss at batch 50 : 0.017953764647245407
Loss at batch 60 : 0.012320420704782009
Loss at batch 70 : 0.02735826000571251
Loss at batch 80 : 0.010987133719027042
Loss at batch 90 : 0.018774088472127914
Loss at batch 100 : 0.010391861200332642
Loss at batch 110 : 0.01911705546081066
Loss at batch 120 : 0.019475316628813744
Loss at batch 130 : 0.007944848388433456
Loss at batch 140 : 0.019407059997320175
Loss at batch 150 : 0.01516185887157917
Loss at batch 160 : 0.03068237565457821
Loss at batch 170 : 0.022535517811775208
Loss at batch 180 : 0.013888727873563766
Loss at batch 190 : 0.015025479719042778
Loss at batch 200 : 0.017853420227766037
Loss at batch 210 : 0.010853435844182968
Loss at batch 220 : 0.01228397898375988
Loss at batch 230 : 0.013751312159001827
Loss at batch 240 : 0.014425545930862427
Loss at batch 250 : 0.015230763703584671
Loss at batch 260 : 0.011906005442142487
Loss at batch 270 : 0.011559725739061832
Loss at batch 280 : 0.017424190416932106
Loss at batch 290 : 0.011280367150902748
Loss at batch 300 : 0.013971896842122078
Loss at batch 310 : 0.010026650503277779
Loss at batch 320 : 0.007306966464966536
Loss at batch 330 : 0.016763580963015556
Loss at batch 340 : 0.012022203765809536
Loss at batch 350 : 0.022712593898177147
Loss at batch 360 : 0.013595867902040482
Loss at batch 370 : 0.014819910749793053
epoch29 finished!
Loss at batch 10 : 0.007328792475163937
Loss at batch 20 : 0.014551322907209396
Loss at batch 30 : 0.01791190356016159
Loss at batch 40 : 0.009674515575170517
Loss at batch 50 : 0.013693863525986671
Loss at batch 60 : 0.01165219210088253
Loss at batch 70 : 0.024100791662931442
Loss at batch 80 : 0.0176716111600399
Loss at batch 90 : 0.010244791395962238
Loss at batch 100 : 0.009941254742443562
Loss at batch 110 : 0.022015564143657684
Loss at batch 120 : 0.018593501299619675
Loss at batch 130 : 0.020054256543517113
Loss at batch 140 : 0.014589455910027027
Loss at batch 150 : 0.022567646577954292
Loss at batch 160 : 0.01616830751299858
Loss at batch 170 : 0.012082126922905445
Loss at batch 180 : 0.013681050390005112
Loss at batch 190 : 0.025120295584201813
Loss at batch 200 : 0.009837525896728039
Loss at batch 210 : 0.015429677441716194
Loss at batch 220 : 0.016070431098341942
Loss at batch 230 : 0.008938439190387726
Loss at batch 240 : 0.016037752851843834
Loss at batch 250 : 0.015106837265193462
Loss at batch 260 : 0.026719428598880768
Loss at batch 270 : 0.011550414375960827
Loss at batch 280 : 0.010628518648445606
Loss at batch 290 : 0.03545065224170685
Loss at batch 300 : 0.014747558161616325
Loss at batch 310 : 0.01628825254738331
Loss at batch 320 : 0.024641044437885284
Loss at batch 330 : 0.016598209738731384
Loss at batch 340 : 0.016348298639059067
Loss at batch 350 : 0.01564914360642433
Loss at batch 360 : 0.017319753766059875
Loss at batch 370 : 0.020647946745157242
epoch30 finished!
Loss at batch 10 : 0.015153834596276283
Loss at batch 20 : 0.025717472657561302
Loss at batch 30 : 0.015582822263240814
Loss at batch 40 : 0.010702839121222496
Loss at batch 50 : 0.026723196730017662
Loss at batch 60 : 0.010857919231057167
Loss at batch 70 : 0.011729064397513866
Loss at batch 80 : 0.008157996460795403
Loss at batch 90 : 0.009015265852212906
Loss at batch 100 : 0.010318961925804615
Loss at batch 110 : 0.013734725303947926
Loss at batch 120 : 0.010453174822032452
Loss at batch 130 : 0.009279390797019005
Loss at batch 140 : 0.018753068521618843
Loss at batch 150 : 0.013598988763988018
Loss at batch 160 : 0.012325514107942581
Loss at batch 170 : 0.016608787700533867
Loss at batch 180 : 0.009295928291976452
Loss at batch 190 : 0.014821109361946583
Loss at batch 200 : 0.014060023240745068
Loss at batch 210 : 0.01318000815808773
Loss at batch 220 : 0.013839934021234512
Loss at batch 230 : 0.008751971647143364
Loss at batch 240 : 0.015613723546266556
Loss at batch 250 : 0.018652470782399178
Loss at batch 260 : 0.01530174259096384
Loss at batch 270 : 0.020539185032248497
Loss at batch 280 : 0.02296527475118637
Loss at batch 290 : 0.02048584446310997
Loss at batch 300 : 0.01658901758491993
Loss at batch 310 : 0.015818679705262184
Loss at batch 320 : 0.012012681923806667
Loss at batch 330 : 0.013558962382376194
Loss at batch 340 : 0.01392617542296648
Loss at batch 350 : 0.016609951853752136
Loss at batch 360 : 0.007223400752991438
Loss at batch 370 : 0.028213758021593094
epoch31 finished!
Loss at batch 10 : 0.013754959218204021
Loss at batch 20 : 0.016103027388453484
Loss at batch 30 : 0.00874683540314436
Loss at batch 40 : 0.012458443641662598
Loss at batch 50 : 0.026020880788564682
Loss at batch 60 : 0.016378551721572876
Loss at batch 70 : 0.018480801954865456
Loss at batch 80 : 0.01232968084514141
Loss at batch 90 : 0.01370187383145094
Loss at batch 100 : 0.025185035541653633
Loss at batch 110 : 0.011007147841155529
Loss at batch 120 : 0.01128473412245512
Loss at batch 130 : 0.016458632424473763
Loss at batch 140 : 0.010263627395033836
Loss at batch 150 : 0.014560248702764511
Loss at batch 160 : 0.010724973864853382
Loss at batch 170 : 0.011925161816179752
Loss at batch 180 : 0.012132723815739155
Loss at batch 190 : 0.01076587475836277
Loss at batch 200 : 0.01590934954583645
Loss at batch 210 : 0.010111330077052116
Loss at batch 220 : 0.016117602586746216
Loss at batch 230 : 0.016976481303572655
Loss at batch 240 : 0.010574054904282093
Loss at batch 250 : 0.013402500189840794
Loss at batch 260 : 0.010626275092363358
Loss at batch 270 : 0.019260218366980553
Loss at batch 280 : 0.01111730094999075
Loss at batch 290 : 0.016831129789352417
Loss at batch 300 : 0.01537794154137373
Loss at batch 310 : 0.009860021062195301
Loss at batch 320 : 0.0230678990483284
Loss at batch 330 : 0.023844854906201363
Loss at batch 340 : 0.011468314565718174
Loss at batch 350 : 0.008732860907912254
Loss at batch 360 : 0.01920967362821102
Loss at batch 370 : 0.014487246051430702
epoch32 finished!
Loss at batch 10 : 0.0169764943420887
Loss at batch 20 : 0.019873488694429398
Loss at batch 30 : 0.013247800059616566
Loss at batch 40 : 0.011503486894071102
Loss at batch 50 : 0.01804046519100666
Loss at batch 60 : 0.008561205118894577
Loss at batch 70 : 0.011147558689117432
Loss at batch 80 : 0.016872016713023186
Loss at batch 90 : 0.013012473471462727
Loss at batch 100 : 0.016806302592158318
Loss at batch 110 : 0.01899544522166252
Loss at batch 120 : 0.022605901584029198
Loss at batch 130 : 0.020196732133626938
Loss at batch 140 : 0.02304997481405735
Loss at batch 150 : 0.010539932176470757
Loss at batch 160 : 0.024428781121969223
Loss at batch 170 : 0.02500109374523163
Loss at batch 180 : 0.016114549711346626
Loss at batch 190 : 0.012184149585664272
Loss at batch 200 : 0.01855369657278061
Loss at batch 210 : 0.016439415514469147
Loss at batch 220 : 0.011145604774355888
Loss at batch 230 : 0.015151656232774258
Loss at batch 240 : 0.013444176875054836
Loss at batch 250 : 0.036934640258550644
Loss at batch 260 : 0.013544658198952675
Loss at batch 270 : 0.017220228910446167
Loss at batch 280 : 0.016577476635575294
Loss at batch 290 : 0.021898621693253517
Loss at batch 300 : 0.010129157453775406
Loss at batch 310 : 0.029216740280389786
Loss at batch 320 : 0.011940007098019123
Loss at batch 330 : 0.011369384825229645
Loss at batch 340 : 0.016742322593927383
Loss at batch 350 : 0.014462113380432129
Loss at batch 360 : 0.009551702998578548
Loss at batch 370 : 0.015335122123360634
epoch33 finished!
Loss at batch 10 : 0.012215979397296906
Loss at batch 20 : 0.011353536508977413
Loss at batch 30 : 0.011820465326309204
Loss at batch 40 : 0.03154730424284935
Loss at batch 50 : 0.0161643885076046
Loss at batch 60 : 0.017309902235865593
Loss at batch 70 : 0.013054466806352139
Loss at batch 80 : 0.0173980463296175
Loss at batch 90 : 0.009247413836419582
Loss at batch 100 : 0.010563861578702927
Loss at batch 110 : 0.01894211955368519
Loss at batch 120 : 0.011688576079905033
Loss at batch 130 : 0.013864701613783836
Loss at batch 140 : 0.005643840413540602
Loss at batch 150 : 0.010673758573830128
Loss at batch 160 : 0.010404921136796474
Loss at batch 170 : 0.00945555791258812
Loss at batch 180 : 0.010381222702562809
Loss at batch 190 : 0.01580970361828804
Loss at batch 200 : 0.012738930061459541
Loss at batch 210 : 0.01580486260354519
Loss at batch 220 : 0.011548281647264957
Loss at batch 230 : 0.017412733286619186
Loss at batch 240 : 0.015817658975720406
Loss at batch 250 : 0.014257831498980522
Loss at batch 260 : 0.01837194338440895
Loss at batch 270 : 0.016498858109116554
Loss at batch 280 : 0.017876755446195602
Loss at batch 290 : 0.013632441870868206
Loss at batch 300 : 0.0102988937869668
Loss at batch 310 : 0.011678891256451607
Loss at batch 320 : 0.021441057324409485
Loss at batch 330 : 0.013433528132736683
Loss at batch 340 : 0.01572609134018421
Loss at batch 350 : 0.01052742451429367
Loss at batch 360 : 0.009758653119206429
Loss at batch 370 : 0.023074841126799583
epoch34 finished!
Loss at batch 10 : 0.01108465250581503
Loss at batch 20 : 0.0065551032312214375
Loss at batch 30 : 0.014974520541727543
Loss at batch 40 : 0.01588173396885395
Loss at batch 50 : 0.02250746265053749
Loss at batch 60 : 0.015295966528356075
Loss at batch 70 : 0.020220117643475533
Loss at batch 80 : 0.020375419408082962
Loss at batch 90 : 0.013816634193062782
Loss at batch 100 : 0.027968421578407288
Loss at batch 110 : 0.012712953612208366
Loss at batch 120 : 0.01904345490038395
Loss at batch 130 : 0.009785214439034462
Loss at batch 140 : 0.023467032238841057
Loss at batch 150 : 0.014676358550786972
Loss at batch 160 : 0.00774069270119071
Loss at batch 170 : 0.021652545779943466
Loss at batch 180 : 0.013429057784378529
Loss at batch 190 : 0.01356390118598938
Loss at batch 200 : 0.009148758836090565
Loss at batch 210 : 0.015530378557741642
Loss at batch 220 : 0.03881281986832619
Loss at batch 230 : 0.012056684121489525
Loss at batch 240 : 0.012405484914779663
Loss at batch 250 : 0.014200914651155472
Loss at batch 260 : 0.018848296254873276
Loss at batch 270 : 0.010325404815375805
Loss at batch 280 : 0.017905930057168007
Loss at batch 290 : 0.014317300170660019
Loss at batch 300 : 0.017255790531635284
Loss at batch 310 : 0.010180837474763393
Loss at batch 320 : 0.013687720522284508
Loss at batch 330 : 0.01684114709496498
Loss at batch 340 : 0.014009639620780945
Loss at batch 350 : 0.019319843500852585
Loss at batch 360 : 0.009925532154738903
Loss at batch 370 : 0.01757398061454296
epoch35 finished!
Loss at batch 10 : 0.007212553173303604
Loss at batch 20 : 0.018069805577397346
Loss at batch 30 : 0.018953775987029076
Loss at batch 40 : 0.015090172179043293
Loss at batch 50 : 0.013544904999434948
Loss at batch 60 : 0.016769500449299812
Loss at batch 70 : 0.018784411251544952
Loss at batch 80 : 0.015895647928118706
Loss at batch 90 : 0.008948298171162605
Loss at batch 100 : 0.013359184376895428
Loss at batch 110 : 0.01575155183672905
Loss at batch 120 : 0.013732530176639557
Loss at batch 130 : 0.013104157522320747
Loss at batch 140 : 0.01885736733675003
Loss at batch 150 : 0.014486968517303467
Loss at batch 160 : 0.011292899027466774
Loss at batch 170 : 0.02488667517900467
Loss at batch 180 : 0.007823305204510689
Loss at batch 190 : 0.01310662366449833
Loss at batch 200 : 0.018635012209415436
Loss at batch 210 : 0.018806802108883858
Loss at batch 220 : 0.012793856672942638
Loss at batch 230 : 0.008532509207725525
Loss at batch 240 : 0.009577336721122265
Loss at batch 250 : 0.01051252894103527
Loss at batch 260 : 0.01117764227092266
Loss at batch 270 : 0.010478148236870766
Loss at batch 280 : 0.0222695954144001
Loss at batch 290 : 0.020833294838666916
Loss at batch 300 : 0.009375042282044888
Loss at batch 310 : 0.014999671839177608
Loss at batch 320 : 0.020757650956511497
Loss at batch 330 : 0.017938490957021713
Loss at batch 340 : 0.011433690786361694
Loss at batch 350 : 0.011377904564142227
Loss at batch 360 : 0.01731734909117222
Loss at batch 370 : 0.012870239093899727
epoch36 finished!
Loss at batch 10 : 0.010163148865103722
Loss at batch 20 : 0.015558233484625816
Loss at batch 30 : 0.014564142562448978
Loss at batch 40 : 0.009917503222823143
Loss at batch 50 : 0.016487158834934235
Loss at batch 60 : 0.00804578885436058
Loss at batch 70 : 0.01925070211291313
Loss at batch 80 : 0.011579996906220913
Loss at batch 90 : 0.011973093263804913
Loss at batch 100 : 0.00797017477452755
Loss at batch 110 : 0.014884521253407001
Loss at batch 120 : 0.010036956518888474
Loss at batch 130 : 0.020478351041674614
Loss at batch 140 : 0.014798491261899471
Loss at batch 150 : 0.010852457024157047
Loss at batch 160 : 0.009739136323332787
Loss at batch 170 : 0.027697579935193062
Loss at batch 180 : 0.011795997619628906
Loss at batch 190 : 0.025628408417105675
Loss at batch 200 : 0.015696287155151367
Loss at batch 210 : 0.012193522416055202
Loss at batch 220 : 0.022678958252072334
Loss at batch 230 : 0.015027622692286968
Loss at batch 240 : 0.012474926188588142
Loss at batch 250 : 0.011899808421730995
Loss at batch 260 : 0.020232031121850014
Loss at batch 270 : 0.014126175083220005
Loss at batch 280 : 0.013969595544040203
Loss at batch 290 : 0.012880800291895866
Loss at batch 300 : 0.011995714157819748
Loss at batch 310 : 0.012350523844361305
Loss at batch 320 : 0.009456734172999859
Loss at batch 330 : 0.011746642179787159
Loss at batch 340 : 0.031492799520492554
Loss at batch 350 : 0.011723016388714314
Loss at batch 360 : 0.015157041139900684
Loss at batch 370 : 0.018587803468108177
epoch37 finished!
Loss at batch 10 : 0.010304128751158714
Loss at batch 20 : 0.012161831371486187
Loss at batch 30 : 0.01264889631420374
Loss at batch 40 : 0.011644221842288971
Loss at batch 50 : 0.010758649557828903
Loss at batch 60 : 0.011009197682142258
Loss at batch 70 : 0.028164690360426903
Loss at batch 80 : 0.01374528743326664
Loss at batch 90 : 0.01714952662587166
Loss at batch 100 : 0.0182122141122818
Loss at batch 110 : 0.01144652534276247
Loss at batch 120 : 0.016581065952777863
Loss at batch 130 : 0.010902474634349346
Loss at batch 140 : 0.018294649198651314
Loss at batch 150 : 0.012735552154481411
Loss at batch 160 : 0.015961648896336555
Loss at batch 170 : 0.01016892772167921
Loss at batch 180 : 0.014057265594601631
Loss at batch 190 : 0.013464463874697685
Loss at batch 200 : 0.014777730219066143
Loss at batch 210 : 0.016015348955988884
Loss at batch 220 : 0.012888561002910137
Loss at batch 230 : 0.01212942972779274
Loss at batch 240 : 0.013712252490222454
Loss at batch 250 : 0.019245296716690063
Loss at batch 260 : 0.012294276617467403
Loss at batch 270 : 0.01133748795837164
Loss at batch 280 : 0.020364774391055107
Loss at batch 290 : 0.014860736206173897
Loss at batch 300 : 0.021401461213827133
Loss at batch 310 : 0.010593030601739883
Loss at batch 320 : 0.01057305559515953
Loss at batch 330 : 0.02266261726617813
Loss at batch 340 : 0.009262452833354473
Loss at batch 350 : 0.017982881516218185
Loss at batch 360 : 0.01606573536992073
Loss at batch 370 : 0.013510534539818764
epoch38 finished!
Loss at batch 10 : 0.007836177945137024
Loss at batch 20 : 0.011929410509765148
Loss at batch 30 : 0.02269994094967842
Loss at batch 40 : 0.01569066010415554
Loss at batch 50 : 0.01204810943454504
Loss at batch 60 : 0.029478365555405617
Loss at batch 70 : 0.02314929850399494
Loss at batch 80 : 0.013906612992286682
Loss at batch 90 : 0.02478771097958088
Loss at batch 100 : 0.01849082112312317
Loss at batch 110 : 0.013716978952288628
Loss at batch 120 : 0.008656748570501804
Loss at batch 130 : 0.010915177874267101
Loss at batch 140 : 0.020549114793539047
Loss at batch 150 : 0.009091012179851532
Loss at batch 160 : 0.014498645439743996
Loss at batch 170 : 0.014368182979524136
Loss at batch 180 : 0.011180232279002666
Loss at batch 190 : 0.005551700945943594
Loss at batch 200 : 0.01741606369614601
Loss at batch 210 : 0.009486135095357895
Loss at batch 220 : 0.015593389049172401
Loss at batch 230 : 0.019064011052250862
Loss at batch 240 : 0.02438867837190628
Loss at batch 250 : 0.014217151328921318
Loss at batch 260 : 0.012908993288874626
Loss at batch 270 : 0.022804738953709602
Loss at batch 280 : 0.014718732796609402
Loss at batch 290 : 0.01964891515672207
Loss at batch 300 : 0.016164513304829597
Loss at batch 310 : 0.01233635377138853
Loss at batch 320 : 0.011312861926853657
Loss at batch 330 : 0.014079886488616467
Loss at batch 340 : 0.0211442019790411
Loss at batch 350 : 0.018610069528222084
Loss at batch 360 : 0.013239553198218346
Loss at batch 370 : 0.012171181850135326
epoch39 finished!
Loss at batch 10 : 0.01916506513953209
Loss at batch 20 : 0.013396558351814747
Loss at batch 30 : 0.018277090042829514
Loss at batch 40 : 0.02988596260547638
Loss at batch 50 : 0.019311513751745224
Loss at batch 60 : 0.014269551262259483
Loss at batch 70 : 0.013827722519636154
Loss at batch 80 : 0.02230008691549301
Loss at batch 90 : 0.01226470060646534
Loss at batch 100 : 0.010321236215531826
Loss at batch 110 : 0.011899677105247974
Loss at batch 120 : 0.014327253215014935
Loss at batch 130 : 0.010341557674109936
Loss at batch 140 : 0.02039203979074955
Loss at batch 150 : 0.01177588477730751
Loss at batch 160 : 0.016779929399490356
Loss at batch 170 : 0.01198928989470005
Loss at batch 180 : 0.015154167078435421
Loss at batch 190 : 0.01412523165345192
Loss at batch 200 : 0.013477448374032974
Loss at batch 210 : 0.018297305330634117
Loss at batch 220 : 0.016269821673631668
Loss at batch 230 : 0.008452345617115498
Loss at batch 240 : 0.012143989093601704
Loss at batch 250 : 0.008194934576749802
Loss at batch 260 : 0.013738391920924187
Loss at batch 270 : 0.01733466610312462
Loss at batch 280 : 0.013019189238548279
Loss at batch 290 : 0.016609318554401398
Loss at batch 300 : 0.013382414355874062
Loss at batch 310 : 0.015025035478174686
Loss at batch 320 : 0.009653269313275814
Loss at batch 330 : 0.039885975420475006
Loss at batch 340 : 0.02290380746126175
Loss at batch 350 : 0.016972770914435387
Loss at batch 360 : 0.005169631447643042
Loss at batch 370 : 0.022484328597784042
epoch40 finished!
Loss at batch 10 : 0.011952453292906284
Loss at batch 20 : 0.009060130454599857
Loss at batch 30 : 0.01834593154489994
Loss at batch 40 : 0.019543597474694252
Loss at batch 50 : 0.0157795250415802
Loss at batch 60 : 0.00814761407673359
Loss at batch 70 : 0.01627672091126442
Loss at batch 80 : 0.009896178729832172
Loss at batch 90 : 0.010273599997162819
Loss at batch 100 : 0.009826391004025936
Loss at batch 110 : 0.016273576766252518
Loss at batch 120 : 0.02327442727982998
Loss at batch 130 : 0.008758917450904846
Loss at batch 140 : 0.027995267882943153
Loss at batch 150 : 0.015584313310682774
Loss at batch 160 : 0.012874599546194077
Loss at batch 170 : 0.013329904526472092
Loss at batch 180 : 0.010555905289947987
Loss at batch 190 : 0.00912247970700264
Loss at batch 200 : 0.017407534644007683
Loss at batch 210 : 0.0070823743008077145
Loss at batch 220 : 0.008835631422698498
Loss at batch 230 : 0.02715563029050827
Loss at batch 240 : 0.015709785744547844
Loss at batch 250 : 0.01136345136910677
Loss at batch 260 : 0.02074114978313446
Loss at batch 270 : 0.0214310884475708
Loss at batch 280 : 0.009872405789792538
Loss at batch 290 : 0.007573819253593683
Loss at batch 300 : 0.025307444855570793
Loss at batch 310 : 0.010157366283237934
Loss at batch 320 : 0.020553499460220337
Loss at batch 330 : 0.008455620147287846
Loss at batch 340 : 0.010901243425905704
Loss at batch 350 : 0.01413183007389307
Loss at batch 360 : 0.01305882353335619
Loss at batch 370 : 0.013632399961352348
epoch41 finished!
Loss at batch 10 : 0.019784480333328247
Loss at batch 20 : 0.010583327151834965
Loss at batch 30 : 0.01139388233423233
Loss at batch 40 : 0.010409855283796787
Loss at batch 50 : 0.009690731763839722
Loss at batch 60 : 0.013403980061411858
Loss at batch 70 : 0.011905163526535034
Loss at batch 80 : 0.016018645837903023
Loss at batch 90 : 0.014397469349205494
Loss at batch 100 : 0.015816988423466682
Loss at batch 110 : 0.014167283661663532
Loss at batch 120 : 0.01428393367677927
Loss at batch 130 : 0.008196381852030754
Loss at batch 140 : 0.01580350659787655
Loss at batch 150 : 0.01796310395002365
Loss at batch 160 : 0.014818044379353523
Loss at batch 170 : 0.02285194955766201
Loss at batch 180 : 0.011171601712703705
Loss at batch 190 : 0.012779881246387959
Loss at batch 200 : 0.00666645634919405
Loss at batch 210 : 0.012213313020765781
Loss at batch 220 : 0.012863939628005028
Loss at batch 230 : 0.012309723533689976
Loss at batch 240 : 0.019395582377910614
Loss at batch 250 : 0.022778287529945374
Loss at batch 260 : 0.009733275510370731
Loss at batch 270 : 0.016644353047013283
Loss at batch 280 : 0.009937035851180553
Loss at batch 290 : 0.00965670682489872
Loss at batch 300 : 0.018216129392385483
Loss at batch 310 : 0.011247503571212292
Loss at batch 320 : 0.020476536825299263
Loss at batch 330 : 0.013589984737336636
Loss at batch 340 : 0.012637212872505188
Loss at batch 350 : 0.015113542787730694
Loss at batch 360 : 0.02098839357495308
Loss at batch 370 : 0.00909984391182661
epoch42 finished!
Loss at batch 10 : 0.008904860354959965
Loss at batch 20 : 0.01334073394536972
Loss at batch 30 : 0.01795831136405468
Loss at batch 40 : 0.014954574406147003
Loss at batch 50 : 0.017916565760970116
Loss at batch 60 : 0.010397281497716904
Loss at batch 70 : 0.011705949902534485
Loss at batch 80 : 0.01573791168630123
Loss at batch 90 : 0.010568453930318356
Loss at batch 100 : 0.02167677693068981
Loss at batch 110 : 0.0120450584217906
Loss at batch 120 : 0.018219294026494026
Loss at batch 130 : 0.017926665022969246
Loss at batch 140 : 0.017962532117962837
Loss at batch 150 : 0.02481887862086296
Loss at batch 160 : 0.011408713646233082
Loss at batch 170 : 0.013994600623846054
Loss at batch 180 : 0.02572016231715679
Loss at batch 190 : 0.014217288233339787
Loss at batch 200 : 0.014536342583596706
Loss at batch 210 : 0.019398804754018784
Loss at batch 220 : 0.017189789563417435
Loss at batch 230 : 0.009281030856072903
Loss at batch 240 : 0.014589040540158749
Loss at batch 250 : 0.009959270246326923
Loss at batch 260 : 0.008152047172188759
Loss at batch 270 : 0.00785459578037262
Loss at batch 280 : 0.014789115637540817
Loss at batch 290 : 0.013764134608209133
Loss at batch 300 : 0.014193283393979073
Loss at batch 310 : 0.008294793777167797
Loss at batch 320 : 0.015724750235676765
Loss at batch 330 : 0.01972193457186222
Loss at batch 340 : 0.014927561394870281
Loss at batch 350 : 0.011931086890399456
Loss at batch 360 : 0.019526343792676926
Loss at batch 370 : 0.012385625392198563
epoch43 finished!
Loss at batch 10 : 0.01478868443518877
Loss at batch 20 : 0.01809396781027317
Loss at batch 30 : 0.01279840525239706
Loss at batch 40 : 0.021494060754776
Loss at batch 50 : 0.011954180896282196
Loss at batch 60 : 0.012196183204650879
Loss at batch 70 : 0.00801989808678627
Loss at batch 80 : 0.014155944809317589
Loss at batch 90 : 0.009458376094698906
Loss at batch 100 : 0.007991759106516838
Loss at batch 110 : 0.02317999303340912
Loss at batch 120 : 0.01025649718940258
Loss at batch 130 : 0.016937686130404472
Loss at batch 140 : 0.0174391008913517
Loss at batch 150 : 0.014839011244475842
Loss at batch 160 : 0.020102977752685547
Loss at batch 170 : 0.01080712117254734
Loss at batch 180 : 0.012954559177160263
Loss at batch 190 : 0.014949606731534004
Loss at batch 200 : 0.018871409818530083
Loss at batch 210 : 0.011407019570469856
Loss at batch 220 : 0.011359344236552715
Loss at batch 230 : 0.015920011326670647
Loss at batch 240 : 0.017042582854628563
Loss at batch 250 : 0.008785583078861237
Loss at batch 260 : 0.022461531683802605
Loss at batch 270 : 0.02119356207549572
Loss at batch 280 : 0.023994777351617813
Loss at batch 290 : 0.015262698754668236
Loss at batch 300 : 0.018860839307308197
Loss at batch 310 : 0.011187631636857986
Loss at batch 320 : 0.01736692525446415
Loss at batch 330 : 0.014989293180406094
Loss at batch 340 : 0.014067304320633411
Loss at batch 350 : 0.008065979927778244
Loss at batch 360 : 0.009617896750569344
Loss at batch 370 : 0.01464571338146925
epoch44 finished!
Loss at batch 10 : 0.007905582897365093
Loss at batch 20 : 0.014352142810821533
Loss at batch 30 : 0.015729602426290512
Loss at batch 40 : 0.015226660296320915
Loss at batch 50 : 0.015689188614487648
Loss at batch 60 : 0.010136187076568604
Loss at batch 70 : 0.010037860833108425
Loss at batch 80 : 0.019852682948112488
Loss at batch 90 : 0.01548593770712614
Loss at batch 100 : 0.016752753406763077
Loss at batch 110 : 0.011274759657680988
Loss at batch 120 : 0.02167273685336113
Loss at batch 130 : 0.010505352169275284
Loss at batch 140 : 0.011265586130321026
Loss at batch 150 : 0.01611240766942501
Loss at batch 160 : 0.015964457765221596
Loss at batch 170 : 0.021993331611156464
Loss at batch 180 : 0.010269327089190483
Loss at batch 190 : 0.011894503608345985
Loss at batch 200 : 0.016004011034965515
Loss at batch 210 : 0.009213000535964966
Loss at batch 220 : 0.015186102129518986
Loss at batch 230 : 0.016511594876646996
Loss at batch 240 : 0.015228763222694397
Loss at batch 250 : 0.010927127674221992
Loss at batch 260 : 0.014109383337199688
Loss at batch 270 : 0.008551463484764099
Loss at batch 280 : 0.009140467271208763
Loss at batch 290 : 0.02209874987602234
Loss at batch 300 : 0.021677112206816673
Loss at batch 310 : 0.019169095903635025
Loss at batch 320 : 0.006794008892029524
Loss at batch 330 : 0.01191598642617464
Loss at batch 340 : 0.02237115614116192
Loss at batch 350 : 0.008130843751132488
Loss at batch 360 : 0.018070325255393982
Loss at batch 370 : 0.015479871071875095
epoch45 finished!
Loss at batch 10 : 0.010169376619160175
Loss at batch 20 : 0.01714213751256466
Loss at batch 30 : 0.011830328032374382
Loss at batch 40 : 0.025639789178967476
Loss at batch 50 : 0.017888570204377174
Loss at batch 60 : 0.010730436071753502
Loss at batch 70 : 0.015603105537593365
Loss at batch 80 : 0.013166256248950958
Loss at batch 90 : 0.028615033254027367
Loss at batch 100 : 0.014461630024015903
Loss at batch 110 : 0.018974412232637405
Loss at batch 120 : 0.007287139538675547
Loss at batch 130 : 0.013855239376425743
Loss at batch 140 : 0.007871564477682114
Loss at batch 150 : 0.01864076964557171
Loss at batch 160 : 0.013288972899317741
Loss at batch 170 : 0.02072126604616642
Loss at batch 180 : 0.013726498931646347
Loss at batch 190 : 0.012040161527693272
Loss at batch 200 : 0.010257657617330551
Loss at batch 210 : 0.012347852811217308
Loss at batch 220 : 0.015799041837453842
Loss at batch 230 : 0.021449020132422447
Loss at batch 240 : 0.013733748346567154
Loss at batch 250 : 0.024611512199044228
Loss at batch 260 : 0.01830284111201763
Loss at batch 270 : 0.006087821442633867
Loss at batch 280 : 0.014787577092647552
Loss at batch 290 : 0.022760633379220963
Loss at batch 300 : 0.008803382515907288
Loss at batch 310 : 0.01725461706519127
Loss at batch 320 : 0.018179981037974358
Loss at batch 330 : 0.01231016218662262
Loss at batch 340 : 0.01079320814460516
Loss at batch 350 : 0.012033267877995968
Loss at batch 360 : 0.019845958799123764
Loss at batch 370 : 0.012807304039597511
epoch46 finished!
Loss at batch 10 : 0.018547995015978813
Loss at batch 20 : 0.011891724541783333
Loss at batch 30 : 0.010618043132126331
Loss at batch 40 : 0.015228920616209507
Loss at batch 50 : 0.008019814267754555
Loss at batch 60 : 0.016311895102262497
Loss at batch 70 : 0.007768771145492792
Loss at batch 80 : 0.00927046500146389
Loss at batch 90 : 0.0125448452308774
Loss at batch 100 : 0.01921434886753559
Loss at batch 110 : 0.01464852038770914
Loss at batch 120 : 0.023426564410328865
Loss at batch 130 : 0.01165097113698721
Loss at batch 140 : 0.018690958619117737
Loss at batch 150 : 0.014137511141598225
Loss at batch 160 : 0.015656735748052597
Loss at batch 170 : 0.021270785480737686
Loss at batch 180 : 0.01287128496915102
Loss at batch 190 : 0.014501579105854034
Loss at batch 200 : 0.01182960532605648
Loss at batch 210 : 0.008646284230053425
Loss at batch 220 : 0.016694461926817894
Loss at batch 230 : 0.02250891551375389
Loss at batch 240 : 0.012935291044414043
Loss at batch 250 : 0.01938668265938759
Loss at batch 260 : 0.011104396544396877
Loss at batch 270 : 0.01124885119497776
Loss at batch 280 : 0.014014600776135921
Loss at batch 290 : 0.007794064469635487
Loss at batch 300 : 0.013109887950122356
Loss at batch 310 : 0.01825564354658127
Loss at batch 320 : 0.009101364761590958
Loss at batch 330 : 0.014731512404978275
Loss at batch 340 : 0.021479276940226555
Loss at batch 350 : 0.02023877389729023
Loss at batch 360 : 0.01926831156015396
Loss at batch 370 : 0.015104319900274277
epoch47 finished!
Loss at batch 10 : 0.016286514699459076
Loss at batch 20 : 0.019657596945762634
Loss at batch 30 : 0.012392371892929077
Loss at batch 40 : 0.009396929293870926
Loss at batch 50 : 0.013689052313566208
Loss at batch 60 : 0.016690021380782127
Loss at batch 70 : 0.011968831531703472
Loss at batch 80 : 0.02039061114192009
Loss at batch 90 : 0.019392400979995728
Loss at batch 100 : 0.043117523193359375
Loss at batch 110 : 0.014369186013936996
Loss at batch 120 : 0.021041376516222954
Loss at batch 130 : 0.014850162900984287
Loss at batch 140 : 0.012194878421723843
Loss at batch 150 : 0.016147678717970848
Loss at batch 160 : 0.014731936156749725
Loss at batch 170 : 0.010462075471878052
Loss at batch 180 : 0.01750262640416622
Loss at batch 190 : 0.013605908490717411
Loss at batch 200 : 0.010784503072500229
Loss at batch 210 : 0.01474739145487547
Loss at batch 220 : 0.011667603626847267
Loss at batch 230 : 0.009472155943512917
Loss at batch 240 : 0.013303359039127827
Loss at batch 250 : 0.013478347100317478
Loss at batch 260 : 0.019294559955596924
Loss at batch 270 : 0.014091338030993938
Loss at batch 280 : 0.00992039404809475
Loss at batch 290 : 0.009243234060704708
Loss at batch 300 : 0.016031775623559952
Loss at batch 310 : 0.015649251639842987
Loss at batch 320 : 0.013055939227342606
Loss at batch 330 : 0.012774917297065258
Loss at batch 340 : 0.014507190324366093
Loss at batch 350 : 0.014810136519372463
Loss at batch 360 : 0.01313940528780222
Loss at batch 370 : 0.012399026192724705
epoch48 finished!
Loss at batch 10 : 0.01089784037321806
Loss at batch 20 : 0.014124035835266113
Loss at batch 30 : 0.012442328035831451
Loss at batch 40 : 0.008346004411578178
Loss at batch 50 : 0.015042348764836788
Loss at batch 60 : 0.02163591794669628
Loss at batch 70 : 0.033908020704984665
Loss at batch 80 : 0.017709946259856224
Loss at batch 90 : 0.015455680899322033
Loss at batch 100 : 0.012440049089491367
Loss at batch 110 : 0.0166540015488863
Loss at batch 120 : 0.014263525605201721
Loss at batch 130 : 0.018063733354210854
Loss at batch 140 : 0.019768787547945976
Loss at batch 150 : 0.00799772422760725
Loss at batch 160 : 0.014739513397216797
Loss at batch 170 : 0.011848392896354198
Loss at batch 180 : 0.01663128100335598
Loss at batch 190 : 0.015466139651834965
Loss at batch 200 : 0.01796911470592022
Loss at batch 210 : 0.016174787655472755
Loss at batch 220 : 0.018853366374969482
Loss at batch 230 : 0.015139305032789707
Loss at batch 240 : 0.014603625982999802
Loss at batch 250 : 0.01479516364634037
Loss at batch 260 : 0.014300068840384483
Loss at batch 270 : 0.007683622185140848
Loss at batch 280 : 0.006126476917415857
Loss at batch 290 : 0.012187030166387558
Loss at batch 300 : 0.015508840791881084
Loss at batch 310 : 0.008573263883590698
Loss at batch 320 : 0.011936672963202
Loss at batch 330 : 0.013102627359330654
Loss at batch 340 : 0.009735288098454475
Loss at batch 350 : 0.010229373350739479
Loss at batch 360 : 0.013141653500497341
Loss at batch 370 : 0.024441109970211983
epoch49 finished!
Loss at batch 10 : 0.014861086383461952
Loss at batch 20 : 0.016752609983086586
Loss at batch 30 : 0.01156378909945488
Loss at batch 40 : 0.007866354659199715
Loss at batch 50 : 0.01426590234041214
Loss at batch 60 : 0.019076235592365265
Loss at batch 70 : 0.00979843270033598
Loss at batch 80 : 0.030933650210499763
Loss at batch 90 : 0.012007281184196472
Loss at batch 100 : 0.011742285452783108
Loss at batch 110 : 0.010616056621074677
Loss at batch 120 : 0.012519726529717445
Loss at batch 130 : 0.010486659593880177
Loss at batch 140 : 0.014370311051607132
Loss at batch 150 : 0.013967490755021572
Loss at batch 160 : 0.01584831438958645
Loss at batch 170 : 0.013118409551680088
Loss at batch 180 : 0.014300073496997356
Loss at batch 190 : 0.010771640576422215
Loss at batch 200 : 0.01661532372236252
Loss at batch 210 : 0.0161173976957798
Loss at batch 220 : 0.011644291691482067
Loss at batch 230 : 0.02048446238040924
Loss at batch 240 : 0.01718200370669365
Loss at batch 250 : 0.008163482882082462
Loss at batch 260 : 0.015549331903457642
Loss at batch 270 : 0.01539322268217802
Loss at batch 280 : 0.017020946368575096
Loss at batch 290 : 0.008497299626469612
Loss at batch 300 : 0.006595729384571314
Loss at batch 310 : 0.02279990166425705
Loss at batch 320 : 0.009258310310542583
Loss at batch 330 : 0.012067890726029873
Loss at batch 340 : 0.01724260114133358
Loss at batch 350 : 0.013397342525422573
Loss at batch 360 : 0.02281714789569378
Loss at batch 370 : 0.019191861152648926
epoch50 finished!
Loss at batch 10 : 0.022964324802160263
Loss at batch 20 : 0.015248890034854412
Loss at batch 30 : 0.011201594024896622
Loss at batch 40 : 0.013884642161428928
Loss at batch 50 : 0.014054778963327408
Loss at batch 60 : 0.012502935715019703
Loss at batch 70 : 0.021578524261713028
Loss at batch 80 : 0.019584963098168373
Loss at batch 90 : 0.027550257742404938
Loss at batch 100 : 0.017531242221593857
Loss at batch 110 : 0.021319927647709846
Loss at batch 120 : 0.008642216213047504
Loss at batch 130 : 0.015054143033921719
Loss at batch 140 : 0.017603689804673195
Loss at batch 150 : 0.014718200080096722
Loss at batch 160 : 0.011467959731817245
Loss at batch 170 : 0.012697270140051842
Loss at batch 180 : 0.012380754575133324
Loss at batch 190 : 0.007428179029375315
Loss at batch 200 : 0.008655324578285217
Loss at batch 210 : 0.016306545585393906
Loss at batch 220 : 0.01586020551621914
Loss at batch 230 : 0.01254676841199398
Loss at batch 240 : 0.007945073768496513
Loss at batch 250 : 0.013068953529000282
Loss at batch 260 : 0.009597789496183395
Loss at batch 270 : 0.01886618323624134
Loss at batch 280 : 0.012775816023349762
Loss at batch 290 : 0.013841385953128338
Loss at batch 300 : 0.018946388736367226
Loss at batch 310 : 0.011735138483345509
Loss at batch 320 : 0.015249156393110752
Loss at batch 330 : 0.01690056174993515
Loss at batch 340 : 0.009009291417896748
Loss at batch 350 : 0.011568295769393444
Loss at batch 360 : 0.018701205030083656
Loss at batch 370 : 0.012365375645458698
epoch51 finished!
Loss at batch 10 : 0.014123661443591118
Loss at batch 20 : 0.011054129339754581
Loss at batch 30 : 0.018657201901078224
Loss at batch 40 : 0.017148474231362343
Loss at batch 50 : 0.009707541204988956
Loss at batch 60 : 0.013198968954384327
Loss at batch 70 : 0.013580679893493652
Loss at batch 80 : 0.013402896001935005
Loss at batch 90 : 0.017697500064969063
Loss at batch 100 : 0.01343635842204094
Loss at batch 110 : 0.016053037717938423
Loss at batch 120 : 0.010739617981016636
Loss at batch 130 : 0.013909390196204185
Loss at batch 140 : 0.02127542905509472
Loss at batch 150 : 0.01614915393292904
Loss at batch 160 : 0.014202861115336418
Loss at batch 170 : 0.014107556082308292
Loss at batch 180 : 0.011270010843873024
Loss at batch 190 : 0.017529312521219254
Loss at batch 200 : 0.017033390700817108
Loss at batch 210 : 0.012703976593911648
Loss at batch 220 : 0.011895895935595036
Loss at batch 230 : 0.012245249934494495
Loss at batch 240 : 0.012361209839582443
Loss at batch 250 : 0.013661501929163933
Loss at batch 260 : 0.008945932611823082
Loss at batch 270 : 0.016461413353681564
Loss at batch 280 : 0.01738099381327629
Loss at batch 290 : 0.012463082559406757
Loss at batch 300 : 0.008859561756253242
Loss at batch 310 : 0.008943376131355762
Loss at batch 320 : 0.014562219381332397
Loss at batch 330 : 0.015265926718711853
Loss at batch 340 : 0.015415591187775135
Loss at batch 350 : 0.02218843810260296
Loss at batch 360 : 0.01180853508412838
Loss at batch 370 : 0.014921884052455425
epoch52 finished!
Loss at batch 10 : 0.023949746042490005
Loss at batch 20 : 0.011090733110904694
Loss at batch 30 : 0.007040450815111399
Loss at batch 40 : 0.013338510878384113
Loss at batch 50 : 0.020828526467084885
Loss at batch 60 : 0.0080541567876935
Loss at batch 70 : 0.009131211787462234
Loss at batch 80 : 0.00811382383108139
Loss at batch 90 : 0.02182151935994625
Loss at batch 100 : 0.009642301127314568
Loss at batch 110 : 0.011664673686027527
Loss at batch 120 : 0.011613910086452961
Loss at batch 130 : 0.013608531095087528
Loss at batch 140 : 0.010761386714875698
Loss at batch 150 : 0.018346335738897324
Loss at batch 160 : 0.008090673945844173
Loss at batch 170 : 0.01305314525961876
Loss at batch 180 : 0.010416013188660145
Loss at batch 190 : 0.01323541160672903
Loss at batch 200 : 0.010052102617919445
Loss at batch 210 : 0.010867519304156303
Loss at batch 220 : 0.013653301633894444
Loss at batch 230 : 0.016213085502386093
Loss at batch 240 : 0.013108002953231335
Loss at batch 250 : 0.020130759105086327
Loss at batch 260 : 0.019095031544566154
Loss at batch 270 : 0.012773926369845867
Loss at batch 280 : 0.011967754922807217
Loss at batch 290 : 0.014695888385176659
Loss at batch 300 : 0.008702794089913368
Loss at batch 310 : 0.013881081715226173
Loss at batch 320 : 0.020052582025527954
Loss at batch 330 : 0.019159240648150444
Loss at batch 340 : 0.01367400772869587
Loss at batch 350 : 0.012970390729606152
Loss at batch 360 : 0.016813963651657104
Loss at batch 370 : 0.011829844675958157
epoch53 finished!
Loss at batch 10 : 0.012149280868470669
Loss at batch 20 : 0.018356529995799065
Loss at batch 30 : 0.012813788838684559
Loss at batch 40 : 0.01673884317278862
Loss at batch 50 : 0.01343236118555069
Loss at batch 60 : 0.01701411046087742
Loss at batch 70 : 0.021092424169182777
Loss at batch 80 : 0.008278832770884037
Loss at batch 90 : 0.010617485269904137
Loss at batch 100 : 0.01087663508951664
Loss at batch 110 : 0.011114070191979408
Loss at batch 120 : 0.021232690662145615
Loss at batch 130 : 0.02215455286204815
Loss at batch 140 : 0.012051485478878021
Loss at batch 150 : 0.011696502566337585
Loss at batch 160 : 0.017253510653972626
Loss at batch 170 : 0.018402613699436188
Loss at batch 180 : 0.012499147094786167
Loss at batch 190 : 0.018547702580690384
Loss at batch 200 : 0.015672430396080017
Loss at batch 210 : 0.010457322932779789
Loss at batch 220 : 0.014028851874172688
Loss at batch 230 : 0.016571160405874252
Loss at batch 240 : 0.008939902298152447
Loss at batch 250 : 0.014405399560928345
Loss at batch 260 : 0.01582806184887886
Loss at batch 270 : 0.014943758025765419
Loss at batch 280 : 0.013463827781379223
Loss at batch 290 : 0.014399904757738113
Loss at batch 300 : 0.016389941796660423
Loss at batch 310 : 0.013333598151803017
Loss at batch 320 : 0.017469830811023712
Loss at batch 330 : 0.02327720820903778
Loss at batch 340 : 0.01519857905805111
Loss at batch 350 : 0.011722507886588573
Loss at batch 360 : 0.01253153383731842
Loss at batch 370 : 0.01852269470691681
epoch54 finished!
Loss at batch 10 : 0.012108057737350464
Loss at batch 20 : 0.009720880538225174
Loss at batch 30 : 0.013573801144957542
Loss at batch 40 : 0.02068113535642624
Loss at batch 50 : 0.027257218956947327
Loss at batch 60 : 0.015300787054002285
Loss at batch 70 : 0.010323775000870228
Loss at batch 80 : 0.010886697098612785
Loss at batch 90 : 0.015061084181070328
Loss at batch 100 : 0.008494359441101551
Loss at batch 110 : 0.01763814501464367
Loss at batch 120 : 0.01672985777258873
Loss at batch 130 : 0.021362757310271263
Loss at batch 140 : 0.011668228544294834
Loss at batch 150 : 0.01513436995446682
Loss at batch 160 : 0.010916859842836857
Loss at batch 170 : 0.016046226024627686
Loss at batch 180 : 0.012921372428536415
Loss at batch 190 : 0.02417396754026413
Loss at batch 200 : 0.009845361113548279
Loss at batch 210 : 0.011792978271842003
Loss at batch 220 : 0.012671006843447685
Loss at batch 230 : 0.012892138212919235
Loss at batch 240 : 0.012805290520191193
Loss at batch 250 : 0.026848727837204933
Loss at batch 260 : 0.013999522663652897
Loss at batch 270 : 0.010113362222909927
Loss at batch 280 : 0.018422670662403107
Loss at batch 290 : 0.02206682600080967
Loss at batch 300 : 0.01769987680017948
Loss at batch 310 : 0.008971200324594975
Loss at batch 320 : 0.015274688601493835
Loss at batch 330 : 0.019136320799589157
Loss at batch 340 : 0.016604170203208923
Loss at batch 350 : 0.02133210562169552
Loss at batch 360 : 0.01681625284254551
Loss at batch 370 : 0.010542312636971474
epoch55 finished!
Loss at batch 10 : 0.022939395159482956
Loss at batch 20 : 0.011175778694450855
Loss at batch 30 : 0.018679536879062653
Loss at batch 40 : 0.012728665955364704
Loss at batch 50 : 0.009543570689857006
Loss at batch 60 : 0.008502094075083733
Loss at batch 70 : 0.027459796518087387
Loss at batch 80 : 0.016778284683823586
Loss at batch 90 : 0.011613043025135994
Loss at batch 100 : 0.010740884579718113
Loss at batch 110 : 0.01228286325931549
Loss at batch 120 : 0.01908649131655693
Loss at batch 130 : 0.02311060205101967
Loss at batch 140 : 0.02207176201045513
Loss at batch 150 : 0.01582765206694603
Loss at batch 160 : 0.011564125306904316
Loss at batch 170 : 0.016570493578910828
Loss at batch 180 : 0.006255790591239929
Loss at batch 190 : 0.01747812330722809
Loss at batch 200 : 0.014326471835374832
Loss at batch 210 : 0.010319860652089119
Loss at batch 220 : 0.022718463093042374
Loss at batch 230 : 0.019678154960274696
Loss at batch 240 : 0.011053277179598808
Loss at batch 250 : 0.006408401299268007
Loss at batch 260 : 0.01939217932522297
Loss at batch 270 : 0.011355426162481308
Loss at batch 280 : 0.018325190991163254
Loss at batch 290 : 0.02499430440366268
Loss at batch 300 : 0.011513378471136093
Loss at batch 310 : 0.012965140864253044
Loss at batch 320 : 0.00809474941343069
Loss at batch 330 : 0.013972802087664604
Loss at batch 340 : 0.014207680709660053
Loss at batch 350 : 0.008507232181727886
Loss at batch 360 : 0.015209825709462166
Loss at batch 370 : 0.008399086073040962
epoch56 finished!
Loss at batch 10 : 0.012421396560966969
Loss at batch 20 : 0.01569182612001896
Loss at batch 30 : 0.018479887396097183
Loss at batch 40 : 0.01169088389724493
Loss at batch 50 : 0.014386294409632683
Loss at batch 60 : 0.01233687810599804
Loss at batch 70 : 0.01256995927542448
Loss at batch 80 : 0.007903172634541988
Loss at batch 90 : 0.017015967518091202
Loss at batch 100 : 0.01923120580613613
Loss at batch 110 : 0.009959140792489052
Loss at batch 120 : 0.01487760990858078
Loss at batch 130 : 0.016249168664216995
Loss at batch 140 : 0.008082727901637554
Loss at batch 150 : 0.017433037981390953
Loss at batch 160 : 0.0251892302185297
Loss at batch 170 : 0.00848003476858139
Loss at batch 180 : 0.0157834030687809
Loss at batch 190 : 0.017410706728696823
Loss at batch 200 : 0.019605476409196854
Loss at batch 210 : 0.014998800121247768
Loss at batch 220 : 0.007928292267024517
Loss at batch 230 : 0.017806341871619225
Loss at batch 240 : 0.014782635495066643
Loss at batch 250 : 0.008972648531198502
Loss at batch 260 : 0.00807785615324974
Loss at batch 270 : 0.010980833321809769
Loss at batch 280 : 0.023799866437911987
Loss at batch 290 : 0.010867532342672348
Loss at batch 300 : 0.012396720238029957
Loss at batch 310 : 0.009454254992306232
Loss at batch 320 : 0.016090726479887962
Loss at batch 330 : 0.01906638592481613
Loss at batch 340 : 0.017997916787862778
Loss at batch 350 : 0.017736908048391342
Loss at batch 360 : 0.01547139510512352
Loss at batch 370 : 0.012485027313232422
epoch57 finished!
Loss at batch 10 : 0.011928870342671871
Loss at batch 20 : 0.018052591010928154
Loss at batch 30 : 0.010402209125459194
Loss at batch 40 : 0.02055053599178791
Loss at batch 50 : 0.007598489988595247
Loss at batch 60 : 0.01390116848051548
Loss at batch 70 : 0.01177442166954279
Loss at batch 80 : 0.00975946057587862
Loss at batch 90 : 0.0204117801040411
Loss at batch 100 : 0.008782329969108105
Loss at batch 110 : 0.0071556661278009415
Loss at batch 120 : 0.019263699650764465
Loss at batch 130 : 0.015171036124229431
Loss at batch 140 : 0.011346383020281792
Loss at batch 150 : 0.019529663026332855
Loss at batch 160 : 0.02059662714600563
Loss at batch 170 : 0.008646785281598568
Loss at batch 180 : 0.016913266852498055
Loss at batch 190 : 0.020070437341928482
Loss at batch 200 : 0.017305774614214897
Loss at batch 210 : 0.014271811582148075
Loss at batch 220 : 0.0117829330265522
Loss at batch 230 : 0.013844020664691925
Loss at batch 240 : 0.013149500824511051
Loss at batch 250 : 0.009927310980856419
Loss at batch 260 : 0.02205466479063034
Loss at batch 270 : 0.02715611457824707
Loss at batch 280 : 0.01820131577551365
Loss at batch 290 : 0.013189824298024178
Loss at batch 300 : 0.019206209108233452
Loss at batch 310 : 0.014507745392620564
Loss at batch 320 : 0.020356809720396996
Loss at batch 330 : 0.011721380054950714
Loss at batch 340 : 0.024829216301441193
Loss at batch 350 : 0.020613184198737144
Loss at batch 360 : 0.00998566672205925
Loss at batch 370 : 0.019780796021223068
epoch58 finished!
Loss at batch 10 : 0.018817448988556862
Loss at batch 20 : 0.014737658202648163
Loss at batch 30 : 0.024069154635071754
Loss at batch 40 : 0.023463966324925423
Loss at batch 50 : 0.015120921656489372
Loss at batch 60 : 0.011790748685598373
Loss at batch 70 : 0.009282932616770267
Loss at batch 80 : 0.014349778182804585
Loss at batch 90 : 0.017499836161732674
Loss at batch 100 : 0.012841506861150265
Loss at batch 110 : 0.011658069677650928
Loss at batch 120 : 0.01230577751994133
Loss at batch 130 : 0.012045023031532764
Loss at batch 140 : 0.014591208659112453
Loss at batch 150 : 0.011249950155615807
Loss at batch 160 : 0.015702011063694954
Loss at batch 170 : 0.012784884311258793
Loss at batch 180 : 0.011295517906546593
Loss at batch 190 : 0.013120290823280811
Loss at batch 200 : 0.012986497022211552
Loss at batch 210 : 0.012645394541323185
Loss at batch 220 : 0.009103527292609215
Loss at batch 230 : 0.0063700368627905846
Loss at batch 240 : 0.013089409098029137
Loss at batch 250 : 0.011725746095180511
Loss at batch 260 : 0.01624593511223793
Loss at batch 270 : 0.02339003048837185
Loss at batch 280 : 0.009803541004657745
Loss at batch 290 : 0.012674343772232533
Loss at batch 300 : 0.012508915737271309
Loss at batch 310 : 0.013127477839589119
Loss at batch 320 : 0.012376930564641953
Loss at batch 330 : 0.02345290407538414
Loss at batch 340 : 0.02115473523736
Loss at batch 350 : 0.017575453966856003
Loss at batch 360 : 0.018359703943133354
Loss at batch 370 : 0.011643030680716038
epoch59 finished!
Loss at batch 10 : 0.015565820038318634
Loss at batch 20 : 0.020830854773521423
Loss at batch 30 : 0.012712656520307064
Loss at batch 40 : 0.02178868092596531
Loss at batch 50 : 0.014814391732215881
Loss at batch 60 : 0.014476364478468895
Loss at batch 70 : 0.015103467740118504
Loss at batch 80 : 0.01003008522093296
Loss at batch 90 : 0.010912969708442688
Loss at batch 100 : 0.01134700607508421
Loss at batch 110 : 0.013710049912333488
Loss at batch 120 : 0.0131979426369071
Loss at batch 130 : 0.010727804154157639
Loss at batch 140 : 0.011643812991678715
Loss at batch 150 : 0.011086408980190754
Loss at batch 160 : 0.015068341977894306
Loss at batch 170 : 0.019731739535927773
Loss at batch 180 : 0.009922877885401249
Loss at batch 190 : 0.020748939365148544
Loss at batch 200 : 0.010487744584679604
Loss at batch 210 : 0.015485654585063457
Loss at batch 220 : 0.011836713179945946
Loss at batch 230 : 0.008847405202686787
Loss at batch 240 : 0.011309638619422913
Loss at batch 250 : 0.011800992302596569
Loss at batch 260 : 0.015604461543262005
Loss at batch 270 : 0.01556324865669012
Loss at batch 280 : 0.01695047877728939
Loss at batch 290 : 0.01882968284189701
Loss at batch 300 : 0.015315013006329536
Loss at batch 310 : 0.007928517647087574
Loss at batch 320 : 0.013462357223033905
Loss at batch 330 : 0.011006688699126244
Loss at batch 340 : 0.01978892832994461
Loss at batch 350 : 0.015048556961119175
Loss at batch 360 : 0.01516712550073862
Loss at batch 370 : 0.018366431817412376
epoch60 finished!
Loss at batch 10 : 0.01607801392674446
Loss at batch 20 : 0.019518038257956505
Loss at batch 30 : 0.012595681473612785
Loss at batch 40 : 0.009537292644381523
Loss at batch 50 : 0.023208409547805786
Loss at batch 60 : 0.01254137884825468
Loss at batch 70 : 0.01883082464337349
Loss at batch 80 : 0.01496372651308775
Loss at batch 90 : 0.020672082901000977
Loss at batch 100 : 0.017698558047413826
Loss at batch 110 : 0.01621893234550953
Loss at batch 120 : 0.01173437014222145
Loss at batch 130 : 0.01654757186770439
Loss at batch 140 : 0.01815887540578842
Loss at batch 150 : 0.013248952105641365
Loss at batch 160 : 0.022395001724362373
Loss at batch 170 : 0.017286334186792374
Loss at batch 180 : 0.02142123505473137
Loss at batch 190 : 0.024444587528705597
Loss at batch 200 : 0.013249603100121021
Loss at batch 210 : 0.00692105945199728
Loss at batch 220 : 0.01083377841860056
Loss at batch 230 : 0.014985707588493824
Loss at batch 240 : 0.015469837933778763
Loss at batch 250 : 0.010224608704447746
Loss at batch 260 : 0.008877858519554138
Loss at batch 270 : 0.017254723235964775
Loss at batch 280 : 0.010332118719816208
Loss at batch 290 : 0.012809449806809425
Loss at batch 300 : 0.007885748520493507
Loss at batch 310 : 0.018791425973176956
Loss at batch 320 : 0.01242944784462452
Loss at batch 330 : 0.02746141329407692
Loss at batch 340 : 0.025689218193292618
Loss at batch 350 : 0.011911088600754738
Loss at batch 360 : 0.008659633807837963
Loss at batch 370 : 0.013488119468092918
epoch61 finished!
Loss at batch 10 : 0.024777239188551903
Loss at batch 20 : 0.01249770913273096
Loss at batch 30 : 0.020575227215886116
Loss at batch 40 : 0.017929192632436752
Loss at batch 50 : 0.013337071985006332
Loss at batch 60 : 0.014240347780287266
Loss at batch 70 : 0.010343615896999836
Loss at batch 80 : 0.011436043307185173
Loss at batch 90 : 0.011636708863079548
Loss at batch 100 : 0.013864722102880478
Loss at batch 110 : 0.011165798641741276
Loss at batch 120 : 0.01686406135559082
Loss at batch 130 : 0.017528383061289787
Loss at batch 140 : 0.013350513763725758
Loss at batch 150 : 0.024487508460879326
Loss at batch 160 : 0.013832086697220802
Loss at batch 170 : 0.02677621692419052
Loss at batch 180 : 0.01113355066627264
Loss at batch 190 : 0.014322624541819096
Loss at batch 200 : 0.012924285605549812
Loss at batch 210 : 0.01011822558939457
Loss at batch 220 : 0.015727337449789047
Loss at batch 230 : 0.012341752648353577
Loss at batch 240 : 0.01819011941552162
Loss at batch 250 : 0.013082179240882397
Loss at batch 260 : 0.016916461288928986
Loss at batch 270 : 0.013335742987692356
Loss at batch 280 : 0.01006354484707117
Loss at batch 290 : 0.01674003154039383
Loss at batch 300 : 0.008369941264390945
Loss at batch 310 : 0.009923411533236504
Loss at batch 320 : 0.00971315149217844
Loss at batch 330 : 0.009888926520943642
Loss at batch 340 : 0.012835625559091568
Loss at batch 350 : 0.020219488069415092
Loss at batch 360 : 0.015852639451622963
Loss at batch 370 : 0.01292305439710617
epoch62 finished!
Loss at batch 10 : 0.015387145802378654
Loss at batch 20 : 0.018438873812556267
Loss at batch 30 : 0.008020436391234398
Loss at batch 40 : 0.01508796401321888
Loss at batch 50 : 0.026585372164845467
Loss at batch 60 : 0.01136055402457714
Loss at batch 70 : 0.019696474075317383
Loss at batch 80 : 0.01976943016052246
Loss at batch 90 : 0.01237153634428978
Loss at batch 100 : 0.027187496423721313
Loss at batch 110 : 0.01521967351436615
Loss at batch 120 : 0.0199369415640831
Loss at batch 130 : 0.012856880202889442
Loss at batch 140 : 0.01106209959834814
Loss at batch 150 : 0.011175859719514847
Loss at batch 160 : 0.01373591274023056
Loss at batch 170 : 0.01630214974284172
Loss at batch 180 : 0.02042900212109089
Loss at batch 190 : 0.018099011853337288
Loss at batch 200 : 0.013183414936065674
Loss at batch 210 : 0.019116049632430077
Loss at batch 220 : 0.007481350563466549
Loss at batch 230 : 0.010207965038716793
Loss at batch 240 : 0.01178671047091484
Loss at batch 250 : 0.017059406265616417
Loss at batch 260 : 0.014463985338807106
Loss at batch 270 : 0.026821309700608253
Loss at batch 280 : 0.012464242056012154
Loss at batch 290 : 0.014181158505380154
Loss at batch 300 : 0.017322823405265808
Loss at batch 310 : 0.03184381499886513
Loss at batch 320 : 0.009719707071781158
Loss at batch 330 : 0.018629183992743492
Loss at batch 340 : 0.01278076320886612
Loss at batch 350 : 0.013325965963304043
Loss at batch 360 : 0.011976730078458786
Loss at batch 370 : 0.01640893891453743
epoch63 finished!
Loss at batch 10 : 0.009282335638999939
Loss at batch 20 : 0.01955546997487545
Loss at batch 30 : 0.016256218776106834
Loss at batch 40 : 0.01624494418501854
Loss at batch 50 : 0.013378639705479145
Loss at batch 60 : 0.023360304534435272
Loss at batch 70 : 0.01147377211600542
Loss at batch 80 : 0.009800247848033905
Loss at batch 90 : 0.021886542439460754
Loss at batch 100 : 0.007289333734661341
Loss at batch 110 : 0.014308364130556583
Loss at batch 120 : 0.03123861365020275
Loss at batch 130 : 0.009161555208265781
Loss at batch 140 : 0.030686939135193825
Loss at batch 150 : 0.014315899461507797
Loss at batch 160 : 0.017863549292087555
Loss at batch 170 : 0.014165869913995266
Loss at batch 180 : 0.013944906182587147
Loss at batch 190 : 0.0128014599904418
Loss at batch 200 : 0.016755683347582817
Loss at batch 210 : 0.008966018445789814
Loss at batch 220 : 0.011135571636259556
Loss at batch 230 : 0.019748222082853317
Loss at batch 240 : 0.013822253793478012
Loss at batch 250 : 0.012943709269165993
Loss at batch 260 : 0.017772741615772247
Loss at batch 270 : 0.015020069666206837
Loss at batch 280 : 0.030222689732909203
Loss at batch 290 : 0.012929581105709076
Loss at batch 300 : 0.011502108536660671
Loss at batch 310 : 0.01532449759542942
Loss at batch 320 : 0.009733416140079498
Loss at batch 330 : 0.015331768430769444
Loss at batch 340 : 0.015893876552581787
Loss at batch 350 : 0.015572273172438145
Loss at batch 360 : 0.015817996114492416
Loss at batch 370 : 0.00855038221925497
epoch64 finished!
Loss at batch 10 : 0.009742995724081993
Loss at batch 20 : 0.008939649909734726
Loss at batch 30 : 0.02245182730257511
Loss at batch 40 : 0.011617696844041348
Loss at batch 50 : 0.006939157377928495
Loss at batch 60 : 0.016725074499845505
Loss at batch 70 : 0.015333383344113827
Loss at batch 80 : 0.015646465122699738
Loss at batch 90 : 0.008898625150322914
Loss at batch 100 : 0.011440768837928772
Loss at batch 110 : 0.022351041436195374
Loss at batch 120 : 0.0072144013829529285
Loss at batch 130 : 0.017306489869952202
Loss at batch 140 : 0.013017205521464348
Loss at batch 150 : 0.014097298495471478
Loss at batch 160 : 0.01630805805325508
Loss at batch 170 : 0.012030483223497868
Loss at batch 180 : 0.016498243436217308
Loss at batch 190 : 0.015232044272124767
Loss at batch 200 : 0.007321332581341267
Loss at batch 210 : 0.014976222068071365
Loss at batch 220 : 0.018040696159005165
Loss at batch 230 : 0.012477193027734756
Loss at batch 240 : 0.009417295455932617
Loss at batch 250 : 0.014642965979874134
Loss at batch 260 : 0.008343532681465149
Loss at batch 270 : 0.012040812522172928
Loss at batch 280 : 0.012406128458678722
Loss at batch 290 : 0.012325389310717583
Loss at batch 300 : 0.01581125520169735
Loss at batch 310 : 0.014279363676905632
Loss at batch 320 : 0.018926281481981277
Loss at batch 330 : 0.013849486596882343
Loss at batch 340 : 0.017063140869140625
Loss at batch 350 : 0.007302410434931517
Loss at batch 360 : 0.014615395106375217
Loss at batch 370 : 0.007432516198605299
epoch65 finished!
Loss at batch 10 : 0.010277697816491127
Loss at batch 20 : 0.010347477160394192
Loss at batch 30 : 0.012194071896374226
Loss at batch 40 : 0.015178566798567772
Loss at batch 50 : 0.008475330658257008
Loss at batch 60 : 0.024038391187787056
Loss at batch 70 : 0.010631615296006203
Loss at batch 80 : 0.012524723075330257
Loss at batch 90 : 0.016964351758360863
Loss at batch 100 : 0.007472171913832426
Loss at batch 110 : 0.016528094187378883
Loss at batch 120 : 0.009291835129261017
Loss at batch 130 : 0.011401058174669743
Loss at batch 140 : 0.015310555696487427
Loss at batch 150 : 0.013849577866494656
Loss at batch 160 : 0.017723068594932556
Loss at batch 170 : 0.011472887359559536
Loss at batch 180 : 0.020976874977350235
Loss at batch 190 : 0.014088588766753674
Loss at batch 200 : 0.01491063553839922
Loss at batch 210 : 0.00797403883188963
Loss at batch 220 : 0.021027468144893646
Loss at batch 230 : 0.021637560799717903
Loss at batch 240 : 0.018696878105401993
Loss at batch 250 : 0.015564179979264736
Loss at batch 260 : 0.008802837692201138
Loss at batch 270 : 0.015330656431615353
Loss at batch 280 : 0.016430212184786797
Loss at batch 290 : 0.02125553973019123
Loss at batch 300 : 0.01309081818908453
Loss at batch 310 : 0.01603144034743309
Loss at batch 320 : 0.014689622446894646
Loss at batch 330 : 0.01687929593026638
Loss at batch 340 : 0.012079587206244469
Loss at batch 350 : 0.02444906160235405
Loss at batch 360 : 0.024710318073630333
Loss at batch 370 : 0.007713867351412773
epoch66 finished!
Loss at batch 10 : 0.02264541946351528
Loss at batch 20 : 0.021891245618462563
Loss at batch 30 : 0.01547743659466505
Loss at batch 40 : 0.011957501992583275
Loss at batch 50 : 0.01191824022680521
Loss at batch 60 : 0.015116664581000805
Loss at batch 70 : 0.01230414118617773
Loss at batch 80 : 0.011630425229668617
Loss at batch 90 : 0.015840720385313034
Loss at batch 100 : 0.015787595883011818
Loss at batch 110 : 0.021019546315073967
Loss at batch 120 : 0.014768448658287525
Loss at batch 130 : 0.018219878897070885
Loss at batch 140 : 0.008361502550542355
Loss at batch 150 : 0.016178255900740623
Loss at batch 160 : 0.013274016790091991
Loss at batch 170 : 0.012345310300588608
Loss at batch 180 : 0.009356717579066753
Loss at batch 190 : 0.014386579394340515
Loss at batch 200 : 0.011277143843472004
Loss at batch 210 : 0.0207213182002306
Loss at batch 220 : 0.008220887742936611
Loss at batch 230 : 0.014172219671308994
Loss at batch 240 : 0.018058989197015762
Loss at batch 250 : 0.007375754415988922
Loss at batch 260 : 0.02757686749100685
Loss at batch 270 : 0.012517386116087437
Loss at batch 280 : 0.006179023068398237
Loss at batch 290 : 0.01621352508664131
Loss at batch 300 : 0.019335554912686348
Loss at batch 310 : 0.01241428591310978
Loss at batch 320 : 0.020305749028921127
Loss at batch 330 : 0.019935201853513718
Loss at batch 340 : 0.02255968749523163
Loss at batch 350 : 0.015003758482635021
Loss at batch 360 : 0.008263293653726578
Loss at batch 370 : 0.021839890629053116
epoch67 finished!
Loss at batch 10 : 0.010318892076611519
Loss at batch 20 : 0.01862405240535736
Loss at batch 30 : 0.018366007134318352
Loss at batch 40 : 0.018957117572426796
Loss at batch 50 : 0.01818883791565895
Loss at batch 60 : 0.015941742807626724
Loss at batch 70 : 0.018107177689671516
Loss at batch 80 : 0.015249022282660007
Loss at batch 90 : 0.007840177044272423
Loss at batch 100 : 0.014655999839305878
Loss at batch 110 : 0.013961438089609146
Loss at batch 120 : 0.022448595613241196
Loss at batch 130 : 0.022829730063676834
Loss at batch 140 : 0.012984005734324455
Loss at batch 150 : 0.008029431104660034
Loss at batch 160 : 0.02035660855472088
Loss at batch 170 : 0.008546099066734314
Loss at batch 180 : 0.007589589338749647
Loss at batch 190 : 0.01374147366732359
Loss at batch 200 : 0.012223959900438786
Loss at batch 210 : 0.012312040664255619
Loss at batch 220 : 0.01836712844669819
Loss at batch 230 : 0.027179794386029243
Loss at batch 240 : 0.010088720358908176
Loss at batch 250 : 0.012822269462049007
Loss at batch 260 : 0.011279202066361904
Loss at batch 270 : 0.018407313153147697
Loss at batch 280 : 0.019865790382027626
Loss at batch 290 : 0.014808131381869316
Loss at batch 300 : 0.014888226985931396
Loss at batch 310 : 0.015473972074687481
Loss at batch 320 : 0.021676618605852127
Loss at batch 330 : 0.012520726770162582
Loss at batch 340 : 0.018482264131307602
Loss at batch 350 : 0.02084382437169552
Loss at batch 360 : 0.012999486178159714
Loss at batch 370 : 0.018375586718320847
epoch68 finished!
Loss at batch 10 : 0.012366269715130329
Loss at batch 20 : 0.015813613310456276
Loss at batch 30 : 0.014326506294310093
Loss at batch 40 : 0.02879742532968521
Loss at batch 50 : 0.015395243652164936
Loss at batch 60 : 0.010223401710391045
Loss at batch 70 : 0.005957064218819141
Loss at batch 80 : 0.009888121858239174
Loss at batch 90 : 0.012500051409006119
Loss at batch 100 : 0.020240195095539093
Loss at batch 110 : 0.014317987486720085
Loss at batch 120 : 0.015729030594229698
Loss at batch 130 : 0.015502726659178734
Loss at batch 140 : 0.01429236214607954
Loss at batch 150 : 0.010628480464220047
Loss at batch 160 : 0.016206175088882446
Loss at batch 170 : 0.017257235944271088
Loss at batch 180 : 0.017006805166602135
Loss at batch 190 : 0.015634888783097267
Loss at batch 200 : 0.00933085847645998
Loss at batch 210 : 0.009369290433824062
Loss at batch 220 : 0.022492678835988045
Loss at batch 230 : 0.015028843656182289
Loss at batch 240 : 0.011788696050643921
Loss at batch 250 : 0.01738879829645157
Loss at batch 260 : 0.012358466163277626
Loss at batch 270 : 0.015346669591963291
Loss at batch 280 : 0.01217542216181755
Loss at batch 290 : 0.015393146313726902
Loss at batch 300 : 0.016045881435275078
Loss at batch 310 : 0.01871153526008129
Loss at batch 320 : 0.02816609852015972
Loss at batch 330 : 0.01522477064281702
Loss at batch 340 : 0.017972776666283607
Loss at batch 350 : 0.010338752530515194
Loss at batch 360 : 0.011818052269518375
Loss at batch 370 : 0.018214760348200798
epoch69 finished!
Loss at batch 10 : 0.010310024954378605
Loss at batch 20 : 0.01915891095995903
Loss at batch 30 : 0.007265827618539333
Loss at batch 40 : 0.013280864804983139
Loss at batch 50 : 0.010695535689592361
Loss at batch 60 : 0.019740791991353035
Loss at batch 70 : 0.012845741584897041
Loss at batch 80 : 0.01593146100640297
Loss at batch 90 : 0.014028922654688358
Loss at batch 100 : 0.01659563183784485
Loss at batch 110 : 0.01712985523045063
Loss at batch 120 : 0.011453192681074142
Loss at batch 130 : 0.013048644177615643
Loss at batch 140 : 0.028973842039704323
Loss at batch 150 : 0.017243636772036552
Loss at batch 160 : 0.01297821942716837
Loss at batch 170 : 0.007461389061063528
Loss at batch 180 : 0.012689962051808834
Loss at batch 190 : 0.020182527601718903
Loss at batch 200 : 0.011787873692810535
Loss at batch 210 : 0.021412817761301994
Loss at batch 220 : 0.020843638107180595
Loss at batch 230 : 0.006733783055096865
Loss at batch 240 : 0.01995478942990303
Loss at batch 250 : 0.01104174554347992
Loss at batch 260 : 0.01768471859395504
Loss at batch 270 : 0.01871808059513569
Loss at batch 280 : 0.011628439649939537
Loss at batch 290 : 0.02488729916512966
Loss at batch 300 : 0.011812078766524792
Loss at batch 310 : 0.009787512011826038
Loss at batch 320 : 0.02318800427019596
Loss at batch 330 : 0.006504828110337257
Loss at batch 340 : 0.0075367814861238
Loss at batch 350 : 0.019456088542938232
Loss at batch 360 : 0.012975119985640049
Loss at batch 370 : 0.014316059648990631
epoch70 finished!
Loss at batch 10 : 0.010275857523083687
Loss at batch 20 : 0.009617931209504604
Loss at batch 30 : 0.013451012782752514
Loss at batch 40 : 0.023350432515144348
Loss at batch 50 : 0.01377097237855196
Loss at batch 60 : 0.03256947174668312
Loss at batch 70 : 0.017134662717580795
Loss at batch 80 : 0.014524534344673157
Loss at batch 90 : 0.01593446172773838
Loss at batch 100 : 0.01176789402961731
Loss at batch 110 : 0.014195181429386139
Loss at batch 120 : 0.007338120136409998
Loss at batch 130 : 0.014947650022804737
Loss at batch 140 : 0.011032705195248127
Loss at batch 150 : 0.010664993897080421
Loss at batch 160 : 0.011812721379101276
Loss at batch 170 : 0.009204573929309845
Loss at batch 180 : 0.02149866335093975
Loss at batch 190 : 0.00783309806138277
Loss at batch 200 : 0.017712732776999474
Loss at batch 210 : 0.011316189542412758
Loss at batch 220 : 0.009808110073208809
Loss at batch 230 : 0.009583838284015656
Loss at batch 240 : 0.012792776338756084
Loss at batch 250 : 0.025129161775112152
Loss at batch 260 : 0.011238018050789833
Loss at batch 270 : 0.020251598209142685
Loss at batch 280 : 0.009583607316017151
Loss at batch 290 : 0.013641668483614922
Loss at batch 300 : 0.017985083162784576
Loss at batch 310 : 0.01918070577085018
Loss at batch 320 : 0.011042744852602482
Loss at batch 330 : 0.021923277527093887
Loss at batch 340 : 0.01666315086185932
Loss at batch 350 : 0.015656229108572006
Loss at batch 360 : 0.01226065307855606
Loss at batch 370 : 0.009240003302693367
epoch71 finished!
Loss at batch 10 : 0.012660003267228603
Loss at batch 20 : 0.015199264511466026
Loss at batch 30 : 0.014063439331948757
Loss at batch 40 : 0.018465038388967514
Loss at batch 50 : 0.028932707384228706
Loss at batch 60 : 0.010492884553968906
Loss at batch 70 : 0.01714896224439144
Loss at batch 80 : 0.011749155819416046
Loss at batch 90 : 0.012463266961276531
Loss at batch 100 : 0.013773329555988312
Loss at batch 110 : 0.012593619525432587
Loss at batch 120 : 0.023125097155570984
Loss at batch 130 : 0.006144965533167124
Loss at batch 140 : 0.019018864259123802
Loss at batch 150 : 0.01702631264925003
Loss at batch 160 : 0.015451940707862377
Loss at batch 170 : 0.00886811874806881
Loss at batch 180 : 0.013845918700098991
Loss at batch 190 : 0.018168402835726738
Loss at batch 200 : 0.01602138951420784
Loss at batch 210 : 0.01290201023221016
Loss at batch 220 : 0.021273519843816757
Loss at batch 230 : 0.016633380204439163
Loss at batch 240 : 0.026615850627422333
Loss at batch 250 : 0.007764863781630993
Loss at batch 260 : 0.013411733321845531
Loss at batch 270 : 0.009626522660255432
Loss at batch 280 : 0.016549041494727135
Loss at batch 290 : 0.014651673845946789
Loss at batch 300 : 0.020026003941893578
Loss at batch 310 : 0.01617179438471794
Loss at batch 320 : 0.015857364982366562
Loss at batch 330 : 0.015585917979478836
Loss at batch 340 : 0.01758217252790928
Loss at batch 350 : 0.019774986431002617
Loss at batch 360 : 0.014990478754043579
Loss at batch 370 : 0.012668308801949024
epoch72 finished!
Loss at batch 10 : 0.010638161562383175
Loss at batch 20 : 0.021134084090590477
Loss at batch 30 : 0.010696778073906898
Loss at batch 40 : 0.01157006062567234
Loss at batch 50 : 0.011892298236489296
Loss at batch 60 : 0.013388585299253464
Loss at batch 70 : 0.021923581138253212
Loss at batch 80 : 0.015215124003589153
Loss at batch 90 : 0.020355872809886932
Loss at batch 100 : 0.021669140085577965
Loss at batch 110 : 0.011543208733201027
Loss at batch 120 : 0.01771128922700882
Loss at batch 130 : 0.021169699728488922
Loss at batch 140 : 0.014304288662970066
Loss at batch 150 : 0.00764412060379982
Loss at batch 160 : 0.014731367118656635
Loss at batch 170 : 0.01656194031238556
Loss at batch 180 : 0.015148292295634747
Loss at batch 190 : 0.014987709000706673
Loss at batch 200 : 0.010571876540780067
Loss at batch 210 : 0.016819646582007408
Loss at batch 220 : 0.01220761425793171
Loss at batch 230 : 0.020717263221740723
Loss at batch 240 : 0.010485716164112091
Loss at batch 250 : 0.014151160605251789
Loss at batch 260 : 0.014104031957685947
Loss at batch 270 : 0.02679135650396347
Loss at batch 280 : 0.007753586862236261
Loss at batch 290 : 0.008294601924717426
Loss at batch 300 : 0.009005029685795307
Loss at batch 310 : 0.023257141932845116
Loss at batch 320 : 0.007485710084438324
Loss at batch 330 : 0.011384818702936172
Loss at batch 340 : 0.01884080097079277
Loss at batch 350 : 0.012502121739089489
Loss at batch 360 : 0.015109854750335217
Loss at batch 370 : 0.009553930722177029
epoch73 finished!
Loss at batch 10 : 0.012118377722799778
Loss at batch 20 : 0.007777913939207792
Loss at batch 30 : 0.01582861691713333
Loss at batch 40 : 0.015157049521803856
Loss at batch 50 : 0.014719253405928612
Loss at batch 60 : 0.013027556240558624
Loss at batch 70 : 0.006978045683354139
Loss at batch 80 : 0.03154296427965164
Loss at batch 90 : 0.019884800538420677
Loss at batch 100 : 0.016069943085312843
Loss at batch 110 : 0.011989953927695751
Loss at batch 120 : 0.019207138568162918
Loss at batch 130 : 0.010008484125137329
Loss at batch 140 : 0.018047401681542397
Loss at batch 150 : 0.01198885403573513
Loss at batch 160 : 0.017694173380732536
Loss at batch 170 : 0.01622614823281765
Loss at batch 180 : 0.01044080127030611
Loss at batch 190 : 0.013834871351718903
Loss at batch 200 : 0.01628870517015457
Loss at batch 210 : 0.00977110955864191
Loss at batch 220 : 0.011695198714733124
Loss at batch 230 : 0.01142873615026474
Loss at batch 240 : 0.013861456885933876
Loss at batch 250 : 0.009511169977486134
Loss at batch 260 : 0.021082337945699692
Loss at batch 270 : 0.016649704426527023
Loss at batch 280 : 0.018657561391592026
Loss at batch 290 : 0.01660510152578354
Loss at batch 300 : 0.013428354635834694
Loss at batch 310 : 0.01962059736251831
Loss at batch 320 : 0.014003455638885498
Loss at batch 330 : 0.01235818862915039
Loss at batch 340 : 0.009102433919906616
Loss at batch 350 : 0.01768685132265091
Loss at batch 360 : 0.019869986921548843
Loss at batch 370 : 0.01794593781232834
epoch74 finished!
Loss at batch 10 : 0.019802916795015335
Loss at batch 20 : 0.016914963722229004
Loss at batch 30 : 0.011354194954037666
Loss at batch 40 : 0.012394675053656101
Loss at batch 50 : 0.016369566321372986
Loss at batch 60 : 0.010589797981083393
Loss at batch 70 : 0.015510409139096737
Loss at batch 80 : 0.018555590882897377
Loss at batch 90 : 0.009025090374052525
Loss at batch 100 : 0.012771626003086567
Loss at batch 110 : 0.02695792354643345
Loss at batch 120 : 0.009346193633973598
Loss at batch 130 : 0.019916750490665436
Loss at batch 140 : 0.013034121133387089
Loss at batch 150 : 0.014202139340341091
Loss at batch 160 : 0.00856536440551281
Loss at batch 170 : 0.014920923858880997
Loss at batch 180 : 0.021329771727323532
Loss at batch 190 : 0.011692666448652744
Loss at batch 200 : 0.015992073342204094
Loss at batch 210 : 0.01715315878391266
Loss at batch 220 : 0.012286326847970486
Loss at batch 230 : 0.007814710959792137
Loss at batch 240 : 0.013709076680243015
Loss at batch 250 : 0.013552185148000717
Loss at batch 260 : 0.017040029168128967
Loss at batch 270 : 0.013121766038239002
Loss at batch 280 : 0.012685097754001617
Loss at batch 290 : 0.011531919240951538
Loss at batch 300 : 0.019244039431214333
Loss at batch 310 : 0.019126340746879578
Loss at batch 320 : 0.025047989562153816
Loss at batch 330 : 0.020122375339269638
Loss at batch 340 : 0.015825534239411354
Loss at batch 350 : 0.007569385226815939
Loss at batch 360 : 0.026857217773795128
Loss at batch 370 : 0.016147460788488388
epoch75 finished!
Loss at batch 10 : 0.00961978081613779
Loss at batch 20 : 0.013342112302780151
Loss at batch 30 : 0.013208223506808281
Loss at batch 40 : 0.0178214181214571
Loss at batch 50 : 0.01642143726348877
Loss at batch 60 : 0.01651049591600895
Loss at batch 70 : 0.023024389520287514
Loss at batch 80 : 0.006496255751699209
Loss at batch 90 : 0.011690442450344563
Loss at batch 100 : 0.019817840307950974
Loss at batch 110 : 0.010112029500305653
Loss at batch 120 : 0.01998940110206604
Loss at batch 130 : 0.01291356049478054
Loss at batch 140 : 0.009920612908899784
Loss at batch 150 : 0.02109246328473091
Loss at batch 160 : 0.010806236416101456
Loss at batch 170 : 0.01198253221809864
Loss at batch 180 : 0.013420602306723595
Loss at batch 190 : 0.01648436114192009
Loss at batch 200 : 0.015701109543442726
Loss at batch 210 : 0.017287785187363625
Loss at batch 220 : 0.01704753004014492
Loss at batch 230 : 0.017582306638360023
Loss at batch 240 : 0.01718229427933693
Loss at batch 250 : 0.02144816517829895
Loss at batch 260 : 0.009051916189491749
Loss at batch 270 : 0.014585313387215137
Loss at batch 280 : 0.014537894167006016
Loss at batch 290 : 0.018017603084445
Loss at batch 300 : 0.014201571233570576
Loss at batch 310 : 0.018325623124837875
Loss at batch 320 : 0.018204715102910995
Loss at batch 330 : 0.02475717104971409
Loss at batch 340 : 0.012052750214934349
Loss at batch 350 : 0.011977733112871647
Loss at batch 360 : 0.01730787381529808
Loss at batch 370 : 0.014776417054235935
epoch76 finished!
Loss at batch 10 : 0.010878881439566612
Loss at batch 20 : 0.012456935830414295
Loss at batch 30 : 0.019296616315841675
Loss at batch 40 : 0.01521204225718975
Loss at batch 50 : 0.014139915816485882
Loss at batch 60 : 0.018826574087142944
Loss at batch 70 : 0.013860329985618591
Loss at batch 80 : 0.01791493408381939
Loss at batch 90 : 0.01761532388627529
Loss at batch 100 : 0.012665814720094204
Loss at batch 110 : 0.008637786842882633
Loss at batch 120 : 0.015572991222143173
Loss at batch 130 : 0.012114623561501503
Loss at batch 140 : 0.007713863160461187
Loss at batch 150 : 0.01741809956729412
Loss at batch 160 : 0.011098003946244717
Loss at batch 170 : 0.01749117486178875
Loss at batch 180 : 0.0159459188580513
Loss at batch 190 : 0.015101405791938305
Loss at batch 200 : 0.015445682220160961
Loss at batch 210 : 0.01703137718141079
Loss at batch 220 : 0.013899756595492363
Loss at batch 230 : 0.019800318405032158
Loss at batch 240 : 0.015347042120993137
Loss at batch 250 : 0.012504291720688343
Loss at batch 260 : 0.012287129648029804
Loss at batch 270 : 0.02556290291249752
Loss at batch 280 : 0.016020607203245163
Loss at batch 290 : 0.02204190567135811
Loss at batch 300 : 0.009260152466595173
Loss at batch 310 : 0.01188422366976738
Loss at batch 320 : 0.017590569332242012
Loss at batch 330 : 0.0228529404848814
Loss at batch 340 : 0.020491033792495728
Loss at batch 350 : 0.023795368149876595
Loss at batch 360 : 0.02190394513309002
Loss at batch 370 : 0.022584417834877968
epoch77 finished!
Loss at batch 10 : 0.007209139876067638
Loss at batch 20 : 0.008460832759737968
Loss at batch 30 : 0.010275939479470253
Loss at batch 40 : 0.0159055944532156
Loss at batch 50 : 0.010493136942386627
Loss at batch 60 : 0.022544139996170998
Loss at batch 70 : 0.00941492710262537
Loss at batch 80 : 0.024413401260972023
Loss at batch 90 : 0.020283423364162445
Loss at batch 100 : 0.008000265806913376
Loss at batch 110 : 0.006770361214876175
Loss at batch 120 : 0.01962048001587391
Loss at batch 130 : 0.01274278573691845
Loss at batch 140 : 0.020326687023043633
Loss at batch 150 : 0.020813824608922005
Loss at batch 160 : 0.010724404826760292
Loss at batch 170 : 0.01708068512380123
Loss at batch 180 : 0.013951015658676624
Loss at batch 190 : 0.011290527880191803
Loss at batch 200 : 0.013686914928257465
Loss at batch 210 : 0.020078418776392937
Loss at batch 220 : 0.021914035081863403
Loss at batch 230 : 0.012508896179497242
Loss at batch 240 : 0.010437500663101673
Loss at batch 250 : 0.01396953221410513
Loss at batch 260 : 0.008365058340132236
Loss at batch 270 : 0.011703914031386375
Loss at batch 280 : 0.011364628560841084
Loss at batch 290 : 0.008226603269577026
Loss at batch 300 : 0.022690411657094955
Loss at batch 310 : 0.012830192223191261
Loss at batch 320 : 0.019333986565470695
Loss at batch 330 : 0.014188756234943867
Loss at batch 340 : 0.009801345877349377
Loss at batch 350 : 0.008668708615005016
Loss at batch 360 : 0.009080344811081886
Loss at batch 370 : 0.016580086201429367
epoch78 finished!
Loss at batch 10 : 0.016352785751223564
Loss at batch 20 : 0.015648191794753075
Loss at batch 30 : 0.015023395419120789
Loss at batch 40 : 0.018194660544395447
Loss at batch 50 : 0.014784618280827999
Loss at batch 60 : 0.013573940843343735
Loss at batch 70 : 0.01593770831823349
Loss at batch 80 : 0.009976671077311039
Loss at batch 90 : 0.011214034631848335
Loss at batch 100 : 0.019263174384832382
Loss at batch 110 : 0.0063420687802135944
Loss at batch 120 : 0.011013003997504711
Loss at batch 130 : 0.0150874312967062
Loss at batch 140 : 0.024926109239459038
Loss at batch 150 : 0.009571291506290436
Loss at batch 160 : 0.02686956338584423
Loss at batch 170 : 0.008426693268120289
Loss at batch 180 : 0.011681884527206421
Loss at batch 190 : 0.016988154500722885
Loss at batch 200 : 0.02138039655983448
Loss at batch 210 : 0.014309906400740147
Loss at batch 220 : 0.019819876179099083
Loss at batch 230 : 0.016121581196784973
Loss at batch 240 : 0.013622424565255642
Loss at batch 250 : 0.010479524731636047
Loss at batch 260 : 0.010775861330330372
Loss at batch 270 : 0.013098304159939289
Loss at batch 280 : 0.012482027523219585
Loss at batch 290 : 0.020039767026901245
Loss at batch 300 : 0.014994051307439804
Loss at batch 310 : 0.016506066545844078
Loss at batch 320 : 0.013221223838627338
Loss at batch 330 : 0.012322930619120598
Loss at batch 340 : 0.02262595295906067
Loss at batch 350 : 0.02130475826561451
Loss at batch 360 : 0.01950189284980297
Loss at batch 370 : 0.008438020944595337
epoch79 finished!
Loss at batch 10 : 0.019397052004933357
Loss at batch 20 : 0.014138282276690006
Loss at batch 30 : 0.021261559799313545
Loss at batch 40 : 0.018650861456990242
Loss at batch 50 : 0.012610909529030323
Loss at batch 60 : 0.009878345765173435
Loss at batch 70 : 0.018053030595183372
Loss at batch 80 : 0.020139817148447037
Loss at batch 90 : 0.010412659496068954
Loss at batch 100 : 0.00715807406231761
Loss at batch 110 : 0.018926706165075302
Loss at batch 120 : 0.013849319890141487
Loss at batch 130 : 0.013505792245268822
Loss at batch 140 : 0.016760198399424553
Loss at batch 150 : 0.008950646966695786
Loss at batch 160 : 0.012379487976431847
Loss at batch 170 : 0.009718148037791252
Loss at batch 180 : 0.014057357795536518
Loss at batch 190 : 0.01651228778064251
Loss at batch 200 : 0.015540079213678837
Loss at batch 210 : 0.014519806951284409
Loss at batch 220 : 0.012426718138158321
Loss at batch 230 : 0.013419374823570251
Loss at batch 240 : 0.016436440870165825
Loss at batch 250 : 0.008101682178676128
Loss at batch 260 : 0.013803819194436073
Loss at batch 270 : 0.013289360329508781
Loss at batch 280 : 0.012535182759165764
Loss at batch 290 : 0.013069153763353825
Loss at batch 300 : 0.012778389267623425
Loss at batch 310 : 0.01061128731817007
Loss at batch 320 : 0.013226804323494434
Loss at batch 330 : 0.018077241256833076
Loss at batch 340 : 0.01625119335949421
Loss at batch 350 : 0.02016771398484707
Loss at batch 360 : 0.011385271325707436
Loss at batch 370 : 0.014024956151843071
epoch80 finished!
Loss at batch 10 : 0.010466303676366806
Loss at batch 20 : 0.015660937875509262
Loss at batch 30 : 0.017893170937895775
Loss at batch 40 : 0.012488467618823051
Loss at batch 50 : 0.021523868665099144
Loss at batch 60 : 0.012653068639338017
Loss at batch 70 : 0.014240995980799198
Loss at batch 80 : 0.02602520026266575
Loss at batch 90 : 0.01375748123973608
Loss at batch 100 : 0.014669938012957573
Loss at batch 110 : 0.016483085229992867
Loss at batch 120 : 0.010683070868253708
Loss at batch 130 : 0.011224357411265373
Loss at batch 140 : 0.008769528940320015
Loss at batch 150 : 0.014119768515229225
Loss at batch 160 : 0.01081004086881876
Loss at batch 170 : 0.008785633370280266
Loss at batch 180 : 0.022307617589831352
Loss at batch 190 : 0.011304664425551891
Loss at batch 200 : 0.013868926092982292
Loss at batch 210 : 0.023418711498379707
Loss at batch 220 : 0.01565498858690262
Loss at batch 230 : 0.010159226134419441
Loss at batch 240 : 0.007497541606426239
Loss at batch 250 : 0.008929675444960594
Loss at batch 260 : 0.024219822138547897
Loss at batch 270 : 0.0193175096064806
Loss at batch 280 : 0.012420115992426872
Loss at batch 290 : 0.014911714941263199
Loss at batch 300 : 0.014115490019321442
Loss at batch 310 : 0.017574524506926537
Loss at batch 320 : 0.014954562298953533
Loss at batch 330 : 0.01657881960272789
Loss at batch 340 : 0.024855388328433037
Loss at batch 350 : 0.009924273937940598
Loss at batch 360 : 0.023483959957957268
Loss at batch 370 : 0.01794394664466381
epoch81 finished!
Loss at batch 10 : 0.00875804852694273
Loss at batch 20 : 0.012605546973645687
Loss at batch 30 : 0.020462853834033012
Loss at batch 40 : 0.008028616197407246
Loss at batch 50 : 0.017954716458916664
Loss at batch 60 : 0.01958872191607952
Loss at batch 70 : 0.010570896789431572
Loss at batch 80 : 0.019192762672901154
Loss at batch 90 : 0.014178277924656868
Loss at batch 100 : 0.017249232158064842
Loss at batch 110 : 0.016557665541768074
Loss at batch 120 : 0.009483344852924347
Loss at batch 130 : 0.013098943047225475
Loss at batch 140 : 0.011142633855342865
Loss at batch 150 : 0.0204620361328125
Loss at batch 160 : 0.008948210626840591
Loss at batch 170 : 0.009823440574109554
Loss at batch 180 : 0.015456418506801128
Loss at batch 190 : 0.019608333706855774
Loss at batch 200 : 0.012276441790163517
Loss at batch 210 : 0.009811189956963062
Loss at batch 220 : 0.014956527389585972
Loss at batch 230 : 0.010869034565985203
Loss at batch 240 : 0.019196482375264168
Loss at batch 250 : 0.011666341684758663
Loss at batch 260 : 0.012328943237662315
Loss at batch 270 : 0.012124433182179928
Loss at batch 280 : 0.01632622256875038
Loss at batch 290 : 0.020438188686966896
Loss at batch 300 : 0.0109293507412076
Loss at batch 310 : 0.013069742359220982
Loss at batch 320 : 0.020677907392382622
Loss at batch 330 : 0.016992824152112007
Loss at batch 340 : 0.014935575425624847
Loss at batch 350 : 0.007613044697791338
Loss at batch 360 : 0.01509971171617508
Loss at batch 370 : 0.00964948907494545
epoch82 finished!
Loss at batch 10 : 0.013437610119581223
Loss at batch 20 : 0.009587227366864681
Loss at batch 30 : 0.0169889647513628
Loss at batch 40 : 0.009710744023323059
Loss at batch 50 : 0.009570857509970665
Loss at batch 60 : 0.01029923651367426
Loss at batch 70 : 0.014181546866893768
Loss at batch 80 : 0.015385545790195465
Loss at batch 90 : 0.015563588589429855
Loss at batch 100 : 0.007124288938939571
Loss at batch 110 : 0.023890534415841103
Loss at batch 120 : 0.020628755912184715
Loss at batch 130 : 0.015497068874537945
Loss at batch 140 : 0.01430810522288084
Loss at batch 150 : 0.017495444044470787
Loss at batch 160 : 0.013698921538889408
Loss at batch 170 : 0.010914383456110954
Loss at batch 180 : 0.015337950550019741
Loss at batch 190 : 0.008240136317908764
Loss at batch 200 : 0.01828845776617527
Loss at batch 210 : 0.01193541195243597
Loss at batch 220 : 0.01434473879635334
Loss at batch 230 : 0.02643270418047905
Loss at batch 240 : 0.008127882145345211
Loss at batch 250 : 0.015920402482151985
Loss at batch 260 : 0.012793452478945255
Loss at batch 270 : 0.009954972192645073
Loss at batch 280 : 0.008109074085950851
Loss at batch 290 : 0.015008276328444481
Loss at batch 300 : 0.011453279294073582
Loss at batch 310 : 0.008890518918633461
Loss at batch 320 : 0.019313987344503403
Loss at batch 330 : 0.019902173429727554
Loss at batch 340 : 0.007799103390425444
Loss at batch 350 : 0.008774750865995884
Loss at batch 360 : 0.017255699262022972
Loss at batch 370 : 0.012878986075520515
epoch83 finished!
Loss at batch 10 : 0.013355960138142109
Loss at batch 20 : 0.008755461312830448
Loss at batch 30 : 0.01785046048462391
Loss at batch 40 : 0.014906520955264568
Loss at batch 50 : 0.010630469769239426
Loss at batch 60 : 0.014551464468240738
Loss at batch 70 : 0.015458351001143456
Loss at batch 80 : 0.0201535914093256
Loss at batch 90 : 0.02166203036904335
Loss at batch 100 : 0.015378081239759922
Loss at batch 110 : 0.012022032402455807
Loss at batch 120 : 0.010072071105241776
Loss at batch 130 : 0.018702341243624687
Loss at batch 140 : 0.010709723457694054
Loss at batch 150 : 0.024560172110795975
Loss at batch 160 : 0.014826730825006962
Loss at batch 170 : 0.024790335446596146
Loss at batch 180 : 0.006940484046936035
Loss at batch 190 : 0.01715146377682686
Loss at batch 200 : 0.013362877070903778
Loss at batch 210 : 0.021923990920186043
Loss at batch 220 : 0.010577182285487652
Loss at batch 230 : 0.016318950802087784
Loss at batch 240 : 0.012745094485580921
Loss at batch 250 : 0.014835531823337078
Loss at batch 260 : 0.0195724256336689
Loss at batch 270 : 0.009015134535729885
Loss at batch 280 : 0.013100018724799156
Loss at batch 290 : 0.009225631132721901
Loss at batch 300 : 0.015963546931743622
Loss at batch 310 : 0.02091377228498459
Loss at batch 320 : 0.01219725701957941
Loss at batch 330 : 0.024607812985777855
Loss at batch 340 : 0.01639365404844284
Loss at batch 350 : 0.011041694320738316
Loss at batch 360 : 0.00809510424733162
Loss at batch 370 : 0.01618751510977745
epoch84 finished!
Loss at batch 10 : 0.011598438024520874
Loss at batch 20 : 0.01625339686870575
Loss at batch 30 : 0.011203495785593987
Loss at batch 40 : 0.018760690465569496
Loss at batch 50 : 0.019502537325024605
Loss at batch 60 : 0.01125250943005085
Loss at batch 70 : 0.010455707088112831
Loss at batch 80 : 0.011838298290967941
Loss at batch 90 : 0.01063587423413992
Loss at batch 100 : 0.010990697890520096
Loss at batch 110 : 0.01661554165184498
Loss at batch 120 : 0.01632831245660782
Loss at batch 130 : 0.008220911957323551
Loss at batch 140 : 0.01405844185501337
Loss at batch 150 : 0.010978595353662968
Loss at batch 160 : 0.014005451463162899
Loss at batch 170 : 0.01614534854888916
Loss at batch 180 : 0.02715570293366909
Loss at batch 190 : 0.013384385034441948
Loss at batch 200 : 0.026667946949601173
Loss at batch 210 : 0.011518190614879131
Loss at batch 220 : 0.012005171738564968
Loss at batch 230 : 0.018863245844841003
Loss at batch 240 : 0.010860110633075237
Loss at batch 250 : 0.01328697893768549
Loss at batch 260 : 0.025591963902115822
Loss at batch 270 : 0.014504307880997658
Loss at batch 280 : 0.012419482693076134
Loss at batch 290 : 0.014742789790034294
Loss at batch 300 : 0.018241390585899353
Loss at batch 310 : 0.008427470922470093
Loss at batch 320 : 0.017383042722940445
Loss at batch 330 : 0.009859174489974976
Loss at batch 340 : 0.016655540093779564
Loss at batch 350 : 0.0182871725410223
Loss at batch 360 : 0.013264363631606102
Loss at batch 370 : 0.011948729865252972
epoch85 finished!
Loss at batch 10 : 0.014675791375339031
Loss at batch 20 : 0.013212477788329124
Loss at batch 30 : 0.009206246584653854
Loss at batch 40 : 0.01228533685207367
Loss at batch 50 : 0.007946694269776344
Loss at batch 60 : 0.015967106446623802
Loss at batch 70 : 0.02309286780655384
Loss at batch 80 : 0.014789348468184471
Loss at batch 90 : 0.01672261208295822
Loss at batch 100 : 0.016167476773262024
Loss at batch 110 : 0.022637490183115005
Loss at batch 120 : 0.011234275065362453
Loss at batch 130 : 0.010908729396760464
Loss at batch 140 : 0.016780829057097435
Loss at batch 150 : 0.016071252524852753
Loss at batch 160 : 0.005827789660543203
Loss at batch 170 : 0.009837176650762558
Loss at batch 180 : 0.01069653034210205
Loss at batch 190 : 0.017923718318343163
Loss at batch 200 : 0.010979371145367622
Loss at batch 210 : 0.013384194113314152
Loss at batch 220 : 0.017344919964671135
Loss at batch 230 : 0.017375441268086433
Loss at batch 240 : 0.012606443837285042
Loss at batch 250 : 0.016846520826220512
Loss at batch 260 : 0.010839606635272503
Loss at batch 270 : 0.0170297808945179
Loss at batch 280 : 0.00965131539851427
Loss at batch 290 : 0.018044348806142807
Loss at batch 300 : 0.03125713765621185
Loss at batch 310 : 0.010643263347446918
Loss at batch 320 : 0.00833128485828638
Loss at batch 330 : 0.00869868602603674
Loss at batch 340 : 0.007910656742751598
Loss at batch 350 : 0.013859431259334087
Loss at batch 360 : 0.012696374207735062
Loss at batch 370 : 0.009802475571632385
epoch86 finished!
Loss at batch 10 : 0.016229839995503426
Loss at batch 20 : 0.010401641018688679
Loss at batch 30 : 0.022526631131768227
Loss at batch 40 : 0.01168007031083107
Loss at batch 50 : 0.022825026884675026
Loss at batch 60 : 0.014704471454024315
Loss at batch 70 : 0.012685563415288925
Loss at batch 80 : 0.008697283454239368
Loss at batch 90 : 0.018847156316041946
Loss at batch 100 : 0.011123301461338997
Loss at batch 110 : 0.010253874585032463
Loss at batch 120 : 0.019546210765838623
Loss at batch 130 : 0.011676368303596973
Loss at batch 140 : 0.01184376422315836
Loss at batch 150 : 0.01246662624180317
Loss at batch 160 : 0.011878982186317444
Loss at batch 170 : 0.01677490398287773
Loss at batch 180 : 0.015408528968691826
Loss at batch 190 : 0.01866898499429226
Loss at batch 200 : 0.01704283617436886
Loss at batch 210 : 0.014706275425851345
Loss at batch 220 : 0.01868184469640255
Loss at batch 230 : 0.015310393646359444
Loss at batch 240 : 0.010020527988672256
Loss at batch 250 : 0.010125355795025826
Loss at batch 260 : 0.011234748177230358
Loss at batch 270 : 0.010866764932870865
Loss at batch 280 : 0.01539274025708437
Loss at batch 290 : 0.024834847077727318
Loss at batch 300 : 0.01409389078617096
Loss at batch 310 : 0.020657610148191452
Loss at batch 320 : 0.011436809785664082
Loss at batch 330 : 0.012672312557697296
Loss at batch 340 : 0.011990447528660297
Loss at batch 350 : 0.01083727553486824
Loss at batch 360 : 0.009596189484000206
Loss at batch 370 : 0.01607445254921913
epoch87 finished!
Loss at batch 10 : 0.02290487475693226
Loss at batch 20 : 0.006427372805774212
Loss at batch 30 : 0.006806818302720785
Loss at batch 40 : 0.017806099727749825
Loss at batch 50 : 0.01366186048835516
Loss at batch 60 : 0.009569242596626282
Loss at batch 70 : 0.008649541065096855
Loss at batch 80 : 0.012249557301402092
Loss at batch 90 : 0.00890928041189909
Loss at batch 100 : 0.011924044229090214
Loss at batch 110 : 0.019767506048083305
Loss at batch 120 : 0.02121550217270851
Loss at batch 130 : 0.010093930177390575
Loss at batch 140 : 0.009834003634750843
Loss at batch 150 : 0.017491063103079796
Loss at batch 160 : 0.0157477930188179
Loss at batch 170 : 0.019061211496591568
Loss at batch 180 : 0.02457394078373909
Loss at batch 190 : 0.011224429123103619
Loss at batch 200 : 0.013460228219628334
Loss at batch 210 : 0.01880965381860733
Loss at batch 220 : 0.01868809200823307
Loss at batch 230 : 0.01760253868997097
Loss at batch 240 : 0.014708593487739563
Loss at batch 250 : 0.018499458208680153
Loss at batch 260 : 0.01992153562605381
Loss at batch 270 : 0.01390390656888485
Loss at batch 280 : 0.010698733851313591
Loss at batch 290 : 0.0082548214122653
Loss at batch 300 : 0.01490053255110979
Loss at batch 310 : 0.0089049581438303
Loss at batch 320 : 0.009432314895093441
Loss at batch 330 : 0.008568107150495052
Loss at batch 340 : 0.006964090280234814
Loss at batch 350 : 0.008217192254960537
Loss at batch 360 : 0.016034863889217377
Loss at batch 370 : 0.012468797154724598
epoch88 finished!
Loss at batch 10 : 0.01828189007937908
Loss at batch 20 : 0.00945859495550394
Loss at batch 30 : 0.02016906812787056
Loss at batch 40 : 0.019357679411768913
Loss at batch 50 : 0.008961406536400318
Loss at batch 60 : 0.01946706883609295
Loss at batch 70 : 0.023771565407514572
Loss at batch 80 : 0.0134787168353796
Loss at batch 90 : 0.00825211126357317
Loss at batch 100 : 0.012623426504433155
Loss at batch 110 : 0.011718415655195713
Loss at batch 120 : 0.00688250781968236
Loss at batch 130 : 0.017831413075327873
Loss at batch 140 : 0.015982072800397873
Loss at batch 150 : 0.016895584762096405
Loss at batch 160 : 0.016971880570054054
Loss at batch 170 : 0.021149899810552597
Loss at batch 180 : 0.013128004036843777
Loss at batch 190 : 0.009054192341864109
Loss at batch 200 : 0.016605319455266
Loss at batch 210 : 0.010765383020043373
Loss at batch 220 : 0.012018087320029736
Loss at batch 230 : 0.02848304808139801
Loss at batch 240 : 0.027141939848661423
Loss at batch 250 : 0.015168512240052223
Loss at batch 260 : 0.018828410655260086
Loss at batch 270 : 0.013333674520254135
Loss at batch 280 : 0.010401585139334202
Loss at batch 290 : 0.016397513449192047
Loss at batch 300 : 0.008995859883725643
Loss at batch 310 : 0.01648123189806938
Loss at batch 320 : 0.019824743270874023
Loss at batch 330 : 0.01218523271381855
Loss at batch 340 : 0.008733972907066345
Loss at batch 350 : 0.018903063610196114
Loss at batch 360 : 0.01666092686355114
Loss at batch 370 : 0.013507623225450516
epoch89 finished!
Loss at batch 10 : 0.022140244022011757
Loss at batch 20 : 0.020221110433340073
Loss at batch 30 : 0.013958477415144444
Loss at batch 40 : 0.014110637828707695
Loss at batch 50 : 0.02741008810698986
Loss at batch 60 : 0.015029316768050194
Loss at batch 70 : 0.023271411657333374
Loss at batch 80 : 0.009372434578835964
Loss at batch 90 : 0.011927722953259945
Loss at batch 100 : 0.009224845096468925
Loss at batch 110 : 0.022039787843823433
Loss at batch 120 : 0.013999680057168007
Loss at batch 130 : 0.01264613214880228
Loss at batch 140 : 0.008354811929166317
Loss at batch 150 : 0.010895914398133755
Loss at batch 160 : 0.01300401333719492
Loss at batch 170 : 0.019456418231129646
Loss at batch 180 : 0.008862614631652832
Loss at batch 190 : 0.015086534433066845
Loss at batch 200 : 0.010131282731890678
Loss at batch 210 : 0.02134312316775322
Loss at batch 220 : 0.02528383955359459
Loss at batch 230 : 0.024069644510746002
Loss at batch 240 : 0.013967068865895271
Loss at batch 250 : 0.014514366164803505
Loss at batch 260 : 0.013091650791466236
Loss at batch 270 : 0.010488849133253098
Loss at batch 280 : 0.018783314153552055
Loss at batch 290 : 0.018729930743575096
Loss at batch 300 : 0.013639379292726517
Loss at batch 310 : 0.01460231188684702
Loss at batch 320 : 0.01639828272163868
Loss at batch 330 : 0.025333061814308167
Loss at batch 340 : 0.016323471441864967
Loss at batch 350 : 0.018325109034776688
Loss at batch 360 : 0.011959655210375786
Loss at batch 370 : 0.013742305338382721
epoch90 finished!
Loss at batch 10 : 0.02070729061961174
Loss at batch 20 : 0.020176036283373833
Loss at batch 30 : 0.01475412305444479
Loss at batch 40 : 0.012929328717291355
Loss at batch 50 : 0.016186101362109184
Loss at batch 60 : 0.011513886973261833
Loss at batch 70 : 0.021322261542081833
Loss at batch 80 : 0.013149200938642025
Loss at batch 90 : 0.012048265896737576
Loss at batch 100 : 0.019895927980542183
Loss at batch 110 : 0.009553459472954273
Loss at batch 120 : 0.011602308601140976
Loss at batch 130 : 0.01679961010813713
Loss at batch 140 : 0.013642319478094578
Loss at batch 150 : 0.007930622436106205
Loss at batch 160 : 0.008478295058012009
Loss at batch 170 : 0.012309970334172249
Loss at batch 180 : 0.022640762850642204
Loss at batch 190 : 0.00973651185631752
Loss at batch 200 : 0.019005877897143364
Loss at batch 210 : 0.018384966999292374
Loss at batch 220 : 0.016995394602417946
Loss at batch 230 : 0.015456796623766422
Loss at batch 240 : 0.009690326638519764
Loss at batch 250 : 0.0270839910954237
Loss at batch 260 : 0.010086540132761002
Loss at batch 270 : 0.013359645381569862
Loss at batch 280 : 0.011621614918112755
Loss at batch 290 : 0.01480059139430523
Loss at batch 300 : 0.021622471511363983
Loss at batch 310 : 0.014050841331481934
Loss at batch 320 : 0.010662943124771118
Loss at batch 330 : 0.02268439717590809
Loss at batch 340 : 0.014909408055245876
Loss at batch 350 : 0.013820712454617023
Loss at batch 360 : 0.011988747864961624
Loss at batch 370 : 0.018125467002391815
epoch91 finished!
Loss at batch 10 : 0.01437431387603283
Loss at batch 20 : 0.01793082244694233
Loss at batch 30 : 0.012632098980247974
Loss at batch 40 : 0.007642787415534258
Loss at batch 50 : 0.010947862640023232
Loss at batch 60 : 0.01494342926889658
Loss at batch 70 : 0.015824172645807266
Loss at batch 80 : 0.01719014160335064
Loss at batch 90 : 0.018230760470032692
Loss at batch 100 : 0.014649116434156895
Loss at batch 110 : 0.015748778358101845
Loss at batch 120 : 0.011329567059874535
Loss at batch 130 : 0.01566973701119423
Loss at batch 140 : 0.01603744737803936
Loss at batch 150 : 0.012827742844820023
Loss at batch 160 : 0.019954893738031387
Loss at batch 170 : 0.01059736032038927
Loss at batch 180 : 0.02334653213620186
Loss at batch 190 : 0.008967542089521885
Loss at batch 200 : 0.01483798585832119
Loss at batch 210 : 0.01378913689404726
Loss at batch 220 : 0.021785564720630646
Loss at batch 230 : 0.012055463157594204
Loss at batch 240 : 0.011055435985326767
Loss at batch 250 : 0.011454169638454914
Loss at batch 260 : 0.020340045914053917
Loss at batch 270 : 0.018541747704148293
Loss at batch 280 : 0.019902518019080162
Loss at batch 290 : 0.010472031310200691
Loss at batch 300 : 0.01774439960718155
Loss at batch 310 : 0.01244986243546009
Loss at batch 320 : 0.015675891190767288
Loss at batch 330 : 0.012902713380753994
Loss at batch 340 : 0.018153848126530647
Loss at batch 350 : 0.01370181143283844
Loss at batch 360 : 0.008884504437446594
Loss at batch 370 : 0.015219402499496937
epoch92 finished!
Loss at batch 10 : 0.011669116094708443
Loss at batch 20 : 0.010914584621787071
Loss at batch 30 : 0.011878063902258873
Loss at batch 40 : 0.016806326806545258
Loss at batch 50 : 0.01094938162714243
Loss at batch 60 : 0.019238393753767014
Loss at batch 70 : 0.022305605933070183
Loss at batch 80 : 0.011176476255059242
Loss at batch 90 : 0.013807233422994614
Loss at batch 100 : 0.012545807287096977
Loss at batch 110 : 0.019672559574246407
Loss at batch 120 : 0.01303498912602663
Loss at batch 130 : 0.031407199800014496
Loss at batch 140 : 0.028242290019989014
Loss at batch 150 : 0.019215775653719902
Loss at batch 160 : 0.006301336456090212
Loss at batch 170 : 0.022397248074412346
Loss at batch 180 : 0.025193579494953156
Loss at batch 190 : 0.012333604507148266
Loss at batch 200 : 0.026550229638814926
Loss at batch 210 : 0.01484594214707613
Loss at batch 220 : 0.010586176998913288
Loss at batch 230 : 0.020456397905945778
Loss at batch 240 : 0.030606254935264587
Loss at batch 250 : 0.019191406667232513
Loss at batch 260 : 0.01758962869644165
Loss at batch 270 : 0.01970061846077442
Loss at batch 280 : 0.007933325134217739
Loss at batch 290 : 0.008253033272922039
Loss at batch 300 : 0.012752539478242397
Loss at batch 310 : 0.01457307394593954
Loss at batch 320 : 0.011995547451078892
Loss at batch 330 : 0.011329409666359425
Loss at batch 340 : 0.014808881096541882
Loss at batch 350 : 0.015084093436598778
Loss at batch 360 : 0.0063989413902163506
Loss at batch 370 : 0.009708269499242306
epoch93 finished!
Loss at batch 10 : 0.009488028474152088
Loss at batch 20 : 0.013438712805509567
Loss at batch 30 : 0.018363041803240776
Loss at batch 40 : 0.01165896188467741
Loss at batch 50 : 0.012745775282382965
Loss at batch 60 : 0.017070643603801727
Loss at batch 70 : 0.009810768999159336
Loss at batch 80 : 0.02322458289563656
Loss at batch 90 : 0.031521767377853394
Loss at batch 100 : 0.014493410475552082
Loss at batch 110 : 0.021764924749732018
Loss at batch 120 : 0.004974124953150749
Loss at batch 130 : 0.01229453831911087
Loss at batch 140 : 0.011153893545269966
Loss at batch 150 : 0.019706005230545998
Loss at batch 160 : 0.016852518543601036
Loss at batch 170 : 0.014076360501348972
Loss at batch 180 : 0.01246793381869793
Loss at batch 190 : 0.010511906817555428
Loss at batch 200 : 0.010984174907207489
Loss at batch 210 : 0.012023940682411194
Loss at batch 220 : 0.008389174938201904
Loss at batch 230 : 0.014912315644323826
Loss at batch 240 : 0.018938696011900902
Loss at batch 250 : 0.011534396559000015
Loss at batch 260 : 0.01878909021615982
Loss at batch 270 : 0.01430156547576189
Loss at batch 280 : 0.010682501830160618
Loss at batch 290 : 0.010378343984484673
Loss at batch 300 : 0.018271472305059433
Loss at batch 310 : 0.019072555005550385
Loss at batch 320 : 0.007939056493341923
Loss at batch 330 : 0.0132745997980237
Loss at batch 340 : 0.018844855949282646
Loss at batch 350 : 0.014646926894783974
Loss at batch 360 : 0.011636560782790184
Loss at batch 370 : 0.016048502177000046
epoch94 finished!
Loss at batch 10 : 0.020018240436911583
Loss at batch 20 : 0.011494144797325134
Loss at batch 30 : 0.02126355469226837
Loss at batch 40 : 0.023995112627744675
Loss at batch 50 : 0.02440485544502735
Loss at batch 60 : 0.006975503638386726
Loss at batch 70 : 0.008944537490606308
Loss at batch 80 : 0.011909051798284054
Loss at batch 90 : 0.01459544152021408
Loss at batch 100 : 0.01551475003361702
Loss at batch 110 : 0.022984251379966736
Loss at batch 120 : 0.016375591978430748
Loss at batch 130 : 0.012807976454496384
Loss at batch 140 : 0.012985335662961006
Loss at batch 150 : 0.012633408419787884
Loss at batch 160 : 0.008335495367646217
Loss at batch 170 : 0.011584109626710415
Loss at batch 180 : 0.01285463385283947
Loss at batch 190 : 0.01692204363644123
Loss at batch 200 : 0.016895003616809845
Loss at batch 210 : 0.014128169976174831
Loss at batch 220 : 0.014446021988987923
Loss at batch 230 : 0.018423326313495636
Loss at batch 240 : 0.019520049914717674
Loss at batch 250 : 0.007970713078975677
Loss at batch 260 : 0.020518358796834946
Loss at batch 270 : 0.01932484097778797
Loss at batch 280 : 0.010096465237438679
Loss at batch 290 : 0.01588302291929722
Loss at batch 300 : 0.006462618708610535
Loss at batch 310 : 0.008569501340389252
Loss at batch 320 : 0.014717478305101395
Loss at batch 330 : 0.010541893541812897
Loss at batch 340 : 0.011702143587172031
Loss at batch 350 : 0.014732827432453632
Loss at batch 360 : 0.008890964090824127
Loss at batch 370 : 0.01622551679611206
epoch95 finished!
Loss at batch 10 : 0.020676041021943092
Loss at batch 20 : 0.0106631089001894
Loss at batch 30 : 0.014405537396669388
Loss at batch 40 : 0.01212314236909151
Loss at batch 50 : 0.023048782721161842
Loss at batch 60 : 0.011675592511892319
Loss at batch 70 : 0.01624857820570469
Loss at batch 80 : 0.015054491348564625
Loss at batch 90 : 0.01264004223048687
Loss at batch 100 : 0.018796777352690697
Loss at batch 110 : 0.00999456923455
Loss at batch 120 : 0.021056700497865677
Loss at batch 130 : 0.017351681366562843
Loss at batch 140 : 0.012399728409945965
Loss at batch 150 : 0.017128830775618553
Loss at batch 160 : 0.014651867561042309
Loss at batch 170 : 0.008454724214971066
Loss at batch 180 : 0.011827229522168636
Loss at batch 190 : 0.01898985169827938
Loss at batch 200 : 0.010258982889354229
Loss at batch 210 : 0.011320874094963074
Loss at batch 220 : 0.014534185640513897
Loss at batch 230 : 0.00951528362929821
Loss at batch 240 : 0.010962615720927715
Loss at batch 250 : 0.018470268696546555
Loss at batch 260 : 0.009026908315718174
Loss at batch 270 : 0.018295226618647575
Loss at batch 280 : 0.010229644365608692
Loss at batch 290 : 0.011163480579853058
Loss at batch 300 : 0.017049290239810944
Loss at batch 310 : 0.012481250800192356
Loss at batch 320 : 0.01795366406440735
Loss at batch 330 : 0.015885718166828156
Loss at batch 340 : 0.014303411357104778
Loss at batch 350 : 0.00969188753515482
Loss at batch 360 : 0.022408772259950638
Loss at batch 370 : 0.022522594779729843
epoch96 finished!
Loss at batch 10 : 0.019544074311852455
Loss at batch 20 : 0.010955634526908398
Loss at batch 30 : 0.012565994635224342
Loss at batch 40 : 0.008841603994369507
Loss at batch 50 : 0.014558246359229088
Loss at batch 60 : 0.013519378378987312
Loss at batch 70 : 0.01170154009014368
Loss at batch 80 : 0.013140348717570305
Loss at batch 90 : 0.010797386057674885
Loss at batch 100 : 0.011909380555152893
Loss at batch 110 : 0.013276403769850731
Loss at batch 120 : 0.01219302136451006
Loss at batch 130 : 0.016988694667816162
Loss at batch 140 : 0.008168868720531464
Loss at batch 150 : 0.01242879219353199
Loss at batch 160 : 0.010403499007225037
Loss at batch 170 : 0.015400374308228493
Loss at batch 180 : 0.012927483767271042
Loss at batch 190 : 0.008732043206691742
Loss at batch 200 : 0.01046542078256607
Loss at batch 210 : 0.013126660138368607
Loss at batch 220 : 0.02163104899227619
Loss at batch 230 : 0.008273971267044544
Loss at batch 240 : 0.01067525427788496
Loss at batch 250 : 0.014273732900619507
Loss at batch 260 : 0.018764471635222435
Loss at batch 270 : 0.015487155877053738
Loss at batch 280 : 0.01971648447215557
Loss at batch 290 : 0.012654553167521954
Loss at batch 300 : 0.014823860488831997
Loss at batch 310 : 0.02683938853442669
Loss at batch 320 : 0.01383137796074152
Loss at batch 330 : 0.01781986467540264
Loss at batch 340 : 0.012328097596764565
Loss at batch 350 : 0.02152368426322937
Loss at batch 360 : 0.009135247208178043
Loss at batch 370 : 0.011875291354954243
epoch97 finished!
Loss at batch 10 : 0.010913645848631859
Loss at batch 20 : 0.020406628027558327
Loss at batch 30 : 0.01514885202050209
Loss at batch 40 : 0.008951053023338318
Loss at batch 50 : 0.01114173885434866
Loss at batch 60 : 0.012704230844974518
Loss at batch 70 : 0.011880035512149334
Loss at batch 80 : 0.011828109622001648
Loss at batch 90 : 0.01878398098051548
Loss at batch 100 : 0.0150259118527174
Loss at batch 110 : 0.01267156284302473
Loss at batch 120 : 0.018041489645838737
Loss at batch 130 : 0.007648028898984194
Loss at batch 140 : 0.008592975325882435
Loss at batch 150 : 0.01541940402239561
Loss at batch 160 : 0.018356140702962875
Loss at batch 170 : 0.012178981676697731
Loss at batch 180 : 0.01769743114709854
Loss at batch 190 : 0.01818547397851944
Loss at batch 200 : 0.00807267241179943
Loss at batch 210 : 0.014093220233917236
Loss at batch 220 : 0.01465900894254446
Loss at batch 230 : 0.014498262666165829
Loss at batch 240 : 0.011291101574897766
Loss at batch 250 : 0.010934663005173206
Loss at batch 260 : 0.012581808492541313
Loss at batch 270 : 0.016550706699490547
Loss at batch 280 : 0.012059549801051617
Loss at batch 290 : 0.017392627894878387
Loss at batch 300 : 0.009114943444728851
Loss at batch 310 : 0.015053960494697094
Loss at batch 320 : 0.009597290307283401
Loss at batch 330 : 0.016730066388845444
Loss at batch 340 : 0.014293910935521126
Loss at batch 350 : 0.014333163388073444
Loss at batch 360 : 0.00856802612543106
Loss at batch 370 : 0.014139904640614986
epoch98 finished!
Loss at batch 10 : 0.005021044984459877
Loss at batch 20 : 0.010684100911021233
Loss at batch 30 : 0.007989266887307167
Loss at batch 40 : 0.015580045990645885
Loss at batch 50 : 0.013107444159686565
Loss at batch 60 : 0.014670207165181637
Loss at batch 70 : 0.008027073927223682
Loss at batch 80 : 0.020678820088505745
Loss at batch 90 : 0.014854831621050835
Loss at batch 100 : 0.013967580161988735
Loss at batch 110 : 0.009886377491056919
Loss at batch 120 : 0.008789352141320705
Loss at batch 130 : 0.014810914173722267
Loss at batch 140 : 0.011083870194852352
Loss at batch 150 : 0.02368883416056633
Loss at batch 160 : 0.013488651253283024
Loss at batch 170 : 0.013876663520932198
Loss at batch 180 : 0.018548306077718735
Loss at batch 190 : 0.015483991242945194
Loss at batch 200 : 0.026200054213404655
Loss at batch 210 : 0.012142435647547245
Loss at batch 220 : 0.019327210262417793
Loss at batch 230 : 0.01153538841754198
Loss at batch 240 : 0.010911660268902779
Loss at batch 250 : 0.013813784345984459
Loss at batch 260 : 0.019601168110966682
Loss at batch 270 : 0.01891864463686943
Loss at batch 280 : 0.027635229751467705
Loss at batch 290 : 0.010191784240305424
Loss at batch 300 : 0.015506643801927567
Loss at batch 310 : 0.017894398421049118
Loss at batch 320 : 0.023031514137983322
Loss at batch 330 : 0.014025546610355377
Loss at batch 340 : 0.018602019175887108
Loss at batch 350 : 0.015129215084016323
Loss at batch 360 : 0.011817552149295807
Loss at batch 370 : 0.010149826295673847
epoch99 finished!
Loss at batch 10 : 0.017774736508727074
Loss at batch 20 : 0.013683464378118515
Loss at batch 30 : 0.009828157722949982
Loss at batch 40 : 0.011685062199831009
Loss at batch 50 : 0.015760337933897972
Loss at batch 60 : 0.01360415294766426
Loss at batch 70 : 0.021273517981171608
Loss at batch 80 : 0.014864949509501457
Loss at batch 90 : 0.00985929649323225
Loss at batch 100 : 0.01443074457347393
Loss at batch 110 : 0.009368347935378551
Loss at batch 120 : 0.00951249711215496
Loss at batch 130 : 0.012081576511263847
Loss at batch 140 : 0.013370651751756668
Loss at batch 150 : 0.010331293568015099
Loss at batch 160 : 0.010819653049111366
Loss at batch 170 : 0.01874239556491375
Loss at batch 180 : 0.01261141523718834
Loss at batch 190 : 0.014470460824668407
Loss at batch 200 : 0.01989232562482357
Loss at batch 210 : 0.01902962662279606
Loss at batch 220 : 0.024840490892529488
Loss at batch 230 : 0.011767402291297913
Loss at batch 240 : 0.013184440322220325
Loss at batch 250 : 0.013385102152824402
Loss at batch 260 : 0.018442751839756966
Loss at batch 270 : 0.02478792332112789
Loss at batch 280 : 0.01528677623718977
Loss at batch 290 : 0.013541506603360176
Loss at batch 300 : 0.02779303304851055
Loss at batch 310 : 0.014920135028660297
Loss at batch 320 : 0.023221859708428383
Loss at batch 330 : 0.018308671191334724
Loss at batch 340 : 0.008088813163340092
Loss at batch 350 : 0.011245987378060818
Loss at batch 360 : 0.010922086425125599
Loss at batch 370 : 0.018660254776477814
epoch100 finished!
Loss at batch 10 : 0.009508947841823101
Loss at batch 20 : 0.0101018026471138
Loss at batch 30 : 0.0180502962321043
Loss at batch 40 : 0.012680776417255402
Loss at batch 50 : 0.012087434530258179
Loss at batch 60 : 0.015544313937425613
Loss at batch 70 : 0.01866855099797249
Loss at batch 80 : 0.014070163480937481
Loss at batch 90 : 0.012103721499443054
Loss at batch 100 : 0.011156248860061169
Loss at batch 110 : 0.010195794515311718
Loss at batch 120 : 0.01855454593896866
Loss at batch 130 : 0.009768083691596985
Loss at batch 140 : 0.01199545431882143
Loss at batch 150 : 0.009634343907237053
Loss at batch 160 : 0.01003982126712799
Loss at batch 170 : 0.014947211369872093
Loss at batch 180 : 0.017534049227833748
Loss at batch 190 : 0.010093881748616695
Loss at batch 200 : 0.018428416922688484
Loss at batch 210 : 0.010861668735742569
Loss at batch 220 : 0.020010393112897873
Loss at batch 230 : 0.009829728864133358
Loss at batch 240 : 0.015815332531929016
Loss at batch 250 : 0.013709602877497673
Loss at batch 260 : 0.017334146425127983
Loss at batch 270 : 0.011666121892631054
Loss at batch 280 : 0.019832564517855644
Loss at batch 290 : 0.009369872510433197
Loss at batch 300 : 0.012134633027017117
Loss at batch 310 : 0.015499149449169636
Loss at batch 320 : 0.023381290957331657
Loss at batch 330 : 0.022402692586183548
Loss at batch 340 : 0.008143911138176918
Loss at batch 350 : 0.00827137939631939
Loss at batch 360 : 0.01177571713924408
Loss at batch 370 : 0.019493985921144485
epoch101 finished!
Loss at batch 10 : 0.01228686235845089
Loss at batch 20 : 0.018032638356089592
Loss at batch 30 : 0.012943074107170105
Loss at batch 40 : 0.017775241285562515
Loss at batch 50 : 0.020734166726469994
Loss at batch 60 : 0.0158315971493721
Loss at batch 70 : 0.01439802534878254
Loss at batch 80 : 0.008088166825473309
Loss at batch 90 : 0.010364774614572525
Loss at batch 100 : 0.015669824555516243
Loss at batch 110 : 0.013319522142410278
Loss at batch 120 : 0.017333179712295532
Loss at batch 130 : 0.021579738706350327
Loss at batch 140 : 0.009840437211096287
Loss at batch 150 : 0.01477778609842062
Loss at batch 160 : 0.017612481489777565
Loss at batch 170 : 0.013748408295214176
Loss at batch 180 : 0.01810462772846222
Loss at batch 190 : 0.012429841794073582
Loss at batch 200 : 0.011681855656206608
Loss at batch 210 : 0.01755410060286522
Loss at batch 220 : 0.017591282725334167
Loss at batch 230 : 0.014467195607721806
Loss at batch 240 : 0.015983743593096733
Loss at batch 250 : 0.013466425240039825
Loss at batch 260 : 0.013422723859548569
Loss at batch 270 : 0.018635332584381104
Loss at batch 280 : 0.018753424286842346
Loss at batch 290 : 0.017986146733164787
Loss at batch 300 : 0.009784274734556675
Loss at batch 310 : 0.013233736157417297
Loss at batch 320 : 0.015634145587682724
Loss at batch 330 : 0.011593121103942394
Loss at batch 340 : 0.011164254508912563
Loss at batch 350 : 0.013450059108436108
Loss at batch 360 : 0.016570746898651123
Loss at batch 370 : 0.00784987024962902
epoch102 finished!
Loss at batch 10 : 0.014284191653132439
Loss at batch 20 : 0.020606068894267082
Loss at batch 30 : 0.011944139376282692
Loss at batch 40 : 0.01384135615080595
Loss at batch 50 : 0.013537752442061901
Loss at batch 60 : 0.013392956927418709
Loss at batch 70 : 0.019951922819018364
Loss at batch 80 : 0.012491866946220398
Loss at batch 90 : 0.010400811210274696
Loss at batch 100 : 0.010161744430661201
Loss at batch 110 : 0.01846831478178501
Loss at batch 120 : 0.009274689480662346
Loss at batch 130 : 0.01755025051534176
Loss at batch 140 : 0.014962046407163143
Loss at batch 150 : 0.020201776176691055
Loss at batch 160 : 0.01297789067029953
Loss at batch 170 : 0.018881957978010178
Loss at batch 180 : 0.016917722299695015
Loss at batch 190 : 0.009806700982153416
Loss at batch 200 : 0.017249854281544685
Loss at batch 210 : 0.023549413308501244
Loss at batch 220 : 0.013913650065660477
Loss at batch 230 : 0.015157953836023808
Loss at batch 240 : 0.020577214658260345
Loss at batch 250 : 0.015634246170520782
Loss at batch 260 : 0.015277727507054806
Loss at batch 270 : 0.018416397273540497
Loss at batch 280 : 0.015863118693232536
Loss at batch 290 : 0.012582908384501934
Loss at batch 300 : 0.017511053010821342
Loss at batch 310 : 0.019015813246369362
Loss at batch 320 : 0.022699521854519844
Loss at batch 330 : 0.011671083979308605
Loss at batch 340 : 0.014513998292386532
Loss at batch 350 : 0.010099741630256176
Loss at batch 360 : 0.011470191180706024
Loss at batch 370 : 0.01735706813633442
epoch103 finished!
Loss at batch 10 : 0.01637330837547779
Loss at batch 20 : 0.026076840236783028
Loss at batch 30 : 0.015934573486447334
Loss at batch 40 : 0.016360871493816376
Loss at batch 50 : 0.015503779985010624
Loss at batch 60 : 0.016296030953526497
Loss at batch 70 : 0.013673888519406319
Loss at batch 80 : 0.01614188775420189
Loss at batch 90 : 0.015934061259031296
Loss at batch 100 : 0.016093553975224495
Loss at batch 110 : 0.01746329478919506
Loss at batch 120 : 0.01344618946313858
Loss at batch 130 : 0.02375844307243824
Loss at batch 140 : 0.02064947970211506
Loss at batch 150 : 0.013573093339800835
Loss at batch 160 : 0.018167389556765556
Loss at batch 170 : 0.02056625485420227
Loss at batch 180 : 0.01899845153093338
Loss at batch 190 : 0.015540319494903088
Loss at batch 200 : 0.018263166770339012
Loss at batch 210 : 0.02429649978876114
Loss at batch 220 : 0.01180836372077465
Loss at batch 230 : 0.010899628512561321
Loss at batch 240 : 0.013455210253596306
Loss at batch 250 : 0.02427474968135357
Loss at batch 260 : 0.013005387969315052
Loss at batch 270 : 0.011441589333117008
Loss at batch 280 : 0.022156715393066406
Loss at batch 290 : 0.020016208291053772
Loss at batch 300 : 0.015011916868388653
Loss at batch 310 : 0.013152019120752811
Loss at batch 320 : 0.010142216458916664
Loss at batch 330 : 0.01146300695836544
Loss at batch 340 : 0.01234870869666338
Loss at batch 350 : 0.01598300412297249
Loss at batch 360 : 0.00767774460837245
Loss at batch 370 : 0.009139110334217548
epoch104 finished!
Loss at batch 10 : 0.014385592192411423
Loss at batch 20 : 0.014891546219587326
Loss at batch 30 : 0.009326049126684666
Loss at batch 40 : 0.020516427233815193
Loss at batch 50 : 0.013639183714985847
Loss at batch 60 : 0.010635245591402054
Loss at batch 70 : 0.01505154650658369
Loss at batch 80 : 0.018751848489046097
Loss at batch 90 : 0.011427560821175575
Loss at batch 100 : 0.013555310666561127
Loss at batch 110 : 0.02208508364856243
Loss at batch 120 : 0.011276991106569767
Loss at batch 130 : 0.021281644701957703
Loss at batch 140 : 0.011475974693894386
Loss at batch 150 : 0.012981744483113289
Loss at batch 160 : 0.022681888192892075
Loss at batch 170 : 0.01121593825519085
Loss at batch 180 : 0.0377427414059639
Loss at batch 190 : 0.009281408041715622
Loss at batch 200 : 0.014394301921129227
Loss at batch 210 : 0.017252838239073753
Loss at batch 220 : 0.013785150833427906
Loss at batch 230 : 0.013519760221242905
Loss at batch 240 : 0.012074384838342667
Loss at batch 250 : 0.01044568233191967
Loss at batch 260 : 0.017587346956133842
Loss at batch 270 : 0.011413919739425182
Loss at batch 280 : 0.010519861243665218
Loss at batch 290 : 0.015491592697799206
Loss at batch 300 : 0.023438742384314537
Loss at batch 310 : 0.012042965739965439
Loss at batch 320 : 0.022609274834394455
Loss at batch 330 : 0.013781577348709106
Loss at batch 340 : 0.03138144314289093
Loss at batch 350 : 0.01800956390798092
Loss at batch 360 : 0.015762727707624435
Loss at batch 370 : 0.007550823036581278
epoch105 finished!
Loss at batch 10 : 0.011053123511373997
Loss at batch 20 : 0.012671822682023048
Loss at batch 30 : 0.016007646918296814
Loss at batch 40 : 0.02253248356282711
Loss at batch 50 : 0.009684916585683823
Loss at batch 60 : 0.011938495561480522
Loss at batch 70 : 0.029189882799983025
Loss at batch 80 : 0.013211565092206001
Loss at batch 90 : 0.015250935219228268
Loss at batch 100 : 0.024785898625850677
Loss at batch 110 : 0.007391566410660744
Loss at batch 120 : 0.013332841917872429
Loss at batch 130 : 0.0187236201018095
Loss at batch 140 : 0.013712313957512379
Loss at batch 150 : 0.021925074979662895
Loss at batch 160 : 0.009773957543075085
Loss at batch 170 : 0.02445169910788536
Loss at batch 180 : 0.010755612514913082
Loss at batch 190 : 0.016090910881757736
Loss at batch 200 : 0.015961719676852226
Loss at batch 210 : 0.013837785460054874
Loss at batch 220 : 0.011851378716528416
Loss at batch 230 : 0.014648997224867344
Loss at batch 240 : 0.01255611702799797
Loss at batch 250 : 0.015991153195500374
Loss at batch 260 : 0.01946333609521389
Loss at batch 270 : 0.016263924539089203
Loss at batch 280 : 0.01112508773803711
Loss at batch 290 : 0.022498194128274918
Loss at batch 300 : 0.01722499169409275
Loss at batch 310 : 0.013948116451501846
Loss at batch 320 : 0.010863101109862328
Loss at batch 330 : 0.012837299145758152
Loss at batch 340 : 0.02394147589802742
Loss at batch 350 : 0.018978513777256012
Loss at batch 360 : 0.015463670715689659
Loss at batch 370 : 0.022881239652633667
epoch106 finished!
Loss at batch 10 : 0.024310331791639328
Loss at batch 20 : 0.010224448516964912
Loss at batch 30 : 0.010264125652611256
Loss at batch 40 : 0.0256081223487854
Loss at batch 50 : 0.011758726090192795
Loss at batch 60 : 0.014980311505496502
Loss at batch 70 : 0.017755892127752304
Loss at batch 80 : 0.014538450166583061
Loss at batch 90 : 0.01838797889649868
Loss at batch 100 : 0.011648028157651424
Loss at batch 110 : 0.01246512308716774
Loss at batch 120 : 0.0121379429474473
Loss at batch 130 : 0.011324141174554825
Loss at batch 140 : 0.00961011927574873
Loss at batch 150 : 0.015008640475571156
Loss at batch 160 : 0.008322170004248619
Loss at batch 170 : 0.01630760170519352
Loss at batch 180 : 0.011752938851714134
Loss at batch 190 : 0.014123397879302502
Loss at batch 200 : 0.018308432772755623
Loss at batch 210 : 0.009090458042919636
Loss at batch 220 : 0.01238125842064619
Loss at batch 230 : 0.022247755900025368
Loss at batch 240 : 0.015229971148073673
Loss at batch 250 : 0.01675613783299923
Loss at batch 260 : 0.009952421300113201
Loss at batch 270 : 0.019241241738200188
Loss at batch 280 : 0.010572921484708786
Loss at batch 290 : 0.009507833048701286
Loss at batch 300 : 0.01647011563181877
Loss at batch 310 : 0.018734436482191086
Loss at batch 320 : 0.015895526856184006
Loss at batch 330 : 0.02219255082309246
Loss at batch 340 : 0.022138765081763268
Loss at batch 350 : 0.012696530669927597
Loss at batch 360 : 0.01786928065121174
Loss at batch 370 : 0.020926743745803833
epoch107 finished!
Loss at batch 10 : 0.010388589464128017
Loss at batch 20 : 0.013089984655380249
Loss at batch 30 : 0.020124202594161034
Loss at batch 40 : 0.023376166820526123
Loss at batch 50 : 0.01801350899040699
Loss at batch 60 : 0.017923740670084953
Loss at batch 70 : 0.026458168402314186
Loss at batch 80 : 0.014546174556016922
Loss at batch 90 : 0.011611813679337502
Loss at batch 100 : 0.015949076041579247
Loss at batch 110 : 0.012968652881681919
Loss at batch 120 : 0.013802965171635151
Loss at batch 130 : 0.010528022423386574
Loss at batch 140 : 0.010255953297019005
Loss at batch 150 : 0.01422625221312046
Loss at batch 160 : 0.01061064749956131
Loss at batch 170 : 0.012303635478019714
Loss at batch 180 : 0.008012869395315647
Loss at batch 190 : 0.011390135623514652
Loss at batch 200 : 0.013348208740353584
Loss at batch 210 : 0.014362304471433163
Loss at batch 220 : 0.010084457695484161
Loss at batch 230 : 0.01392305362969637
Loss at batch 240 : 0.013910386711359024
Loss at batch 250 : 0.017051059752702713
Loss at batch 260 : 0.01265929639339447
Loss at batch 270 : 0.00913258921355009
Loss at batch 280 : 0.014433274045586586
Loss at batch 290 : 0.016489019617438316
Loss at batch 300 : 0.01535351388156414
Loss at batch 310 : 0.011900796554982662
Loss at batch 320 : 0.006609792821109295
Loss at batch 330 : 0.015402777120471
Loss at batch 340 : 0.02601008117198944
Loss at batch 350 : 0.010938640683889389
Loss at batch 360 : 0.00967364851385355
Loss at batch 370 : 0.023421991616487503
epoch108 finished!
Loss at batch 10 : 0.01739884354174137
Loss at batch 20 : 0.01684386283159256
Loss at batch 30 : 0.011451688595116138
Loss at batch 40 : 0.009844549000263214
Loss at batch 50 : 0.01035017054527998
Loss at batch 60 : 0.00828115176409483
Loss at batch 70 : 0.015014293603599072
Loss at batch 80 : 0.015903199091553688
Loss at batch 90 : 0.011643832549452782
Loss at batch 100 : 0.016192076727747917
Loss at batch 110 : 0.013840414583683014
Loss at batch 120 : 0.01920597068965435
Loss at batch 130 : 0.011611148715019226
Loss at batch 140 : 0.013920060358941555
Loss at batch 150 : 0.023878373205661774
Loss at batch 160 : 0.012297118082642555
Loss at batch 170 : 0.018078910186886787
Loss at batch 180 : 0.008144251070916653
Loss at batch 190 : 0.014083906076848507
Loss at batch 200 : 0.014869973063468933
Loss at batch 210 : 0.009812630712985992
Loss at batch 220 : 0.013547548092901707
Loss at batch 230 : 0.0066457525826990604
Loss at batch 240 : 0.015881571918725967
Loss at batch 250 : 0.009925278834998608
Loss at batch 260 : 0.010844049043953419
Loss at batch 270 : 0.011469707824289799
Loss at batch 280 : 0.013738111592829227
Loss at batch 290 : 0.019047534093260765
Loss at batch 300 : 0.03972860798239708
Loss at batch 310 : 0.01327433716505766
Loss at batch 320 : 0.021135054528713226
Loss at batch 330 : 0.01854313351213932
Loss at batch 340 : 0.010185004211962223
Loss at batch 350 : 0.01190947461873293
Loss at batch 360 : 0.018033534288406372
Loss at batch 370 : 0.013323424383997917
epoch109 finished!
