[2024-04-24 22:57:30.810423] test start with snapshots1/DehazeNet_epoch0.pth
[2024-04-24 22:58:00.264454] test end with snapshots1/DehazeNet_epoch0.pth
[2024-04-24 22:59:29.895211] Avg_PSNR: 18.79798457622806 dB, Avg_SSIM: 0.8656816424441612
[2024-04-24 22:59:29.921426] test start with snapshots1/record-DehazeNet_epoch30.pth
[2024-04-24 22:59:59.099733] test end with snapshots1/record-DehazeNet_epoch30.pth
[2024-04-24 23:01:28.727070] Avg_PSNR: 18.82702041347954 dB, Avg_SSIM: 0.8606343243785589
[2024-04-24 23:01:28.753359] test start with snapshots1/DehazeNet_epoch99.pth
[2024-04-24 23:01:58.003787] test end with snapshots1/DehazeNet_epoch99.pth
[2024-04-24 23:03:28.088590] Avg_PSNR: 19.388905799393758 dB, Avg_SSIM: 0.8652947818768609
[2024-04-24 23:03:28.129907] test start with snapshots1/DehazeNet_epoch92.pth
[2024-04-24 23:03:57.651809] test end with snapshots1/DehazeNet_epoch92.pth
[2024-04-24 23:05:27.537485] Avg_PSNR: 19.268548220351335 dB, Avg_SSIM: 0.8648350495050625
[2024-04-24 23:05:27.575129] test start with snapshots1/DehazeNet_epoch100.pth
[2024-04-24 23:05:57.051301] test end with snapshots1/DehazeNet_epoch100.pth
[2024-04-24 23:07:26.759532] Avg_PSNR: 19.3125331441198 dB, Avg_SSIM: 0.864698312240791
[2024-04-24 23:07:26.797771] test start with snapshots1/DehazeNet_epoch197.pth
[2024-04-24 23:07:56.052238] test end with snapshots1/DehazeNet_epoch197.pth
[2024-04-24 23:09:25.696302] Avg_PSNR: 19.358370295319506 dB, Avg_SSIM: 0.8647406812421798
[2024-04-24 23:09:25.738716] test start with snapshots1/DehazeNet_epoch54.pth
[2024-04-24 23:09:54.898480] test end with snapshots1/DehazeNet_epoch54.pth
[2024-04-24 23:11:25.582675] Avg_PSNR: 19.301245636109588 dB, Avg_SSIM: 0.8645922891571739
[2024-04-24 23:11:25.604811] test start with snapshots1/DehazeNet_epoch33.pth
[2024-04-24 23:11:54.859974] test end with snapshots1/DehazeNet_epoch33.pth
[2024-04-24 23:13:28.746815] Avg_PSNR: 19.00696501539684 dB, Avg_SSIM: 0.8739075511847213
[2024-04-24 23:13:28.772632] test start with snapshots1/DehazeNet_epoch94.pth
[2024-04-24 23:13:59.462469] test end with snapshots1/DehazeNet_epoch94.pth
[2024-04-24 23:15:34.888034] Avg_PSNR: 19.285174827408156 dB, Avg_SSIM: 0.863013682545166
[2024-04-24 23:15:34.909570] test start with snapshots1/DehazeNet_epoch154.pth
[2024-04-24 23:16:05.985469] test end with snapshots1/DehazeNet_epoch154.pth
[2024-04-24 23:17:42.813333] Avg_PSNR: 19.600018516970696 dB, Avg_SSIM: 0.8656923597169706
[2024-04-24 23:17:42.839216] test start with snapshots1/DehazeNet_epoch180.pth
[2024-04-24 23:18:14.266570] test end with snapshots1/DehazeNet_epoch180.pth
[2024-04-24 23:19:59.686632] Avg_PSNR: 19.26366224928087 dB, Avg_SSIM: 0.8594549382433783
[2024-04-24 23:19:59.727769] test start with snapshots1/DehazeNet_epoch73.pth
[2024-04-24 23:20:33.652089] test end with snapshots1/DehazeNet_epoch73.pth
[2024-04-24 23:22:20.281563] Avg_PSNR: 19.188566489394027 dB, Avg_SSIM: 0.8586057651555045
[2024-04-24 23:22:20.326733] test start with snapshots1/DehazeNet_epoch77.pth
[2024-04-24 23:22:54.032257] test end with snapshots1/DehazeNet_epoch77.pth
[2024-04-24 23:24:39.672428] Avg_PSNR: 19.234739874777254 dB, Avg_SSIM: 0.8600300626524799
[2024-04-24 23:24:39.719272] test start with snapshots1/DehazeNet_epoch90.pth
[2024-04-24 23:25:13.294079] test end with snapshots1/DehazeNet_epoch90.pth
[2024-04-24 23:26:59.046032] Avg_PSNR: 19.515171062921848 dB, Avg_SSIM: 0.8675238312870391
[2024-04-24 23:26:59.086436] test start with snapshots1/DehazeNet_epoch39.pth
[2024-04-24 23:27:32.910535] test end with snapshots1/DehazeNet_epoch39.pth
[2024-04-24 23:29:19.125810] Avg_PSNR: 19.23661595808432 dB, Avg_SSIM: 0.8755663081770377
[2024-04-24 23:29:19.157717] test start with snapshots1/DehazeNet_epoch182.pth
[2024-04-24 23:29:52.855049] test end with snapshots1/DehazeNet_epoch182.pth
[2024-04-24 23:31:38.791079] Avg_PSNR: 19.447976276074918 dB, Avg_SSIM: 0.8619570544274766
[2024-04-24 23:31:38.837918] test start with snapshots1/DehazeNet_epoch101.pth
[2024-04-24 23:32:12.505922] test end with snapshots1/DehazeNet_epoch101.pth
[2024-04-24 23:33:58.221371] Avg_PSNR: 19.34591436848286 dB, Avg_SSIM: 0.8633762859934158
[2024-04-24 23:33:58.275328] test start with snapshots1/DehazeNet_epoch89.pth
[2024-04-24 23:34:32.298673] test end with snapshots1/DehazeNet_epoch89.pth
[2024-04-24 23:36:18.473650] Avg_PSNR: 19.385725344274643 dB, Avg_SSIM: 0.8605710662265452
[2024-04-24 23:36:18.515799] test start with snapshots1/DehazeNet_epoch41.pth
[2024-04-24 23:36:52.592698] test end with snapshots1/DehazeNet_epoch41.pth
[2024-04-24 23:38:39.005696] Avg_PSNR: 19.264893911949205 dB, Avg_SSIM: 0.8752555197976432
[2024-04-24 23:38:39.051621] test start with snapshots1/DehazeNet_epoch116.pth
[2024-04-24 23:39:12.997258] test end with snapshots1/DehazeNet_epoch116.pth
[2024-04-24 23:40:59.900756] Avg_PSNR: 19.30598855623742 dB, Avg_SSIM: 0.8638613738306727
[2024-04-24 23:40:59.954759] test start with snapshots1/DehazeNet_epoch195.pth
[2024-04-24 23:41:33.936151] test end with snapshots1/DehazeNet_epoch195.pth
[2024-04-24 23:43:20.251177] Avg_PSNR: 19.164646921108204 dB, Avg_SSIM: 0.8560151705844172
[2024-04-24 23:43:20.294186] test start with snapshots1/DehazeNet_epoch122.pth
[2024-04-24 23:43:54.159648] test end with snapshots1/DehazeNet_epoch122.pth
[2024-04-24 23:45:40.383816] Avg_PSNR: 19.473495343648917 dB, Avg_SSIM: 0.8688353523197498
[2024-04-24 23:45:40.426599] test start with snapshots1/DehazeNet_epoch97.pth
[2024-04-24 23:46:14.107040] test end with snapshots1/DehazeNet_epoch97.pth
[2024-04-24 23:48:00.393339] Avg_PSNR: 19.227386912142098 dB, Avg_SSIM: 0.8622676113597416
[2024-04-24 23:48:00.444555] test start with snapshots1/DehazeNet_epoch9.pth
[2024-04-24 23:48:34.442635] test end with snapshots1/DehazeNet_epoch9.pth
[2024-04-24 23:50:20.839416] Avg_PSNR: 19.098889374558087 dB, Avg_SSIM: 0.8756182839228103
[2024-04-24 23:50:20.887879] test start with snapshots1/DehazeNet_epoch82.pth
[2024-04-24 23:50:55.114493] test end with snapshots1/DehazeNet_epoch82.pth
[2024-04-24 23:52:41.000695] Avg_PSNR: 19.376336762896905 dB, Avg_SSIM: 0.8634910373532616
[2024-04-24 23:52:41.047738] test start with snapshots1/DehazeNet_epoch48.pth
[2024-04-24 23:53:15.418710] test end with snapshots1/DehazeNet_epoch48.pth
[2024-04-24 23:55:01.684062] Avg_PSNR: 19.30359606008779 dB, Avg_SSIM: 0.8692518028817522
[2024-04-24 23:55:01.732522] test start with snapshots1/DehazeNet_epoch103.pth
[2024-04-24 23:55:35.697528] test end with snapshots1/DehazeNet_epoch103.pth
[2024-04-24 23:57:21.908826] Avg_PSNR: 19.40761078581017 dB, Avg_SSIM: 0.8652526567922475
[2024-04-24 23:57:21.952230] test start with snapshots1/DehazeNet_epoch136.pth
[2024-04-24 23:57:55.845593] test end with snapshots1/DehazeNet_epoch136.pth
[2024-04-24 23:59:42.386919] Avg_PSNR: 19.273178748654022 dB, Avg_SSIM: 0.8615793448736059
[2024-04-24 23:59:42.427272] test start with snapshots1/DehazeNet_epoch26.pth
[2024-04-25 00:00:16.433134] test end with snapshots1/DehazeNet_epoch26.pth
[2024-04-25 00:02:02.650690] Avg_PSNR: 18.942176794882258 dB, Avg_SSIM: 0.8678965280504428
[2024-04-25 00:02:02.690667] test start with snapshots1/DehazeNet_epoch148.pth
[2024-04-25 00:02:36.359812] test end with snapshots1/DehazeNet_epoch148.pth
[2024-04-25 00:04:21.718972] Avg_PSNR: 19.296910371981014 dB, Avg_SSIM: 0.862030001822018
[2024-04-25 00:04:21.760140] test start with snapshots1/DehazeNet_epoch146.pth
[2024-04-25 00:04:55.465274] test end with snapshots1/DehazeNet_epoch146.pth
[2024-04-25 00:06:41.836367] Avg_PSNR: 19.466125335676306 dB, Avg_SSIM: 0.8652944796623129
[2024-04-25 00:06:41.877430] test start with snapshots1/DehazeNet_epoch45.pth
[2024-04-25 00:07:15.691676] test end with snapshots1/DehazeNet_epoch45.pth
[2024-04-25 00:09:01.786037] Avg_PSNR: 19.24728819865463 dB, Avg_SSIM: 0.8725924908104765
[2024-04-25 00:09:01.833319] test start with snapshots1/DehazeNet_epoch161.pth
[2024-04-25 00:09:35.660748] test end with snapshots1/DehazeNet_epoch161.pth
[2024-04-25 00:11:21.184739] Avg_PSNR: 19.36162598156995 dB, Avg_SSIM: 0.8659673383612195
[2024-04-25 00:11:21.230011] test start with snapshots1/DehazeNet_epoch196.pth
[2024-04-25 00:11:54.979329] test end with snapshots1/DehazeNet_epoch196.pthLoss at batch 10 : 0.017923427745699883

net2
Total train examples: 3000
Loss at batch 10 : 0.3601958155632019
Loss at batch 20 : 0.340424120426178
Loss at batch 30 : 0.2560274004936218
Loss at batch 40 : 0.2169145941734314
Loss at batch 50 : 0.2275862842798233
Loss at batch 60 : 0.16572554409503937
Loss at batch 70 : 0.1729603260755539
Loss at batch 80 : 0.08756190538406372
Loss at batch 90 : 0.07709542661905289
Loss at batch 100 : 0.03160089999437332
Loss at batch 110 : 0.024288056418299675
Loss at batch 120 : 0.014799383468925953
Loss at batch 130 : 0.0271143838763237
Loss at batch 140 : 0.0152269983664155
Loss at batch 150 : 0.01155666820704937
Loss at batch 160 : 0.017512762919068336
Loss at batch 170 : 0.021291008219122887
Loss at batch 180 : 0.014170398935675621
Loss at batch 190 : 0.02387521229684353
Loss at batch 200 : 0.020960608497262
Loss at batch 210 : 0.018105523660779
Loss at batch 220 : 0.013439929112792015
Loss at batch 230 : 0.026108065620064735
Loss at batch 240 : 0.011436216533184052
Loss at batch 250 : 0.010174451395869255
Loss at batch 260 : 0.018805528059601784
Loss at batch 270 : 0.01485753245651722
Loss at batch 280 : 0.014897216111421585
Loss at batch 290 : 0.03425353392958641
Loss at batch 300 : 0.009124139323830605
Loss at batch 310 : 0.01654667779803276
Loss at batch 320 : 0.014093449339270592
Loss at batch 330 : 0.03218342736363411
Loss at batch 340 : 0.013010748662054539
Loss at batch 350 : 0.017657749354839325
Loss at batch 360 : 0.013289275579154491
Loss at batch 370 : 0.010239174589514732
epoch0 finished!
Loss at batch 10 : 0.01340368203818798
Loss at batch 20 : 0.01210810337215662
Loss at batch 30 : 0.03089422918856144
Loss at batch 40 : 0.01242106407880783
Loss at batch 50 : 0.011282955296337605
Loss at batch 60 : 0.022193385288119316
Loss at batch 70 : 0.008638398721814156
Loss at batch 80 : 0.007001284044235945
Loss at batch 90 : 0.012161384336650372
Loss at batch 100 : 0.009961036033928394
Loss at batch 110 : 0.024482786655426025
Loss at batch 120 : 0.0071539320051670074
Loss at batch 130 : 0.015517447143793106
Loss at batch 140 : 0.022717073559761047
Loss at batch 150 : 0.01723175123333931
Loss at batch 160 : 0.016434364020824432
Loss at batch 170 : 0.010159214958548546
Loss at batch 180 : 0.015389010310173035
Loss at batch 190 : 0.02141377329826355
Loss at batch 200 : 0.010596061125397682
Loss at batch 210 : 0.014881166629493237
Loss at batch 220 : 0.014829541556537151
Loss at batch 230 : 0.010873791761696339
Loss at batch 240 : 0.013011844828724861
Loss at batch 250 : 0.011175517924129963
Loss at batch 260 : 0.010864601470530033
Loss at batch 270 : 0.02749555930495262
Loss at batch 280 : 0.01075240783393383
Loss at batch 290 : 0.01747169718146324
Loss at batch 300 : 0.02153266966342926
Loss at batch 310 : 0.008825229480862617
Loss at batch 320 : 0.01803593337535858
Loss at batch 330 : 0.019406726583838463
Loss at batch 340 : 0.020907003432512283
Loss at batch 350 : 0.010342513211071491
Loss at batch 360 : 0.03159533813595772
Loss at batch 370 : 0.009930956177413464
epoch1 finished!
Loss at batch 10 : 0.011526436544954777
Loss at batch 20 : 0.01620715670287609
Loss at batch 30 : 0.018387723714113235
Loss at batch 40 : 0.008447899483144283
Loss at batch 50 : 0.012296837754547596
Loss at batch 60 : 0.016068272292613983
Loss at batch 70 : 0.018739867955446243
Loss at batch 80 : 0.01892707683146
Loss at batch 90 : 0.02730039320886135
Loss at batch 100 : 0.01424455363303423
Loss at batch 110 : 0.016504324972629547
Loss at batch 120 : 0.02241574227809906
Loss at batch 130 : 0.0203155055642128
Loss at batch 140 : 0.021737543866038322
Loss at batch 150 : 0.01705632358789444
Loss at batch 160 : 0.01281636394560337
Loss at batch 170 : 0.010562651790678501
Loss at batch 180 : 0.012541886419057846
Loss at batch 190 : 0.02028806507587433
Loss at batch 200 : 0.01904858648777008
Loss at batch 210 : 0.01458006538450718
Loss at batch 220 : 0.022522158920764923
Loss at batch 230 : 0.019450567662715912
Loss at batch 240 : 0.01210318598896265
Loss at batch 250 : 0.016124717891216278
Loss at batch 260 : 0.0166631992906332
Loss at batch 270 : 0.022210311144590378
Loss at batch 280 : 0.01350446231663227
Loss at batch 290 : 0.019372988492250443
Loss at batch 300 : 0.015603000298142433
Loss at batch 310 : 0.02908775582909584
Loss at batch 320 : 0.013588921166956425
Loss at batch 330 : 0.018451444804668427
Loss at batch 340 : 0.017099132761359215
Loss at batch 350 : 0.013124472461640835
Loss at batch 360 : 0.015164695680141449
Loss at batch 370 : 0.01379401795566082
epoch2 finished!
Loss at batch 10 : 0.015199909918010235
Loss at batch 20 : 0.016688993200659752
Loss at batch 30 : 0.017035892233252525
Loss at batch 40 : 0.010524407029151917
Loss at batch 50 : 0.01396204624325037
Loss at batch 60 : 0.015254486352205276
Loss at batch 70 : 0.009727886877954006
Loss at batch 80 : 0.020198814570903778
Loss at batch 90 : 0.023660510778427124
Loss at batch 100 : 0.025790583342313766
Loss at batch 110 : 0.02627847157418728
Loss at batch 120 : 0.019999491050839424
Loss at batch 130 : 0.015062396414577961
Loss at batch 140 : 0.01694512367248535
Loss at batch 150 : 0.019203536212444305
Loss at batch 160 : 0.012185158208012581
Loss at batch 170 : 0.014287692494690418
Loss at batch 180 : 0.02724338509142399
Loss at batch 190 : 0.019614405930042267
Loss at batch 200 : 0.015222666785120964
Loss at batch 210 : 0.01936996541917324
Loss at batch 220 : 0.0155027499422431
Loss at batch 230 : 0.011484764516353607
Loss at batch 240 : 0.013091232627630234
Loss at batch 250 : 0.01379008125513792
Loss at batch 260 : 0.017606664448976517
Loss at batch 270 : 0.01563367061316967
Loss at batch 280 : 0.012032488361001015
Loss at batch 290 : 0.01191001944243908
Loss at batch 300 : 0.016603972762823105
Loss at batch 310 : 0.010559012182056904
Loss at batch 320 : 0.015467041172087193
Loss at batch 330 : 0.02448972500860691
Loss at batch 340 : 0.02780103124678135
Loss at batch 350 : 0.016581373289227486
Loss at batch 360 : 0.02554715797305107
Loss at batch 370 : 0.02005683071911335
epoch3 finished!
Loss at batch 10 : 0.37340855598449707
Loss at batch 20 : 0.2662612497806549
Loss at batch 30 : 0.21483348309993744
Loss at batch 40 : 0.18848416209220886
Loss at batch 50 : 0.13889539241790771
Loss at batch 60 : 0.11716625839471817
Loss at batch 70 : 0.056093133985996246
Loss at batch 80 : 0.04583314061164856
Loss at batch 90 : 0.02454620599746704
Loss at batch 100 : 0.02046658843755722
Loss at batch 110 : 0.016502391546964645
Loss at batch 120 : 0.026852604001760483
Loss at batch 130 : 0.01579771563410759
Loss at batch 140 : 0.015438497997820377
Loss at batch 150 : 0.013930569402873516
Loss at batch 160 : 0.0122934365645051
Loss at batch 170 : 0.013469045981764793
Loss at batch 180 : 0.016259077936410904
Loss at batch 190 : 0.015013092197477818
Loss at batch 200 : 0.025587959215044975
Loss at batch 210 : 0.014191489666700363
Loss at batch 220 : 0.015898404642939568
Loss at batch 230 : 0.01605917699635029
Loss at batch 240 : 0.01695629023015499
Loss at batch 250 : 0.01188406441360712
Loss at batch 260 : 0.022402793169021606
Loss at batch 270 : 0.01286664791405201
Loss at batch 280 : 0.015173478052020073
Loss at batch 290 : 0.02098466269671917
Loss at batch 300 : 0.025056254118680954
Loss at batch 310 : 0.024267354980111122
Loss at batch 320 : 0.019228892400860786
Loss at batch 330 : 0.02220323123037815
Loss at batch 340 : 0.013934488408267498
Loss at batch 350 : 0.014260118827223778
Loss at batch 360 : 0.012623216956853867
Loss at batch 370 : 0.013296409510076046
epoch0 finished!
Loss at batch 10 : 0.3856522738933563
Loss at batch 20 : 0.3423742353916168
Loss at batch 30 : 0.31835588812828064
Loss at batch 40 : 0.2944502532482147
Loss at batch 50 : 0.27716684341430664
Loss at batch 60 : 0.2748902142047882
Loss at batch 70 : 0.22489939630031586
Loss at batch 80 : 0.2271038293838501
Loss at batch 90 : 0.21903486549854279
Loss at batch 100 : 0.21347852051258087
Loss at batch 110 : 0.1981642097234726
Loss at batch 120 : 0.15199026465415955
Loss at batch 130 : 0.16222460567951202
Loss at batch 140 : 0.13157086074352264
Loss at batch 150 : 0.15320192277431488
Loss at batch 160 : 0.15265460312366486
Loss at batch 170 : 0.16538144648075104
Loss at batch 180 : 0.13524119555950165
Loss at batch 190 : 0.14224852621555328
Loss at batch 200 : 0.13516280055046082
Loss at batch 210 : 0.16483323276042938
Loss at batch 220 : 0.13969595730304718
Loss at batch 230 : 0.15018436312675476
Loss at batch 240 : 0.17764566838741302
Loss at batch 250 : 0.1608295887708664
Loss at batch 260 : 0.12104977667331696
Loss at batch 270 : 0.16081485152244568
Loss at batch 280 : 0.1323906034231186
Loss at batch 290 : 0.17037123441696167
Loss at batch 300 : 0.15637104213237762
Loss at batch 310 : 0.13442444801330566
Loss at batch 320 : 0.13838012516498566
Loss at batch 330 : 0.16489137709140778
Loss at batch 340 : 0.14846035838127136
Loss at batch 350 : 0.14388367533683777
Loss at batch 360 : 0.16058692336082458
Loss at batch 370 : 0.14731775224208832
epoch0 finished!
Loss at batch 10 : 0.013520889915525913
Loss at batch 20 : 0.013790181837975979
Loss at batch 30 : 0.01705515943467617
Loss at batch 40 : 0.015394851565361023
Loss at batch 50 : 0.01286874245852232
Loss at batch 60 : 0.016267025843262672
Loss at batch 70 : 0.012613773345947266
Loss at batch 80 : 0.02147252857685089
Loss at batch 90 : 0.019712189212441444
Loss at batch 100 : 0.03784463182091713
Loss at batch 110 : 0.019671766087412834
Loss at batch 120 : 0.020410753786563873
Loss at batch 130 : 0.02165430597960949
Loss at batch 140 : 0.009993053041398525
Loss at batch 150 : 0.010417601093649864
Loss at batch 160 : 0.02498394437134266
Loss at batch 170 : 0.016131635755300522
Loss at batch 180 : 0.01721739023923874
Loss at batch 190 : 0.014797087758779526
Loss at batch 200 : 0.018499018624424934
Loss at batch 210 : 0.017195913940668106
Loss at batch 220 : 0.019859762862324715
Loss at batch 230 : 0.03183674439787865
Loss at batch 240 : 0.01895812153816223
Loss at batch 250 : 0.011500438675284386
Loss at batch 260 : 0.0163628738373518
Loss at batch 270 : 0.012610705569386482
Loss at batch 280 : 0.017419975250959396
Loss at batch 290 : 0.010577205568552017
Loss at batch 300 : 0.011115512810647488
Loss at batch 310 : 0.01932922750711441
Loss at batch 320 : 0.01898801699280739
Loss at batch 330 : 0.021100305020809174
Loss at batch 340 : 0.017239972949028015
Loss at batch 350 : 0.013438250869512558
Loss at batch 360 : 0.014281880110502243
Loss at batch 370 : 0.018404444679617882
epoch4 finished!
Loss at batch 10 : 0.010802391916513443
Loss at batch 20 : 0.019964642822742462
Loss at batch 30 : 0.012853847816586494
Loss at batch 40 : 0.02023283764719963
Loss at batch 50 : 0.0149984210729599
Loss at batch 60 : 0.010627907700836658
Loss at batch 70 : 0.02103533409535885
Loss at batch 80 : 0.013947189785540104
Loss at batch 90 : 0.012450640089809895
Loss at batch 100 : 0.011127764359116554
Loss at batch 110 : 0.023190924897789955
Loss at batch 120 : 0.020333951339125633
Loss at batch 130 : 0.009169138967990875
Loss at batch 140 : 0.011856469325721264
Loss at batch 150 : 0.01744820922613144
Loss at batch 160 : 0.014957917854189873
Loss at batch 170 : 0.011274321004748344
Loss at batch 180 : 0.00922726932913065
Loss at batch 190 : 0.01631893962621689
Loss at batch 200 : 0.014945757575333118
Loss at batch 210 : 0.01369649637490511
Loss at batch 220 : 0.014337016269564629
Loss at batch 230 : 0.011660370975732803
Loss at batch 240 : 0.018820064142346382
Loss at batch 250 : 0.02726941555738449
Loss at batch 260 : 0.012622928246855736
Loss at batch 270 : 0.009687673300504684
Loss at batch 280 : 0.01852557808160782
Loss at batch 290 : 0.024173611775040627
Loss at batch 300 : 0.01169044803828001
Loss at batch 310 : 0.019925517961382866
Loss at batch 320 : 0.014302426017820835
Loss at batch 330 : 0.010754074901342392
Loss at batch 340 : 0.013490250334143639
Loss at batch 350 : 0.01677260547876358
Loss at batch 360 : 0.012403195723891258
Loss at batch 370 : 0.01895834691822529
epoch5 finished!
Loss at batch 10 : 0.020448841154575348
Loss at batch 20 : 0.011545496061444283
Loss at batch 30 : 0.014728700742125511
Loss at batch 40 : 0.028430050238966942
Loss at batch 50 : 0.015031605958938599
Loss at batch 60 : 0.01632191427052021
Loss at batch 70 : 0.013576923869550228
Loss at batch 80 : 0.026392096653580666
Loss at batch 90 : 0.01183793693780899
Loss at batch 100 : 0.02323073148727417
Loss at batch 110 : 0.017047882080078125
Loss at batch 120 : 0.012507528997957706
Loss at batch 130 : 0.006406435742974281
Loss at batch 140 : 0.02489861473441124
Loss at batch 150 : 0.010352164506912231
Loss at batch 160 : 0.02184711955487728
Loss at batch 170 : 0.010965321213006973
Loss at batch 180 : 0.01994132809340954
Loss at batch 190 : 0.021635225042700768
Loss at batch 200 : 0.023868277668952942
Loss at batch 210 : 0.011668040417134762
Loss at batch 220 : 0.01226047333329916
Loss at batch 230 : 0.010082757100462914
Loss at batch 240 : 0.022860756143927574
Loss at batch 250 : 0.011341686360538006
Loss at batch 260 : 0.012714661657810211
Loss at batch 270 : 0.011662637814879417
Loss at batch 280 : 0.013863191939890385
Loss at batch 290 : 0.012438016012310982
Loss at batch 300 : 0.025137662887573242
Loss at batch 310 : 0.0190900806337595
Loss at batch 320 : 0.017079785466194153
Loss at batch 330 : 0.01307614054530859
Loss at batch 340 : 0.014796461910009384
Loss at batch 350 : 0.011704765260219574
Loss at batch 360 : 0.018350813537836075
Loss at batch 370 : 0.01718389056622982
epoch1 finished!
Loss at batch 10 : 0.02295014262199402
Loss at batch 20 : 0.011553516611456871
Loss at batch 30 : 0.015008553862571716
Loss at batch 40 : 0.008253506384789944
Loss at batch 50 : 0.01136077381670475
Loss at batch 60 : 0.01778547465801239
Loss at batch 70 : 0.013038611970841885
Loss at batch 80 : 0.022526178508996964
Loss at batch 90 : 0.015941862016916275
Loss at batch 100 : 0.008040216751396656
Loss at batch 110 : 0.015720820054411888
Loss at batch 120 : 0.014549901708960533
Loss at batch 130 : 0.021332096308469772
Loss at batch 140 : 0.02123364433646202
Loss at batch 150 : 0.01894298940896988
Loss at batch 160 : 0.016014568507671356
Loss at batch 170 : 0.019551243633031845
Loss at batch 180 : 0.02134050242602825
Loss at batch 190 : 0.008755983784794807
Loss at batch 200 : 0.00915800966322422
Loss at batch 210 : 0.011551404371857643
Loss at batch 220 : 0.011992176994681358
Loss at batch 230 : 0.011930014938116074
Loss at batch 240 : 0.011517135426402092
Loss at batch 250 : 0.014680112712085247
Loss at batch 260 : 0.02601689100265503
Loss at batch 270 : 0.009725997224450111
Loss at batch 280 : 0.011891525238752365
Loss at batch 290 : 0.02399474009871483
Loss at batch 300 : 0.013101596385240555
Loss at batch 310 : 0.013483921065926552
Loss at batch 320 : 0.013322347775101662
Loss at batch 330 : 0.010859578847885132
Loss at batch 340 : 0.010065681301057339
Loss at batch 350 : 0.01843830570578575
Loss at batch 360 : 0.014867211692035198
Loss at batch 370 : 0.020951353013515472
epoch6 finished!
Loss at batch 10 : 0.13645710051059723
Loss at batch 20 : 0.11658113449811935
Loss at batch 30 : 0.1588064730167389
Loss at batch 40 : 0.1411302238702774
Loss at batch 50 : 0.13670602440834045
Loss at batch 60 : 0.14597244560718536
Loss at batch 70 : 0.14779329299926758
Loss at batch 80 : 0.16273607313632965
Loss at batch 90 : 0.16061297059059143
Loss at batch 100 : 0.1649390012025833
Loss at batch 110 : 0.10534157603979111
Loss at batch 120 : 0.1309570074081421
Loss at batch 130 : 0.1420125663280487
Loss at batch 140 : 0.18433664739131927
Loss at batch 150 : 0.16987955570220947
Loss at batch 160 : 0.1084069237112999
Loss at batch 170 : 0.14257942140102386
Loss at batch 180 : 0.13838589191436768
Loss at batch 190 : 0.13550439476966858
Loss at batch 200 : 0.15116281807422638
Loss at batch 210 : 0.147492915391922
Loss at batch 220 : 0.17821361124515533
Loss at batch 230 : 0.17428448796272278
Loss at batch 240 : 0.16617320477962494
Loss at batch 250 : 0.16301380097866058
Loss at batch 260 : 0.13448257744312286
Loss at batch 270 : 0.16254954040050507
Loss at batch 280 : 0.12881754338741302
Loss at batch 290 : 0.14995969831943512
Loss at batch 300 : 0.1660260707139969
Loss at batch 310 : 0.10477305203676224
Loss at batch 320 : 0.06327801197767258
Loss at batch 330 : 0.02827855572104454
Loss at batch 340 : 0.021173780784010887
Loss at batch 350 : 0.0130129624158144
Loss at batch 360 : 0.008549460209906101
Loss at batch 370 : 0.01596495322883129
epoch1 finished!
Loss at batch 10 : 0.014485427178442478
Loss at batch 20 : 0.011762365698814392
Loss at batch 30 : 0.012659645639359951
Loss at batch 40 : 0.009598678909242153
Loss at batch 50 : 0.017713185399770737
Loss at batch 60 : 0.015318365767598152
Loss at batch 70 : 0.0188307985663414
Loss at batch 80 : 0.010244229808449745
Loss at batch 90 : 0.0162185188382864
Loss at batch 100 : 0.022827716544270515
Loss at batch 110 : 0.017716893926262856
Loss at batch 120 : 0.011940022930502892
Loss at batch 130 : 0.0202200748026371
Loss at batch 140 : 0.009642246179282665
Loss at batch 150 : 0.017801983281970024
Loss at batch 160 : 0.01566600427031517
Loss at batch 170 : 0.015637153759598732
Loss at batch 180 : 0.018805794417858124
Loss at batch 190 : 0.015110374428331852
Loss at batch 200 : 0.018581267446279526
Loss at batch 210 : 0.017266081646084785
Loss at batch 220 : 0.021558614447712898
Loss at batch 230 : 0.0172609630972147
Loss at batch 240 : 0.015570802614092827
Loss at batch 250 : 0.012193501926958561
Loss at batch 260 : 0.013491367921233177
Loss at batch 270 : 0.01783011667430401
Loss at batch 280 : 0.020232083275914192
Loss at batch 290 : 0.013540772721171379
Loss at batch 300 : 0.02100711315870285
Loss at batch 310 : 0.009170282632112503
Loss at batch 320 : 0.017744312062859535
Loss at batch 330 : 0.010361656546592712
Loss at batch 340 : 0.00807422585785389
Loss at batch 350 : 0.009049026295542717
Loss at batch 360 : 0.01717039942741394
Loss at batch 370 : 0.016029028221964836
epoch7 finished!
Loss at batch 10 : 0.018287990242242813
Loss at batch 20 : 0.019337033852934837
Loss at batch 30 : 0.011495716869831085
Loss at batch 40 : 0.014719465747475624
Loss at batch 50 : 0.0198447797447443
Loss at batch 60 : 0.009764854796230793
Loss at batch 70 : 0.017629390582442284
Loss at batch 80 : 0.016243284568190575
Loss at batch 90 : 0.01375601440668106
Loss at batch 100 : 0.015306364744901657
Loss at batch 110 : 0.011695491150021553
Loss at batch 120 : 0.01431277021765709
Loss at batch 130 : 0.014065321534872055
Loss at batch 140 : 0.012634938582777977
Loss at batch 150 : 0.015993405133485794
Loss at batch 160 : 0.008123785257339478
Loss at batch 170 : 0.015187612734735012
Loss at batch 180 : 0.00850343331694603
Loss at batch 190 : 0.013996124267578125
Loss at batch 200 : 0.018863830715417862
Loss at batch 210 : 0.01698329485952854
Loss at batch 220 : 0.016956770792603493
Loss at batch 230 : 0.011834698729217052
Loss at batch 240 : 0.017996275797486305
Loss at batch 250 : 0.015558111481368542
Loss at batch 260 : 0.009039117954671383
Loss at batch 270 : 0.01857098564505577
Loss at batch 280 : 0.01725735515356064
Loss at batch 290 : 0.01117710955440998
Loss at batch 300 : 0.020644551143050194
Loss at batch 310 : 0.015881381928920746
Loss at batch 320 : 0.01484591793268919
Loss at batch 330 : 0.00965144857764244
Loss at batch 340 : 0.011857815086841583
Loss at batch 350 : 0.016666077077388763
Loss at batch 360 : 0.022279731929302216
Loss at batch 370 : 0.011740418151021004
epoch8 finished!
Loss at batch 10 : 0.012020356953144073
Loss at batch 20 : 0.009590447880327702
Loss at batch 30 : 0.01173518504947424
Loss at batch 40 : 0.019866058602929115
Loss at batch 50 : 0.01167268119752407
Loss at batch 60 : 0.011568896472454071
Loss at batch 70 : 0.011087583377957344
Loss at batch 80 : 0.016972217708826065
Loss at batch 90 : 0.028957758098840714
Loss at batch 100 : 0.021515492349863052
Loss at batch 110 : 0.014247332699596882
Loss at batch 120 : 0.024379244074225426
Loss at batch 130 : 0.010586841963231564
Loss at batch 140 : 0.00730986287817359
Loss at batch 150 : 0.014097803272306919
Loss at batch 160 : 0.011858537793159485
Loss at batch 170 : 0.015008714981377125
Loss at batch 180 : 0.017133546993136406
Loss at batch 190 : 0.013933410868048668
Loss at batch 200 : 0.008443395607173443
Loss at batch 210 : 0.011336547322571278
Loss at batch 220 : 0.020520595833659172
Loss at batch 230 : 0.018339941278100014
Loss at batch 240 : 0.009251795709133148
Loss at batch 250 : 0.02643268182873726
Loss at batch 260 : 0.01474335789680481
Loss at batch 270 : 0.016701065003871918
Loss at batch 280 : 0.018899057060480118
Loss at batch 290 : 0.013558379374444485
Loss at batch 300 : 0.014213433489203453
Loss at batch 310 : 0.011741056106984615
Loss at batch 320 : 0.012479784898459911
Loss at batch 330 : 0.011908425949513912
Loss at batch 340 : 0.01666831597685814
Loss at batch 350 : 0.013689488172531128
Loss at batch 360 : 0.013196468353271484
Loss at batch 370 : 0.011134120635688305
epoch2 finished!
Loss at batch 10 : 0.013508100993931293
Loss at batch 20 : 0.008527008816599846
Loss at batch 30 : 0.01640147529542446
Loss at batch 40 : 0.007660069968551397
Loss at batch 50 : 0.01177610456943512
Loss at batch 60 : 0.01293509267270565
Loss at batch 70 : 0.019941911101341248
Loss at batch 80 : 0.028417853638529778
Loss at batch 90 : 0.014826426282525063
Loss at batch 100 : 0.01979675702750683
Loss at batch 110 : 0.028358668088912964
Loss at batch 120 : 0.014568720944225788
Loss at batch 130 : 0.01655639335513115
Loss at batch 140 : 0.018066709861159325
Loss at batch 150 : 0.022070668637752533
Loss at batch 160 : 0.013649397529661655
Loss at batch 170 : 0.013168455101549625
Loss at batch 180 : 0.019321249797940254
Loss at batch 190 : 0.012497764080762863
Loss at batch 200 : 0.012239530682563782
Loss at batch 210 : 0.01614372991025448
Loss at batch 220 : 0.013064872473478317
Loss at batch 230 : 0.02005748450756073
Loss at batch 240 : 0.015700018033385277
Loss at batch 250 : 0.010000172071158886
Loss at batch 260 : 0.01493880432099104
Loss at batch 270 : 0.014896633103489876
Loss at batch 280 : 0.014406869187951088
Loss at batch 290 : 0.016608107835054398
Loss at batch 300 : 0.013224716298282146
Loss at batch 310 : 0.013038896024227142
Loss at batch 320 : 0.025860007852315903
Loss at batch 330 : 0.00984419696033001
Loss at batch 340 : 0.019865484908223152
Loss at batch 350 : 0.015686538070440292
Loss at batch 360 : 0.028490981087088585
Loss at batch 370 : 0.014388923533260822
epoch2 finished!
Loss at batch 10 : 0.017890557646751404
Loss at batch 20 : 0.01868291012942791
Loss at batch 30 : 0.02013908512890339
Loss at batch 40 : 0.012643784284591675
Loss at batch 50 : 0.015453219413757324
Loss at batch 60 : 0.010957501828670502
Loss at batch 70 : 0.011806624941527843
Loss at batch 80 : 0.016080312430858612
Loss at batch 90 : 0.011429755948483944
Loss at batch 100 : 0.011948362924158573
Loss at batch 110 : 0.02219432406127453
Loss at batch 120 : 0.014435460790991783
Loss at batch 130 : 0.0214413832873106
Loss at batch 140 : 0.01718311198055744
Loss at batch 150 : 0.009611469693481922
Loss at batch 160 : 0.032334718853235245
Loss at batch 170 : 0.016610143706202507
Loss at batch 180 : 0.009959736838936806
Loss at batch 190 : 0.02055812068283558
Loss at batch 200 : 0.01369781605899334
Loss at batch 210 : 0.013341092504560947
Loss at batch 220 : 0.009979961439967155
Loss at batch 230 : 0.012391267344355583
Loss at batch 240 : 0.016683772206306458
Loss at batch 250 : 0.017876435071229935
Loss at batch 260 : 0.013885686174035072
Loss at batch 270 : 0.0176149420440197
Loss at batch 280 : 0.014424290508031845
Loss at batch 290 : 0.010533767752349377
Loss at batch 300 : 0.008477152325212955
Loss at batch 310 : 0.006909494753926992
Loss at batch 320 : 0.025887273252010345
Loss at batch 330 : 0.009633478708565235
Loss at batch 340 : 0.020701000466942787
Loss at batch 350 : 0.020717663690447807
Loss at batch 360 : 0.02054479904472828
Loss at batch 370 : 0.01066281832754612
epoch9 finished!
Loss at batch 10 : 0.01359511911869049
Loss at batch 20 : 0.016927070915699005
Loss at batch 30 : 0.015335801057517529
Loss at batch 40 : 0.013765723444521427
Loss at batch 50 : 0.02277548983693123
Loss at batch 60 : 0.024966051802039146
Loss at batch 70 : 0.02277110330760479
Loss at batch 80 : 0.008781062439084053
Loss at batch 90 : 0.016511991620063782
Loss at batch 100 : 0.01846335642039776
Loss at batch 110 : 0.02700088918209076
Loss at batch 120 : 0.012445746921002865
Loss at batch 130 : 0.019598599523305893
Loss at batch 140 : 0.01593918725848198
Loss at batch 150 : 0.014261195436120033
Loss at batch 160 : 0.009770829230546951
Loss at batch 170 : 0.013304883614182472
Loss at batch 180 : 0.015524230897426605
Loss at batch 190 : 0.01047223899513483
Loss at batch 200 : 0.02346826158463955
Loss at batch 210 : 0.008946508169174194
Loss at batch 220 : 0.012193484231829643
Loss at batch 230 : 0.023768283426761627
Loss at batch 240 : 0.007295603863894939
Loss at batch 250 : 0.015719585120677948
Loss at batch 260 : 0.019105102866888046
Loss at batch 270 : 0.01138769369572401
Loss at batch 280 : 0.017800994217395782
Loss at batch 290 : 0.013406261801719666
Loss at batch 300 : 0.012663359753787518
Loss at batch 310 : 0.013585995882749557
Loss at batch 320 : 0.013726063072681427
Loss at batch 330 : 0.016962802037596703
Loss at batch 340 : 0.014654857106506824
Loss at batch 350 : 0.01473872922360897
Loss at batch 360 : 0.026830170303583145
Loss at batch 370 : 0.01508642639964819
epoch10 finished!
Loss at batch 10 : 0.021841194480657578
Loss at batch 20 : 0.008371591567993164
Loss at batch 30 : 0.010893501341342926
Loss at batch 40 : 0.014774473384022713
Loss at batch 50 : 0.02463286928832531
Loss at batch 60 : 0.011065514758229256
Loss at batch 70 : 0.014964088797569275
Loss at batch 80 : 0.016741903498768806
Loss at batch 90 : 0.009743830189108849
Loss at batch 100 : 0.020398439839482307
Loss at batch 110 : 0.022330310195684433
Loss at batch 120 : 0.011273813433945179
Loss at batch 130 : 0.01329495757818222
Loss at batch 140 : 0.013943267986178398
Loss at batch 150 : 0.01750071719288826
Loss at batch 160 : 0.022896617650985718
Loss at batch 170 : 0.017680831253528595
Loss at batch 180 : 0.013631218113005161
Loss at batch 190 : 0.008507094345986843
Loss at batch 200 : 0.013154033571481705
Loss at batch 210 : 0.017591582611203194
Loss at batch 220 : 0.01507887989282608
Loss at batch 230 : 0.012846703641116619
Loss at batch 240 : 0.008420481346547604
Loss at batch 250 : 0.01931929774582386
Loss at batch 260 : 0.01142986211925745
Loss at batch 270 : 0.013896167278289795
Loss at batch 280 : 0.014491669833660126
Loss at batch 290 : 0.020909730345010757
Loss at batch 300 : 0.00856501143425703
Loss at batch 310 : 0.013798977248370647
Loss at batch 320 : 0.014621841721236706
Loss at batch 330 : 0.014280667528510094
Loss at batch 340 : 0.018769357353448868
Loss at batch 350 : 0.022112645208835602
Loss at batch 360 : 0.012405036948621273
Loss at batch 370 : 0.022303329780697823
epoch3 finished!
Loss at batch 10 : 0.00865256879478693
Loss at batch 20 : 0.010243266820907593
Loss at batch 30 : 0.017307354137301445
Loss at batch 40 : 0.019699545577168465
Loss at batch 50 : 0.015149781480431557
Loss at batch 60 : 0.022813690826296806
Loss at batch 70 : 0.018004288896918297
Loss at batch 80 : 0.008855999447405338
Loss at batch 90 : 0.009085055440664291
Loss at batch 100 : 0.017413869500160217
Loss at batch 110 : 0.011269115842878819
Loss at batch 120 : 0.008106345310807228
Loss at batch 130 : 0.016232408583164215
Loss at batch 140 : 0.012013723142445087
Loss at batch 150 : 0.014616580680012703
Loss at batch 160 : 0.013680304400622845
Loss at batch 170 : 0.012668569572269917
Loss at batch 180 : 0.0159193966537714
Loss at batch 190 : 0.023774176836013794
Loss at batch 200 : 0.01174679584801197
Loss at batch 210 : 0.009427712298929691
Loss at batch 220 : 0.016515571624040604
Loss at batch 230 : 0.017967011779546738
Loss at batch 240 : 0.016161305829882622
Loss at batch 250 : 0.011829867959022522
Loss at batch 260 : 0.018896490335464478
Loss at batch 270 : 0.02191586047410965
Loss at batch 280 : 0.009002694860100746
Loss at batch 290 : 0.021041739732027054
Loss at batch 300 : 0.01390866655856371
Loss at batch 310 : 0.01790931075811386
Loss at batch 320 : 0.011447141878306866
Loss at batch 330 : 0.019903678447008133
Loss at batch 340 : 0.020381558686494827
Loss at batch 350 : 0.025926213711500168
Loss at batch 360 : 0.025119628757238388
Loss at batch 370 : 0.019213350489735603
epoch3 finished!
Loss at batch 10 : 0.01617625541985035
Loss at batch 20 : 0.01696089655160904
Loss at batch 30 : 0.009609660133719444
Loss at batch 40 : 0.03135579451918602
Loss at batch 50 : 0.016279073432087898
Loss at batch 60 : 0.012094981968402863
Loss at batch 70 : 0.020411409437656403
Loss at batch 80 : 0.011349651962518692
Loss at batch 90 : 0.011156722903251648
Loss at batch 100 : 0.021187469363212585
Loss at batch 110 : 0.006540888454765081
Loss at batch 120 : 0.013049068860709667
Loss at batch 130 : 0.018537526950240135
Loss at batch 140 : 0.015986893326044083
Loss at batch 150 : 0.019670406356453896
Loss at batch 160 : 0.009349235333502293
Loss at batch 170 : 0.011267098598182201
Loss at batch 180 : 0.015275252051651478
Loss at batch 190 : 0.011385127902030945
Loss at batch 200 : 0.016567133367061615
Loss at batch 210 : 0.021012578159570694
Loss at batch 220 : 0.007553668227046728
Loss at batch 230 : 0.011366564780473709
Loss at batch 240 : 0.015915358439087868
Loss at batch 250 : 0.009597787633538246
Loss at batch 260 : 0.008764191530644894
Loss at batch 270 : 0.023091265931725502
Loss at batch 280 : 0.020966563373804092
Loss at batch 290 : 0.020257839933037758
Loss at batch 300 : 0.01268728543072939
Loss at batch 310 : 0.017501775175333023
Loss at batch 320 : 0.009457402862608433
Loss at batch 330 : 0.020734500139951706
Loss at batch 340 : 0.012930935248732567
Loss at batch 350 : 0.01911497302353382
Loss at batch 360 : 0.007124842144548893
Loss at batch 370 : 0.018928706645965576
epoch11 finished!
Loss at batch 10 : 0.014660964719951153
Loss at batch 20 : 0.015596217475831509
Loss at batch 30 : 0.019515346735715866
Loss at batch 40 : 0.010357177816331387
Loss at batch 50 : 0.009741171263158321
Loss at batch 60 : 0.019701551645994186
Loss at batch 70 : 0.012113978154957294
Loss at batch 80 : 0.014143136329948902
Loss at batch 90 : 0.013890269212424755
Loss at batch 100 : 0.01286780834197998
Loss at batch 110 : 0.015314356423914433
Loss at batch 120 : 0.010329829528927803
Loss at batch 130 : 0.009003703482449055
Loss at batch 140 : 0.016687102615833282
Loss at batch 150 : 0.01685662381350994
Loss at batch 160 : 0.02806437388062477
Loss at batch 170 : 0.009279274381697178
Loss at batch 180 : 0.02383597381412983
Loss at batch 190 : 0.011801605112850666
Loss at batch 200 : 0.014145661145448685
Loss at batch 210 : 0.011606714688241482
Loss at batch 220 : 0.018844451755285263
Loss at batch 230 : 0.021348431706428528
Loss at batch 240 : 0.00835572648793459
Loss at batch 250 : 0.009272565133869648
Loss at batch 260 : 0.016966991126537323
Loss at batch 270 : 0.024353669956326485
Loss at batch 280 : 0.00860730279237032
Loss at batch 290 : 0.009020078927278519
Loss at batch 300 : 0.011974181979894638
Loss at batch 310 : 0.011233811266720295
Loss at batch 320 : 0.018958786502480507
Loss at batch 330 : 0.01332476269453764
Loss at batch 340 : 0.014988471753895283
Loss at batch 350 : 0.02707468345761299
Loss at batch 360 : 0.016890427097678185
Loss at batch 370 : 0.015173469670116901
epoch12 finished!
Loss at batch 10 : 0.026838619261980057
Loss at batch 20 : 0.017568649724125862
Loss at batch 30 : 0.021277980878949165
Loss at batch 40 : 0.019736934453248978
Loss at batch 50 : 0.01427463535219431
Loss at batch 60 : 0.008546154014766216
Loss at batch 70 : 0.0192253477871418
Loss at batch 80 : 0.009885633364319801
Loss at batch 90 : 0.018698951229453087
Loss at batch 100 : 0.01697283610701561
Loss at batch 110 : 0.012722738087177277
Loss at batch 120 : 0.009251167066395283
Loss at batch 130 : 0.019079547375440598
Loss at batch 140 : 0.008125336840748787
Loss at batch 150 : 0.018722280859947205
Loss at batch 160 : 0.017765792086720467
Loss at batch 170 : 0.02230612188577652
Loss at batch 180 : 0.02532261796295643
Loss at batch 190 : 0.01987363211810589
Loss at batch 200 : 0.021067170426249504
Loss at batch 210 : 0.014402635395526886
Loss at batch 220 : 0.01948663406074047
Loss at batch 230 : 0.016065439209342003
Loss at batch 240 : 0.018104510381817818
Loss at batch 250 : 0.020498059689998627
Loss at batch 260 : 0.01750018447637558
Loss at batch 270 : 0.009951886720955372
Loss at batch 280 : 0.029897915199398994
Loss at batch 290 : 0.02030295878648758
Loss at batch 300 : 0.017828455194830894
Loss at batch 310 : 0.012797471135854721
Loss at batch 320 : 0.022863494232296944
Loss at batch 330 : 0.009336190298199654
Loss at batch 340 : 0.018581125885248184
Loss at batch 350 : 0.016484782099723816
Loss at batch 360 : 0.008313477970659733
Loss at batch 370 : 0.015189331956207752
epoch4 finished!
Loss at batch 10 : 0.01326743047684431
Loss at batch 20 : 0.007218494080007076
Loss at batch 30 : 0.01915423572063446
Loss at batch 40 : 0.009975424967706203
Loss at batch 50 : 0.008795355446636677
Loss at batch 60 : 0.02016480825841427
Loss at batch 70 : 0.020018087700009346
Loss at batch 80 : 0.008225111290812492
Loss at batch 90 : 0.02495546266436577
Loss at batch 100 : 0.014385572634637356
Loss at batch 110 : 0.014802816323935986
Loss at batch 120 : 0.010454380884766579
Loss at batch 130 : 0.00899028591811657
Loss at batch 140 : 0.015756404027342796
Loss at batch 150 : 0.01067239698022604
Loss at batch 160 : 0.018197933211922646
Loss at batch 170 : 0.021592577919363976
Loss at batch 180 : 0.013418808579444885
Loss at batch 190 : 0.01505355630069971
Loss at batch 200 : 0.010582697577774525
Loss at batch 210 : 0.01294358167797327
Loss at batch 220 : 0.008013843558728695
Loss at batch 230 : 0.01037453580647707
Loss at batch 240 : 0.024327857419848442
Loss at batch 250 : 0.02319975569844246
Loss at batch 260 : 0.01260368712246418
Loss at batch 270 : 0.016116410493850708
Loss at batch 280 : 0.010777576826512814
Loss at batch 290 : 0.015712948516011238
Loss at batch 300 : 0.01175406388938427
Loss at batch 310 : 0.017345650121569633
Loss at batch 320 : 0.01949041709303856
Loss at batch 330 : 0.01534937135875225
Loss at batch 340 : 0.025688262656331062
Loss at batch 350 : 0.011138001456856728
Loss at batch 360 : 0.013334356248378754
Loss at batch 370 : 0.01863749511539936
epoch4 finished!
Loss at batch 10 : 0.015067211352288723
Loss at batch 20 : 0.02739790827035904
Loss at batch 30 : 0.01165229082107544
Loss at batch 40 : 0.008851288817822933
Loss at batch 50 : 0.017643196508288383
Loss at batch 60 : 0.020666882395744324
Loss at batch 70 : 0.014543471857905388
Loss at batch 80 : 0.014830296859145164
Loss at batch 90 : 0.014172765426337719
Loss at batch 100 : 0.016859428957104683
Loss at batch 110 : 0.013256479986011982
Loss at batch 120 : 0.018197225406765938
Loss at batch 130 : 0.011372563429176807
Loss at batch 140 : 0.0131495650857687
Loss at batch 150 : 0.007607859559357166
Loss at batch 160 : 0.012374883517622948
Loss at batch 170 : 0.016710441559553146
Loss at batch 180 : 0.011945790611207485
Loss at batch 190 : 0.01180933602154255
Loss at batch 200 : 0.016713570803403854
Loss at batch 210 : 0.014668690040707588
Loss at batch 220 : 0.013066760264337063
Loss at batch 230 : 0.01083737425506115
Loss at batch 240 : 0.016178395599126816
Loss at batch 250 : 0.006302562076598406
Loss at batch 260 : 0.02447744645178318
Loss at batch 270 : 0.01288269367069006
Loss at batch 280 : 0.021229036152362823
Loss at batch 290 : 0.026629718020558357
Loss at batch 300 : 0.01820940524339676
Loss at batch 310 : 0.011439572088420391
Loss at batch 320 : 0.01726168766617775
Loss at batch 330 : 0.011246096342802048
Loss at batch 340 : 0.01937316171824932
Loss at batch 350 : 0.01222298014909029
Loss at batch 360 : 0.0248126033693552
Loss at batch 370 : 0.013758578337728977
epoch13 finished!
Loss at batch 10 : 0.012619949877262115
Loss at batch 20 : 0.017449388280510902
Loss at batch 30 : 0.007617369759827852
Loss at batch 40 : 0.013400095514953136
Loss at batch 50 : 0.012160370126366615
Loss at batch 60 : 0.02070607617497444
Loss at batch 70 : 0.011881150305271149
Loss at batch 80 : 0.012992220930755138
Loss at batch 90 : 0.013462572358548641
Loss at batch 100 : 0.013578826561570168
Loss at batch 110 : 0.010291843675076962
Loss at batch 120 : 0.021063169464468956
Loss at batch 130 : 0.013740727677941322
Loss at batch 140 : 0.010057146660983562
Loss at batch 150 : 0.012128080241382122
Loss at batch 160 : 0.016368718817830086
Loss at batch 170 : 0.013387531973421574
Loss at batch 180 : 0.015156586654484272
Loss at batch 190 : 0.015125640667974949
Loss at batch 200 : 0.01187682244926691
Loss at batch 210 : 0.017226645722985268
Loss at batch 220 : 0.02361500822007656
Loss at batch 230 : 0.014271240681409836
Loss at batch 240 : 0.012444393709301949
Loss at batch 250 : 0.01315037626773119
Loss at batch 260 : 0.009234593249857426
Loss at batch 270 : 0.01963254064321518
Loss at batch 280 : 0.013397975824773312
Loss at batch 290 : 0.009261419996619225
Loss at batch 300 : 0.011934769339859486
Loss at batch 310 : 0.010255705565214157
Loss at batch 320 : 0.011953787878155708
Loss at batch 330 : 0.01651121862232685
Loss at batch 340 : 0.013335760682821274
Loss at batch 350 : 0.018092304468154907
Loss at batch 360 : 0.015664275735616684
Loss at batch 370 : 0.012622786685824394
epoch14 finished!
Loss at batch 10 : 0.016711905598640442
Loss at batch 20 : 0.007052457891404629
Loss at batch 30 : 0.012140640057623386
Loss at batch 40 : 0.012611296959221363
Loss at batch 50 : 0.012753648683428764
Loss at batch 60 : 0.00729451235383749
Loss at batch 70 : 0.01459695678204298
Loss at batch 80 : 0.0178101547062397
Loss at batch 90 : 0.016515273600816727
Loss at batch 100 : 0.01807226613163948
Loss at batch 110 : 0.027530135586857796
Loss at batch 120 : 0.011036370880901814
Loss at batch 130 : 0.020103810355067253
Loss at batch 140 : 0.026272650808095932
Loss at batch 150 : 0.026996193453669548
Loss at batch 160 : 0.014386794529855251
Loss at batch 170 : 0.01513747125864029
Loss at batch 180 : 0.009771536104381084
Loss at batch 190 : 0.011983984149992466
Loss at batch 200 : 0.015384731814265251
Loss at batch 210 : 0.01319045852869749
Loss at batch 220 : 0.01574528031051159
Loss at batch 230 : 0.017702709883451462
Loss at batch 240 : 0.010401368141174316
Loss at batch 250 : 0.009945208206772804
Loss at batch 260 : 0.02519429661333561
Loss at batch 270 : 0.01643465645611286
Loss at batch 280 : 0.028021065518260002
Loss at batch 290 : 0.015391731634736061
Loss at batch 300 : 0.009043709374964237
Loss at batch 310 : 0.010431495495140553
Loss at batch 320 : 0.008480803109705448
Loss at batch 330 : 0.01711340807378292
Loss at batch 340 : 0.00823286734521389
Loss at batch 350 : 0.018549632281064987
Loss at batch 360 : 0.008263027295470238
Loss at batch 370 : 0.011649219319224358
epoch5 finished!
Loss at batch 10 : 0.021463263779878616
Loss at batch 20 : 0.011654481291770935
Loss at batch 30 : 0.012136482633650303
Loss at batch 40 : 0.029492022469639778
Loss at batch 50 : 0.016025811433792114
Loss at batch 60 : 0.01233845017850399
Loss at batch 70 : 0.010225052945315838
Loss at batch 80 : 0.0123625248670578
Loss at batch 90 : 0.02952580153942108
Loss at batch 100 : 0.017034029588103294
Loss at batch 110 : 0.015664799138903618
Loss at batch 120 : 0.012973387725651264
Loss at batch 130 : 0.018023675307631493
Loss at batch 140 : 0.012941750697791576
Loss at batch 150 : 0.01942312903702259
Loss at batch 160 : 0.01048289891332388
Loss at batch 170 : 0.018176749348640442
Loss at batch 180 : 0.028990430757403374
Loss at batch 190 : 0.012491459958255291
Loss at batch 200 : 0.02804678864777088
Loss at batch 210 : 0.015604806132614613
Loss at batch 220 : 0.007957915775477886
Loss at batch 230 : 0.0212871003895998
Loss at batch 240 : 0.01601884886622429
Loss at batch 250 : 0.016657400876283646
Loss at batch 260 : 0.01754753664135933
Loss at batch 270 : 0.01136202272027731
Loss at batch 280 : 0.008769609034061432
Loss at batch 290 : 0.015636300668120384
Loss at batch 300 : 0.020015183836221695
Loss at batch 310 : 0.010122571140527725
Loss at batch 320 : 0.012502769008278847
Loss at batch 330 : 0.016225997358560562
Loss at batch 340 : 0.023788172751665115
Loss at batch 350 : 0.011025655083358288
Loss at batch 360 : 0.016169529408216476
Loss at batch 370 : 0.016149362549185753
epoch5 finished!
Loss at batch 10 : 0.011307849548757076
Loss at batch 20 : 0.030710725113749504
Loss at batch 30 : 0.01592293381690979
Loss at batch 40 : 0.013636660762131214
Loss at batch 50 : 0.013540840707719326
Loss at batch 60 : 0.021045584231615067
Loss at batch 70 : 0.01288915891200304
Loss at batch 80 : 0.014756348915398121
Loss at batch 90 : 0.01367119885981083
Loss at batch 100 : 0.015798848122358322
Loss at batch 110 : 0.02190002053976059
Loss at batch 120 : 0.017495358362793922
Loss at batch 130 : 0.0192329790443182
Loss at batch 140 : 0.020231397822499275
Loss at batch 150 : 0.01041282806545496
Loss at batch 160 : 0.009903641417622566
Loss at batch 170 : 0.018727798014879227
Loss at batch 180 : 0.013575030490756035
Loss at batch 190 : 0.009292807430028915
Loss at batch 200 : 0.02134530618786812
Loss at batch 210 : 0.009096121415495872
Loss at batch 220 : 0.011060518212616444
Loss at batch 230 : 0.014820014126598835
Loss at batch 240 : 0.017483647912740707
Loss at batch 250 : 0.012464328669011593
Loss at batch 260 : 0.012387072667479515
Loss at batch 270 : 0.01317253801971674
Loss at batch 280 : 0.01442098431289196
Loss at batch 290 : 0.016700968146324158
Loss at batch 300 : 0.01496582105755806
Loss at batch 310 : 0.009460903704166412
Loss at batch 320 : 0.010224868543446064
Loss at batch 330 : 0.025125574320554733
Loss at batch 340 : 0.0236915722489357
Loss at batch 350 : 0.006780710536986589
Loss at batch 360 : 0.01161778625100851
Loss at batch 370 : 0.015175879001617432
epoch15 finished!
Loss at batch 10 : 0.028576724231243134
Loss at batch 20 : 0.013197558932006359
Loss at batch 30 : 0.018171802163124084
Loss at batch 40 : 0.02045634761452675
Loss at batch 50 : 0.02101256512105465
Loss at batch 60 : 0.019623829051852226
Loss at batch 70 : 0.018713749945163727
Loss at batch 80 : 0.014316601678729057
Loss at batch 90 : 0.011902431026101112
Loss at batch 100 : 0.01589922234416008
Loss at batch 110 : 0.012445223517715931
Loss at batch 120 : 0.01960328035056591
Loss at batch 130 : 0.0121846878901124
Loss at batch 140 : 0.016210859641432762
Loss at batch 150 : 0.009824703447520733
Loss at batch 160 : 0.020568910986185074
Loss at batch 170 : 0.017728211358189583
Loss at batch 180 : 0.019881896674633026
Loss at batch 190 : 0.010060757398605347
Loss at batch 200 : 0.014018669724464417
Loss at batch 210 : 0.010771705769002438
Loss at batch 220 : 0.009506777860224247
Loss at batch 230 : 0.01108508463948965
Loss at batch 240 : 0.023241212591528893
Loss at batch 250 : 0.025199783965945244
Loss at batch 260 : 0.018186187371611595
Loss at batch 270 : 0.012544173747301102
Loss at batch 280 : 0.00895613618195057
Loss at batch 290 : 0.01599704846739769
Loss at batch 300 : 0.014162109233438969
Loss at batch 310 : 0.019959228113293648
Loss at batch 320 : 0.0186037365347147
Loss at batch 330 : 0.020463287830352783
Loss at batch 340 : 0.0067578996531665325
Loss at batch 350 : 0.01451285183429718
Loss at batch 360 : 0.016893450170755386
Loss at batch 370 : 0.041703321039676666
epoch16 finished!
Loss at batch 10 : 0.018900066614151
Loss at batch 20 : 0.01476370170712471
Loss at batch 30 : 0.008350856602191925
Loss at batch 40 : 0.03153067082166672
Loss at batch 50 : 0.013584621250629425
Loss at batch 60 : 0.011811007745563984
Loss at batch 70 : 0.01224283967167139
Loss at batch 80 : 0.02092638611793518
Loss at batch 90 : 0.007890118286013603
Loss at batch 100 : 0.014319239184260368
Loss at batch 110 : 0.014212150126695633
Loss at batch 120 : 0.016348788514733315
Loss at batch 130 : 0.01520968321710825
Loss at batch 140 : 0.02459990233182907
Loss at batch 150 : 0.013753342442214489
Loss at batch 160 : 0.014107350260019302
Loss at batch 170 : 0.012350492179393768
Loss at batch 180 : 0.016871538013219833
Loss at batch 190 : 0.01538923941552639
Loss at batch 200 : 0.01311243511736393
Loss at batch 210 : 0.007351954001933336
Loss at batch 220 : 0.013754058629274368
Loss at batch 230 : 0.0214084479957819
Loss at batch 240 : 0.021235166117548943
Loss at batch 250 : 0.015896081924438477
Loss at batch 260 : 0.017985576763749123
Loss at batch 270 : 0.014660777524113655
Loss at batch 280 : 0.009130981750786304
Loss at batch 290 : 0.020673014223575592
Loss at batch 300 : 0.011966966092586517
Loss at batch 310 : 0.015536369755864143
Loss at batch 320 : 0.02289431355893612
Loss at batch 330 : 0.020756840705871582
Loss at batch 340 : 0.010628734715282917
Loss at batch 350 : 0.028163177892565727
Loss at batch 360 : 0.022825226187705994
Loss at batch 370 : 0.01503268163651228
epoch6 finished!
Loss at batch 10 : 0.012452539056539536
Loss at batch 20 : 0.015959039330482483
Loss at batch 30 : 0.02130095660686493
Loss at batch 40 : 0.007304188795387745
Loss at batch 50 : 0.00958196260035038
Loss at batch 60 : 0.02563638985157013
Loss at batch 70 : 0.01723286509513855
Loss at batch 80 : 0.014753298833966255
Loss at batch 90 : 0.012541723437607288
Loss at batch 100 : 0.01832042820751667
Loss at batch 110 : 0.011679687537252903
Loss at batch 120 : 0.014433879405260086
Loss at batch 130 : 0.01359772402793169
Loss at batch 140 : 0.017626995220780373
Loss at batch 150 : 0.018356451764702797
Loss at batch 160 : 0.025155236944556236
Loss at batch 170 : 0.014481631107628345
Loss at batch 180 : 0.02099628746509552
Loss at batch 190 : 0.017481623217463493
Loss at batch 200 : 0.010971853509545326
Loss at batch 210 : 0.01335502415895462
Loss at batch 220 : 0.022468365728855133
Loss at batch 230 : 0.015205413103103638
Loss at batch 240 : 0.013238996267318726
Loss at batch 250 : 0.012972593307495117
Loss at batch 260 : 0.014797198586165905
Loss at batch 270 : 0.012776930816471577
Loss at batch 280 : 0.014322255738079548
Loss at batch 290 : 0.02082589454948902
Loss at batch 300 : 0.010363212786614895
Loss at batch 310 : 0.018758872523903847
Loss at batch 320 : 0.01432011742144823
Loss at batch 330 : 0.022009627893567085
Loss at batch 340 : 0.01801544427871704
Loss at batch 350 : 0.013806477189064026
Loss at batch 360 : 0.012775328010320663
Loss at batch 370 : 0.013891992159187794
epoch6 finished!
Loss at batch 10 : 0.014740477316081524
Loss at batch 20 : 0.01691214181482792
Loss at batch 30 : 0.010691524483263493
Loss at batch 40 : 0.009440719150006771
Loss at batch 50 : 0.014361250214278698
Loss at batch 60 : 0.00904975924640894
Loss at batch 70 : 0.02008834294974804
Loss at batch 80 : 0.015315067023038864
Loss at batch 90 : 0.011110195890069008
Loss at batch 100 : 0.014513717964291573
Loss at batch 110 : 0.00984184630215168
Loss at batch 120 : 0.012586191296577454
Loss at batch 130 : 0.017968347296118736
Loss at batch 140 : 0.017473027110099792
Loss at batch 150 : 0.011781275272369385
Loss at batch 160 : 0.01705978997051716
Loss at batch 170 : 0.008405042812228203
Loss at batch 180 : 0.017224512994289398
Loss at batch 190 : 0.022446807473897934
Loss at batch 200 : 0.010953896678984165
Loss at batch 210 : 0.025200964882969856
Loss at batch 220 : 0.014603310264647007
Loss at batch 230 : 0.009102323092520237
Loss at batch 240 : 0.006098881829530001
Loss at batch 250 : 0.023461049422621727
Loss at batch 260 : 0.01768464408814907
Loss at batch 270 : 0.015050472691655159
Loss at batch 280 : 0.015012218616902828
Loss at batch 290 : 0.010779563337564468
Loss at batch 300 : 0.014878777787089348
Loss at batch 310 : 0.019426079466938972
Loss at batch 320 : 0.011527311988174915
Loss at batch 330 : 0.014928975142538548
Loss at batch 340 : 0.02765420824289322
Loss at batch 350 : 0.012120873667299747
Loss at batch 360 : 0.014198515564203262
Loss at batch 370 : 0.02271503582596779
epoch17 finished!
Loss at batch 10 : 0.015172222629189491
Loss at batch 20 : 0.010277737863361835
Loss at batch 30 : 0.013221055269241333
Loss at batch 40 : 0.011173301376402378
Loss at batch 50 : 0.012110110372304916
Loss at batch 60 : 0.010430467315018177
Loss at batch 70 : 0.020052162930369377
Loss at batch 80 : 0.02444722130894661
Loss at batch 90 : 0.022995207458734512
Loss at batch 100 : 0.007514263037592173
Loss at batch 110 : 0.01932702586054802
Loss at batch 120 : 0.021067140623927116
Loss at batch 130 : 0.011104041710495949
Loss at batch 140 : 0.011960935778915882
Loss at batch 150 : 0.02672645077109337
Loss at batch 160 : 0.010690170340240002
Loss at batch 170 : 0.01736762374639511
Loss at batch 180 : 0.011613769456744194
Loss at batch 190 : 0.015539949759840965
Loss at batch 200 : 0.018750613555312157
Loss at batch 210 : 0.013653084635734558
Loss at batch 220 : 0.02278980240225792
Loss at batch 230 : 0.02519860677421093
Loss at batch 240 : 0.012631521560251713
Loss at batch 250 : 0.01416714396327734
Loss at batch 260 : 0.019765282049775124
Loss at batch 270 : 0.006547690834850073
Loss at batch 280 : 0.008272474631667137
Loss at batch 290 : 0.011797280050814152
Loss at batch 300 : 0.02440490387380123
Loss at batch 310 : 0.008810997009277344
Loss at batch 320 : 0.01625225692987442
Loss at batch 330 : 0.020996198058128357
Loss at batch 340 : 0.012586233206093311
Loss at batch 350 : 0.02192016690969467
Loss at batch 360 : 0.015266356989741325
Loss at batch 370 : 0.016769573092460632
epoch18 finished!
Loss at batch 10 : 0.016224343329668045
Loss at batch 20 : 0.017188340425491333
Loss at batch 30 : 0.022389572113752365
Loss at batch 40 : 0.014954323880374432
Loss at batch 50 : 0.016757313162088394
Loss at batch 60 : 0.008751382119953632
Loss at batch 70 : 0.016016051173210144
Loss at batch 80 : 0.010228073224425316
Loss at batch 90 : 0.017928006127476692
Loss at batch 100 : 0.014354389160871506
Loss at batch 110 : 0.015080559067428112
Loss at batch 120 : 0.017806969583034515
Loss at batch 130 : 0.010541541501879692
Loss at batch 140 : 0.016003049910068512
Loss at batch 150 : 0.012754246592521667
Loss at batch 160 : 0.016178546473383904
Loss at batch 170 : 0.025738267228007317
Loss at batch 180 : 0.020145699381828308
Loss at batch 190 : 0.02065519243478775
Loss at batch 200 : 0.010724281892180443
Loss at batch 210 : 0.01778257079422474
Loss at batch 220 : 0.013621296733617783
Loss at batch 230 : 0.014690808951854706
Loss at batch 240 : 0.013766171410679817
Loss at batch 250 : 0.01850694976747036
Loss at batch 260 : 0.013862762600183487
Loss at batch 270 : 0.013482344336807728
Loss at batch 280 : 0.015089632011950016
Loss at batch 290 : 0.016863707453012466
Loss at batch 300 : 0.021080242469906807
Loss at batch 310 : 0.01395686250180006
Loss at batch 320 : 0.012483599595725536
Loss at batch 330 : 0.014796005561947823
Loss at batch 340 : 0.012356040999293327
Loss at batch 350 : 0.00844294112175703
Loss at batch 360 : 0.019833175465464592
Loss at batch 370 : 0.016621844843029976
epoch7 finished!
Loss at batch 10 : 0.01508056465536356
Loss at batch 20 : 0.014637907035648823
Loss at batch 30 : 0.008717210963368416
Loss at batch 40 : 0.01152379997074604
Loss at batch 50 : 0.010546195320785046
Loss at batch 60 : 0.014936587773263454
Loss at batch 70 : 0.014079117216169834
Loss at batch 80 : 0.018759550526738167
Loss at batch 90 : 0.027751466259360313
Loss at batch 100 : 0.009092053398489952
Loss at batch 110 : 0.04236004501581192
Loss at batch 120 : 0.014139687642455101
Loss at batch 130 : 0.01808701828122139
Loss at batch 140 : 0.021745527163147926
Loss at batch 150 : 0.018436182290315628
Loss at batch 160 : 0.02852696366608143
Loss at batch 170 : 0.015300962142646313
Loss at batch 180 : 0.018903682008385658
Loss at batch 190 : 0.03013676404953003
Loss at batch 200 : 0.023207008838653564
Loss at batch 210 : 0.018775442615151405
Loss at batch 220 : 0.011847478337585926
Loss at batch 230 : 0.021616699174046516
Loss at batch 240 : 0.02008737064898014
Loss at batch 250 : 0.014620809815824032
Loss at batch 260 : 0.014846449717879295
Loss at batch 270 : 0.02288268692791462
Loss at batch 280 : 0.011948772706091404
Loss at batch 290 : 0.013205651193857193
Loss at batch 300 : 0.015728479251265526
Loss at batch 310 : 0.013572750613093376
Loss at batch 320 : 0.011033170856535435
Loss at batch 330 : 0.013919660821557045
Loss at batch 340 : 0.011544346809387207
Loss at batch 350 : 0.012049281038343906
Loss at batch 360 : 0.02369358204305172
Loss at batch 370 : 0.011476383544504642
epoch19 finished!
Loss at batch 10 : 0.017477676272392273
Loss at batch 20 : 0.012389255687594414
Loss at batch 30 : 0.014770662412047386
Loss at batch 40 : 0.013645047321915627
Loss at batch 50 : 0.01825856976211071
Loss at batch 60 : 0.0109774274751544
Loss at batch 70 : 0.020862000063061714
Loss at batch 80 : 0.010968768037855625
Loss at batch 90 : 0.02341221272945404
Loss at batch 100 : 0.01822276972234249
Loss at batch 110 : 0.014709939248859882
Loss at batch 120 : 0.010760960169136524
Loss at batch 130 : 0.012231996282935143
Loss at batch 140 : 0.009597337804734707
Loss at batch 150 : 0.006454759277403355
Loss at batch 160 : 0.013730999082326889
Loss at batch 170 : 0.011890907771885395
Loss at batch 180 : 0.01130278967320919
Loss at batch 190 : 0.009741965681314468
Loss at batch 200 : 0.016082612797617912
Loss at batch 210 : 0.017327941954135895
Loss at batch 220 : 0.011903953738510609
Loss at batch 230 : 0.009004109539091587
Loss at batch 240 : 0.0180941391736269
Loss at batch 250 : 0.01516444981098175
Loss at batch 260 : 0.010231014341115952
Loss at batch 270 : 0.01191016100347042
Loss at batch 280 : 0.019529348239302635
Loss at batch 290 : 0.020344620570540428
Loss at batch 300 : 0.01435188390314579
Loss at batch 310 : 0.02849290892481804
Loss at batch 320 : 0.01979946158826351
Loss at batch 330 : 0.018037918955087662
Loss at batch 340 : 0.013149302452802658
Loss at batch 350 : 0.009719518944621086
Loss at batch 360 : 0.012846910394728184
Loss at batch 370 : 0.019294211640954018
epoch7 finished!
Loss at batch 10 : 0.014294982887804508
Loss at batch 20 : 0.017181547358632088
Loss at batch 30 : 0.012470669113099575
Loss at batch 40 : 0.017266036942601204
Loss at batch 50 : 0.02379537932574749
Loss at batch 60 : 0.01459211390465498
Loss at batch 70 : 0.013775709085166454
Loss at batch 80 : 0.010927153751254082
Loss at batch 90 : 0.021850353106856346
Loss at batch 100 : 0.019743211567401886
Loss at batch 110 : 0.008109858259558678
Loss at batch 120 : 0.010766786523163319
Loss at batch 130 : 0.013276399113237858
Loss at batch 140 : 0.017092488706111908
Loss at batch 150 : 0.009317339397966862
Loss at batch 160 : 0.02256646193563938
Loss at batch 170 : 0.014700708910822868
Loss at batch 180 : 0.01996522769331932
Loss at batch 190 : 0.016175728291273117
Loss at batch 200 : 0.025000764057040215
Loss at batch 210 : 0.02519049309194088
Loss at batch 220 : 0.015372897498309612
Loss at batch 230 : 0.011633739806711674
Loss at batch 240 : 0.012888766825199127
Loss at batch 250 : 0.019163576886057854
Loss at batch 260 : 0.012828570790588856
Loss at batch 270 : 0.02066170610487461
Loss at batch 280 : 0.01604676991701126
Loss at batch 290 : 0.006899380125105381
Loss at batch 300 : 0.018163569271564484
Loss at batch 310 : 0.013735747896134853
Loss at batch 320 : 0.011314082890748978
Loss at batch 330 : 0.014416413381695747
Loss at batch 340 : 0.006469258572906256
Loss at batch 350 : 0.015246815979480743
Loss at batch 360 : 0.016651196405291557
Loss at batch 370 : 0.025066597387194633
epoch20 finished!
Loss at batch 10 : 0.019730912521481514
Loss at batch 20 : 0.021990090608596802
Loss at batch 30 : 0.016415806487202644
Loss at batch 40 : 0.012478215619921684
Loss at batch 50 : 0.01787901110947132
Loss at batch 60 : 0.0207236185669899
Loss at batch 70 : 0.017887448891997337
Loss at batch 80 : 0.018811408430337906
Loss at batch 90 : 0.015547544695436954
Loss at batch 100 : 0.012961831875145435
Loss at batch 110 : 0.014180101454257965
Loss at batch 120 : 0.019110681489109993
Loss at batch 130 : 0.01398412324488163
Loss at batch 140 : 0.012347563169896603
Loss at batch 150 : 0.018748832866549492
Loss at batch 160 : 0.02042093500494957
Loss at batch 170 : 0.013891013339161873
Loss at batch 180 : 0.015423089265823364
Loss at batch 190 : 0.010462811216711998
Loss at batch 200 : 0.013943521305918694
Loss at batch 210 : 0.01127772219479084
Loss at batch 220 : 0.020703740417957306
Loss at batch 230 : 0.010635841637849808
Loss at batch 240 : 0.010385562665760517
Loss at batch 250 : 0.010402440093457699
Loss at batch 260 : 0.014346313662827015
Loss at batch 270 : 0.03236975893378258
Loss at batch 280 : 0.017628483474254608
Loss at batch 290 : 0.01186104491353035
Loss at batch 300 : 0.009262237697839737
Loss at batch 310 : 0.014642175287008286
Loss at batch 320 : 0.01698470674455166
Loss at batch 330 : 0.02243947423994541
Loss at batch 340 : 0.014966270886361599
Loss at batch 350 : 0.015279152430593967
Loss at batch 360 : 0.02238919585943222
Loss at batch 370 : 0.013341954909265041
epoch8 finished!
Loss at batch 10 : 0.018682217225432396
Loss at batch 20 : 0.019716845825314522
Loss at batch 30 : 0.02563866227865219
Loss at batch 40 : 0.01589091308414936
Loss at batch 50 : 0.015831923112273216
Loss at batch 60 : 0.018072139471769333
Loss at batch 70 : 0.015113119035959244
Loss at batch 80 : 0.016922805458307266
Loss at batch 90 : 0.010936466045677662
Loss at batch 100 : 0.015423092991113663
Loss at batch 110 : 0.014190447516739368
Loss at batch 120 : 0.01658831723034382
Loss at batch 130 : 0.019661540165543556
Loss at batch 140 : 0.018120285123586655
Loss at batch 150 : 0.016237180680036545
Loss at batch 160 : 0.010471533983945847
Loss at batch 170 : 0.01267919596284628
Loss at batch 180 : 0.019772633910179138
Loss at batch 190 : 0.013768106698989868
Loss at batch 200 : 0.017496807500720024
Loss at batch 210 : 0.010189089924097061
Loss at batch 220 : 0.014928721822798252
Loss at batch 230 : 0.011365042999386787
Loss at batch 240 : 0.025129420682787895
Loss at batch 250 : 0.014045110903680325
Loss at batch 260 : 0.012830950319766998
Loss at batch 270 : 0.013484247028827667
Loss at batch 280 : 0.008445536717772484
Loss at batch 290 : 0.012537852860987186
Loss at batch 300 : 0.024918777868151665
Loss at batch 310 : 0.01743829809129238
Loss at batch 320 : 0.016069138422608376
Loss at batch 330 : 0.01932854764163494
Loss at batch 340 : 0.008918275125324726
Loss at batch 350 : 0.024036183953285217
Loss at batch 360 : 0.011652183718979359
Loss at batch 370 : 0.01281303446739912
epoch21 finished!
Loss at batch 10 : 0.007787107490003109
Loss at batch 20 : 0.009235112927854061
Loss at batch 30 : 0.010701066814363003
Loss at batch 40 : 0.019205784425139427
Loss at batch 50 : 0.015800820663571358
Loss at batch 60 : 0.02051757462322712
Loss at batch 70 : 0.02526198886334896
Loss at batch 80 : 0.03029680997133255
Loss at batch 90 : 0.013053896836936474
Loss at batch 100 : 0.01754533126950264
Loss at batch 110 : 0.015612690709531307
Loss at batch 120 : 0.01636824570596218
Loss at batch 130 : 0.01267712190747261
Loss at batch 140 : 0.014853802509605885
Loss at batch 150 : 0.010507256723940372
Loss at batch 160 : 0.03131450340151787
Loss at batch 170 : 0.008566210977733135
Loss at batch 180 : 0.024419404566287994
Loss at batch 190 : 0.020677365362644196
Loss at batch 200 : 0.023065604269504547
Loss at batch 210 : 0.01601581647992134
Loss at batch 220 : 0.014133261516690254
Loss at batch 230 : 0.010846746154129505
Loss at batch 240 : 0.011738413013517857
Loss at batch 250 : 0.011137502267956734
Loss at batch 260 : 0.014681350439786911
Loss at batch 270 : 0.016035540029406548
Loss at batch 280 : 0.009813189506530762
Loss at batch 290 : 0.031030265614390373
Loss at batch 300 : 0.01997123472392559
Loss at batch 310 : 0.010602014139294624
Loss at batch 320 : 0.01589064486324787
Loss at batch 330 : 0.010251982137560844
Loss at batch 340 : 0.011955149471759796
Loss at batch 350 : 0.014027131721377373
Loss at batch 360 : 0.01545721385627985
Loss at batch 370 : 0.01592830754816532
epoch8 finished!
Loss at batch 10 : 0.020374249666929245
Loss at batch 20 : 0.01454933825880289
Loss at batch 30 : 0.025406545028090477
Loss at batch 40 : 0.01436205580830574
Loss at batch 50 : 0.013724361546337605
Loss at batch 60 : 0.018535830080509186
Loss at batch 70 : 0.017261164262890816
Loss at batch 80 : 0.010919813066720963
Loss at batch 90 : 0.008475761860609055
Loss at batch 100 : 0.01160114724189043
Loss at batch 110 : 0.008237861096858978
Loss at batch 120 : 0.018188240006566048
Loss at batch 130 : 0.007560462225228548
Loss at batch 140 : 0.00874336063861847
Loss at batch 150 : 0.0067014810629189014
Loss at batch 160 : 0.014660416170954704
Loss at batch 170 : 0.00804252177476883
Loss at batch 180 : 0.018974261358380318
Loss at batch 190 : 0.013830117881298065
Loss at batch 200 : 0.015681561082601547
Loss at batch 210 : 0.023933790624141693
Loss at batch 220 : 0.01948956772685051
Loss at batch 230 : 0.024998491629958153
Loss at batch 240 : 0.015056097880005836
Loss at batch 250 : 0.020889058709144592
Loss at batch 260 : 0.019218601286411285
Loss at batch 270 : 0.033961959183216095
Loss at batch 280 : 0.017359644174575806
Loss at batch 290 : 0.011552051641047001
Loss at batch 300 : 0.021383149549365044
Loss at batch 310 : 0.01799609325826168
Loss at batch 320 : 0.015555506572127342
Loss at batch 330 : 0.018082210794091225
Loss at batch 340 : 0.012605519033968449
Loss at batch 350 : 0.01417832262814045
Loss at batch 360 : 0.008138302713632584
Loss at batch 370 : 0.0094205467030406
epoch22 finished!
Loss at batch 10 : 0.016246428713202477
Loss at batch 20 : 0.011199201457202435
Loss at batch 30 : 0.019549740478396416
Loss at batch 40 : 0.01196411345154047
Loss at batch 50 : 0.014308011159300804
Loss at batch 60 : 0.017581908032298088
Loss at batch 70 : 0.014887032099068165
Loss at batch 80 : 0.020743519067764282
Loss at batch 90 : 0.02181554026901722
Loss at batch 100 : 0.01210063323378563
Loss at batch 110 : 0.016903631389141083
Loss at batch 120 : 0.012975353747606277
Loss at batch 130 : 0.009630461223423481
Loss at batch 140 : 0.02375507913529873
Loss at batch 150 : 0.010666134767234325
Loss at batch 160 : 0.017127638682723045
Loss at batch 170 : 0.013940799981355667
Loss at batch 180 : 0.014900801703333855
Loss at batch 190 : 0.014836096204817295
Loss at batch 200 : 0.014090335927903652
Loss at batch 210 : 0.014063258655369282
Loss at batch 220 : 0.012044621631503105
Loss at batch 230 : 0.01774866320192814
Loss at batch 240 : 0.017707359045743942
Loss at batch 250 : 0.011415546759963036
Loss at batch 260 : 0.017178235575556755
Loss at batch 270 : 0.015030194073915482
Loss at batch 280 : 0.02134721539914608
Loss at batch 290 : 0.007411828730255365
Loss at batch 300 : 0.013486475683748722
Loss at batch 310 : 0.014332614839076996
Loss at batch 320 : 0.01065699104219675
Loss at batch 330 : 0.016257181763648987
Loss at batch 340 : 0.017006177455186844
Loss at batch 350 : 0.01614455133676529
Loss at batch 360 : 0.01838635466992855
Loss at batch 370 : 0.012306810356676579
epoch23 finished!
Loss at batch 10 : 0.019606124609708786
Loss at batch 20 : 0.012954041361808777
Loss at batch 30 : 0.00974939577281475
Loss at batch 40 : 0.012771159410476685
Loss at batch 50 : 0.016703519970178604
Loss at batch 60 : 0.027175119146704674
Loss at batch 70 : 0.017106443643569946
Loss at batch 80 : 0.01661568135023117
Loss at batch 90 : 0.013943048194050789
Loss at batch 100 : 0.012626131065189838
Loss at batch 110 : 0.017152266576886177
Loss at batch 120 : 0.02571083791553974
Loss at batch 130 : 0.01120209414511919
Loss at batch 140 : 0.02392779290676117
Loss at batch 150 : 0.013645256869494915
Loss at batch 160 : 0.017123963683843613
Loss at batch 170 : 0.020561644807457924
Loss at batch 180 : 0.023730183020234108
Loss at batch 190 : 0.009283972904086113
Loss at batch 200 : 0.021517569199204445
Loss at batch 210 : 0.012063964270055294
Loss at batch 220 : 0.009887573309242725
Loss at batch 230 : 0.019063014537096024
Loss at batch 240 : 0.010977528989315033
Loss at batch 250 : 0.014081614091992378
Loss at batch 260 : 0.018895043060183525
Loss at batch 270 : 0.017281558364629745
Loss at batch 280 : 0.019884999841451645
Loss at batch 290 : 0.012143347412347794
Loss at batch 300 : 0.017244748771190643
Loss at batch 310 : 0.021186498925089836
Loss at batch 320 : 0.010097350925207138
Loss at batch 330 : 0.023515110835433006
Loss at batch 340 : 0.01146656833589077
Loss at batch 350 : 0.012396681122481823
Loss at batch 360 : 0.009455784223973751
Loss at batch 370 : 0.016420654952526093
epoch9 finished!
Loss at batch 10 : 0.01966940052807331
Loss at batch 20 : 0.009695969521999359
Loss at batch 30 : 0.013714873231947422
Loss at batch 40 : 0.020261913537979126
Loss at batch 50 : 0.021605946123600006
Loss at batch 60 : 0.02061411924660206
Loss at batch 70 : 0.01584506407380104
Loss at batch 80 : 0.014659431762993336
Loss at batch 90 : 0.011609595268964767
Loss at batch 100 : 0.013235102407634258
Loss at batch 110 : 0.010404432192444801
Loss at batch 120 : 0.01733347214758396
Loss at batch 130 : 0.013826385140419006
Loss at batch 140 : 0.0311744287610054
Loss at batch 150 : 0.011230536736547947
Loss at batch 160 : 0.019967900589108467
Loss at batch 170 : 0.012147999368607998
Loss at batch 180 : 0.015776490792632103
Loss at batch 190 : 0.026316028088331223
Loss at batch 200 : 0.010788170620799065
Loss at batch 210 : 0.016757002100348473
Loss at batch 220 : 0.013232458382844925
Loss at batch 230 : 0.011219048872590065
Loss at batch 240 : 0.030741849914193153
Loss at batch 250 : 0.01300128735601902
Loss at batch 260 : 0.01669318415224552
Loss at batch 270 : 0.010047069750726223
Loss at batch 280 : 0.010633892379701138
Loss at batch 290 : 0.01006812509149313
Loss at batch 300 : 0.011865366250276566
Loss at batch 310 : 0.02333165518939495
Loss at batch 320 : 0.01627129316329956
Loss at batch 330 : 0.011372638866305351
Loss at batch 340 : 0.01214201096445322
Loss at batch 350 : 0.01251633558422327
Loss at batch 360 : 0.027052907273173332
Loss at batch 370 : 0.010582578368484974
epoch9 finished!
Loss at batch 10 : 0.015048147179186344
Loss at batch 20 : 0.013489359058439732
Loss at batch 30 : 0.016400175169110298
Loss at batch 40 : 0.010648674331605434
Loss at batch 50 : 0.01701885089278221
Loss at batch 60 : 0.028779979795217514
Loss at batch 70 : 0.022828510031104088
Loss at batch 80 : 0.014238805510103703
Loss at batch 90 : 0.025188900530338287
Loss at batch 100 : 0.015132644213736057
Loss at batch 110 : 0.01629103533923626
Loss at batch 120 : 0.024542881175875664
Loss at batch 130 : 0.02135331928730011
Loss at batch 140 : 0.01583023928105831
Loss at batch 150 : 0.02087819017469883
Loss at batch 160 : 0.015497932210564613
Loss at batch 170 : 0.014077487401664257
Loss at batch 180 : 0.012980809435248375
Loss at batch 190 : 0.017438655719161034
Loss at batch 200 : 0.02131389081478119
Loss at batch 210 : 0.013632445596158504
Loss at batch 220 : 0.017560098320245743
Loss at batch 230 : 0.016884474083781242
Loss at batch 240 : 0.024875564500689507
Loss at batch 250 : 0.013952569104731083
Loss at batch 260 : 0.012783731333911419
Loss at batch 270 : 0.009151124395430088
Loss at batch 280 : 0.025910720229148865
Loss at batch 290 : 0.017704011872410774
Loss at batch 300 : 0.00877024419605732
Loss at batch 310 : 0.023967087268829346
Loss at batch 320 : 0.010856111533939838
Loss at batch 330 : 0.00507176760584116
Loss at batch 340 : 0.01581483520567417
Loss at batch 350 : 0.010394802317023277
Loss at batch 360 : 0.009280332364141941
Loss at batch 370 : 0.022764205932617188
epoch24 finished!
Loss at batch 10 : 0.008205137215554714
Loss at batch 20 : 0.011822200380265713
Loss at batch 30 : 0.015544906258583069
Loss at batch 40 : 0.011780223809182644
Loss at batch 50 : 0.0138124730437994
Loss at batch 60 : 0.019110362976789474
Loss at batch 70 : 0.010046886280179024
Loss at batch 80 : 0.01287468709051609
Loss at batch 90 : 0.012953046709299088
Loss at batch 100 : 0.01649406924843788
Loss at batch 110 : 0.015977712348103523
Loss at batch 120 : 0.01378234289586544
Loss at batch 130 : 0.010988892987370491
Loss at batch 140 : 0.015046808868646622
Loss at batch 150 : 0.009844371117651463
Loss at batch 160 : 0.00949619710445404
Loss at batch 170 : 0.016285108402371407
Loss at batch 180 : 0.01674029417335987
Loss at batch 190 : 0.023827919736504555
Loss at batch 200 : 0.016128577291965485
Loss at batch 210 : 0.012138063088059425
Loss at batch 220 : 0.025534482672810555
Loss at batch 230 : 0.01373643521219492
Loss at batch 240 : 0.010672014206647873
Loss at batch 250 : 0.018116485327482224
Loss at batch 260 : 0.01063996646553278
Loss at batch 270 : 0.013184299692511559
Loss at batch 280 : 0.025415658950805664
Loss at batch 290 : 0.010587227530777454
Loss at batch 300 : 0.01437697745859623
Loss at batch 310 : 0.013372610323131084
Loss at batch 320 : 0.011178186163306236
Loss at batch 330 : 0.017322665080428123
Loss at batch 340 : 0.01662929728627205
Loss at batch 350 : 0.0214387234300375
Loss at batch 360 : 0.012696686200797558
Loss at batch 370 : 0.02328181266784668
epoch25 finished!
Loss at batch 10 : 0.028253214433789253
Loss at batch 20 : 0.013449019752442837
Loss at batch 30 : 0.015069467946887016
Loss at batch 40 : 0.015565868467092514
Loss at batch 50 : 0.016172833740711212
Loss at batch 60 : 0.016222843900322914
Loss at batch 70 : 0.011923404410481453
Loss at batch 80 : 0.010526435449719429
Loss at batch 90 : 0.022638313472270966
Loss at batch 100 : 0.013627232052385807
Loss at batch 110 : 0.012377391569316387
Loss at batch 120 : 0.014325849711894989
Loss at batch 130 : 0.012270810082554817
Loss at batch 140 : 0.02348669059574604
Loss at batch 150 : 0.009991399943828583
Loss at batch 160 : 0.01147831417620182
Loss at batch 170 : 0.016331356018781662
Loss at batch 180 : 0.0131842577829957
Loss at batch 190 : 0.018383733928203583
Loss at batch 200 : 0.01675308682024479
Loss at batch 210 : 0.012413432821631432
Loss at batch 220 : 0.017191344872117043
Loss at batch 230 : 0.010801644064486027
Loss at batch 240 : 0.02080502174794674
Loss at batch 250 : 0.012420744635164738
Loss at batch 260 : 0.010091256350278854
Loss at batch 270 : 0.013023891486227512
Loss at batch 280 : 0.01219647005200386
Loss at batch 290 : 0.014384280890226364
Loss at batch 300 : 0.01655961014330387
Loss at batch 310 : 0.01407100073993206
Loss at batch 320 : 0.023424366489052773
Loss at batch 330 : 0.011561542749404907
Loss at batch 340 : 0.01944800466299057
Loss at batch 350 : 0.01989494077861309
Loss at batch 360 : 0.01622186414897442
Loss at batch 370 : 0.01459129061549902
epoch10 finished!
Loss at batch 10 : 0.009897162206470966
Loss at batch 20 : 0.013030151836574078
Loss at batch 30 : 0.013473259285092354
Loss at batch 40 : 0.01583496853709221
Loss at batch 50 : 0.01149032637476921
Loss at batch 60 : 0.01807660609483719
Loss at batch 70 : 0.009959729388356209
Loss at batch 80 : 0.009893263690173626
Loss at batch 90 : 0.013013854622840881
Loss at batch 100 : 0.014200545847415924
Loss at batch 110 : 0.009177223779261112
Loss at batch 120 : 0.029111087322235107
Loss at batch 130 : 0.018456876277923584
Loss at batch 140 : 0.011283909901976585
Loss at batch 150 : 0.02029438316822052
Loss at batch 160 : 0.015326491557061672
Loss at batch 170 : 0.01118621788918972
Loss at batch 180 : 0.00855536200106144
Loss at batch 190 : 0.008420933037996292
Loss at batch 200 : 0.016635123640298843
Loss at batch 210 : 0.02016472816467285
Loss at batch 220 : 0.01544942893087864
Loss at batch 230 : 0.009450403042137623
Loss at batch 240 : 0.015542359091341496
Loss at batch 250 : 0.01770774833858013
Loss at batch 260 : 0.014240620657801628
Loss at batch 270 : 0.012058945372700691
Loss at batch 280 : 0.015204881317913532
Loss at batch 290 : 0.017243022099137306
Loss at batch 300 : 0.015160614624619484
Loss at batch 310 : 0.015303737483918667
Loss at batch 320 : 0.01654781587421894
Loss at batch 330 : 0.021593734622001648
Loss at batch 340 : 0.011663125827908516
Loss at batch 350 : 0.010652212426066399
Loss at batch 360 : 0.02409452758729458
Loss at batch 370 : 0.017695443704724312
epoch10 finished!
Loss at batch 10 : 0.013281391933560371
Loss at batch 20 : 0.015326924622058868
Loss at batch 30 : 0.01111560221761465
Loss at batch 40 : 0.015624046325683594
Loss at batch 50 : 0.012082495726644993
Loss at batch 60 : 0.010511026717722416
Loss at batch 70 : 0.011389806866645813
Loss at batch 80 : 0.012013464234769344
Loss at batch 90 : 0.015669075772166252
Loss at batch 100 : 0.0139619717374444
Loss at batch 110 : 0.017729755491018295
Loss at batch 120 : 0.014761543832719326
Loss at batch 130 : 0.01453054416924715
Loss at batch 140 : 0.009896030649542809
Loss at batch 150 : 0.030657129362225533
Loss at batch 160 : 0.015397252514958382
Loss at batch 170 : 0.01170860230922699
Loss at batch 180 : 0.027858391404151917
Loss at batch 190 : 0.018979426473379135
Loss at batch 200 : 0.012886147014796734
Loss at batch 210 : 0.013331500813364983
Loss at batch 220 : 0.015116240829229355
Loss at batch 230 : 0.009100396186113358
Loss at batch 240 : 0.01412272173911333
Loss at batch 250 : 0.011079179123044014
Loss at batch 260 : 0.013245251961052418
Loss at batch 270 : 0.022542811930179596
Loss at batch 280 : 0.009118052199482918
Loss at batch 290 : 0.015137695707380772
Loss at batch 300 : 0.013591143302619457
Loss at batch 310 : 0.01654391549527645
Loss at batch 320 : 0.01783405803143978
Loss at batch 330 : 0.014713114127516747
Loss at batch 340 : 0.018872398883104324
Loss at batch 350 : 0.02190656214952469
Loss at batch 360 : 0.013296568766236305
Loss at batch 370 : 0.01660715416073799
epoch26 finished!
Loss at batch 10 : 0.00990153755992651
Loss at batch 20 : 0.017109926789999008
Loss at batch 30 : 0.026166535913944244
Loss at batch 40 : 0.007998989894986153
Loss at batch 50 : 0.019221164286136627
Loss at batch 60 : 0.017926041036844254
Loss at batch 70 : 0.023210028186440468
Loss at batch 80 : 0.02219274826347828
Loss at batch 90 : 0.018358372151851654
Loss at batch 100 : 0.01549783069640398
Loss at batch 110 : 0.022388698533177376
Loss at batch 120 : 0.011817860417068005
Loss at batch 130 : 0.024111976847052574
Loss at batch 140 : 0.01646033301949501
Loss at batch 150 : 0.01754050888121128
Loss at batch 160 : 0.01482944842427969
Loss at batch 170 : 0.019263235852122307
Loss at batch 180 : 0.015838608145713806
Loss at batch 190 : 0.012174049392342567
Loss at batch 200 : 0.01851506158709526
Loss at batch 210 : 0.019638393074274063
Loss at batch 220 : 0.011218228377401829
Loss at batch 230 : 0.012204424478113651
Loss at batch 240 : 0.019220951944589615
Loss at batch 250 : 0.008630716241896152
Loss at batch 260 : 0.025777390226721764
Loss at batch 270 : 0.01895837113261223
Loss at batch 280 : 0.010378006845712662
Loss at batch 290 : 0.019244445487856865
Loss at batch 300 : 0.01962491311132908
Loss at batch 310 : 0.019195877015590668
Loss at batch 320 : 0.009885837323963642
Loss at batch 330 : 0.015649840235710144
Loss at batch 340 : 0.019286494702100754
Loss at batch 350 : 0.021029921248555183
Loss at batch 360 : 0.014942876994609833
Loss at batch 370 : 0.018813954666256905
epoch27 finished!
Loss at batch 10 : 0.011252891272306442
Loss at batch 20 : 0.01332200225442648
Loss at batch 30 : 0.022573217749595642
Loss at batch 40 : 0.0158500075340271
Loss at batch 50 : 0.009935887530446053
Loss at batch 60 : 0.00940224900841713
Loss at batch 70 : 0.01226278580725193
Loss at batch 80 : 0.01992652378976345
Loss at batch 90 : 0.017452070489525795
Loss at batch 100 : 0.022501831874251366
Loss at batch 110 : 0.02739056944847107
Loss at batch 120 : 0.02338952012360096
Loss at batch 130 : 0.014783435501158237
Loss at batch 140 : 0.022734109312295914
Loss at batch 150 : 0.012952005490660667
Loss at batch 160 : 0.01856953650712967
Loss at batch 170 : 0.009897109121084213
Loss at batch 180 : 0.00861907098442316
Loss at batch 190 : 0.0197199247777462
Loss at batch 200 : 0.016928404569625854
Loss at batch 210 : 0.00725984014570713
Loss at batch 220 : 0.01732468791306019
Loss at batch 230 : 0.014967676252126694
Loss at batch 240 : 0.014591553248465061
Loss at batch 250 : 0.009556565433740616
Loss at batch 260 : 0.017025286331772804
Loss at batch 270 : 0.017083745449781418
Loss at batch 280 : 0.010709029622375965
Loss at batch 290 : 0.013407086953520775
Loss at batch 300 : 0.015831492841243744
Loss at batch 310 : 0.017933765426278114
Loss at batch 320 : 0.013012882322072983
Loss at batch 330 : 0.013981232419610023
Loss at batch 340 : 0.007512570824474096
Loss at batch 350 : 0.01563681662082672
Loss at batch 360 : 0.018133187666535378
Loss at batch 370 : 0.024728907272219658
epoch11 finished!
Loss at batch 10 : 0.020339928567409515
Loss at batch 20 : 0.006487653590738773
Loss at batch 30 : 0.010298790410161018
Loss at batch 40 : 0.011906426399946213
Loss at batch 50 : 0.008549811318516731
Loss at batch 60 : 0.012594906613230705
Loss at batch 70 : 0.012477273121476173
Loss at batch 80 : 0.018177080899477005
Loss at batch 90 : 0.012384495697915554
Loss at batch 100 : 0.01989385299384594
Loss at batch 110 : 0.014214291237294674
Loss at batch 120 : 0.013041085563600063
Loss at batch 130 : 0.01339183934032917
Loss at batch 140 : 0.012702426873147488
Loss at batch 150 : 0.013150002807378769
Loss at batch 160 : 0.02011045068502426
Loss at batch 170 : 0.013508631847798824
Loss at batch 180 : 0.011112827807664871
Loss at batch 190 : 0.014888214878737926
Loss at batch 200 : 0.013165866956114769
Loss at batch 210 : 0.01109258271753788
Loss at batch 220 : 0.014909266494214535
Loss at batch 230 : 0.022427573800086975
Loss at batch 240 : 0.024802593514323235
Loss at batch 250 : 0.02281642146408558
Loss at batch 260 : 0.014336815103888512
Loss at batch 270 : 0.01712549291551113
Loss at batch 280 : 0.020647380501031876
Loss at batch 290 : 0.014367141760885715
Loss at batch 300 : 0.018953239545226097
Loss at batch 310 : 0.009017802774906158
Loss at batch 320 : 0.011205161921679974
Loss at batch 330 : 0.016237936913967133
Loss at batch 340 : 0.010855844244360924
Loss at batch 350 : 0.026044858619570732
Loss at batch 360 : 0.02139926515519619
Loss at batch 370 : 0.018612245097756386
epoch11 finished!
Loss at batch 10 : 0.01383200567215681
Loss at batch 20 : 0.013511736877262592
Loss at batch 30 : 0.004896536935120821
Loss at batch 40 : 0.013589771464467049
Loss at batch 50 : 0.008530066348612309
Loss at batch 60 : 0.013175803236663342
Loss at batch 70 : 0.01067268569022417
Loss at batch 80 : 0.009462964721024036
Loss at batch 90 : 0.015738055109977722
Loss at batch 100 : 0.015990788117051125
Loss at batch 110 : 0.01598431169986725
Loss at batch 120 : 0.016462232917547226
Loss at batch 130 : 0.017430882900953293
Loss at batch 140 : 0.027673304080963135
Loss at batch 150 : 0.016881650313735008
Loss at batch 160 : 0.014415198005735874
Loss at batch 170 : 0.01736747846007347
Loss at batch 180 : 0.011810671538114548
Loss at batch 190 : 0.023722320795059204
Loss at batch 200 : 0.012718881480395794
Loss at batch 210 : 0.021944653242826462
Loss at batch 220 : 0.015773702412843704
Loss at batch 230 : 0.013912993483245373
Loss at batch 240 : 0.01652078703045845
Loss at batch 250 : 0.01345121394842863
Loss at batch 260 : 0.012198970653116703
Loss at batch 270 : 0.016040116548538208
Loss at batch 280 : 0.022487180307507515
Loss at batch 290 : 0.022250046953558922
Loss at batch 300 : 0.012083279900252819
Loss at batch 310 : 0.01711658015847206
Loss at batch 320 : 0.015300806611776352
Loss at batch 330 : 0.019550049677491188
Loss at batch 340 : 0.013344518840312958
Loss at batch 350 : 0.010051165707409382
Loss at batch 360 : 0.008446643128991127
Loss at batch 370 : 0.0065912120044231415
epoch28 finished!
Loss at batch 10 : 0.020734461024403572
Loss at batch 20 : 0.019333653151988983
Loss at batch 30 : 0.011026227846741676
Loss at batch 40 : 0.018110090866684914
Loss at batch 50 : 0.011382308788597584
Loss at batch 60 : 0.010374720208346844
Loss at batch 70 : 0.008825397118926048
Loss at batch 80 : 0.012078615836799145
Loss at batch 90 : 0.011407393962144852
Loss at batch 100 : 0.00880199484527111
Loss at batch 110 : 0.01771649345755577
Loss at batch 120 : 0.009616421535611153
Loss at batch 130 : 0.017663849517703056
Loss at batch 140 : 0.018287209793925285
Loss at batch 150 : 0.021608348935842514
Loss at batch 160 : 0.013635149225592613
Loss at batch 170 : 0.022240465506911278
Loss at batch 180 : 0.01051894947886467
Loss at batch 190 : 0.009174736216664314
Loss at batch 200 : 0.0251168180257082
Loss at batch 210 : 0.009971894323825836
Loss at batch 220 : 0.0112470593303442
Loss at batch 230 : 0.011931080371141434
Loss at batch 240 : 0.017222726717591286
Loss at batch 250 : 0.010361251421272755
Loss at batch 260 : 0.022777661681175232
Loss at batch 270 : 0.01676781289279461
Loss at batch 280 : 0.024978099390864372
Loss at batch 290 : 0.01127540785819292
Loss at batch 300 : 0.02218821458518505
Loss at batch 310 : 0.00966768991202116
Loss at batch 320 : 0.01839747279882431
Loss at batch 330 : 0.010629883036017418
Loss at batch 340 : 0.01861446350812912
Loss at batch 350 : 0.01541802380234003
Loss at batch 360 : 0.014481725171208382
Loss at batch 370 : 0.017516983672976494
epoch29 finished!
Loss at batch 10 : 0.00879696849733591
Loss at batch 20 : 0.012784457765519619
Loss at batch 30 : 0.02494843862950802
Loss at batch 40 : 0.024656124413013458
Loss at batch 50 : 0.016141407191753387
Loss at batch 60 : 0.020528364926576614
Loss at batch 70 : 0.01148817129433155
Loss at batch 80 : 0.019356828182935715
Loss at batch 90 : 0.019086012616753578
Loss at batch 100 : 0.011841877363622189
Loss at batch 110 : 0.016303690150380135
Loss at batch 120 : 0.010558811016380787
Loss at batch 130 : 0.02091672271490097
Loss at batch 140 : 0.016959108412265778
Loss at batch 150 : 0.012109723873436451
Loss at batch 160 : 0.01675231195986271
Loss at batch 170 : 0.01793523319065571
Loss at batch 180 : 0.015386081300675869
Loss at batch 190 : 0.012052436359226704
Loss at batch 200 : 0.015136834233999252
Loss at batch 210 : 0.01755598932504654
Loss at batch 220 : 0.013613258488476276
Loss at batch 230 : 0.01233807485550642
Loss at batch 240 : 0.01737964153289795
Loss at batch 250 : 0.00990096852183342
Loss at batch 260 : 0.02517671510577202
Loss at batch 270 : 0.009654238820075989
Loss at batch 280 : 0.01467223558574915
Loss at batch 290 : 0.023382171988487244
Loss at batch 300 : 0.013286896049976349
Loss at batch 310 : 0.025769801810383797
Loss at batch 320 : 0.015295877121388912
Loss at batch 330 : 0.010721947997808456
Loss at batch 340 : 0.012920505367219448
Loss at batch 350 : 0.013062956742942333
Loss at batch 360 : 0.01717326231300831
Loss at batch 370 : 0.01256481371819973
epoch12 finished!
Loss at batch 10 : 0.01590864360332489
Loss at batch 20 : 0.014172936789691448
Loss at batch 30 : 0.028076469898223877
Loss at batch 40 : 0.011337491683661938
Loss at batch 50 : 0.014133057557046413
Loss at batch 60 : 0.017342975363135338
Loss at batch 70 : 0.018363693729043007
Loss at batch 80 : 0.010618523694574833
Loss at batch 90 : 0.01508273184299469
Loss at batch 100 : 0.009195681661367416
Loss at batch 110 : 0.012453611008822918
Loss at batch 120 : 0.015522128902375698
Loss at batch 130 : 0.009204786270856857
Loss at batch 140 : 0.018584171310067177
Loss at batch 150 : 0.019159523770213127
Loss at batch 160 : 0.013585122302174568
Loss at batch 170 : 0.016326576471328735
Loss at batch 180 : 0.010932165198028088
Loss at batch 190 : 0.007922306656837463
Loss at batch 200 : 0.011141042225062847
Loss at batch 210 : 0.008540595881640911
Loss at batch 220 : 0.01600332371890545
Loss at batch 230 : 0.012405325658619404
Loss at batch 240 : 0.0097084054723382
Loss at batch 250 : 0.011239269748330116
Loss at batch 260 : 0.017286911606788635
Loss at batch 270 : 0.011947596445679665
Loss at batch 280 : 0.008254813961684704
Loss at batch 290 : 0.013569486327469349
Loss at batch 300 : 0.01733168587088585
Loss at batch 310 : 0.013067605905234814
Loss at batch 320 : 0.023096131160855293
Loss at batch 330 : 0.013699430041015148
Loss at batch 340 : 0.019811762496829033
Loss at batch 350 : 0.022891269996762276
Loss at batch 360 : 0.01440618745982647
Loss at batch 370 : 0.011143466457724571
epoch12 finished!
Loss at batch 10 : 0.0139474393799901
Loss at batch 20 : 0.013325173407793045
Loss at batch 30 : 0.013656146824359894
Loss at batch 40 : 0.03059152513742447
Loss at batch 50 : 0.025083186104893684
Loss at batch 60 : 0.017758598551154137
Loss at batch 70 : 0.013545285910367966
Loss at batch 80 : 0.01487343292683363
Loss at batch 90 : 0.014302274212241173
Loss at batch 100 : 0.01771845482289791
Loss at batch 110 : 0.01081086602061987
Loss at batch 120 : 0.018044833093881607
Loss at batch 130 : 0.007015851326286793
Loss at batch 140 : 0.010509437881410122
Loss at batch 150 : 0.01911184936761856
Loss at batch 160 : 0.019832393154501915
Loss at batch 170 : 0.008249218575656414
Loss at batch 180 : 0.016178861260414124
Loss at batch 190 : 0.01849975995719433
Loss at batch 200 : 0.010751135647296906
Loss at batch 210 : 0.01693648472428322
Loss at batch 220 : 0.014973809942603111
Loss at batch 230 : 0.023701544851064682
Loss at batch 240 : 0.01084107719361782
Loss at batch 250 : 0.01801184006035328
Loss at batch 260 : 0.011760937049984932
Loss at batch 270 : 0.016507863998413086
Loss at batch 280 : 0.014296595007181168
Loss at batch 290 : 0.009341900236904621
Loss at batch 300 : 0.022061211988329887
Loss at batch 310 : 0.01761586405336857
Loss at batch 320 : 0.016678357496857643
Loss at batch 330 : 0.014307308942079544
Loss at batch 340 : 0.010155619122087955
Loss at batch 350 : 0.01712426170706749
Loss at batch 360 : 0.011243157088756561
Loss at batch 370 : 0.016922442242503166
epoch30 finished!
Loss at batch 20 : 0.011245577596127987
Loss at batch 30 : 0.010672328062355518
Loss at batch 40 : 0.015323861502110958
Loss at batch 50 : 0.007518256548792124
Loss at batch 60 : 0.01871543563902378
Loss at batch 70 : 0.014918732456862926
Loss at batch 80 : 0.015306386165320873
Loss at batch 90 : 0.014200969599187374
Loss at batch 100 : 0.012196620926260948
Loss at batch 110 : 0.026880765333771706
Loss at batch 120 : 0.008958821184933186
Loss at batch 130 : 0.011603107675909996
Loss at batch 140 : 0.014157703146338463
Loss at batch 150 : 0.013746416196227074
Loss at batch 160 : 0.015163692645728588
Loss at batch 170 : 0.01259151566773653
Loss at batch 180 : 0.017558535560965538
Loss at batch 190 : 0.016498228535056114
Loss at batch 200 : 0.014449718408286572
Loss at batch 210 : 0.02740744687616825
Loss at batch 220 : 0.009551585651934147
Loss at batch 230 : 0.02541290409862995
Loss at batch 240 : 0.013378053903579712
Loss at batch 250 : 0.00888901948928833
Loss at batch 260 : 0.009741158224642277
Loss at batch 270 : 0.02066764049232006
Loss at batch 280 : 0.014202632941305637
Loss at batch 290 : 0.011709327809512615
Loss at batch 300 : 0.01457592286169529
Loss at batch 310 : 0.011548977345228195
Loss at batch 320 : 0.01535065658390522
Loss at batch 330 : 0.017642516642808914
Loss at batch 340 : 0.010333928279578686
Loss at batch 350 : 0.01662321761250496
Loss at batch 360 : 0.012456167489290237
Loss at batch 370 : 0.014721853658556938
epoch31 finished!
Loss at batch 10 : 0.025511840358376503
Loss at batch 20 : 0.01094223652034998
Loss at batch 30 : 0.025336503982543945
Loss at batch 40 : 0.014860948547720909
Loss at batch 50 : 0.012513864785432816
Loss at batch 60 : 0.009661405347287655
Loss at batch 70 : 0.01118418201804161
Loss at batch 80 : 0.01821792870759964
Loss at batch 90 : 0.01089619193226099
Loss at batch 100 : 0.012791831977665424
Loss at batch 110 : 0.027116063982248306
Loss at batch 120 : 0.012293688952922821
Loss at batch 130 : 0.010177860967814922
Loss at batch 140 : 0.015018577687442303
Loss at batch 150 : 0.006387520115822554
Loss at batch 160 : 0.016255339607596397
Loss at batch 170 : 0.024397803470492363
Loss at batch 180 : 0.011309890076518059
Loss at batch 190 : 0.009412966668605804
Loss at batch 200 : 0.02158930152654648
Loss at batch 210 : 0.02231261320412159
Loss at batch 220 : 0.016718046739697456
Loss at batch 230 : 0.02101930044591427
Loss at batch 240 : 0.02031557261943817
Loss at batch 250 : 0.013072106055915356
Loss at batch 260 : 0.016673380509018898
Loss at batch 270 : 0.009433547034859657
Loss at batch 280 : 0.014337866567075253
Loss at batch 290 : 0.014646757394075394
Loss at batch 300 : 0.01636672206223011
Loss at batch 310 : 0.013694142922759056
Loss at batch 320 : 0.012570396065711975
Loss at batch 330 : 0.01807567849755287
Loss at batch 340 : 0.01655079796910286
Loss at batch 350 : 0.010869838297367096
Loss at batch 360 : 0.020324094220995903
Loss at batch 370 : 0.018293220549821854
epoch13 finished!
Loss at batch 10 : 0.010430367663502693
Loss at batch 20 : 0.007981481961905956
Loss at batch 30 : 0.008513713255524635
Loss at batch 40 : 0.007988007739186287
Loss at batch 50 : 0.01699393056333065
Loss at batch 60 : 0.011251532472670078
Loss at batch 70 : 0.01689928211271763
Loss at batch 80 : 0.02106846496462822
Loss at batch 90 : 0.017782021313905716
Loss at batch 100 : 0.018314186483621597
Loss at batch 110 : 0.011501734144985676
Loss at batch 120 : 0.01884652115404606
Loss at batch 130 : 0.018449559807777405
Loss at batch 140 : 0.009328082203865051
Loss at batch 150 : 0.013699303381145
Loss at batch 160 : 0.015456666238605976
Loss at batch 170 : 0.010109907947480679
Loss at batch 180 : 0.01882200501859188
Loss at batch 190 : 0.00913279876112938
Loss at batch 200 : 0.01685125194489956
Loss at batch 210 : 0.015199856832623482
Loss at batch 220 : 0.021900340914726257
Loss at batch 230 : 0.025450021028518677
Loss at batch 240 : 0.021016428247094154
Loss at batch 250 : 0.020263150334358215
Loss at batch 260 : 0.011273328214883804
Loss at batch 270 : 0.012795833870768547
Loss at batch 280 : 0.014742078259587288
Loss at batch 290 : 0.01583794876933098
Loss at batch 300 : 0.012217015027999878
Loss at batch 310 : 0.015698550269007683
Loss at batch 320 : 0.014086020179092884
Loss at batch 330 : 0.027081439271569252
Loss at batch 340 : 0.019256116822361946
Loss at batch 350 : 0.029348749667406082
Loss at batch 360 : 0.019679944962263107
Loss at batch 370 : 0.010114318691194057
epoch32 finished!
Loss at batch 10 : 0.022550806403160095
Loss at batch 20 : 0.0109908701851964
Loss at batch 30 : 0.01947265863418579
Loss at batch 40 : 0.015706373378634453
Loss at batch 50 : 0.013095078058540821
Loss at batch 60 : 0.01656554639339447
Loss at batch 70 : 0.008992606773972511
Loss at batch 80 : 0.008291395381093025
Loss at batch 90 : 0.016123158857226372
Loss at batch 100 : 0.022381452843546867
Loss at batch 110 : 0.016716262325644493
Loss at batch 120 : 0.015399922616779804
Loss at batch 130 : 0.018754983320832253
Loss at batch 140 : 0.013611988164484501
Loss at batch 150 : 0.009426532313227654
Loss at batch 160 : 0.01838577724993229
Loss at batch 170 : 0.013871322385966778
Loss at batch 180 : 0.009370592422783375
Loss at batch 190 : 0.020002899691462517
Loss at batch 200 : 0.00842696987092495
Loss at batch 210 : 0.015327714383602142
Loss at batch 220 : 0.03133981674909592
Loss at batch 230 : 0.02746601216495037
Loss at batch 240 : 0.020815949887037277
Loss at batch 250 : 0.018297022208571434
Loss at batch 260 : 0.012266259640455246
Loss at batch 270 : 0.011472909711301327
Loss at batch 280 : 0.01274706982076168
Loss at batch 290 : 0.011019676923751831
Loss at batch 300 : 0.011003884486854076
Loss at batch 310 : 0.011386413127183914
Loss at batch 320 : 0.009210294112563133
Loss at batch 330 : 0.021202728152275085
Loss at batch 340 : 0.014149509370326996
Loss at batch 350 : 0.011528275907039642
Loss at batch 360 : 0.012231738306581974
Loss at batch 370 : 0.018397286534309387
epoch13 finished!
Loss at batch 10 : 0.014865664765238762
Loss at batch 20 : 0.009279448539018631
Loss at batch 30 : 0.008414684794843197
Loss at batch 40 : 0.009059411473572254
Loss at batch 50 : 0.02779475413262844
Loss at batch 60 : 0.01240550633519888
Loss at batch 70 : 0.013496072962880135
Loss at batch 80 : 0.02405502460896969
Loss at batch 90 : 0.017091067507863045
Loss at batch 100 : 0.015470301732420921
Loss at batch 110 : 0.021002503111958504
Loss at batch 120 : 0.013981531374156475
Loss at batch 130 : 0.012370293959975243
Loss at batch 140 : 0.02607603743672371
Loss at batch 150 : 0.014134290628135204
Loss at batch 160 : 0.01944802701473236
Loss at batch 170 : 0.015497381798923016
Loss at batch 180 : 0.02524399757385254
Loss at batch 190 : 0.015559116378426552
Loss at batch 200 : 0.012807721272110939
Loss at batch 210 : 0.014999108389019966
Loss at batch 220 : 0.023326989263296127
Loss at batch 230 : 0.014254024252295494
Loss at batch 240 : 0.009031779132783413
Loss at batch 250 : 0.02886800654232502
Loss at batch 260 : 0.02276236191391945
Loss at batch 270 : 0.010161768645048141
Loss at batch 280 : 0.013784105889499187
Loss at batch 290 : 0.009466086514294147
Loss at batch 300 : 0.01193197537213564
Loss at batch 310 : 0.010744111612439156
Loss at batch 320 : 0.01722591184079647
Loss at batch 330 : 0.012564693577587605
Loss at batch 340 : 0.009281372651457787
Loss at batch 350 : 0.015491655096411705
Loss at batch 360 : 0.01035237219184637
Loss at batch 370 : 0.01390921976417303
epoch33 finished!
Loss at batch 10 : 0.009451192803680897
Loss at batch 20 : 0.011953769251704216
Loss at batch 30 : 0.012907428666949272
Loss at batch 40 : 0.023333584889769554
Loss at batch 50 : 0.016576776280999184
Loss at batch 60 : 0.009976598434150219
Loss at batch 70 : 0.012264139950275421
Loss at batch 80 : 0.017480187118053436
Loss at batch 90 : 0.013867352157831192
Loss at batch 100 : 0.01944415271282196
Loss at batch 110 : 0.01658063381910324
Loss at batch 120 : 0.009845161810517311
Loss at batch 130 : 0.012223361991345882
Loss at batch 140 : 0.01383204199373722
Loss at batch 150 : 0.012427691370248795
Loss at batch 160 : 0.015149462036788464
Loss at batch 170 : 0.01780150644481182
Loss at batch 180 : 0.025072012096643448
Loss at batch 190 : 0.017809974029660225
Loss at batch 200 : 0.023626312613487244
Loss at batch 210 : 0.013111417181789875
Loss at batch 220 : 0.01112343743443489
Loss at batch 230 : 0.023521343246102333
Loss at batch 240 : 0.012621663510799408
Loss at batch 250 : 0.029271647334098816
Loss at batch 260 : 0.02814306505024433
Loss at batch 270 : 0.0139066893607378
Loss at batch 280 : 0.020520003512501717
Loss at batch 290 : 0.011217823252081871
Loss at batch 300 : 0.015720101073384285
Loss at batch 310 : 0.016809124499559402
Loss at batch 320 : 0.023187018930912018
Loss at batch 330 : 0.014684844762086868
Loss at batch 340 : 0.015462520532310009
Loss at batch 350 : 0.025560224428772926
Loss at batch 360 : 0.010126745328307152
Loss at batch 370 : 0.015439022332429886
epoch14 finished!
Loss at batch 10 : 0.029195386916399002
Loss at batch 20 : 0.01862768828868866
Loss at batch 30 : 0.01305144838988781
Loss at batch 40 : 0.026475513353943825
Loss at batch 50 : 0.01724674552679062
Loss at batch 60 : 0.01811053417623043
Loss at batch 70 : 0.01295748632401228
Loss at batch 80 : 0.018631964921951294
Loss at batch 90 : 0.008539918810129166
Loss at batch 100 : 0.012567003257572651
Loss at batch 110 : 0.014760681428015232
Loss at batch 120 : 0.029002534225583076
Loss at batch 130 : 0.018206041306257248
Loss at batch 140 : 0.010331274010241032
Loss at batch 150 : 0.023933665826916695
Loss at batch 160 : 0.017999229952692986
Loss at batch 170 : 0.01444254256784916
Loss at batch 180 : 0.011016330681741238
Loss at batch 190 : 0.011814012192189693
Loss at batch 200 : 0.016161229461431503
Loss at batch 210 : 0.01040496863424778
Loss at batch 220 : 0.015096344985067844
Loss at batch 230 : 0.013191500678658485
Loss at batch 240 : 0.01605851948261261
Loss at batch 250 : 0.009498032741248608
Loss at batch 260 : 0.012422106228768826
Loss at batch 270 : 0.013905194588005543
Loss at batch 280 : 0.011078974232077599
Loss at batch 290 : 0.010788005776703358
Loss at batch 300 : 0.01091989316046238
Loss at batch 310 : 0.012944070622324944
Loss at batch 320 : 0.014388389885425568
Loss at batch 330 : 0.019763153046369553
Loss at batch 340 : 0.011720037087798119
Loss at batch 350 : 0.01414564996957779
Loss at batch 360 : 0.01827269420027733
Loss at batch 370 : 0.021921642124652863
epoch34 finished!
Loss at batch 10 : 0.00954692903906107
Loss at batch 20 : 0.012198107317090034
Loss at batch 30 : 0.0381854847073555
Loss at batch 40 : 0.013550819829106331
Loss at batch 50 : 0.012991797178983688
Loss at batch 60 : 0.011294655501842499
Loss at batch 70 : 0.00731740053743124
Loss at batch 80 : 0.01787816919386387
Loss at batch 90 : 0.02425544708967209
Loss at batch 100 : 0.014555600471794605
Loss at batch 110 : 0.01812034286558628
Loss at batch 120 : 0.017908448353409767
Loss at batch 130 : 0.011692920699715614
Loss at batch 140 : 0.007911408320069313
Loss at batch 150 : 0.020183494314551353
Loss at batch 160 : 0.026410799473524094
Loss at batch 170 : 0.018611133098602295
Loss at batch 180 : 0.018892131745815277
Loss at batch 190 : 0.01271645724773407
Loss at batch 200 : 0.01997467689216137
Loss at batch 210 : 0.012036731466650963
Loss at batch 220 : 0.009588286280632019
Loss at batch 230 : 0.012039822526276112
Loss at batch 240 : 0.009316881187260151
Loss at batch 250 : 0.018794644623994827
Loss at batch 260 : 0.02023235522210598
Loss at batch 270 : 0.013831015676259995
Loss at batch 280 : 0.036308202892541885
Loss at batch 290 : 0.012246998026967049
Loss at batch 300 : 0.011813296936452389
Loss at batch 310 : 0.012571942061185837
Loss at batch 320 : 0.013257387094199657
Loss at batch 330 : 0.03573751822113991
Loss at batch 340 : 0.020060429349541664
Loss at batch 350 : 0.024657197296619415
Loss at batch 360 : 0.011444060131907463
Loss at batch 370 : 0.014553519897162914
epoch14 finished!
Loss at batch 10 : 0.015641754493117332
Loss at batch 20 : 0.01528609823435545
Loss at batch 30 : 0.015425112098455429
Loss at batch 40 : 0.013945871964097023
Loss at batch 50 : 0.01806127466261387
Loss at batch 60 : 0.01089162565767765
Loss at batch 70 : 0.012441124767065048
Loss at batch 80 : 0.013184484094381332
Loss at batch 90 : 0.018777256831526756
Loss at batch 100 : 0.020050741732120514
Loss at batch 110 : 0.013780022971332073
Loss at batch 120 : 0.01177266426384449
Loss at batch 130 : 0.01270963903516531
Loss at batch 140 : 0.012308889999985695
Loss at batch 150 : 0.014576473273336887
Loss at batch 160 : 0.014439854770898819
Loss at batch 170 : 0.012264766730368137
Loss at batch 180 : 0.018786536529660225
Loss at batch 190 : 0.010853337123990059
Loss at batch 200 : 0.011985077522695065
Loss at batch 210 : 0.02451482228934765
Loss at batch 220 : 0.009722580201923847
Loss at batch 230 : 0.014772206544876099
Loss at batch 240 : 0.010732815600931644
Loss at batch 250 : 0.011825069785118103
Loss at batch 260 : 0.01646527089178562
Loss at batch 270 : 0.019724277779459953
Loss at batch 280 : 0.02196829952299595
Loss at batch 290 : 0.015209129080176353
Loss at batch 300 : 0.026621833443641663
Loss at batch 310 : 0.013995883986353874
Loss at batch 320 : 0.023792814463377
Loss at batch 330 : 0.017459886148571968
Loss at batch 340 : 0.02457074075937271
Loss at batch 350 : 0.011157816275954247
Loss at batch 360 : 0.0111018605530262
Loss at batch 370 : 0.01408773846924305
epoch35 finished!
Loss at batch 10 : 0.016998259350657463
Loss at batch 20 : 0.008763371966779232
Loss at batch 30 : 0.02037166617810726
Loss at batch 40 : 0.01858288235962391
Loss at batch 50 : 0.0118720019236207
Loss at batch 60 : 0.01643846556544304
Loss at batch 70 : 0.015790734440088272
Loss at batch 80 : 0.007220073603093624
Loss at batch 90 : 0.011159072630107403
Loss at batch 100 : 0.012908931821584702
Loss at batch 110 : 0.017895128577947617
Loss at batch 120 : 0.023793594911694527
Loss at batch 130 : 0.01057794876396656
Loss at batch 140 : 0.01888233609497547
Loss at batch 150 : 0.013925312086939812
Loss at batch 160 : 0.014141608960926533
Loss at batch 170 : 0.016586938872933388
Loss at batch 180 : 0.016444876790046692
Loss at batch 190 : 0.018904661759734154
Loss at batch 200 : 0.008831937797367573
Loss at batch 210 : 0.014797978103160858
Loss at batch 220 : 0.011686433106660843
Loss at batch 230 : 0.014402762986719608
Loss at batch 240 : 0.01012667827308178
Loss at batch 250 : 0.012587666511535645
Loss at batch 260 : 0.018264424055814743
Loss at batch 270 : 0.01268010400235653
Loss at batch 280 : 0.017714833840727806
Loss at batch 290 : 0.012149276211857796
Loss at batch 300 : 0.024842791259288788
Loss at batch 310 : 0.026026485487818718
Loss at batch 320 : 0.016941802576184273
Loss at batch 330 : 0.02519739791750908
Loss at batch 340 : 0.012068205513060093
Loss at batch 350 : 0.012892812490463257
Loss at batch 360 : 0.013202769681811333
Loss at batch 370 : 0.012109463103115559
epoch36 finished!
Loss at batch 10 : 0.021482905372977257
Loss at batch 20 : 0.010889559984207153
Loss at batch 30 : 0.016508471220731735
Loss at batch 40 : 0.018798116594552994
Loss at batch 50 : 0.010970083996653557
Loss at batch 60 : 0.019407330080866814
Loss at batch 70 : 0.011154910549521446
Loss at batch 80 : 0.019707243889570236
Loss at batch 90 : 0.014789948239922523
Loss at batch 100 : 0.022027606144547462
Loss at batch 110 : 0.014334284700453281
Loss at batch 120 : 0.013697264716029167
Loss at batch 130 : 0.018152637407183647
Loss at batch 140 : 0.012251288630068302
Loss at batch 150 : 0.01098517794162035
Loss at batch 160 : 0.021886596456170082
Loss at batch 170 : 0.014597887173295021
Loss at batch 180 : 0.018141984939575195
Loss at batch 190 : 0.010854944586753845
Loss at batch 200 : 0.01076878048479557
Loss at batch 210 : 0.012324082665145397
Loss at batch 220 : 0.010214525274932384
Loss at batch 230 : 0.016912085935473442
Loss at batch 240 : 0.01600751280784607
Loss at batch 250 : 0.014086127281188965
Loss at batch 260 : 0.011061334982514381
Loss at batch 270 : 0.03090452030301094
Loss at batch 280 : 0.014450118876993656
Loss at batch 290 : 0.012587296776473522
Loss at batch 300 : 0.01218392513692379
Loss at batch 310 : 0.009134044870734215
Loss at batch 320 : 0.016440248116850853
Loss at batch 330 : 0.01370718702673912
Loss at batch 340 : 0.008865706622600555
Loss at batch 350 : 0.017771566286683083
Loss at batch 360 : 0.024033602327108383
Loss at batch 370 : 0.008297325111925602
epoch15 finished!
Loss at batch 10 : 0.025202607735991478
Loss at batch 20 : 0.009517990052700043
Loss at batch 30 : 0.012559528462588787
Loss at batch 40 : 0.013610955327749252
Loss at batch 50 : 0.009547512046992779
Loss at batch 60 : 0.0075722080655395985
Loss at batch 70 : 0.010539455339312553
Loss at batch 80 : 0.011353781446814537
Loss at batch 90 : 0.01794554851949215
Loss at batch 100 : 0.022801408544182777
Loss at batch 110 : 0.006987820845097303
Loss at batch 120 : 0.012497389689087868
Loss at batch 130 : 0.012178008444607258
Loss at batch 140 : 0.022844800725579262
Loss at batch 150 : 0.0165085606276989
Loss at batch 160 : 0.010655478574335575
Loss at batch 170 : 0.01529877819120884
Loss at batch 180 : 0.021200286224484444
Loss at batch 190 : 0.013589799404144287
Loss at batch 200 : 0.014296411536633968
Loss at batch 210 : 0.018362540751695633
Loss at batch 220 : 0.010214428417384624
Loss at batch 230 : 0.014711791649460793
Loss at batch 240 : 0.027513816952705383
Loss at batch 250 : 0.016209004446864128
Loss at batch 260 : 0.021357214078307152
Loss at batch 270 : 0.02979939803481102
Loss at batch 280 : 0.019024481996893883
Loss at batch 290 : 0.017125913873314857
Loss at batch 300 : 0.014410641975700855
Loss at batch 310 : 0.010532122105360031
Loss at batch 320 : 0.010571343824267387
Loss at batch 330 : 0.013131805695593357
Loss at batch 340 : 0.007468865253031254
Loss at batch 350 : 0.011838887818157673
Loss at batch 360 : 0.013441953808069229
Loss at batch 370 : 0.013105052523314953
epoch15 finished!
Loss at batch 10 : 0.011719824746251106
Loss at batch 20 : 0.016749277710914612
Loss at batch 30 : 0.01619747467339039
Loss at batch 40 : 0.014368814416229725
Loss at batch 50 : 0.018196314573287964
Loss at batch 60 : 0.015577049925923347
Loss at batch 70 : 0.023039232939481735
Loss at batch 80 : 0.011696303263306618
Loss at batch 90 : 0.01295635849237442
Loss at batch 100 : 0.011099644005298615
Loss at batch 110 : 0.01400119997560978
Loss at batch 120 : 0.01388726569712162
Loss at batch 130 : 0.010535543784499168
Loss at batch 140 : 0.012422965839505196
Loss at batch 150 : 0.017255933955311775
Loss at batch 160 : 0.015871686860919
Loss at batch 170 : 0.015477277338504791
Loss at batch 180 : 0.016053225845098495
Loss at batch 190 : 0.0135957021266222
Loss at batch 200 : 0.016259534284472466
Loss at batch 210 : 0.011960040777921677
Loss at batch 220 : 0.008935300633311272
Loss at batch 230 : 0.02013418823480606
Loss at batch 240 : 0.011521078646183014
Loss at batch 250 : 0.014470107853412628
Loss at batch 260 : 0.01827080175280571
Loss at batch 270 : 0.009657531976699829
Loss at batch 280 : 0.021082932129502296
Loss at batch 290 : 0.020667385309934616
Loss at batch 300 : 0.011378517374396324
Loss at batch 310 : 0.013788723386824131
Loss at batch 320 : 0.01711561530828476
Loss at batch 330 : 0.012109139002859592
Loss at batch 340 : 0.022284869104623795
Loss at batch 350 : 0.018036657944321632
Loss at batch 360 : 0.019146451726555824
Loss at batch 370 : 0.014230095781385899
epoch37 finished!
Loss at batch 10 : 0.011844797059893608
Loss at batch 20 : 0.014531656168401241
Loss at batch 30 : 0.0165853351354599
Loss at batch 40 : 0.011666682548820972
Loss at batch 50 : 0.013374797068536282
Loss at batch 60 : 0.015055647119879723
Loss at batch 70 : 0.010023255832493305
Loss at batch 80 : 0.008647741749882698
Loss at batch 90 : 0.02210151217877865
Loss at batch 100 : 0.009447102434933186
Loss at batch 110 : 0.012005172669887543
Loss at batch 120 : 0.01891019009053707
Loss at batch 130 : 0.006533264648169279
Loss at batch 140 : 0.01644805073738098
Loss at batch 150 : 0.011448826640844345
Loss at batch 160 : 0.021304592490196228
Loss at batch 170 : 0.016642123460769653
Loss at batch 180 : 0.019115425646305084
Loss at batch 190 : 0.025476694107055664
Loss at batch 200 : 0.013493364676833153
Loss at batch 210 : 0.009257214143872261
Loss at batch 220 : 0.010775139555335045
Loss at batch 230 : 0.01661182940006256
Loss at batch 240 : 0.022763816639780998
Loss at batch 250 : 0.012003312818706036
Loss at batch 260 : 0.010070879012346268
Loss at batch 270 : 0.011428370140492916
Loss at batch 280 : 0.022986574098467827
Loss at batch 290 : 0.007621777709573507
Loss at batch 300 : 0.010570231825113297
Loss at batch 310 : 0.011740981601178646
Loss at batch 320 : 0.009969319216907024
Loss at batch 330 : 0.010511163622140884
Loss at batch 340 : 0.019822323694825172
Loss at batch 350 : 0.010627352632582188
Loss at batch 360 : 0.0197878610342741
Loss at batch 370 : 0.02077876590192318
epoch38 finished!
Loss at batch 10 : 0.012764549814164639
Loss at batch 20 : 0.016646072268486023
Loss at batch 30 : 0.016132215037941933
Loss at batch 40 : 0.01087411679327488
Loss at batch 50 : 0.013945403508841991
Loss at batch 60 : 0.01647021807730198
Loss at batch 70 : 0.028962573036551476
Loss at batch 80 : 0.008225347846746445
Loss at batch 90 : 0.01011683139950037
Loss at batch 100 : 0.019681118428707123
Loss at batch 110 : 0.012959452345967293
Loss at batch 120 : 0.018389973789453506
Loss at batch 130 : 0.015138107351958752
Loss at batch 140 : 0.011487787589430809
Loss at batch 150 : 0.015136774629354477
Loss at batch 160 : 0.01648261956870556
Loss at batch 170 : 0.0181236881762743
Loss at batch 180 : 0.01583496294915676
Loss at batch 190 : 0.01555946096777916
Loss at batch 200 : 0.014766743406653404
Loss at batch 210 : 0.011422979645431042
Loss at batch 220 : 0.018552172929048538
Loss at batch 230 : 0.014736571349203587
Loss at batch 240 : 0.0076730018481612206
Loss at batch 250 : 0.01747427135705948
Loss at batch 260 : 0.014529646374285221
Loss at batch 270 : 0.02127433568239212
Loss at batch 280 : 0.010941064916551113
Loss at batch 290 : 0.014100718311965466
Loss at batch 300 : 0.011001546867191792
Loss at batch 310 : 0.013705718331038952
Loss at batch 320 : 0.016492934897542
Loss at batch 330 : 0.015683557838201523
Loss at batch 340 : 0.016611462458968163
Loss at batch 350 : 0.0214315764605999
Loss at batch 360 : 0.023327315226197243
Loss at batch 370 : 0.015978025272488594
epoch16 finished!
Loss at batch 10 : 0.014659253880381584
Loss at batch 20 : 0.010868541896343231
Loss at batch 30 : 0.013106320984661579
Loss at batch 40 : 0.016105618327856064
Loss at batch 50 : 0.012250304222106934
Loss at batch 60 : 0.008749020285904408
Loss at batch 70 : 0.01606639288365841
Loss at batch 80 : 0.01703929342329502
Loss at batch 90 : 0.019665533676743507
Loss at batch 100 : 0.02305455133318901
Loss at batch 110 : 0.015519838780164719
Loss at batch 120 : 0.013312364928424358
Loss at batch 130 : 0.013479427434504032
Loss at batch 140 : 0.012881645932793617
Loss at batch 150 : 0.012991144321858883
Loss at batch 160 : 0.013808894902467728
Loss at batch 170 : 0.01055783499032259
Loss at batch 180 : 0.014498753473162651
Loss at batch 190 : 0.03972865268588066
Loss at batch 200 : 0.013927231542766094
Loss at batch 210 : 0.014544697478413582
Loss at batch 220 : 0.009254691191017628
Loss at batch 230 : 0.008896579965949059
Loss at batch 240 : 0.013168320059776306
Loss at batch 250 : 0.013663760386407375
Loss at batch 260 : 0.013019466772675514
Loss at batch 270 : 0.012302303686738014
Loss at batch 280 : 0.013906089588999748
Loss at batch 290 : 0.01478874683380127
Loss at batch 300 : 0.029157422482967377
Loss at batch 310 : 0.021868225187063217
Loss at batch 320 : 0.01829133741557598
Loss at batch 330 : 0.018053609877824783
Loss at batch 340 : 0.018919844180345535
Loss at batch 350 : 0.014198707416653633
Loss at batch 360 : 0.018555527552962303
Loss at batch 370 : 0.013122616335749626
epoch16 finished!
Loss at batch 10 : 0.00954795628786087
Loss at batch 20 : 0.007504498120397329
Loss at batch 30 : 0.013076229020953178
Loss at batch 40 : 0.020030474290251732
Loss at batch 50 : 0.015922056511044502
Loss at batch 60 : 0.012726934626698494
Loss at batch 70 : 0.011627817526459694
Loss at batch 80 : 0.026507915928959846
Loss at batch 90 : 0.018117796629667282
Loss at batch 100 : 0.016210593283176422
Loss at batch 110 : 0.012466905638575554
Loss at batch 120 : 0.013106321915984154
Loss at batch 130 : 0.014851131476461887
Loss at batch 140 : 0.0133671211078763
Loss at batch 150 : 0.016013216227293015
Loss at batch 160 : 0.013986793346703053
Loss at batch 170 : 0.017497194930911064
Loss at batch 180 : 0.019778016954660416
Loss at batch 190 : 0.015196427702903748
Loss at batch 200 : 0.01672150380909443
Loss at batch 210 : 0.0169981736689806
Loss at batch 220 : 0.01260561402887106
Loss at batch 230 : 0.015183479525148869
Loss at batch 240 : 0.015357268042862415
Loss at batch 250 : 0.0143386609852314
Loss at batch 260 : 0.014041467569768429
Loss at batch 270 : 0.014238321222364902
Loss at batch 280 : 0.03413030877709389
Loss at batch 290 : 0.010768054984509945
Loss at batch 300 : 0.007340357173234224
Loss at batch 310 : 0.015563667751848698
Loss at batch 320 : 0.011878357268869877
Loss at batch 330 : 0.012785019353032112
Loss at batch 340 : 0.019361916929483414
Loss at batch 350 : 0.012418660335242748
Loss at batch 360 : 0.015549111180007458
Loss at batch 370 : 0.01554692629724741
epoch39 finished!
Loss at batch 10 : 0.03316505253314972
Loss at batch 20 : 0.012276407331228256
Loss at batch 30 : 0.022726906463503838
Loss at batch 40 : 0.022686243057250977
Loss at batch 50 : 0.013438507914543152
Loss at batch 60 : 0.023323707282543182
Loss at batch 70 : 0.01481793075799942
Loss at batch 80 : 0.01118237804621458
Loss at batch 90 : 0.009095505811274052
Loss at batch 100 : 0.01097085326910019
Loss at batch 110 : 0.01911654882133007
Loss at batch 120 : 0.009634234011173248
Loss at batch 130 : 0.012302699498832226
Loss at batch 140 : 0.012134933844208717
Loss at batch 150 : 0.017542146146297455
Loss at batch 160 : 0.010784249752759933
Loss at batch 170 : 0.015307952649891376
Loss at batch 180 : 0.016544345766305923
Loss at batch 190 : 0.02558816783130169
Loss at batch 200 : 0.015733402222394943
Loss at batch 210 : 0.01695849932730198
Loss at batch 220 : 0.010019555687904358
Loss at batch 230 : 0.012071843259036541
Loss at batch 240 : 0.014239341020584106
Loss at batch 250 : 0.010913889855146408
Loss at batch 260 : 0.006855964194983244
Loss at batch 270 : 0.019633794203400612
Loss at batch 280 : 0.017912328243255615
Loss at batch 290 : 0.019387854263186455
Loss at batch 300 : 0.013495220802724361
Loss at batch 310 : 0.022398579865694046
Loss at batch 320 : 0.01542410347610712
Loss at batch 330 : 0.0061568887904286385
Loss at batch 340 : 0.017246441915631294
Loss at batch 350 : 0.011446836404502392
Loss at batch 360 : 0.024101274088025093
Loss at batch 370 : 0.011829141527414322
epoch40 finished!
Loss at batch 10 : 0.018857497721910477
Loss at batch 20 : 0.02119293250143528
Loss at batch 30 : 0.018290607258677483
Loss at batch 40 : 0.021112684160470963
Loss at batch 50 : 0.015396205708384514
Loss at batch 60 : 0.018741048872470856
Loss at batch 70 : 0.011566774919629097
Loss at batch 80 : 0.018820615485310555
Loss at batch 90 : 0.022781312465667725
Loss at batch 100 : 0.010103541426360607
Loss at batch 110 : 0.01578369364142418
Loss at batch 120 : 0.01044402550905943
Loss at batch 130 : 0.018844785168766975
Loss at batch 140 : 0.011761518195271492
Loss at batch 150 : 0.016791854053735733
Loss at batch 160 : 0.020062260329723358
Loss at batch 170 : 0.02160206250846386
Loss at batch 180 : 0.011987393721938133
Loss at batch 190 : 0.015181356109678745
Loss at batch 200 : 0.013153858482837677
Loss at batch 210 : 0.00888761691749096
Loss at batch 220 : 0.010116206482052803
Loss at batch 230 : 0.01181017141789198
Loss at batch 240 : 0.011349343694746494
Loss at batch 250 : 0.020633388310670853
Loss at batch 260 : 0.010766655206680298
Loss at batch 270 : 0.013895303010940552
Loss at batch 280 : 0.012153874151408672
Loss at batch 290 : 0.02210467867553234
Loss at batch 300 : 0.025565532967448235
Loss at batch 310 : 0.011188006959855556
Loss at batch 320 : 0.013924060389399529
Loss at batch 330 : 0.013197602704167366
Loss at batch 340 : 0.01121947169303894
Loss at batch 350 : 0.020695894956588745
Loss at batch 360 : 0.02645293064415455
Loss at batch 370 : 0.019521497189998627
epoch17 finished!
Loss at batch 10 : 0.022610919550061226
Loss at batch 20 : 0.012965432368218899
Loss at batch 30 : 0.01789112761616707
Loss at batch 40 : 0.027975108474493027
Loss at batch 50 : 0.014208857901394367
Loss at batch 60 : 0.012349389493465424
Loss at batch 70 : 0.017420867457985878
Loss at batch 80 : 0.01991119794547558
Loss at batch 90 : 0.009866190142929554
Loss at batch 100 : 0.012478132732212543
Loss at batch 110 : 0.02226102538406849
Loss at batch 120 : 0.011034658178687096
Loss at batch 130 : 0.0226101353764534
Loss at batch 140 : 0.018563950434327126
Loss at batch 150 : 0.0080014169216156
Loss at batch 160 : 0.02027687057852745
Loss at batch 170 : 0.018633373081684113
Loss at batch 180 : 0.013813785277307034
Loss at batch 190 : 0.027284838259220123
Loss at batch 200 : 0.014798161573708057
Loss at batch 210 : 0.013637153431773186
Loss at batch 220 : 0.013792586512863636
Loss at batch 230 : 0.02774779498577118
Loss at batch 240 : 0.017132822424173355
Loss at batch 250 : 0.014804857783019543
Loss at batch 260 : 0.019803645089268684
Loss at batch 270 : 0.01419302448630333
Loss at batch 280 : 0.02238866314291954
Loss at batch 290 : 0.013763447292149067
Loss at batch 300 : 0.009368360973894596
Loss at batch 310 : 0.017364727333188057
Loss at batch 320 : 0.012858270667493343
Loss at batch 330 : 0.020415252074599266
Loss at batch 340 : 0.015324934385716915
Loss at batch 350 : 0.009878681972622871
Loss at batch 360 : 0.014295278117060661
Loss at batch 370 : 0.008932867087423801
epoch17 finished!
Loss at batch 10 : 0.007537036668509245
Loss at batch 20 : 0.024331776425242424
Loss at batch 30 : 0.011973506771028042
Loss at batch 40 : 0.012221066281199455
Loss at batch 50 : 0.01424976997077465
Loss at batch 60 : 0.012424676679074764
Loss at batch 70 : 0.013487722724676132
Loss at batch 80 : 0.013347087427973747
Loss at batch 90 : 0.01207655854523182
Loss at batch 100 : 0.02066764049232006
Loss at batch 110 : 0.012363001704216003
Loss at batch 120 : 0.010230039246380329
Loss at batch 130 : 0.009820746257901192
Loss at batch 140 : 0.011431030929088593
Loss at batch 150 : 0.010428541339933872
Loss at batch 160 : 0.01374464575201273
Loss at batch 170 : 0.010312057100236416
Loss at batch 180 : 0.011829513125121593
Loss at batch 190 : 0.007588026579469442
Loss at batch 200 : 0.012898538261651993
Loss at batch 210 : 0.01703696884214878
Loss at batch 220 : 0.014851892367005348
Loss at batch 230 : 0.013009794056415558
Loss at batch 240 : 0.012052822858095169
Loss at batch 250 : 0.015928030014038086
Loss at batch 260 : 0.013040903024375439
Loss at batch 270 : 0.018364805728197098
Loss at batch 280 : 0.019164808094501495
Loss at batch 290 : 0.009484817273914814
Loss at batch 300 : 0.01434751320630312
Loss at batch 310 : 0.016717970371246338
Loss at batch 320 : 0.022645993158221245
Loss at batch 330 : 0.012844969518482685
Loss at batch 340 : 0.009904439561069012
Loss at batch 350 : 0.016884690150618553
Loss at batch 360 : 0.030194194987416267
Loss at batch 370 : 0.012766335159540176
epoch41 finished!
Loss at batch 10 : 0.013830365613102913
Loss at batch 20 : 0.01985614374279976
Loss at batch 30 : 0.014640643261373043
Loss at batch 40 : 0.016894161701202393
Loss at batch 50 : 0.009470329619944096
Loss at batch 60 : 0.011594187468290329
Loss at batch 70 : 0.014566680416464806
Loss at batch 80 : 0.01509389840066433
Loss at batch 90 : 0.015344399958848953
Loss at batch 100 : 0.013303171843290329
Loss at batch 110 : 0.012307955883443356
Loss at batch 120 : 0.01642855443060398
Loss at batch 130 : 0.016177834942936897
Loss at batch 140 : 0.01101681962609291
Loss at batch 150 : 0.010529491119086742
Loss at batch 160 : 0.010435694828629494
Loss at batch 170 : 0.015232671052217484
Loss at batch 180 : 0.0231702271848917
Loss at batch 190 : 0.017553167417645454
Loss at batch 200 : 0.022421469911932945
Loss at batch 210 : 0.008285457268357277
Loss at batch 220 : 0.02334088273346424
Loss at batch 230 : 0.007798042614012957
Loss at batch 240 : 0.011685102246701717
Loss at batch 250 : 0.013575296849012375
Loss at batch 260 : 0.007994611747562885
Loss at batch 270 : 0.015548436902463436
Loss at batch 280 : 0.013963844627141953
Loss at batch 290 : 0.008432147093117237
Loss at batch 300 : 0.007810576353222132
Loss at batch 310 : 0.012227499857544899
Loss at batch 320 : 0.01997298002243042
Loss at batch 330 : 0.020807910710573196
Loss at batch 340 : 0.010148081928491592
Loss at batch 350 : 0.013869686052203178
Loss at batch 360 : 0.007389633450657129
Loss at batch 370 : 0.012861436232924461
epoch42 finished!
Loss at batch 10 : 0.015598387457430363
Loss at batch 20 : 0.020168164744973183
Loss at batch 30 : 0.01870565302670002
Loss at batch 40 : 0.03260572999715805
Loss at batch 50 : 0.009977302514016628
Loss at batch 60 : 0.013084692880511284
Loss at batch 70 : 0.01647184044122696
Loss at batch 80 : 0.012997204437851906
Loss at batch 90 : 0.011979655362665653
Loss at batch 100 : 0.023172354325652122
Loss at batch 110 : 0.010099627077579498
Loss at batch 120 : 0.016429588198661804
Loss at batch 130 : 0.0142457140609622
Loss at batch 140 : 0.011029548943042755
Loss at batch 150 : 0.015333487652242184
Loss at batch 160 : 0.013419149443507195
Loss at batch 170 : 0.01532791182398796
Loss at batch 180 : 0.014556899666786194
Loss at batch 190 : 0.013620587065815926
Loss at batch 200 : 0.021892039105296135
Loss at batch 210 : 0.007296110037714243
Loss at batch 220 : 0.020188959315419197
Loss at batch 230 : 0.012000241316854954
Loss at batch 240 : 0.009640212170779705
Loss at batch 250 : 0.01202938612550497
Loss at batch 260 : 0.006973284296691418
Loss at batch 270 : 0.013710753060877323
Loss at batch 280 : 0.019889598712325096
Loss at batch 290 : 0.014082398265600204
Loss at batch 300 : 0.016682857647538185
Loss at batch 310 : 0.01744462177157402
Loss at batch 320 : 0.01495353039354086
Loss at batch 330 : 0.012676313519477844
Loss at batch 340 : 0.012034513987600803
Loss at batch 350 : 0.010587266646325588
Loss at batch 360 : 0.014498140662908554
Loss at batch 370 : 0.011259451508522034
epoch18 finished!
Loss at batch 10 : 0.020251823589205742
Loss at batch 20 : 0.015985071659088135
Loss at batch 30 : 0.014787138439714909
Loss at batch 40 : 0.023134371265769005
Loss at batch 50 : 0.009690982289612293
Loss at batch 60 : 0.019839834421873093
Loss at batch 70 : 0.012268619611859322
Loss at batch 80 : 0.024768320843577385
Loss at batch 90 : 0.014523109421133995
Loss at batch 100 : 0.016644831746816635
Loss at batch 110 : 0.01656603068113327
Loss at batch 120 : 0.01893257163465023
Loss at batch 130 : 0.018409784883260727
Loss at batch 140 : 0.009185717441141605
Loss at batch 150 : 0.01773662306368351
Loss at batch 160 : 0.010418755002319813
Loss at batch 170 : 0.010817719623446465
Loss at batch 180 : 0.020427916198968887
Loss at batch 190 : 0.018269319087266922
Loss at batch 200 : 0.015857823193073273
Loss at batch 210 : 0.012841847725212574
Loss at batch 220 : 0.012534241192042828
Loss at batch 230 : 0.010760225355625153
Loss at batch 240 : 0.017904795706272125
Loss at batch 250 : 0.015699150040745735
Loss at batch 260 : 0.013637671247124672
Loss at batch 270 : 0.02442042902112007
Loss at batch 280 : 0.01628384180366993
Loss at batch 290 : 0.023597581312060356
Loss at batch 300 : 0.021105997264385223
Loss at batch 310 : 0.011599401012063026
Loss at batch 320 : 0.018788574263453484
Loss at batch 330 : 0.018177855759859085
Loss at batch 340 : 0.013280875980854034
Loss at batch 350 : 0.011552845127880573
Loss at batch 360 : 0.015582048334181309
Loss at batch 370 : 0.017090264707803726
epoch18 finished!
Loss at batch 10 : 0.013133367523550987
Loss at batch 20 : 0.027998272329568863
Loss at batch 30 : 0.015316507779061794
Loss at batch 40 : 0.010445859283208847
Loss at batch 50 : 0.016210606321692467
Loss at batch 60 : 0.008657129481434822
Loss at batch 70 : 0.016784481704235077
Loss at batch 80 : 0.01384572684764862
Loss at batch 90 : 0.01145881600677967
Loss at batch 100 : 0.008473495952785015
Loss at batch 110 : 0.01167367771267891
Loss at batch 120 : 0.007691388018429279
Loss at batch 130 : 0.015295781195163727
Loss at batch 140 : 0.015022259205579758
Loss at batch 150 : 0.020261764526367188
Loss at batch 160 : 0.019453801214694977
Loss at batch 170 : 0.020829714834690094
Loss at batch 180 : 0.016859302297234535
Loss at batch 190 : 0.011509272269904613
Loss at batch 200 : 0.01616177335381508
Loss at batch 210 : 0.01370046753436327
Loss at batch 220 : 0.015551069751381874
Loss at batch 230 : 0.01666940003633499
Loss at batch 240 : 0.01588687300682068
Loss at batch 250 : 0.013024031184613705
Loss at batch 260 : 0.014665987342596054
Loss at batch 270 : 0.01644875481724739
Loss at batch 280 : 0.019602229818701744
Loss at batch 290 : 0.014484666287899017
Loss at batch 300 : 0.013544026762247086
Loss at batch 310 : 0.015355756506323814
Loss at batch 320 : 0.011370336636900902
Loss at batch 330 : 0.007671816274523735
Loss at batch 340 : 0.009239482693374157
Loss at batch 350 : 0.012945819646120071
Loss at batch 360 : 0.011471198871731758
Loss at batch 370 : 0.012164567597210407
epoch43 finished!
Loss at batch 10 : 0.014691812917590141
Loss at batch 20 : 0.023140883073210716
Loss at batch 30 : 0.009466616436839104
Loss at batch 40 : 0.01658516749739647
Loss at batch 50 : 0.022135727107524872
Loss at batch 60 : 0.019380105659365654
Loss at batch 70 : 0.020481687039136887
Loss at batch 80 : 0.014817288145422935
Loss at batch 90 : 0.011469188146293163
Loss at batch 100 : 0.017741672694683075
Loss at batch 110 : 0.016518741846084595
Loss at batch 120 : 0.017181504517793655
Loss at batch 130 : 0.017486952245235443
Loss at batch 140 : 0.014034993015229702
Loss at batch 150 : 0.010773341171443462
Loss at batch 160 : 0.01133091002702713
Loss at batch 170 : 0.02259332314133644
Loss at batch 180 : 0.01977311074733734
Loss at batch 190 : 0.01234401110559702
Loss at batch 200 : 0.011996034532785416
Loss at batch 210 : 0.010208607651293278
Loss at batch 220 : 0.012336019426584244
Loss at batch 230 : 0.01920556277036667
Loss at batch 240 : 0.02457365393638611
Loss at batch 250 : 0.02794760838150978
Loss at batch 260 : 0.01962517760694027
Loss at batch 270 : 0.011546061374247074
Loss at batch 280 : 0.012162664905190468
Loss at batch 290 : 0.012151026166975498
Loss at batch 300 : 0.011463017202913761
Loss at batch 310 : 0.008930912241339684
Loss at batch 320 : 0.011771868914365768
Loss at batch 330 : 0.010002861730754375
Loss at batch 340 : 0.015444260090589523
Loss at batch 350 : 0.010936778970062733
Loss at batch 360 : 0.014301071874797344
Loss at batch 370 : 0.012588497251272202
epoch44 finished!
Loss at batch 10 : 0.01780153438448906
Loss at batch 20 : 0.02050514705479145
Loss at batch 30 : 0.01909884810447693
Loss at batch 40 : 0.011940397322177887
Loss at batch 50 : 0.020046018064022064
Loss at batch 60 : 0.025801032781600952
Loss at batch 70 : 0.015764020383358
Loss at batch 80 : 0.025540640577673912
Loss at batch 90 : 0.02222513221204281
Loss at batch 100 : 0.02073853462934494
Loss at batch 110 : 0.011224704794585705
Loss at batch 120 : 0.013387836515903473
Loss at batch 130 : 0.018758689984679222
Loss at batch 140 : 0.008796125650405884
Loss at batch 150 : 0.011990146711468697
Loss at batch 160 : 0.006249615922570229
Loss at batch 170 : 0.00935576856136322
Loss at batch 180 : 0.02226601541042328
Loss at batch 190 : 0.024303017184138298
Loss at batch 200 : 0.021158766001462936
Loss at batch 210 : 0.012445640750229359
Loss at batch 220 : 0.011792044155299664
Loss at batch 230 : 0.012352113611996174
Loss at batch 240 : 0.012005452066659927
Loss at batch 250 : 0.01464884728193283
Loss at batch 260 : 0.014592697843909264
Loss at batch 270 : 0.02258947305381298
Loss at batch 280 : 0.010631991550326347
Loss at batch 290 : 0.013456711545586586
Loss at batch 300 : 0.02141905017197132
Loss at batch 310 : 0.017937490716576576
Loss at batch 320 : 0.021494101732969284
Loss at batch 330 : 0.019699297845363617
Loss at batch 340 : 0.018639326095581055
Loss at batch 350 : 0.022257987409830093
Loss at batch 360 : 0.011981799267232418
Loss at batch 370 : 0.014933406375348568
epoch19 finished!
Loss at batch 10 : 0.015176940709352493
Loss at batch 20 : 0.01173614151775837
Loss at batch 30 : 0.01231071725487709
Loss at batch 40 : 0.009291301481425762
Loss at batch 50 : 0.010739936493337154
Loss at batch 60 : 0.022069083526730537
Loss at batch 70 : 0.019960617646574974
Loss at batch 80 : 0.011010780930519104
Loss at batch 90 : 0.01658746786415577
Loss at batch 100 : 0.019351407885551453
Loss at batch 110 : 0.017452910542488098
Loss at batch 120 : 0.011153739877045155
Loss at batch 130 : 0.023130057379603386
Loss at batch 140 : 0.013369722291827202
Loss at batch 150 : 0.016176322475075722
Loss at batch 160 : 0.0111267464235425
Loss at batch 170 : 0.010271583683788776
Loss at batch 180 : 0.013306353241205215
Loss at batch 190 : 0.01317744143307209
Loss at batch 200 : 0.01571575365960598
Loss at batch 210 : 0.008349889889359474
Loss at batch 220 : 0.01759290136396885
Loss at batch 230 : 0.015122747048735619
Loss at batch 240 : 0.015460959635674953
Loss at batch 250 : 0.010434686206281185
Loss at batch 260 : 0.016207635402679443
Loss at batch 270 : 0.01435675099492073
Loss at batch 280 : 0.014253511093556881
Loss at batch 290 : 0.01567046530544758
Loss at batch 300 : 0.010718295350670815
Loss at batch 310 : 0.015311118215322495
Loss at batch 320 : 0.013852200470864773
Loss at batch 330 : 0.011168662458658218
Loss at batch 340 : 0.023780006915330887
Loss at batch 350 : 0.015980590134859085
Loss at batch 360 : 0.017514118924736977
Loss at batch 370 : 0.020480381324887276
epoch19 finished!
Loss at batch 10 : 0.017049776390194893
Loss at batch 20 : 0.011044176295399666
Loss at batch 30 : 0.012220709584653378
Loss at batch 40 : 0.010878236033022404
Loss at batch 50 : 0.011797858402132988
Loss at batch 60 : 0.013785742223262787
Loss at batch 70 : 0.009445599280297756
Loss at batch 80 : 0.017870387062430382
Loss at batch 90 : 0.01427244208753109
Loss at batch 100 : 0.00962652824819088
Loss at batch 110 : 0.009566476568579674
Loss at batch 120 : 0.01563662476837635
Loss at batch 130 : 0.008642262779176235
Loss at batch 140 : 0.01334410160779953
Loss at batch 150 : 0.016337690874934196
Loss at batch 160 : 0.019367549568414688
Loss at batch 170 : 0.013969451189041138
Loss at batch 180 : 0.023328378796577454
Loss at batch 190 : 0.011567316018044949
Loss at batch 200 : 0.011347504332661629
Loss at batch 210 : 0.017821261659264565
Loss at batch 220 : 0.012195279821753502
Loss at batch 230 : 0.02927241101861
Loss at batch 240 : 0.0178888700902462
Loss at batch 250 : 0.02857952192425728
Loss at batch 260 : 0.018875041976571083
Loss at batch 270 : 0.020842259749770164
Loss at batch 280 : 0.01129070669412613
Loss at batch 290 : 0.024091258645057678
Loss at batch 300 : 0.014075705781579018
Loss at batch 310 : 0.022246308624744415
Loss at batch 320 : 0.009583812206983566
Loss at batch 330 : 0.012366516515612602
Loss at batch 340 : 0.013733495026826859
Loss at batch 350 : 0.013176295906305313
Loss at batch 360 : 0.010568349622189999
Loss at batch 370 : 0.014666593633592129
epoch45 finished!
Loss at batch 10 : 0.02531489171087742
Loss at batch 20 : 0.009254364296793938
Loss at batch 30 : 0.020555980503559113
Loss at batch 40 : 0.021397370845079422
Loss at batch 50 : 0.014613236300647259
Loss at batch 60 : 0.012417401187121868
Loss at batch 70 : 0.016272837296128273
Loss at batch 80 : 0.01917712576687336
Loss at batch 90 : 0.008219066075980663
Loss at batch 100 : 0.020868832245469093
Loss at batch 110 : 0.014412574470043182
Loss at batch 120 : 0.021134817972779274
Loss at batch 130 : 0.013133780099451542
Loss at batch 140 : 0.021536432206630707
Loss at batch 150 : 0.011061957105994225
Loss at batch 160 : 0.01634339615702629
Loss at batch 170 : 0.01856043189764023
Loss at batch 180 : 0.017601115629076958
Loss at batch 190 : 0.008260984905064106
Loss at batch 200 : 0.020818615332245827
Loss at batch 210 : 0.02345375530421734
Loss at batch 220 : 0.0136867081746459
Loss at batch 230 : 0.011085239239037037
Loss at batch 240 : 0.016855498775839806
Loss at batch 250 : 0.01304982602596283
Loss at batch 260 : 0.020972106605768204
Loss at batch 270 : 0.009310427121818066
Loss at batch 280 : 0.008514108136296272
Loss at batch 290 : 0.014120771549642086
Loss at batch 300 : 0.014712795615196228
Loss at batch 310 : 0.006983798462897539
Loss at batch 320 : 0.012696523219347
Loss at batch 330 : 0.01496070809662342
Loss at batch 340 : 0.014627974480390549
Loss at batch 350 : 0.019216394051909447
Loss at batch 360 : 0.0167477298527956
Loss at batch 370 : 0.0126797528937459
epoch46 finished!
Loss at batch 10 : 0.012782069854438305
Loss at batch 20 : 0.02771729789674282
Loss at batch 30 : 0.013783684000372887
Loss at batch 40 : 0.020295333117246628
Loss at batch 50 : 0.013713512569665909
Loss at batch 60 : 0.02190396934747696
Loss at batch 70 : 0.015368239022791386
Loss at batch 80 : 0.011267137713730335
Loss at batch 90 : 0.024526385590434074
Loss at batch 100 : 0.008020175620913506
Loss at batch 110 : 0.011354046873748302
Loss at batch 120 : 0.015192301012575626
Loss at batch 130 : 0.0171725582331419
Loss at batch 140 : 0.01898186281323433
Loss at batch 150 : 0.018488295376300812
Loss at batch 160 : 0.011048678308725357
Loss at batch 170 : 0.018439140170812607
Loss at batch 180 : 0.020467953756451607
Loss at batch 190 : 0.014414824545383453
Loss at batch 200 : 0.017785334959626198
Loss at batch 210 : 0.025121156126260757
Loss at batch 220 : 0.01032202411442995
Loss at batch 230 : 0.013061227276921272
Loss at batch 240 : 0.013983748853206635
Loss at batch 250 : 0.010079903528094292
Loss at batch 260 : 0.011284406296908855
Loss at batch 270 : 0.022052627056837082
Loss at batch 280 : 0.015480018220841885
Loss at batch 290 : 0.01014906819909811
Loss at batch 300 : 0.01645715720951557
Loss at batch 310 : 0.018820930272340775
Loss at batch 320 : 0.01350681483745575
Loss at batch 330 : 0.019637390971183777
Loss at batch 340 : 0.014390968717634678
Loss at batch 350 : 0.021815385669469833
Loss at batch 360 : 0.019095683470368385
Loss at batch 370 : 0.01523362472653389
epoch20 finished!
Loss at batch 10 : 0.01670331507921219
Loss at batch 20 : 0.01293367613106966
Loss at batch 30 : 0.010731151327490807
Loss at batch 40 : 0.029802603647112846
Loss at batch 50 : 0.023716341704130173
Loss at batch 60 : 0.00926272664219141
Loss at batch 70 : 0.011822158470749855
Loss at batch 80 : 0.014500102959573269
Loss at batch 90 : 0.01908164657652378
Loss at batch 100 : 0.016458168625831604
Loss at batch 110 : 0.015347515232861042
Loss at batch 120 : 0.014205248095095158
Loss at batch 130 : 0.01261165551841259
Loss at batch 140 : 0.01760433241724968
Loss at batch 150 : 0.020093970000743866
Loss at batch 160 : 0.015571135096251965
Loss at batch 170 : 0.011280834674835205
Loss at batch 180 : 0.01583736389875412
Loss at batch 190 : 0.009505522437393665
Loss at batch 200 : 0.018604910001158714
Loss at batch 210 : 0.026476165279746056
Loss at batch 220 : 0.019177090376615524
Loss at batch 230 : 0.013918285258114338
Loss at batch 240 : 0.014461197890341282
Loss at batch 250 : 0.01798292063176632
Loss at batch 260 : 0.015110364183783531
Loss at batch 270 : 0.024229368194937706
Loss at batch 280 : 0.015681099146604538
Loss at batch 290 : 0.009010681882500648
Loss at batch 300 : 0.013010131195187569
Loss at batch 310 : 0.006780331954360008
Loss at batch 320 : 0.01278816256672144
Loss at batch 330 : 0.004689843859523535
Loss at batch 340 : 0.01965278387069702
Loss at batch 350 : 0.008015597239136696
Loss at batch 360 : 0.012579163536429405
Loss at batch 370 : 0.013509688898921013
epoch47 finished!
Loss at batch 10 : 0.013274408876895905
Loss at batch 20 : 0.014831462875008583
Loss at batch 30 : 0.008169256150722504
Loss at batch 40 : 0.016452420502901077
Loss at batch 50 : 0.015598532743752003
Loss at batch 60 : 0.015944965183734894
Loss at batch 70 : 0.025662587955594063
Loss at batch 80 : 0.016614535823464394
Loss at batch 90 : 0.024247052147984505
Loss at batch 100 : 0.019940076395869255
Loss at batch 110 : 0.017253490164875984
Loss at batch 120 : 0.01593855954706669
Loss at batch 130 : 0.015361497178673744
Loss at batch 140 : 0.014198916032910347
Loss at batch 150 : 0.00878689344972372
Loss at batch 160 : 0.012896642088890076
Loss at batch 170 : 0.010451192036271095
Loss at batch 180 : 0.023482492193579674
Loss at batch 190 : 0.01580229215323925
Loss at batch 200 : 0.014113042503595352
Loss at batch 210 : 0.00890552531927824
Loss at batch 220 : 0.01296108029782772
Loss at batch 230 : 0.015460783615708351
Loss at batch 240 : 0.007749124895781279
Loss at batch 250 : 0.0243754331022501
Loss at batch 260 : 0.013299817219376564
Loss at batch 270 : 0.010001950897276402
Loss at batch 280 : 0.01184720266610384
Loss at batch 290 : 0.020545905455946922
Loss at batch 300 : 0.019266627728939056
Loss at batch 310 : 0.022071557119488716
Loss at batch 320 : 0.009803161025047302
Loss at batch 330 : 0.013987538404762745
Loss at batch 340 : 0.020416704937815666
Loss at batch 350 : 0.013915207237005234
Loss at batch 360 : 0.017858413979411125
Loss at batch 370 : 0.015915071591734886
epoch20 finished!
Loss at batch 10 : 0.02864726632833481
Loss at batch 20 : 0.013801674358546734
Loss at batch 30 : 0.0124187171459198
Loss at batch 40 : 0.012258680537343025
Loss at batch 50 : 0.01211494579911232
Loss at batch 60 : 0.024892855435609818
Loss at batch 70 : 0.017910173162817955
Loss at batch 80 : 0.016454875469207764
Loss at batch 90 : 0.008699155412614346
Loss at batch 100 : 0.01195538230240345
Loss at batch 110 : 0.02813158743083477
Loss at batch 120 : 0.020303286612033844
Loss at batch 130 : 0.014154339209198952
Loss at batch 140 : 0.011864404194056988
Loss at batch 150 : 0.01375347189605236
Loss at batch 160 : 0.009404093958437443
Loss at batch 170 : 0.011460287496447563
Loss at batch 180 : 0.01621093973517418
Loss at batch 190 : 0.01361007895320654
Loss at batch 200 : 0.008758063428103924
Loss at batch 210 : 0.024911269545555115
Loss at batch 220 : 0.013666079379618168
Loss at batch 230 : 0.008273164741694927
Loss at batch 240 : 0.01379427406936884
Loss at batch 250 : 0.014271405525505543
Loss at batch 260 : 0.026839660480618477
Loss at batch 270 : 0.01845860481262207
Loss at batch 280 : 0.023459790274500847
Loss at batch 290 : 0.020098894834518433
Loss at batch 300 : 0.015524892136454582
Loss at batch 310 : 0.01665559411048889
Loss at batch 320 : 0.012607840821146965
Loss at batch 330 : 0.011926948092877865
Loss at batch 340 : 0.02419215813279152
Loss at batch 350 : 0.013046392239630222
Loss at batch 360 : 0.02065255679190159
Loss at batch 370 : 0.01519628707319498
epoch48 finished!
Loss at batch 10 : 0.013253888115286827
Loss at batch 20 : 0.012630993500351906
Loss at batch 30 : 0.02189307101070881
Loss at batch 40 : 0.015010545961558819
Loss at batch 50 : 0.008759818971157074
Loss at batch 60 : 0.00849405862390995
Loss at batch 70 : 0.019674288108944893
Loss at batch 80 : 0.009612619876861572
Loss at batch 90 : 0.009022067300975323
Loss at batch 100 : 0.015576576814055443
Loss at batch 110 : 0.012884178198873997
Loss at batch 120 : 0.018681326881051064
Loss at batch 130 : 0.011890106834471226
Loss at batch 140 : 0.04386695846915245
Loss at batch 150 : 0.01670493185520172
Loss at batch 160 : 0.020514408126473427
Loss at batch 170 : 0.009714477695524693
Loss at batch 180 : 0.018887607380747795
Loss at batch 190 : 0.017781704664230347
Loss at batch 200 : 0.01218587625771761
Loss at batch 210 : 0.014501392841339111
Loss at batch 220 : 0.009699455462396145
Loss at batch 230 : 0.01753736287355423
Loss at batch 240 : 0.016422005370259285
Loss at batch 250 : 0.008994595147669315
Loss at batch 260 : 0.01471930742263794
Loss at batch 270 : 0.016904223710298538
Loss at batch 280 : 0.01650589518249035
Loss at batch 290 : 0.008982177823781967
Loss at batch 300 : 0.015865454450249672
Loss at batch 310 : 0.014719553291797638
Loss at batch 320 : 0.01135038211941719
Loss at batch 330 : 0.012502927333116531
Loss at batch 340 : 0.016586381942033768
Loss at batch 350 : 0.013956096023321152
Loss at batch 360 : 0.024365611374378204
Loss at batch 370 : 0.016733188182115555
epoch21 finished!
Loss at batch 10 : 0.00952308252453804
Loss at batch 20 : 0.016001394018530846
Loss at batch 30 : 0.009294266812503338
Loss at batch 40 : 0.02237830124795437
Loss at batch 50 : 0.0077788447961211205
Loss at batch 60 : 0.022453786805272102
Loss at batch 70 : 0.023935161530971527
Loss at batch 80 : 0.01936154253780842
Loss at batch 90 : 0.009549020789563656
Loss at batch 100 : 0.013297210447490215
Loss at batch 110 : 0.024695027619600296
Loss at batch 120 : 0.011243942193686962
Loss at batch 130 : 0.019448157399892807
Loss at batch 140 : 0.0074668885208666325
Loss at batch 150 : 0.010494762100279331
Loss at batch 160 : 0.018977703526616096
Loss at batch 170 : 0.03015049546957016
Loss at batch 180 : 0.02860712818801403
Loss at batch 190 : 0.019381282851099968
Loss at batch 200 : 0.007805871311575174
Loss at batch 210 : 0.009304068982601166
Loss at batch 220 : 0.009919020347297192
Loss at batch 230 : 0.016080040484666824
Loss at batch 240 : 0.016379455104470253
Loss at batch 250 : 0.012337288819253445
Loss at batch 260 : 0.008595699444413185
Loss at batch 270 : 0.017869697883725166
Loss at batch 280 : 0.027876172214746475
Loss at batch 290 : 0.014208262786269188
Loss at batch 300 : 0.014925793744623661
Loss at batch 310 : 0.01720665954053402
Loss at batch 320 : 0.014924251474440098
Loss at batch 330 : 0.017468152567744255
Loss at batch 340 : 0.012669622898101807
Loss at batch 350 : 0.01138149295002222
Loss at batch 360 : 0.014534126967191696
Loss at batch 370 : 0.015728088095784187
epoch49 finished!
Loss at batch 10 : 0.01072182971984148
Loss at batch 20 : 0.012814734131097794
Loss at batch 30 : 0.01093984767794609
Loss at batch 40 : 0.012917377054691315
Loss at batch 50 : 0.011613898910582066
Loss at batch 60 : 0.018629083409905434
Loss at batch 70 : 0.011891098693013191
Loss at batch 80 : 0.03303397074341774
Loss at batch 90 : 0.0124191390350461
Loss at batch 100 : 0.022320542484521866
Loss at batch 110 : 0.015618286095559597
Loss at batch 120 : 0.02010606788098812
Loss at batch 130 : 0.015910981222987175
Loss at batch 140 : 0.01631544530391693
Loss at batch 150 : 0.01951519399881363
Loss at batch 160 : 0.008072911761701107
Loss at batch 170 : 0.007305521052330732
Loss at batch 180 : 0.026123205199837685
Loss at batch 190 : 0.017709502950310707
Loss at batch 200 : 0.012785888276994228
Loss at batch 210 : 0.010496006347239017
Loss at batch 220 : 0.008506150916218758
Loss at batch 230 : 0.021313199773430824
Loss at batch 240 : 0.019381480291485786
Loss at batch 250 : 0.015226172283291817
Loss at batch 260 : 0.013582663610577583
Loss at batch 270 : 0.021903296932578087
Loss at batch 280 : 0.012666617520153522
Loss at batch 290 : 0.012804916128516197
Loss at batch 300 : 0.011373220942914486
Loss at batch 310 : 0.0250715222209692
Loss at batch 320 : 0.020286815240979195
Loss at batch 330 : 0.006718707736581564
Loss at batch 340 : 0.0204154085367918
Loss at batch 350 : 0.008570190519094467
Loss at batch 360 : 0.012213623151183128
Loss at batch 370 : 0.01287152897566557
epoch21 finished!
Loss at batch 10 : 0.01486497838050127
Loss at batch 20 : 0.022638406604528427
Loss at batch 30 : 0.01700417324900627
Loss at batch 40 : 0.011339792981743813
Loss at batch 50 : 0.0074510714039206505
Loss at batch 60 : 0.009761516004800797
Loss at batch 70 : 0.024744274094700813
Loss at batch 80 : 0.013082950375974178
Loss at batch 90 : 0.015095358714461327
Loss at batch 100 : 0.01589101366698742
Loss at batch 110 : 0.018446635454893112
Loss at batch 120 : 0.023109950125217438
Loss at batch 130 : 0.013634419068694115
Loss at batch 140 : 0.021819300949573517
Loss at batch 150 : 0.01112773735076189
Loss at batch 160 : 0.017150787636637688
Loss at batch 170 : 0.010945954360067844
Loss at batch 180 : 0.007679264526814222
Loss at batch 190 : 0.013345286250114441
Loss at batch 200 : 0.016726579517126083
Loss at batch 210 : 0.009343836456537247
Loss at batch 220 : 0.01564510352909565
Loss at batch 230 : 0.01014852523803711
Loss at batch 240 : 0.012652365490794182
Loss at batch 250 : 0.021184124052524567
Loss at batch 260 : 0.019259393215179443
Loss at batch 270 : 0.011327113956212997
Loss at batch 280 : 0.011549415998160839
Loss at batch 290 : 0.01386230904608965
Loss at batch 300 : 0.018970215693116188
Loss at batch 310 : 0.023189447820186615
Loss at batch 320 : 0.017954599112272263
Loss at batch 330 : 0.014839242212474346
Loss at batch 340 : 0.008887669071555138
Loss at batch 350 : 0.011364155448973179
Loss at batch 360 : 0.012462489306926727
Loss at batch 370 : 0.013134797103703022
epoch50 finished!
Loss at batch 10 : 0.010948777198791504
Loss at batch 20 : 0.014475704170763493
Loss at batch 30 : 0.014468559995293617
Loss at batch 40 : 0.011674377135932446
Loss at batch 50 : 0.01466355286538601
Loss at batch 60 : 0.023372728377580643
Loss at batch 70 : 0.015876680612564087
Loss at batch 80 : 0.01165488176047802
Loss at batch 90 : 0.009483212605118752
Loss at batch 100 : 0.005916551221162081
Loss at batch 110 : 0.014336926862597466
Loss at batch 120 : 0.011462618596851826
Loss at batch 130 : 0.011035057716071606
Loss at batch 140 : 0.024252990260720253
Loss at batch 150 : 0.012176066637039185
Loss at batch 160 : 0.012586616910994053
Loss at batch 170 : 0.011480100452899933
Loss at batch 180 : 0.009497362188994884
Loss at batch 190 : 0.01357973087579012
Loss at batch 200 : 0.010111909359693527
Loss at batch 210 : 0.01610102877020836
Loss at batch 220 : 0.017935851588845253
Loss at batch 230 : 0.01354103535413742
Loss at batch 240 : 0.013861974701285362
Loss at batch 250 : 0.025338230654597282
Loss at batch 260 : 0.016008447855710983
Loss at batch 270 : 0.012237385846674442
Loss at batch 280 : 0.017724130302667618
Loss at batch 290 : 0.01471035648137331
Loss at batch 300 : 0.011390101164579391
Loss at batch 310 : 0.008516124449670315
Loss at batch 320 : 0.011082756333053112
Loss at batch 330 : 0.01353129930794239
Loss at batch 340 : 0.008353037759661674
Loss at batch 350 : 0.023582372814416885
Loss at batch 360 : 0.011142888106405735
Loss at batch 370 : 0.018206177279353142
epoch51 finished!
Loss at batch 10 : 0.01298682950437069
Loss at batch 20 : 0.02517145685851574
Loss at batch 30 : 0.014707610011100769
Loss at batch 40 : 0.01397413294762373
Loss at batch 50 : 0.021037191152572632
Loss at batch 60 : 0.009668614715337753
Loss at batch 70 : 0.017460418865084648
Loss at batch 80 : 0.01429418008774519
Loss at batch 90 : 0.01520491112023592
Loss at batch 100 : 0.02778046950697899
Loss at batch 110 : 0.01542105432599783
Loss at batch 120 : 0.018747329711914062
Loss at batch 130 : 0.010464117862284184
Loss at batch 140 : 0.02187352068722248
Loss at batch 150 : 0.013939662836492062
Loss at batch 160 : 0.017089830711483955
Loss at batch 170 : 0.022045854479074478
Loss at batch 180 : 0.013661741279065609
Loss at batch 190 : 0.021805403754115105
Loss at batch 200 : 0.014380519278347492
Loss at batch 210 : 0.010368150658905506
Loss at batch 220 : 0.008012828417122364
Loss at batch 230 : 0.01988593116402626
Loss at batch 240 : 0.02655867300927639
Loss at batch 250 : 0.008658520877361298
Loss at batch 260 : 0.010410972870886326
Loss at batch 270 : 0.009446273557841778
Loss at batch 280 : 0.013508989475667477
Loss at batch 290 : 0.022876542061567307
Loss at batch 300 : 0.010817712172865868
Loss at batch 310 : 0.01271747425198555
Loss at batch 320 : 0.011282996274530888
Loss at batch 330 : 0.015395628288388252
Loss at batch 340 : 0.016102060675621033
Loss at batch 350 : 0.011893217451870441
Loss at batch 360 : 0.010540115647017956
Loss at batch 370 : 0.009517676196992397
epoch22 finished!
Loss at batch 10 : 0.008342873305082321
Loss at batch 20 : 0.019374966621398926
Loss at batch 30 : 0.029681507498025894
Loss at batch 40 : 0.019552476704120636
Loss at batch 50 : 0.014316227287054062
Loss at batch 60 : 0.01293885987251997
Loss at batch 70 : 0.02922765351831913
Loss at batch 80 : 0.015389700420200825
Loss at batch 90 : 0.013556734658777714
Loss at batch 100 : 0.030381549149751663
Loss at batch 110 : 0.009509984403848648
Loss at batch 120 : 0.010678650811314583
Loss at batch 130 : 0.021007195115089417
Loss at batch 140 : 0.013597112149000168
Loss at batch 150 : 0.007100607268512249
Loss at batch 160 : 0.013797281309962273
Loss at batch 170 : 0.009743510745465755
Loss at batch 180 : 0.02459379844367504
Loss at batch 190 : 0.012401744723320007
Loss at batch 200 : 0.017639514058828354
Loss at batch 210 : 0.01673944480717182
Loss at batch 220 : 0.019316118210554123
Loss at batch 230 : 0.02823280543088913
Loss at batch 240 : 0.0173395536839962
Loss at batch 250 : 0.01263823639601469
Loss at batch 260 : 0.012799596413969994
Loss at batch 270 : 0.026379752904176712
Loss at batch 280 : 0.011997746303677559
Loss at batch 290 : 0.02399243228137493
Loss at batch 300 : 0.011732643470168114
Loss at batch 310 : 0.01896738074719906
Loss at batch 320 : 0.010503202676773071
Loss at batch 330 : 0.008709312416613102
Loss at batch 340 : 0.015704484656453133
Loss at batch 350 : 0.019976625218987465
Loss at batch 360 : 0.011706719174981117
Loss at batch 370 : 0.011587672866880894
epoch22 finished!
Loss at batch 10 : 0.014112697914242744
Loss at batch 20 : 0.015180605463683605
Loss at batch 30 : 0.009947595186531544
Loss at batch 40 : 0.011861098930239677
Loss at batch 50 : 0.026013489812612534
Loss at batch 60 : 0.01607956364750862
Loss at batch 70 : 0.010489014908671379
Loss at batch 80 : 0.00969255343079567
Loss at batch 90 : 0.015146906487643719
Loss at batch 100 : 0.016385292634367943
Loss at batch 110 : 0.01092678215354681
Loss at batch 120 : 0.01804644614458084
Loss at batch 130 : 0.01653759926557541
Loss at batch 140 : 0.01239328645169735
Loss at batch 150 : 0.02445799857378006
Loss at batch 160 : 0.013382092118263245
Loss at batch 170 : 0.006726158782839775
Loss at batch 180 : 0.021220553666353226
Loss at batch 190 : 0.017053667455911636
Loss at batch 200 : 0.017124980688095093
Loss at batch 210 : 0.011055841110646725
Loss at batch 220 : 0.01372127141803503
Loss at batch 230 : 0.010374261997640133
Loss at batch 240 : 0.012251908890902996
Loss at batch 250 : 0.01335223764181137
Loss at batch 260 : 0.017354397103190422
Loss at batch 270 : 0.014840410090982914
Loss at batch 280 : 0.02153099700808525
Loss at batch 290 : 0.012965497560799122
Loss at batch 300 : 0.02137797512114048
Loss at batch 310 : 0.02091262862086296
Loss at batch 320 : 0.01062626950442791
Loss at batch 330 : 0.021297669038176537
Loss at batch 340 : 0.013570468872785568
Loss at batch 350 : 0.015004011802375317
Loss at batch 360 : 0.013372169807553291
Loss at batch 370 : 0.02478252910077572
epoch52 finished!
Loss at batch 10 : 0.009100367315113544
Loss at batch 20 : 0.011491462588310242
Loss at batch 30 : 0.01610160432755947
Loss at batch 40 : 0.018689412623643875
Loss at batch 50 : 0.013375106267631054
Loss at batch 60 : 0.017763128504157066
Loss at batch 70 : 0.008842715993523598
Loss at batch 80 : 0.017661504447460175
Loss at batch 90 : 0.012494485825300217
Loss at batch 100 : 0.020279597491025925
Loss at batch 110 : 0.01726502738893032
Loss at batch 120 : 0.013722384348511696
Loss at batch 130 : 0.01324036531150341
Loss at batch 140 : 0.02131764218211174
Loss at batch 150 : 0.01145485695451498
Loss at batch 160 : 0.017953423783183098
Loss at batch 170 : 0.010868946090340614
Loss at batch 180 : 0.015950795263051987
Loss at batch 190 : 0.016190938651561737
Loss at batch 200 : 0.01521409209817648
Loss at batch 210 : 0.009566080756485462
Loss at batch 220 : 0.016922907903790474
Loss at batch 230 : 0.014609641395509243
Loss at batch 240 : 0.0160889383405447
Loss at batch 250 : 0.022082002833485603
Loss at batch 260 : 0.008499503135681152
Loss at batch 270 : 0.011078179813921452
Loss at batch 280 : 0.019599059596657753
Loss at batch 290 : 0.010073074139654636
Loss at batch 300 : 0.014261805452406406
Loss at batch 310 : 0.01747363992035389
Loss at batch 320 : 0.013686228543519974
Loss at batch 330 : 0.01890338957309723
Loss at batch 340 : 0.023054683580994606
Loss at batch 350 : 0.014411553740501404
Loss at batch 360 : 0.011654398404061794
Loss at batch 370 : 0.029820701107382774
epoch53 finished!
Loss at batch 10 : 0.008714018389582634
Loss at batch 20 : 0.015645707026124
Loss at batch 30 : 0.01457044668495655
Loss at batch 40 : 0.010331321507692337
Loss at batch 50 : 0.019373109564185143
Loss at batch 60 : 0.0073187267407774925
Loss at batch 70 : 0.007156230043619871
Loss at batch 80 : 0.012231925502419472
Loss at batch 90 : 0.016280168667435646
Loss at batch 100 : 0.01670026406645775
Loss at batch 110 : 0.011735605075955391
Loss at batch 120 : 0.01367886085063219
Loss at batch 130 : 0.00768235232681036
Loss at batch 140 : 0.011111563071608543
Loss at batch 150 : 0.01574293151497841
Loss at batch 160 : 0.01125657930970192
Loss at batch 170 : 0.015184508636593819
Loss at batch 180 : 0.013197515159845352
Loss at batch 190 : 0.013558686710894108
Loss at batch 200 : 0.007676124107092619
Loss at batch 210 : 0.011977498419582844
Loss at batch 220 : 0.0102340467274189
Loss at batch 230 : 0.010088273324072361
Loss at batch 240 : 0.013644011691212654
Loss at batch 250 : 0.012129894457757473
Loss at batch 260 : 0.023278340697288513
Loss at batch 270 : 0.013484613969922066
Loss at batch 280 : 0.011405673809349537
Loss at batch 290 : 0.016379816457629204
Loss at batch 300 : 0.016436534002423286
Loss at batch 310 : 0.01880629174411297
Loss at batch 320 : 0.008928323164582253
Loss at batch 330 : 0.010566623881459236
Loss at batch 340 : 0.022852949798107147
Loss at batch 350 : 0.012798367999494076
Loss at batch 360 : 0.013750122860074043
Loss at batch 370 : 0.02114623598754406
epoch23 finished!
Loss at batch 10 : 0.01980876550078392
Loss at batch 20 : 0.026692865416407585
Loss at batch 30 : 0.01639530435204506
Loss at batch 40 : 0.00848052091896534
Loss at batch 50 : 0.009769931435585022
Loss at batch 60 : 0.01506770495325327
Loss at batch 70 : 0.014046499505639076
Loss at batch 80 : 0.025333911180496216
Loss at batch 90 : 0.01184158120304346
Loss at batch 100 : 0.011559630744159222
Loss at batch 110 : 0.009349921718239784
Loss at batch 120 : 0.02009786106646061
Loss at batch 130 : 0.01998879760503769
Loss at batch 140 : 0.012829147279262543
Loss at batch 150 : 0.01571783609688282
Loss at batch 160 : 0.023166384547948837
Loss at batch 170 : 0.01624554954469204
Loss at batch 180 : 0.013545031659305096
Loss at batch 190 : 0.019904708489775658
Loss at batch 200 : 0.010444494895637035
Loss at batch 210 : 0.0111868130043149
Loss at batch 220 : 0.012127974070608616
Loss at batch 230 : 0.010805533267557621
Loss at batch 240 : 0.015135947614908218
Loss at batch 250 : 0.019467908889055252
Loss at batch 260 : 0.012378506362438202
Loss at batch 270 : 0.012085952796041965
Loss at batch 280 : 0.009919420816004276
Loss at batch 290 : 0.008292090147733688
Loss at batch 300 : 0.011864854954183102
Loss at batch 310 : 0.016994280740618706
Loss at batch 320 : 0.011620262637734413
Loss at batch 330 : 0.008624608628451824
Loss at batch 340 : 0.019969481974840164
Loss at batch 350 : 0.022318987175822258
Loss at batch 360 : 0.020857932046055794
Loss at batch 370 : 0.008309457451105118
epoch23 finished!
Loss at batch 10 : 0.01459284033626318
Loss at batch 20 : 0.021499643102288246
Loss at batch 30 : 0.013829570263624191
Loss at batch 40 : 0.014121796004474163
Loss at batch 50 : 0.02324235811829567
Loss at batch 60 : 0.010433708317577839
Loss at batch 70 : 0.012528962455689907
Loss at batch 80 : 0.018289661034941673
Loss at batch 90 : 0.012232202105224133
Loss at batch 100 : 0.013552919030189514
Loss at batch 110 : 0.014487053267657757
Loss at batch 120 : 0.011062229983508587
Loss at batch 130 : 0.015468800440430641
Loss at batch 140 : 0.012763435021042824
Loss at batch 150 : 0.011376681737601757
Loss at batch 160 : 0.014523334801197052
Loss at batch 170 : 0.01121117826551199
Loss at batch 180 : 0.015038001351058483
Loss at batch 190 : 0.013773193582892418
Loss at batch 200 : 0.012393048964440823
Loss at batch 210 : 0.016069985926151276
Loss at batch 220 : 0.007177671883255243
Loss at batch 230 : 0.017994174733757973
Loss at batch 240 : 0.02198711223900318
Loss at batch 250 : 0.01162052433937788
Loss at batch 260 : 0.008278822526335716
Loss at batch 270 : 0.015713084489107132
Loss at batch 280 : 0.010742418467998505
Loss at batch 290 : 0.011312796734273434
Loss at batch 300 : 0.02025027945637703
Loss at batch 310 : 0.017787734046578407
Loss at batch 320 : 0.016194568946957588
Loss at batch 330 : 0.012350858189165592
Loss at batch 340 : 0.014497371390461922
Loss at batch 350 : 0.017379721626639366
Loss at batch 360 : 0.012765016406774521
Loss at batch 370 : 0.01598857343196869
epoch54 finished!
Loss at batch 10 : 0.013347062282264233
Loss at batch 20 : 0.02518598921597004
Loss at batch 30 : 0.011233844794332981
Loss at batch 40 : 0.010123727843165398
Loss at batch 50 : 0.011284535750746727
Loss at batch 60 : 0.010219652205705643
Loss at batch 70 : 0.015259502455592155
Loss at batch 80 : 0.012601850554347038
Loss at batch 90 : 0.019498033449053764
Loss at batch 100 : 0.011734950356185436
Loss at batch 110 : 0.008822067640721798
Loss at batch 120 : 0.00678986357524991
Loss at batch 130 : 0.013603809289634228
Loss at batch 140 : 0.018254784867167473
Loss at batch 150 : 0.014854120090603828
Loss at batch 160 : 0.013960465788841248
Loss at batch 170 : 0.012788187712430954
Loss at batch 180 : 0.013069708831608295
Loss at batch 190 : 0.01860629953444004
Loss at batch 200 : 0.030672607943415642
Loss at batch 210 : 0.017096566036343575
Loss at batch 220 : 0.013073640875518322
Loss at batch 230 : 0.019403928890824318
Loss at batch 240 : 0.019284643232822418
Loss at batch 250 : 0.013883201405405998
Loss at batch 260 : 0.00965788308531046
Loss at batch 270 : 0.01920473761856556
Loss at batch 280 : 0.02803085744380951
Loss at batch 290 : 0.015748025849461555
Loss at batch 300 : 0.015436329878866673
Loss at batch 310 : 0.01452592946588993
Loss at batch 320 : 0.011879535391926765
Loss at batch 330 : 0.014361399225890636
Loss at batch 340 : 0.021063504740595818
Loss at batch 350 : 0.011676128022372723
Loss at batch 360 : 0.016088299453258514
Loss at batch 370 : 0.01123354583978653
epoch55 finished!
Loss at batch 10 : 0.01796966977417469
Loss at batch 20 : 0.017621634528040886
Loss at batch 30 : 0.022196264937520027
Loss at batch 40 : 0.03101303242146969
Loss at batch 50 : 0.010402031242847443
Loss at batch 60 : 0.020144572481513023
Loss at batch 70 : 0.008245210163295269
Loss at batch 80 : 0.009196043945848942
Loss at batch 90 : 0.014805511571466923
Loss at batch 100 : 0.02036764845252037
Loss at batch 110 : 0.026853390038013458
Loss at batch 120 : 0.0119255306199193
Loss at batch 130 : 0.01744212955236435
Loss at batch 140 : 0.0070793600752949715
Loss at batch 150 : 0.015214650891721249
Loss at batch 160 : 0.011647975072264671
Loss at batch 170 : 0.023310013115406036
Loss at batch 180 : 0.017461441457271576
Loss at batch 190 : 0.009336916729807854
Loss at batch 200 : 0.018523121252655983
Loss at batch 210 : 0.020905273035168648
Loss at batch 220 : 0.014525524340569973
Loss at batch 230 : 0.01230998057872057
Loss at batch 240 : 0.016045980155467987
Loss at batch 250 : 0.012293964624404907
Loss at batch 260 : 0.020728856325149536
Loss at batch 270 : 0.015498455613851547
Loss at batch 280 : 0.01444985345005989
Loss at batch 290 : 0.009178096428513527
Loss at batch 300 : 0.015718499198555946
Loss at batch 310 : 0.014205317944288254
Loss at batch 320 : 0.015394287183880806
Loss at batch 330 : 0.01696733757853508
Loss at batch 340 : 0.009342966601252556
Loss at batch 350 : 0.013390318490564823
Loss at batch 360 : 0.010705909691751003
Loss at batch 370 : 0.020740054547786713
epoch24 finished!
Loss at batch 10 : 0.013078453950583935
Loss at batch 20 : 0.01649140566587448
Loss at batch 30 : 0.009675062261521816
Loss at batch 40 : 0.015074518509209156
Loss at batch 50 : 0.021129785105586052
Loss at batch 60 : 0.028704850003123283
Loss at batch 70 : 0.015887273475527763
Loss at batch 80 : 0.011228691786527634
Loss at batch 90 : 0.014170333743095398
Loss at batch 100 : 0.014696331694722176
Loss at batch 110 : 0.010156898759305477
Loss at batch 120 : 0.011765348725020885
Loss at batch 130 : 0.013338019140064716
Loss at batch 140 : 0.01796375773847103
Loss at batch 150 : 0.011161948554217815
Loss at batch 160 : 0.007916418835520744
Loss at batch 170 : 0.015019788406789303
Loss at batch 180 : 0.010863815434277058
Loss at batch 190 : 0.010365291498601437
Loss at batch 200 : 0.014456530101597309
Loss at batch 210 : 0.008593244478106499
Loss at batch 220 : 0.011797988787293434
Loss at batch 230 : 0.016546133905649185
Loss at batch 240 : 0.017342623323202133
Loss at batch 250 : 0.01883057877421379
Loss at batch 260 : 0.010911850258708
Loss at batch 270 : 0.017392706125974655
Loss at batch 280 : 0.015448642894625664
Loss at batch 290 : 0.015431840904057026
Loss at batch 300 : 0.00665708864107728
Loss at batch 310 : 0.019134650006890297
Loss at batch 320 : 0.02234986610710621
Loss at batch 330 : 0.027177607640624046
Loss at batch 340 : 0.013478984124958515
Loss at batch 350 : 0.015063158236443996
Loss at batch 360 : 0.026480281725525856
Loss at batch 370 : 0.01389595028012991
epoch24 finished!
Loss at batch 10 : 0.015038187615573406
Loss at batch 20 : 0.015258803963661194
Loss at batch 30 : 0.018199434503912926
Loss at batch 40 : 0.012385218404233456
Loss at batch 50 : 0.013247150927782059
Loss at batch 60 : 0.01401388831436634
Loss at batch 70 : 0.011332380585372448
Loss at batch 80 : 0.011362015269696712
Loss at batch 90 : 0.008633201941847801
Loss at batch 100 : 0.015100173652172089
Loss at batch 110 : 0.012506875209510326
Loss at batch 120 : 0.010762575082480907
Loss at batch 130 : 0.020426934584975243
Loss at batch 140 : 0.01818590797483921
Loss at batch 150 : 0.018529506400227547
Loss at batch 160 : 0.009100310504436493
Loss at batch 170 : 0.010786213912069798
Loss at batch 180 : 0.015527432784438133
Loss at batch 190 : 0.010884211398661137
Loss at batch 200 : 0.01784905232489109
Loss at batch 210 : 0.015253014862537384
Loss at batch 220 : 0.012794509530067444
Loss at batch 230 : 0.020634299144148827
Loss at batch 240 : 0.019283302128314972
Loss at batch 250 : 0.01793142966926098
Loss at batch 260 : 0.013357548043131828
Loss at batch 270 : 0.02021268755197525
Loss at batch 280 : 0.01335348840802908
Loss at batch 290 : 0.012496663257479668
Loss at batch 300 : 0.013744445517659187
Loss at batch 310 : 0.010437438264489174
Loss at batch 320 : 0.03066977486014366
Loss at batch 330 : 0.020687809213995934
Loss at batch 340 : 0.01627166196703911
Loss at batch 350 : 0.016146576032042503
Loss at batch 360 : 0.011454252526164055
Loss at batch 370 : 0.015115927904844284
epoch56 finished!
Loss at batch 10 : 0.015873102471232414
Loss at batch 20 : 0.015680836513638496
Loss at batch 30 : 0.01452703308314085
Loss at batch 40 : 0.010720361024141312
Loss at batch 50 : 0.013750080950558186
Loss at batch 60 : 0.01203227136284113
Loss at batch 70 : 0.014639483764767647
Loss at batch 80 : 0.010214429348707199
Loss at batch 90 : 0.017156444489955902
Loss at batch 100 : 0.019013863056898117
Loss at batch 110 : 0.011013895273208618
Loss at batch 120 : 0.009183083660900593
Loss at batch 130 : 0.013532220385968685
Loss at batch 140 : 0.015384242869913578
Loss at batch 150 : 0.018166830763220787
Loss at batch 160 : 0.021708674728870392
Loss at batch 170 : 0.008168886415660381
Loss at batch 180 : 0.012397026643157005
Loss at batch 190 : 0.021366504952311516
Loss at batch 200 : 0.009317154996097088
Loss at batch 210 : 0.01604698784649372
Loss at batch 220 : 0.009693568572402
Loss at batch 230 : 0.013479548506438732
Loss at batch 240 : 0.013882879167795181
Loss at batch 250 : 0.010087556205689907
Loss at batch 260 : 0.01367935910820961
Loss at batch 270 : 0.01124382670968771
Loss at batch 280 : 0.026305273175239563
Loss at batch 290 : 0.013452330604195595
Loss at batch 300 : 0.010145552456378937
Loss at batch 310 : 0.015392768196761608
Loss at batch 320 : 0.014859306626021862
Loss at batch 330 : 0.011614371091127396
Loss at batch 340 : 0.017991533502936363
Loss at batch 350 : 0.01526456419378519
Loss at batch 360 : 0.008493342436850071
Loss at batch 370 : 0.015008685179054737
epoch57 finished!
Loss at batch 10 : 0.017353344708681107
Loss at batch 20 : 0.011663625948131084
Loss at batch 30 : 0.016432253643870354
Loss at batch 40 : 0.024819519370794296
Loss at batch 50 : 0.011677573435008526
Loss at batch 60 : 0.013737193308770657
Loss at batch 70 : 0.012137036770582199
Loss at batch 80 : 0.019716640934348106
Loss at batch 90 : 0.014261774718761444
Loss at batch 100 : 0.014270561747252941
Loss at batch 110 : 0.02380530722439289
Loss at batch 120 : 0.020646819844841957
Loss at batch 130 : 0.008677833713591099
Loss at batch 140 : 0.02266060747206211
Loss at batch 150 : 0.008214910514652729
Loss at batch 160 : 0.010773311369121075
Loss at batch 170 : 0.00921718217432499
Loss at batch 180 : 0.016401736065745354
Loss at batch 190 : 0.012016480788588524
Loss at batch 200 : 0.014320877380669117
Loss at batch 210 : 0.021692166104912758
Loss at batch 220 : 0.03007054701447487
Loss at batch 230 : 0.011683201417326927
Loss at batch 240 : 0.014785423874855042
Loss at batch 250 : 0.013780108653008938
Loss at batch 260 : 0.008916229009628296
Loss at batch 270 : 0.017439885064959526
Loss at batch 280 : 0.013299921527504921
Loss at batch 290 : 0.019175000488758087
Loss at batch 300 : 0.018717516213655472
Loss at batch 310 : 0.017565783113241196
Loss at batch 320 : 0.015159128233790398
Loss at batch 330 : 0.010038252919912338
Loss at batch 340 : 0.01816076599061489
Loss at batch 350 : 0.011317064985632896
Loss at batch 360 : 0.02016102336347103
Loss at batch 370 : 0.021903598681092262
epoch25 finished!
Loss at batch 10 : 0.023866958916187286
Loss at batch 20 : 0.017362801358103752
Loss at batch 30 : 0.0122887147590518
Loss at batch 40 : 0.012922556139528751
Loss at batch 50 : 0.019828680902719498
Loss at batch 60 : 0.010369284078478813
Loss at batch 70 : 0.01570267789065838
Loss at batch 80 : 0.013216922990977764
Loss at batch 90 : 0.029645631089806557
Loss at batch 100 : 0.013969364576041698
Loss at batch 110 : 0.018956616520881653
Loss at batch 120 : 0.016327302902936935
Loss at batch 130 : 0.01306300051510334
Loss at batch 140 : 0.013671087101101875
Loss at batch 150 : 0.014127250760793686
Loss at batch 160 : 0.019679544493556023
Loss at batch 170 : 0.015681732445955276
Loss at batch 180 : 0.018738960847258568
Loss at batch 190 : 0.01212430838495493
Loss at batch 200 : 0.019294625148177147
Loss at batch 210 : 0.020266562700271606
Loss at batch 220 : 0.013252710923552513
Loss at batch 230 : 0.018951788544654846
Loss at batch 240 : 0.009230156429111958
Loss at batch 250 : 0.018307378515601158
Loss at batch 260 : 0.01740836165845394
Loss at batch 270 : 0.014290699735283852
Loss at batch 280 : 0.024226171895861626
Loss at batch 290 : 0.014068091288208961
Loss at batch 300 : 0.01573241874575615
Loss at batch 310 : 0.010336837731301785
Loss at batch 320 : 0.023124150931835175
Loss at batch 330 : 0.014939723536372185
Loss at batch 340 : 0.011184126138687134
Loss at batch 350 : 0.013318122364580631
Loss at batch 360 : 0.00806752871721983
Loss at batch 370 : 0.01725679822266102
epoch25 finished!
Loss at batch 10 : 0.00993188377469778
Loss at batch 20 : 0.013624579645693302
Loss at batch 30 : 0.016665266826748848
Loss at batch 40 : 0.014741696417331696
Loss at batch 50 : 0.01408841460943222
Loss at batch 60 : 0.01157611794769764
Loss at batch 70 : 0.016312720254063606
Loss at batch 80 : 0.009805179201066494
Loss at batch 90 : 0.01732267439365387
Loss at batch 100 : 0.00948886014521122
Loss at batch 110 : 0.012403881177306175
Loss at batch 120 : 0.009444640949368477
Loss at batch 130 : 0.010697939433157444
Loss at batch 140 : 0.008509489707648754
Loss at batch 150 : 0.016913028433918953
Loss at batch 160 : 0.01121596060693264
Loss at batch 170 : 0.011328976601362228
Loss at batch 180 : 0.016013622283935547
Loss at batch 190 : 0.012158437632024288
Loss at batch 200 : 0.009892022237181664
Loss at batch 210 : 0.013184603303670883
Loss at batch 220 : 0.015096105635166168
Loss at batch 230 : 0.02191135846078396
Loss at batch 240 : 0.018051913008093834
Loss at batch 250 : 0.013859308324754238
Loss at batch 260 : 0.017166415229439735
Loss at batch 270 : 0.01162920892238617
Loss at batch 280 : 0.013042880222201347
Loss at batch 290 : 0.01235244795680046
Loss at batch 300 : 0.01495296135544777
Loss at batch 310 : 0.014381400309503078
Loss at batch 320 : 0.014242618344724178
Loss at batch 330 : 0.009683488868176937
Loss at batch 340 : 0.011874629184603691
Loss at batch 350 : 0.01177156437188387
Loss at batch 360 : 0.018999874591827393
Loss at batch 370 : 0.009330099448561668
epoch58 finished!
Loss at batch 10 : 0.020105069503188133
Loss at batch 20 : 0.013170769438147545
Loss at batch 30 : 0.013167205266654491
Loss at batch 40 : 0.009789451956748962
Loss at batch 50 : 0.012887145392596722
Loss at batch 60 : 0.015383008867502213
Loss at batch 70 : 0.010062607936561108
Loss at batch 80 : 0.012049597688019276
Loss at batch 90 : 0.018254393711686134
Loss at batch 100 : 0.030218565836548805
Loss at batch 110 : 0.011222678236663342
Loss at batch 120 : 0.008349447511136532
Loss at batch 130 : 0.015369855798780918
Loss at batch 140 : 0.009838426485657692
Loss at batch 150 : 0.011237114667892456
Loss at batch 160 : 0.012961938977241516
Loss at batch 170 : 0.011016471311450005
Loss at batch 180 : 0.01804250292479992
Loss at batch 190 : 0.01618717797100544
Loss at batch 200 : 0.013322299346327782
Loss at batch 210 : 0.010970169678330421
Loss at batch 220 : 0.036274101585149765
Loss at batch 230 : 0.013452703133225441
Loss at batch 240 : 0.010642838664352894
Loss at batch 250 : 0.012071738950908184
Loss at batch 260 : 0.01494528166949749
Loss at batch 270 : 0.009269790723919868
Loss at batch 280 : 0.020548544824123383
Loss at batch 290 : 0.01625083014369011
Loss at batch 300 : 0.017819739878177643
Loss at batch 310 : 0.02459392324090004
Loss at batch 320 : 0.014951742254197598
Loss at batch 330 : 0.010513119399547577
Loss at batch 340 : 0.016103001311421394
Loss at batch 350 : 0.014107337221503258
Loss at batch 360 : 0.009800025261938572
Loss at batch 370 : 0.012062770314514637
epoch59 finished!
Loss at batch 10 : 0.014118417166173458
Loss at batch 20 : 0.009702298790216446
Loss at batch 30 : 0.018361886963248253
Loss at batch 40 : 0.01794460043311119
Loss at batch 50 : 0.020703967660665512
Loss at batch 60 : 0.017773214727640152
Loss at batch 70 : 0.026444464921951294
Loss at batch 80 : 0.03644191473722458
Loss at batch 90 : 0.01592986099421978
Loss at batch 100 : 0.018796097487211227
Loss at batch 110 : 0.01842562109231949
Loss at batch 120 : 0.013572468422353268
Loss at batch 130 : 0.0175187848508358
Loss at batch 140 : 0.0137247946113348
Loss at batch 150 : 0.01384397316724062
Loss at batch 160 : 0.01225424837321043
Loss at batch 170 : 0.016045644879341125
Loss at batch 180 : 0.011669241823256016
Loss at batch 190 : 0.012090406380593777
Loss at batch 200 : 0.014219514094293118
Loss at batch 210 : 0.0169058907777071
Loss at batch 220 : 0.024093827232718468
Loss at batch 230 : 0.012461533769965172
Loss at batch 240 : 0.014950137585401535
Loss at batch 250 : 0.015891283750534058
Loss at batch 260 : 0.026583563536405563
Loss at batch 270 : 0.01652108132839203
Loss at batch 280 : 0.011461468413472176
Loss at batch 290 : 0.01535726711153984
Loss at batch 300 : 0.014022939838469028
Loss at batch 310 : 0.01826375722885132
Loss at batch 320 : 0.010891261510550976
Loss at batch 330 : 0.014341776259243488
Loss at batch 340 : 0.01010016817599535
Loss at batch 350 : 0.021453259512782097
Loss at batch 360 : 0.01563878543674946
Loss at batch 370 : 0.016506370157003403
epoch26 finished!
Loss at batch 10 : 0.025514081120491028
Loss at batch 20 : 0.018967030569911003
Loss at batch 30 : 0.027285868301987648
Loss at batch 40 : 0.02209354378283024
Loss at batch 50 : 0.011364532634615898
Loss at batch 60 : 0.013459530659019947
Loss at batch 70 : 0.016537953168153763
Loss at batch 80 : 0.012343942187726498
Loss at batch 90 : 0.015821320936083794
Loss at batch 100 : 0.02391217276453972
Loss at batch 110 : 0.014425735920667648
Loss at batch 120 : 0.010350571945309639
Loss at batch 130 : 0.011295894160866737
Loss at batch 140 : 0.017950421199202538
Loss at batch 150 : 0.023306982591748238
Loss at batch 160 : 0.010909616015851498
Loss at batch 170 : 0.01838182657957077
Loss at batch 180 : 0.0126034589484334
Loss at batch 190 : 0.01013720128685236
Loss at batch 200 : 0.014272702857851982
Loss at batch 210 : 0.012061439454555511
Loss at batch 220 : 0.0194865632802248
Loss at batch 230 : 0.012857571244239807
Loss at batch 240 : 0.014030280523002148
Loss at batch 250 : 0.025634003803133965
Loss at batch 260 : 0.015208056196570396
Loss at batch 270 : 0.014298290014266968
Loss at batch 280 : 0.018494823947548866
Loss at batch 290 : 0.017934640869498253
Loss at batch 300 : 0.012559917755424976
Loss at batch 310 : 0.013021965511143208
Loss at batch 320 : 0.019273541867733
Loss at batch 330 : 0.011178689077496529
Loss at batch 340 : 0.008256420493125916
Loss at batch 350 : 0.007429150864481926
Loss at batch 360 : 0.014908223412930965
Loss at batch 370 : 0.017074493691325188
epoch26 finished!
Loss at batch 10 : 0.013003314845263958
Loss at batch 20 : 0.015382477082312107
Loss at batch 30 : 0.00848021823912859
Loss at batch 40 : 0.015493770129978657
Loss at batch 50 : 0.021817253902554512
Loss at batch 60 : 0.02163131721317768
Loss at batch 70 : 0.011735513806343079
Loss at batch 80 : 0.012507718987762928
Loss at batch 90 : 0.013920004479587078
Loss at batch 100 : 0.011603999882936478
Loss at batch 110 : 0.018565060570836067
Loss at batch 120 : 0.013425477780401707
Loss at batch 130 : 0.01491098664700985
Loss at batch 140 : 0.0096543338149786
Loss at batch 150 : 0.005609660875052214
Loss at batch 160 : 0.016241390258073807
Loss at batch 170 : 0.013771026395261288
Loss at batch 180 : 0.013004430569708347
Loss at batch 190 : 0.005867497064173222
Loss at batch 200 : 0.014074565842747688
Loss at batch 210 : 0.02071838453412056
Loss at batch 220 : 0.020482216030359268
Loss at batch 230 : 0.014049814082682133
Loss at batch 240 : 0.0236416794359684
Loss at batch 250 : 0.012416611425578594
Loss at batch 260 : 0.01496542152017355
Loss at batch 270 : 0.015507619827985764
Loss at batch 280 : 0.015091347508132458
Loss at batch 290 : 0.01795329712331295
Loss at batch 300 : 0.01642274297773838
Loss at batch 310 : 0.009109674952924252
Loss at batch 320 : 0.013513347133994102
Loss at batch 330 : 0.023394238203763962
Loss at batch 340 : 0.015838397666811943
Loss at batch 350 : 0.01786075346171856
Loss at batch 360 : 0.01376846618950367
Loss at batch 370 : 0.023303013294935226
epoch60 finished!
Loss at batch 10 : 0.01462075300514698
Loss at batch 20 : 0.01591850258409977
Loss at batch 30 : 0.010728647001087666
Loss at batch 40 : 0.02617689035832882
Loss at batch 50 : 0.009642655029892921
Loss at batch 60 : 0.009074483066797256
Loss at batch 70 : 0.01356915570795536
Loss at batch 80 : 0.009014079347252846
Loss at batch 90 : 0.01671484299004078
Loss at batch 100 : 0.013650940731167793
Loss at batch 110 : 0.020185785368084908
Loss at batch 120 : 0.024206724017858505
Loss at batch 130 : 0.012741483747959137
Loss at batch 140 : 0.01694738306105137
Loss at batch 150 : 0.03140529245138168
Loss at batch 160 : 0.01869986020028591
Loss at batch 170 : 0.013907338492572308
Loss at batch 180 : 0.011071094311773777
Loss at batch 190 : 0.023198692128062248
Loss at batch 200 : 0.024274557828903198
Loss at batch 210 : 0.010960837826132774
Loss at batch 220 : 0.006681494880467653
Loss at batch 230 : 0.011605402454733849
Loss at batch 240 : 0.008235878311097622
Loss at batch 250 : 0.01679917238652706
Loss at batch 260 : 0.01453551184386015
Loss at batch 270 : 0.0201661828905344
Loss at batch 280 : 0.01665029302239418
Loss at batch 290 : 0.010199672542512417
Loss at batch 300 : 0.008286887779831886
Loss at batch 310 : 0.013545994646847248
Loss at batch 320 : 0.010527798905968666
Loss at batch 330 : 0.012137428857386112
Loss at batch 340 : 0.023160580545663834
Loss at batch 350 : 0.015812857076525688
Loss at batch 360 : 0.017307395115494728
Loss at batch 370 : 0.02179797925055027
epoch61 finished!
Loss at batch 10 : 0.014761255122721195
Loss at batch 20 : 0.009818603284657001
Loss at batch 30 : 0.010935086756944656
Loss at batch 40 : 0.02017446607351303
Loss at batch 50 : 0.01473104115575552
Loss at batch 60 : 0.008811344392597675
Loss at batch 70 : 0.011565119959414005
Loss at batch 80 : 0.030641498044133186
Loss at batch 90 : 0.01906943880021572
Loss at batch 100 : 0.012928077019751072
Loss at batch 110 : 0.01971721276640892
Loss at batch 120 : 0.012078962288796902
Loss at batch 130 : 0.023426637053489685
Loss at batch 140 : 0.008655416779220104
Loss at batch 150 : 0.016577476635575294
Loss at batch 160 : 0.017779503017663956
Loss at batch 170 : 0.011222178116440773
Loss at batch 180 : 0.01337999664247036
Loss at batch 190 : 0.01451869122684002
Loss at batch 200 : 0.0227584857493639
Loss at batch 210 : 0.016248751431703568
Loss at batch 220 : 0.007586132735013962
Loss at batch 230 : 0.018877500668168068
Loss at batch 240 : 0.012564356438815594
Loss at batch 250 : 0.011993599124252796
Loss at batch 260 : 0.017064299434423447
Loss at batch 270 : 0.021326536312699318
Loss at batch 280 : 0.022147180512547493
Loss at batch 290 : 0.009148279204964638
Loss at batch 300 : 0.015201051719486713
Loss at batch 310 : 0.0125957066193223
Loss at batch 320 : 0.023385684937238693
Loss at batch 330 : 0.01772998459637165
Loss at batch 340 : 0.013359489850699902
Loss at batch 350 : 0.015147189609706402
Loss at batch 360 : 0.011889800429344177
Loss at batch 370 : 0.01438393909484148
epoch27 finished!
Loss at batch 10 : 0.011648011393845081
Loss at batch 20 : 0.01954243890941143
Loss at batch 30 : 0.009003289975225925
Loss at batch 40 : 0.008581595495343208
Loss at batch 50 : 0.016057752072811127
Loss at batch 60 : 0.01111561618745327
Loss at batch 70 : 0.013448391109704971
Loss at batch 80 : 0.016265323385596275
Loss at batch 90 : 0.029165523126721382
Loss at batch 100 : 0.013817514292895794
Loss at batch 110 : 0.016664642840623856
Loss at batch 120 : 0.01856837421655655
Loss at batch 130 : 0.009993228130042553
Loss at batch 140 : 0.016992229968309402
Loss at batch 150 : 0.008876108564436436
Loss at batch 160 : 0.013285399414598942
Loss at batch 170 : 0.016053810715675354
Loss at batch 180 : 0.013273443095386028
Loss at batch 190 : 0.0092899389564991
Loss at batch 200 : 0.009529921226203442
Loss at batch 210 : 0.01735481061041355
Loss at batch 220 : 0.010021894238889217
Loss at batch 230 : 0.017221953719854355
Loss at batch 240 : 0.01554709579795599
Loss at batch 250 : 0.02154834382236004
Loss at batch 260 : 0.007242534775286913
Loss at batch 270 : 0.02248258888721466
Loss at batch 280 : 0.012130827642977238
Loss at batch 290 : 0.014401889406144619
Loss at batch 300 : 0.016789250075817108
Loss at batch 310 : 0.02391255833208561
Loss at batch 320 : 0.013955590315163136
Loss at batch 330 : 0.011445355601608753
Loss at batch 340 : 0.011870237067341805
Loss at batch 350 : 0.02644222415983677
Loss at batch 360 : 0.023366060107946396
Loss at batch 370 : 0.018750064074993134
epoch62 finished!
Loss at batch 10 : 0.010144219733774662
Loss at batch 20 : 0.011412221938371658
Loss at batch 30 : 0.010831098072230816
Loss at batch 40 : 0.01885170117020607
Loss at batch 50 : 0.008249371312558651
Loss at batch 60 : 0.02849714830517769
Loss at batch 70 : 0.0198381245136261
Loss at batch 80 : 0.017790015786886215
Loss at batch 90 : 0.00899843405932188
Loss at batch 100 : 0.02417675033211708
Loss at batch 110 : 0.008622012101113796
Loss at batch 120 : 0.015416296198964119
Loss at batch 130 : 0.012724180705845356
Loss at batch 140 : 0.01314928475767374
Loss at batch 150 : 0.012481373734772205
Loss at batch 160 : 0.01235111616551876
Loss at batch 170 : 0.023430608212947845
Loss at batch 180 : 0.011097533628344536
Loss at batch 190 : 0.024391712620854378
Loss at batch 200 : 0.015218365006148815
Loss at batch 210 : 0.0123361274600029
Loss at batch 220 : 0.010620777495205402
Loss at batch 230 : 0.0162897277623415
Loss at batch 240 : 0.012649023905396461
Loss at batch 250 : 0.009448840282857418
Loss at batch 260 : 0.013546597212553024
Loss at batch 270 : 0.012930967845022678
Loss at batch 280 : 0.010992991738021374
Loss at batch 290 : 0.023766912519931793
Loss at batch 300 : 0.00948792789131403
Loss at batch 310 : 0.020581422373652458
Loss at batch 320 : 0.0165061317384243
Loss at batch 330 : 0.011828349903225899
Loss at batch 340 : 0.011036847718060017
Loss at batch 350 : 0.015340792946517467
Loss at batch 360 : 0.02137572504580021
Loss at batch 370 : 0.01897296868264675
epoch27 finished!
Loss at batch 10 : 0.01786261796951294
Loss at batch 20 : 0.018612761050462723
Loss at batch 30 : 0.0072890897281467915
Loss at batch 40 : 0.026077015325427055
Loss at batch 50 : 0.013900097459554672
Loss at batch 60 : 0.010631198063492775
Loss at batch 70 : 0.024162856861948967
Loss at batch 80 : 0.018646560609340668
Loss at batch 90 : 0.013211752288043499
Loss at batch 100 : 0.010055500082671642
Loss at batch 110 : 0.008786412887275219
Loss at batch 120 : 0.018005648627877235
Loss at batch 130 : 0.015588873997330666
Loss at batch 140 : 0.016720380634069443
Loss at batch 150 : 0.02070961520075798
Loss at batch 160 : 0.01668611727654934
Loss at batch 170 : 0.01227356493473053
Loss at batch 180 : 0.017124822363257408
Loss at batch 190 : 0.011487403884530067
Loss at batch 200 : 0.012665479443967342
Loss at batch 210 : 0.012655938975512981
Loss at batch 220 : 0.006351857911795378
Loss at batch 230 : 0.008367977105081081
Loss at batch 240 : 0.00734809460118413
Loss at batch 250 : 0.018617207184433937
Loss at batch 260 : 0.007880382239818573
Loss at batch 270 : 0.01437288522720337
Loss at batch 280 : 0.01848587580025196
Loss at batch 290 : 0.021116754040122032
Loss at batch 300 : 0.012623544782400131
Loss at batch 310 : 0.007762599270790815
Loss at batch 320 : 0.015472536906599998
Loss at batch 330 : 0.01738843508064747
Loss at batch 340 : 0.020029891282320023
Loss at batch 350 : 0.010610678233206272
Loss at batch 360 : 0.02016144059598446
Loss at batch 370 : 0.008768557570874691
epoch63 finished!
Loss at batch 10 : 0.022958777844905853
Loss at batch 20 : 0.011573481373488903
Loss at batch 30 : 0.02567928284406662
Loss at batch 40 : 0.02042725868523121
Loss at batch 50 : 0.01112061645835638
Loss at batch 60 : 0.014921736903488636
Loss at batch 70 : 0.01466783694922924
Loss at batch 80 : 0.019099418073892593
Loss at batch 90 : 0.013097206130623817
Loss at batch 100 : 0.016354864463210106
Loss at batch 110 : 0.01609981432557106
Loss at batch 120 : 0.015328471548855305
Loss at batch 130 : 0.019370045512914658
Loss at batch 140 : 0.02244170382618904
Loss at batch 150 : 0.005736912600696087
Loss at batch 160 : 0.007632738910615444
Loss at batch 170 : 0.024837203323841095
Loss at batch 180 : 0.01777959242463112
Loss at batch 190 : 0.018146537244319916
Loss at batch 200 : 0.015213733538985252
Loss at batch 210 : 0.025092506781220436
Loss at batch 220 : 0.014039113186299801
Loss at batch 230 : 0.01959466189146042
Loss at batch 240 : 0.017450787127017975
Loss at batch 250 : 0.0130430543795228
Loss at batch 260 : 0.012459753081202507
Loss at batch 270 : 0.008778673596680164
Loss at batch 280 : 0.019463904201984406
Loss at batch 290 : 0.020571138709783554
Loss at batch 300 : 0.012814064510166645
Loss at batch 310 : 0.015942968428134918
Loss at batch 320 : 0.013075878843665123
Loss at batch 330 : 0.008697956800460815
Loss at batch 340 : 0.0131700299680233
Loss at batch 350 : 0.014773781411349773
Loss at batch 360 : 0.012624712660908699
Loss at batch 370 : 0.009376990608870983
epoch64 finished!
Loss at batch 10 : 0.0272815003991127
Loss at batch 20 : 0.020265622064471245
Loss at batch 30 : 0.015981178730726242
Loss at batch 40 : 0.026025747880339622
Loss at batch 50 : 0.00990048423409462
Loss at batch 60 : 0.022480923682451248
Loss at batch 70 : 0.023900708183646202
Loss at batch 80 : 0.014052181504666805
Loss at batch 90 : 0.012739722616970539
Loss at batch 100 : 0.012059464119374752
Loss at batch 110 : 0.01942785643041134
Loss at batch 120 : 0.018708093091845512
Loss at batch 130 : 0.017905723303556442
Loss at batch 140 : 0.009913288056850433
Loss at batch 150 : 0.02177424170076847
Loss at batch 160 : 0.013192412443459034
Loss at batch 170 : 0.014410339295864105
Loss at batch 180 : 0.014747530221939087
Loss at batch 190 : 0.015148451551795006
Loss at batch 200 : 0.01479871291667223
Loss at batch 210 : 0.025168856605887413
Loss at batch 220 : 0.019837934523820877
Loss at batch 230 : 0.012214959599077702
Loss at batch 240 : 0.017327195033431053
Loss at batch 250 : 0.029525185003876686
Loss at batch 260 : 0.020778466016054153
Loss at batch 270 : 0.03172359615564346
Loss at batch 280 : 0.012814372777938843
Loss at batch 290 : 0.01899082213640213
Loss at batch 300 : 0.020347412675619125
Loss at batch 310 : 0.012436743825674057
Loss at batch 320 : 0.013432462699711323
Loss at batch 330 : 0.016572704538702965
Loss at batch 340 : 0.014414248988032341
Loss at batch 350 : 0.011113129556179047
Loss at batch 360 : 0.017457537353038788
Loss at batch 370 : 0.01738162152469158
epoch28 finished!
Loss at batch 10 : 0.01088385283946991
Loss at batch 20 : 0.012752278707921505
Loss at batch 30 : 0.01345234178006649
Loss at batch 40 : 0.019712721928954124
Loss at batch 50 : 0.010544887743890285
Loss at batch 60 : 0.020842645317316055
Loss at batch 70 : 0.014277092181146145
Loss at batch 80 : 0.014187125489115715
Loss at batch 90 : 0.013049564324319363
Loss at batch 100 : 0.010610398836433887
Loss at batch 110 : 0.022308578714728355
Loss at batch 120 : 0.010572687722742558
Loss at batch 130 : 0.013306817039847374
Loss at batch 140 : 0.009972844272851944
Loss at batch 150 : 0.01717517524957657
Loss at batch 160 : 0.02543484978377819
Loss at batch 170 : 0.022000180557370186
Loss at batch 180 : 0.014417827129364014
Loss at batch 190 : 0.015869995579123497
Loss at batch 200 : 0.015311402268707752
Loss at batch 210 : 0.01986798644065857
Loss at batch 220 : 0.0236152783036232
Loss at batch 230 : 0.017124595120549202
Loss at batch 240 : 0.013599306344985962
Loss at batch 250 : 0.01123956311494112
Loss at batch 260 : 0.01460364367812872
Loss at batch 270 : 0.01630483753979206
Loss at batch 280 : 0.019691666588187218
Loss at batch 290 : 0.010542228817939758
Loss at batch 300 : 0.009676065295934677
Loss at batch 310 : 0.009312367998063564
Loss at batch 320 : 0.01757817342877388
Loss at batch 330 : 0.009671137668192387
Loss at batch 340 : 0.014127282425761223
Loss at batch 350 : 0.014940285123884678
Loss at batch 360 : 0.01879122480750084
Loss at batch 370 : 0.007567930966615677
epoch28 finished!
Loss at batch 10 : 0.009276926517486572
Loss at batch 20 : 0.01068919524550438
Loss at batch 30 : 0.014669982716441154
Loss at batch 40 : 0.01699627935886383
Loss at batch 50 : 0.010031967423856258
Loss at batch 60 : 0.00846909824758768
Loss at batch 70 : 0.009559668600559235
Loss at batch 80 : 0.016799321398139
Loss at batch 90 : 0.022535113617777824
Loss at batch 100 : 0.015437230467796326
Loss at batch 110 : 0.007484917063266039
Loss at batch 120 : 0.012439357116818428
Loss at batch 130 : 0.010561378672719002
Loss at batch 140 : 0.01830536313354969
Loss at batch 150 : 0.013452759943902493
Loss at batch 160 : 0.013644934631884098
Loss at batch 170 : 0.010337768122553825
Loss at batch 180 : 0.010488523170351982
Loss at batch 190 : 0.009770343080163002
Loss at batch 200 : 0.011290377005934715
Loss at batch 210 : 0.009130790829658508
Loss at batch 220 : 0.009058297611773014
Loss at batch 230 : 0.01188228465616703
Loss at batch 240 : 0.013933385722339153
Loss at batch 250 : 0.015540464781224728
Loss at batch 260 : 0.008646493777632713
Loss at batch 270 : 0.024881569668650627
Loss at batch 280 : 0.011259128339588642
Loss at batch 290 : 0.02876465395092964
Loss at batch 300 : 0.02074025757610798
Loss at batch 310 : 0.025756360962986946
Loss at batch 320 : 0.011125287972390652
Loss at batch 330 : 0.022577138617634773
Loss at batch 340 : 0.02169293910264969
Loss at batch 350 : 0.01290331594645977
Loss at batch 360 : 0.011055957525968552
Loss at batch 370 : 0.015492504462599754
epoch65 finished!
Loss at batch 10 : 0.011324887163937092
Loss at batch 20 : 0.010294645093381405
Loss at batch 30 : 0.021260062232613564
Loss at batch 40 : 0.015119334682822227
Loss at batch 50 : 0.01562565192580223
Loss at batch 60 : 0.014395381323993206
Loss at batch 70 : 0.01899952068924904
Loss at batch 80 : 0.014571315608918667
Loss at batch 90 : 0.01273762620985508
Loss at batch 100 : 0.009687913581728935
Loss at batch 110 : 0.009723992086946964
Loss at batch 120 : 0.011087802238762379
Loss at batch 130 : 0.009678618051111698
Loss at batch 140 : 0.018907221034169197
Loss at batch 150 : 0.009620128199458122
Loss at batch 160 : 0.014667538926005363
Loss at batch 170 : 0.022387197241187096
Loss at batch 180 : 0.011449324898421764
Loss at batch 190 : 0.0069997175596654415
Loss at batch 200 : 0.01153924223035574
Loss at batch 210 : 0.020060596987605095
Loss at batch 220 : 0.019497931003570557
Loss at batch 230 : 0.018366262316703796
Loss at batch 240 : 0.012111527845263481
Loss at batch 250 : 0.013039163313806057
Loss at batch 260 : 0.011071343906223774
Loss at batch 270 : 0.008755587041378021
Loss at batch 280 : 0.01148535031825304
Loss at batch 290 : 0.010640159249305725
Loss at batch 300 : 0.011204320937395096
Loss at batch 310 : 0.01499889325350523
Loss at batch 320 : 0.016537733376026154
Loss at batch 330 : 0.012262079864740372
Loss at batch 340 : 0.009290177375078201
Loss at batch 350 : 0.020281344652175903
Loss at batch 360 : 0.008478393778204918
Loss at batch 370 : 0.012132284231483936
epoch66 finished!
Loss at batch 10 : 0.012021317146718502
Loss at batch 20 : 0.015157164074480534
Loss at batch 30 : 0.010093051008880138
Loss at batch 40 : 0.014836571179330349
Loss at batch 50 : 0.008546832017600536
Loss at batch 60 : 0.01283958088606596
Loss at batch 70 : 0.009442716836929321
Loss at batch 80 : 0.014227153733372688
Loss at batch 90 : 0.016510725021362305
Loss at batch 100 : 0.023761410266160965
Loss at batch 110 : 0.018212085589766502
Loss at batch 120 : 0.011550072580575943
Loss at batch 130 : 0.019580388441681862
Loss at batch 140 : 0.028922073543071747
Loss at batch 150 : 0.02375619299709797
Loss at batch 160 : 0.015991579741239548
Loss at batch 170 : 0.020873676985502243
Loss at batch 180 : 0.01785822957754135
Loss at batch 190 : 0.02260158583521843
Loss at batch 200 : 0.025440655648708344
Loss at batch 210 : 0.018250877037644386
Loss at batch 220 : 0.012373184785246849
Loss at batch 230 : 0.012463505379855633
Loss at batch 240 : 0.018504124134778976
Loss at batch 250 : 0.020754192024469376
Loss at batch 260 : 0.017253903672099113
Loss at batch 270 : 0.01770673878490925
Loss at batch 280 : 0.023241359740495682
Loss at batch 290 : 0.02015162631869316
Loss at batch 300 : 0.01236091647297144
Loss at batch 310 : 0.015874546021223068
Loss at batch 320 : 0.013607428409159184
Loss at batch 330 : 0.020063521340489388
Loss at batch 340 : 0.014063565991818905
Loss at batch 350 : 0.02213546633720398
Loss at batch 360 : 0.011219522915780544
Loss at batch 370 : 0.01148387510329485
epoch29 finished!
Loss at batch 10 : 0.01930774748325348
Loss at batch 20 : 0.015547451563179493
Loss at batch 30 : 0.015994446352124214
Loss at batch 40 : 0.017582407221198082
Loss at batch 50 : 0.014365077018737793
Loss at batch 60 : 0.012613076716661453
Loss at batch 70 : 0.01703920029103756
Loss at batch 80 : 0.010625847615301609
Loss at batch 90 : 0.0123079102486372
Loss at batch 100 : 0.009731571190059185
Loss at batch 110 : 0.020633485168218613
Loss at batch 120 : 0.012172813527286053
Loss at batch 130 : 0.01442705001682043
Loss at batch 140 : 0.01063498668372631
Loss at batch 150 : 0.022125137969851494
Loss at batch 160 : 0.017883772030472755
Loss at batch 170 : 0.014265480451285839
Loss at batch 180 : 0.017470981925725937
Loss at batch 190 : 0.015927791595458984
Loss at batch 200 : 0.01666439138352871
Loss at batch 210 : 0.011319205164909363
Loss at batch 220 : 0.012083246372640133
Loss at batch 230 : 0.011746765114367008
Loss at batch 240 : 0.01808331348001957
Loss at batch 250 : 0.011100253090262413
Loss at batch 260 : 0.01266862265765667
Loss at batch 270 : 0.017273759469389915
Loss at batch 280 : 0.010836129076778889
Loss at batch 290 : 0.009785733185708523
Loss at batch 300 : 0.02305697463452816
Loss at batch 310 : 0.019563939422369003
Loss at batch 320 : 0.01652820035815239
Loss at batch 330 : 0.016386892646551132
Loss at batch 340 : 0.006994383409619331
Loss at batch 350 : 0.01906874217092991
Loss at batch 360 : 0.016761483624577522
Loss at batch 370 : 0.011922142468392849
epoch29 finished!
Loss at batch 10 : 0.017417578026652336
Loss at batch 20 : 0.02078387886285782
Loss at batch 30 : 0.017157822847366333
Loss at batch 40 : 0.01286956388503313
Loss at batch 50 : 0.010351607576012611
Loss at batch 60 : 0.013564935885369778
Loss at batch 70 : 0.01650284230709076
Loss at batch 80 : 0.007872487418353558
Loss at batch 90 : 0.014198812656104565
Loss at batch 100 : 0.01858917437493801
Loss at batch 110 : 0.009642860852181911
Loss at batch 120 : 0.013292461633682251
Loss at batch 130 : 0.010069694370031357
Loss at batch 140 : 0.011413058266043663
Loss at batch 150 : 0.01636653020977974
Loss at batch 160 : 0.00966592412441969
Loss at batch 170 : 0.017455900087952614
Loss at batch 180 : 0.013782139867544174
Loss at batch 190 : 0.015249823220074177
Loss at batch 200 : 0.013633020222187042
Loss at batch 210 : 0.011565914377570152
Loss at batch 220 : 0.019297899678349495
Loss at batch 230 : 0.022428924217820168
Loss at batch 240 : 0.013584977947175503
Loss at batch 250 : 0.01731046475470066
Loss at batch 260 : 0.013151130639016628
Loss at batch 270 : 0.015113302506506443
Loss at batch 280 : 0.009155738167464733
Loss at batch 290 : 0.01748719811439514
Loss at batch 300 : 0.008949285373091698
Loss at batch 310 : 0.01412297785282135
Loss at batch 320 : 0.011523660272359848
Loss at batch 330 : 0.033126216381788254
Loss at batch 340 : 0.015154387801885605
Loss at batch 350 : 0.011651949025690556
Loss at batch 360 : 0.009937762282788754
Loss at batch 370 : 0.03126980736851692
epoch67 finished!
Loss at batch 10 : 0.014289632439613342
Loss at batch 20 : 0.01212356612086296
Loss at batch 30 : 0.014319517649710178
Loss at batch 40 : 0.01909177377820015
Loss at batch 50 : 0.013840192928910255
Loss at batch 60 : 0.01535181887447834
Loss at batch 70 : 0.023546569049358368
Loss at batch 80 : 0.02464824914932251
Loss at batch 90 : 0.015324542298913002
Loss at batch 100 : 0.011751010082662106
Loss at batch 110 : 0.015431218780577183
Loss at batch 120 : 0.014129080809652805
Loss at batch 130 : 0.009459637105464935
Loss at batch 140 : 0.024080628529191017
Loss at batch 150 : 0.02252703532576561
Loss at batch 160 : 0.010723627172410488
Loss at batch 170 : 0.02102109231054783
Loss at batch 180 : 0.008164522238075733
Loss at batch 190 : 0.024941911920905113
Loss at batch 200 : 0.015659848228096962
Loss at batch 210 : 0.010913766920566559
Loss at batch 220 : 0.019082853570580482
Loss at batch 230 : 0.012419949285686016
Loss at batch 240 : 0.01915857195854187
Loss at batch 250 : 0.01764264889061451
Loss at batch 260 : 0.01914650946855545
Loss at batch 270 : 0.01635446399450302
Loss at batch 280 : 0.01042398251593113
Loss at batch 290 : 0.016295459121465683
Loss at batch 300 : 0.007665950804948807
Loss at batch 310 : 0.011481852270662785
Loss at batch 320 : 0.017636701464653015
Loss at batch 330 : 0.008506386540830135
Loss at batch 340 : 0.01355178002268076
Loss at batch 350 : 0.018242567777633667
Loss at batch 360 : 0.009969414211809635
Loss at batch 370 : 0.016948580741882324
epoch68 finished!
Loss at batch 10 : 0.0086915772408247
Loss at batch 20 : 0.020542437210679054
Loss at batch 30 : 0.01200324110686779
Loss at batch 40 : 0.012572715990245342
Loss at batch 50 : 0.011197461746633053
Loss at batch 60 : 0.013879622332751751
Loss at batch 70 : 0.023317553102970123
Loss at batch 80 : 0.020873790606856346
Loss at batch 90 : 0.011658317409455776
Loss at batch 100 : 0.015479620546102524
Loss at batch 110 : 0.012521385215222836
Loss at batch 120 : 0.013431674800813198
Loss at batch 130 : 0.018811779096722603
Loss at batch 140 : 0.015721846371889114
Loss at batch 150 : 0.011903112754225731
Loss at batch 160 : 0.008440263569355011
Loss at batch 170 : 0.019443329423666
Loss at batch 180 : 0.011658607050776482
Loss at batch 190 : 0.014941181987524033
Loss at batch 200 : 0.020285824313759804
Loss at batch 210 : 0.009955071844160557
Loss at batch 220 : 0.02401461824774742
Loss at batch 230 : 0.01151692308485508
Loss at batch 240 : 0.007740365341305733
Loss at batch 250 : 0.021860014647245407
Loss at batch 260 : 0.018135061487555504
Loss at batch 270 : 0.01403499860316515
Loss at batch 280 : 0.01916682906448841
Loss at batch 290 : 0.011296368204057217
Loss at batch 300 : 0.014057341031730175
Loss at batch 310 : 0.01198175922036171
Loss at batch 320 : 0.01725855842232704
Loss at batch 330 : 0.013901690021157265
Loss at batch 340 : 0.010699081234633923
Loss at batch 350 : 0.014063830487430096
Loss at batch 360 : 0.021322261542081833
Loss at batch 370 : 0.01287475973367691
epoch30 finished!
Loss at batch 10 : 0.008795591071248055
Loss at batch 20 : 0.010796618647873402
Loss at batch 30 : 0.012876641936600208
Loss at batch 40 : 0.010950312949717045
Loss at batch 50 : 0.014718540944159031
Loss at batch 60 : 0.016846610233187675
Loss at batch 70 : 0.009768759831786156
Loss at batch 80 : 0.016403961926698685
Loss at batch 90 : 0.008747450076043606
Loss at batch 100 : 0.024869004264473915
Loss at batch 110 : 0.013532489538192749
Loss at batch 120 : 0.018212033435702324
Loss at batch 130 : 0.011262785643339157
Loss at batch 140 : 0.01967802084982395
Loss at batch 150 : 0.0149472551420331
Loss at batch 160 : 0.01095488015562296
Loss at batch 170 : 0.014666314236819744
Loss at batch 180 : 0.01362620573490858
Loss at batch 190 : 0.018694113940000534
Loss at batch 200 : 0.015721457079052925
Loss at batch 210 : 0.011716415174305439
Loss at batch 220 : 0.015153646469116211
Loss at batch 230 : 0.01703454740345478
Loss at batch 240 : 0.019525334239006042
Loss at batch 250 : 0.017298413440585136
Loss at batch 260 : 0.008477402850985527
Loss at batch 270 : 0.007961488328874111
Loss at batch 280 : 0.009324680082499981
Loss at batch 290 : 0.01727946288883686
Loss at batch 300 : 0.018028512597084045
Loss at batch 310 : 0.01236905250698328
Loss at batch 320 : 0.024024078622460365
Loss at batch 330 : 0.011871744878590107
Loss at batch 340 : 0.024188455194234848
Loss at batch 350 : 0.008417756296694279
Loss at batch 360 : 0.01847454532980919
Loss at batch 370 : 0.014447671361267567
epoch30 finished!
Loss at batch 10 : 0.013433422893285751
Loss at batch 20 : 0.022581839933991432
Loss at batch 30 : 0.016076698899269104
Loss at batch 40 : 0.009494595229625702
Loss at batch 50 : 0.017975956201553345
Loss at batch 60 : 0.01330476999282837
Loss at batch 70 : 0.008206910453736782
Loss at batch 80 : 0.014184476807713509
Loss at batch 90 : 0.010322922840714455
Loss at batch 100 : 0.020239461213350296
Loss at batch 110 : 0.011633814312517643
Loss at batch 120 : 0.012504998594522476
Loss at batch 130 : 0.016267534345388412
Loss at batch 140 : 0.02398352138698101
Loss at batch 150 : 0.025347888469696045
Loss at batch 160 : 0.01517709530889988
Loss at batch 170 : 0.006739656440913677
Loss at batch 180 : 0.017211951315402985
Loss at batch 190 : 0.023930221796035767
Loss at batch 200 : 0.01518501527607441
Loss at batch 210 : 0.03036816231906414
Loss at batch 220 : 0.015267339535057545
Loss at batch 230 : 0.01042128074914217
Loss at batch 240 : 0.023219143971800804
Loss at batch 250 : 0.012623323127627373
Loss at batch 260 : 0.018386078998446465
Loss at batch 270 : 0.015008969232439995
Loss at batch 280 : 0.0160564836114645
Loss at batch 290 : 0.008611587807536125
Loss at batch 300 : 0.01411179918795824
Loss at batch 310 : 0.01482207328081131
Loss at batch 320 : 0.017413968220353127
Loss at batch 330 : 0.017618989571928978
Loss at batch 340 : 0.023114191368222237
Loss at batch 350 : 0.01564135029911995
Loss at batch 360 : 0.01129526924341917
Loss at batch 370 : 0.009929507039487362
epoch69 finished!
Loss at batch 10 : 0.027023501694202423
Loss at batch 20 : 0.019015369936823845
Loss at batch 30 : 0.012432124465703964
Loss at batch 40 : 0.024314826354384422
Loss at batch 50 : 0.0238755214959383
Loss at batch 60 : 0.006870588753372431
Loss at batch 70 : 0.009977688081562519
Loss at batch 80 : 0.01604481041431427
Loss at batch 90 : 0.010087910108268261
Loss at batch 100 : 0.017261162400245667
Loss at batch 110 : 0.016831258311867714
Loss at batch 120 : 0.011485718190670013
Loss at batch 130 : 0.023912327364087105
Loss at batch 140 : 0.013125131838023663
Loss at batch 150 : 0.00805316586047411
Loss at batch 160 : 0.02130310982465744
Loss at batch 170 : 0.018107784911990166
Loss at batch 180 : 0.009365096688270569
Loss at batch 190 : 0.015294412150979042
Loss at batch 200 : 0.012293370440602303
Loss at batch 210 : 0.01566927507519722
Loss at batch 220 : 0.017962295562028885
Loss at batch 230 : 0.015048714354634285
Loss at batch 240 : 0.010929713025689125
Loss at batch 250 : 0.016341974958777428
Loss at batch 260 : 0.02217032015323639
Loss at batch 270 : 0.01622254028916359
Loss at batch 280 : 0.016203613951802254
Loss at batch 290 : 0.013246939517557621
Loss at batch 300 : 0.016398770734667778
Loss at batch 310 : 0.015120835043489933
Loss at batch 320 : 0.028947992250323296
Loss at batch 330 : 0.01840958185493946
Loss at batch 340 : 0.01156763918697834
Loss at batch 350 : 0.009577902965247631
Loss at batch 360 : 0.022556932643055916
Loss at batch 370 : 0.013919389806687832
epoch70 finished!
Loss at batch 10 : 0.00913152750581503
Loss at batch 20 : 0.008139035664498806
Loss at batch 30 : 0.03139623999595642
Loss at batch 40 : 0.015537364408373833
Loss at batch 50 : 0.012347305193543434
Loss at batch 60 : 0.007860406301915646
Loss at batch 70 : 0.01707453839480877
Loss at batch 80 : 0.013700704090297222
Loss at batch 90 : 0.016971075907349586
Loss at batch 100 : 0.017980631440877914
Loss at batch 110 : 0.02014276571571827
Loss at batch 120 : 0.01517568901181221
Loss at batch 130 : 0.015096647664904594
Loss at batch 140 : 0.012419586069881916
Loss at batch 150 : 0.016310568898916245
Loss at batch 160 : 0.01791505143046379
Loss at batch 170 : 0.010562937706708908
Loss at batch 180 : 0.018459197133779526
Loss at batch 190 : 0.01580333337187767
Loss at batch 200 : 0.021074211224913597
Loss at batch 210 : 0.009639383293688297
Loss at batch 220 : 0.01296828594058752
Loss at batch 230 : 0.009376698173582554
Loss at batch 240 : 0.019997313618659973
Loss at batch 250 : 0.01158558577299118
Loss at batch 260 : 0.011092291213572025
Loss at batch 270 : 0.011538987047970295
Loss at batch 280 : 0.019623158499598503
Loss at batch 290 : 0.019046513363718987
Loss at batch 300 : 0.012608202174305916
Loss at batch 310 : 0.025734834372997284
Loss at batch 320 : 0.01523369736969471
Loss at batch 330 : 0.017488103359937668
Loss at batch 340 : 0.0203328188508749
Loss at batch 350 : 0.018603971228003502
Loss at batch 360 : 0.012161117047071457
Loss at batch 370 : 0.01942061446607113
epoch31 finished!
Loss at batch 10 : 0.012737967073917389
Loss at batch 20 : 0.013054098933935165
Loss at batch 30 : 0.01479283906519413
Loss at batch 40 : 0.012791200540959835
Loss at batch 50 : 0.013526282273232937
Loss at batch 60 : 0.011296197772026062
Loss at batch 70 : 0.026810117065906525
Loss at batch 80 : 0.019197413697838783
Loss at batch 90 : 0.015218578279018402
Loss at batch 100 : 0.012300374917685986
Loss at batch 110 : 0.008704342879354954
Loss at batch 120 : 0.01966315694153309
Loss at batch 130 : 0.019386377185583115
Loss at batch 140 : 0.01981605403125286
Loss at batch 150 : 0.007562377955764532
Loss at batch 160 : 0.015417479909956455
Loss at batch 170 : 0.022534459829330444
Loss at batch 180 : 0.006933973636478186
Loss at batch 190 : 0.011147766374051571
Loss at batch 200 : 0.02058536559343338
Loss at batch 210 : 0.01626822166144848
Loss at batch 220 : 0.023252148181200027
Loss at batch 230 : 0.008521349169313908
Loss at batch 240 : 0.023529523983597755
Loss at batch 250 : 0.010251966305077076
Loss at batch 260 : 0.009552907198667526
Loss at batch 270 : 0.010776911862194538
Loss at batch 280 : 0.011525995098054409
Loss at batch 290 : 0.021197833120822906
Loss at batch 300 : 0.022465011104941368
Loss at batch 310 : 0.015186576172709465
Loss at batch 320 : 0.018584631383419037
Loss at batch 330 : 0.016624338924884796
Loss at batch 340 : 0.01873600482940674
Loss at batch 350 : 0.01683598756790161
Loss at batch 360 : 0.011457939632236958
Loss at batch 370 : 0.012538287788629532
epoch31 finished!
Loss at batch 10 : 0.011323689483106136
Loss at batch 20 : 0.02047744393348694
Loss at batch 30 : 0.007199875544756651
Loss at batch 40 : 0.014555316418409348
Loss at batch 50 : 0.013829250819981098
Loss at batch 60 : 0.0116658890619874
Loss at batch 70 : 0.01601700484752655
Loss at batch 80 : 0.008812039159238338
Loss at batch 90 : 0.012444180436432362
Loss at batch 100 : 0.006302745081484318
Loss at batch 110 : 0.011050143279135227
Loss at batch 120 : 0.008115804754197598
Loss at batch 130 : 0.014621910639107227
Loss at batch 140 : 0.010119604878127575
Loss at batch 150 : 0.008470299653708935
Loss at batch 160 : 0.0196477510035038
Loss at batch 170 : 0.014346858486533165
Loss at batch 180 : 0.009420552290976048
Loss at batch 190 : 0.01942664571106434
Loss at batch 200 : 0.01946752518415451
Loss at batch 210 : 0.012924036011099815
Loss at batch 220 : 0.0104690445587039
Loss at batch 230 : 0.02229217067360878
Loss at batch 240 : 0.017133453860878944
Loss at batch 250 : 0.008208239451050758
Loss at batch 260 : 0.010230022482573986
Loss at batch 270 : 0.011602627113461494
Loss at batch 280 : 0.007908758707344532
Loss at batch 290 : 0.00936927367001772
Loss at batch 300 : 0.024608392268419266
Loss at batch 310 : 0.014464205130934715
Loss at batch 320 : 0.00995770562440157
Loss at batch 330 : 0.011423119343817234
Loss at batch 340 : 0.020481763407588005
Loss at batch 350 : 0.015127570368349552
Loss at batch 360 : 0.023697275668382645
Loss at batch 370 : 0.017440350726246834
epoch71 finished!
Loss at batch 10 : 0.009660555981099606
Loss at batch 20 : 0.021029319614171982
Loss at batch 30 : 0.022454118356108665
Loss at batch 40 : 0.012296153232455254
Loss at batch 50 : 0.00938089843839407
Loss at batch 60 : 0.005668280180543661
Loss at batch 70 : 0.009310449473559856
Loss at batch 80 : 0.015610668808221817
Loss at batch 90 : 0.015777450054883957
Loss at batch 100 : 0.011244823224842548
Loss at batch 110 : 0.021128946915268898
Loss at batch 120 : 0.02062522992491722
Loss at batch 130 : 0.00931999646127224
Loss at batch 140 : 0.01633242331445217
Loss at batch 150 : 0.011605729348957539
Loss at batch 160 : 0.017399027943611145
Loss at batch 170 : 0.01699364371597767
Loss at batch 180 : 0.011309043504297733
Loss at batch 190 : 0.018229860812425613
Loss at batch 200 : 0.011845412664115429
Loss at batch 210 : 0.012078127823770046
Loss at batch 220 : 0.00867161899805069
Loss at batch 230 : 0.018682830035686493
Loss at batch 240 : 0.012000279501080513
Loss at batch 250 : 0.020808305591344833
Loss at batch 260 : 0.012580378912389278
Loss at batch 270 : 0.0157687459141016
Loss at batch 280 : 0.01030512060970068
Loss at batch 290 : 0.018056483939290047
Loss at batch 300 : 0.011803173460066319
Loss at batch 310 : 0.02376212365925312
Loss at batch 320 : 0.01427328959107399
Loss at batch 330 : 0.011577212251722813
Loss at batch 340 : 0.01841883361339569
Loss at batch 350 : 0.01545319426804781
Loss at batch 360 : 0.018079092726111412
Loss at batch 370 : 0.016631580889225006
epoch72 finished!
Loss at batch 10 : 0.020512420684099197
Loss at batch 20 : 0.018031857907772064
Loss at batch 30 : 0.013762900605797768
Loss at batch 40 : 0.009304847568273544
Loss at batch 50 : 0.02028365433216095
Loss at batch 60 : 0.009012773633003235
Loss at batch 70 : 0.010728131048381329
Loss at batch 80 : 0.008634528145194054
Loss at batch 90 : 0.013057018630206585
Loss at batch 100 : 0.009149494580924511
Loss at batch 110 : 0.02616678550839424
Loss at batch 120 : 0.01949041336774826
Loss at batch 130 : 0.02428724803030491
Loss at batch 140 : 0.011533476412296295
Loss at batch 150 : 0.014863794669508934
Loss at batch 160 : 0.01658778265118599
Loss at batch 170 : 0.01286938413977623
Loss at batch 180 : 0.011869460344314575
Loss at batch 190 : 0.009848782792687416
Loss at batch 200 : 0.011767785996198654
Loss at batch 210 : 0.030886497348546982
Loss at batch 220 : 0.028838833793997765
Loss at batch 230 : 0.02028239704668522
Loss at batch 240 : 0.01871187798678875
Loss at batch 250 : 0.015657853335142136
Loss at batch 260 : 0.015071936883032322
Loss at batch 270 : 0.016155876219272614
Loss at batch 280 : 0.02327778749167919
Loss at batch 290 : 0.019596178084611893
Loss at batch 300 : 0.01036712247878313
Loss at batch 310 : 0.018715931102633476
Loss at batch 320 : 0.01876581832766533
Loss at batch 330 : 0.016367442905902863
Loss at batch 340 : 0.021094391122460365
Loss at batch 350 : 0.01697893626987934
Loss at batch 360 : 0.016076643019914627
Loss at batch 370 : 0.014984363690018654
epoch32 finished!
Loss at batch 10 : 0.012861491180956364
Loss at batch 20 : 0.014172369614243507
Loss at batch 30 : 0.011286228895187378
Loss at batch 40 : 0.016694432124495506
Loss at batch 50 : 0.015091273002326488
Loss at batch 60 : 0.009456568397581577
Loss at batch 70 : 0.015950970351696014
Loss at batch 80 : 0.016628727316856384
Loss at batch 90 : 0.025850601494312286
Loss at batch 100 : 0.015041585080325603
Loss at batch 110 : 0.018030809238553047
Loss at batch 120 : 0.032278113067150116
Loss at batch 130 : 0.01985851675271988
Loss at batch 140 : 0.012444118037819862
Loss at batch 150 : 0.023915791884064674
Loss at batch 160 : 0.013959205709397793
Loss at batch 170 : 0.010828242637217045
Loss at batch 180 : 0.020808329805731773
Loss at batch 190 : 0.011166956275701523
Loss at batch 200 : 0.011332697235047817
Loss at batch 210 : 0.012024860829114914
Loss at batch 220 : 0.008045253343880177
Loss at batch 230 : 0.01106072124093771
Loss at batch 240 : 0.012930674478411674
Loss at batch 250 : 0.010318564251065254
Loss at batch 260 : 0.018643587827682495
Loss at batch 270 : 0.01302365679293871
Loss at batch 280 : 0.015588502399623394
Loss at batch 290 : 0.013438009656965733
Loss at batch 300 : 0.014776993542909622
Loss at batch 310 : 0.011920151300728321
Loss at batch 320 : 0.013124318793416023
Loss at batch 330 : 0.011843410320580006
Loss at batch 340 : 0.011160117574036121
Loss at batch 350 : 0.016444720327854156
Loss at batch 360 : 0.011352959088981152
Loss at batch 370 : 0.024548277258872986
epoch32 finished!
Loss at batch 10 : 0.011850619688630104
Loss at batch 20 : 0.024520844221115112
Loss at batch 30 : 0.009592074900865555
Loss at batch 40 : 0.01319638080894947
Loss at batch 50 : 0.01735958829522133
Loss at batch 60 : 0.021619316190481186
Loss at batch 70 : 0.022403188049793243
Loss at batch 80 : 0.02418074756860733
Loss at batch 90 : 0.01700134016573429
Loss at batch 100 : 0.012074127793312073
Loss at batch 110 : 0.011634244583547115
Loss at batch 120 : 0.01079629361629486
Loss at batch 130 : 0.013904637657105923
Loss at batch 140 : 0.020340465009212494
Loss at batch 150 : 0.012151755392551422
Loss at batch 160 : 0.015057375654578209
Loss at batch 170 : 0.01532273180782795
Loss at batch 180 : 0.01067908201366663
Loss at batch 190 : 0.010667109861969948
Loss at batch 200 : 0.01019364409148693
Loss at batch 210 : 0.020448438823223114
Loss at batch 220 : 0.015517493709921837
Loss at batch 230 : 0.009876037016510963
Loss at batch 240 : 0.013193226419389248
Loss at batch 250 : 0.010303128510713577
Loss at batch 260 : 0.0130021832883358
Loss at batch 270 : 0.009253446944057941
Loss at batch 280 : 0.01748337782919407
Loss at batch 290 : 0.021258026361465454
Loss at batch 300 : 0.010689500719308853
Loss at batch 310 : 0.006669174879789352
Loss at batch 320 : 0.011599909514188766
Loss at batch 330 : 0.021161125972867012
Loss at batch 340 : 0.01511617936193943
Loss at batch 350 : 0.019403988495469093
Loss at batch 360 : 0.011154287494719028
Loss at batch 370 : 0.01416278537362814
epoch73 finished!
Loss at batch 10 : 0.013845592737197876
Loss at batch 20 : 0.00985743198543787
Loss at batch 30 : 0.017961032688617706
Loss at batch 40 : 0.020000318065285683
Loss at batch 50 : 0.01029766071587801
Loss at batch 60 : 0.009305151179432869
Loss at batch 70 : 0.013775692321360111
Loss at batch 80 : 0.00727858766913414
Loss at batch 90 : 0.023244226351380348
Loss at batch 100 : 0.017850343137979507
Loss at batch 110 : 0.015510234981775284
Loss at batch 120 : 0.01537547167390585
Loss at batch 130 : 0.014023075811564922
Loss at batch 140 : 0.00992028322070837
Loss at batch 150 : 0.011857079342007637
Loss at batch 160 : 0.018081214278936386
Loss at batch 170 : 0.013730905950069427
Loss at batch 180 : 0.023180853575468063
Loss at batch 190 : 0.012783241458237171
Loss at batch 200 : 0.012625854462385178
Loss at batch 210 : 0.009294604882597923
Loss at batch 220 : 0.01887497864663601
Loss at batch 230 : 0.011769012548029423
Loss at batch 240 : 0.011847718618810177
Loss at batch 250 : 0.012417251244187355
Loss at batch 260 : 0.015406789258122444
Loss at batch 270 : 0.018861792981624603
Loss at batch 280 : 0.017209405079483986
Loss at batch 290 : 0.008108670823276043
Loss at batch 300 : 0.008841942995786667
Loss at batch 310 : 0.014764178544282913
Loss at batch 320 : 0.01932242512702942
Loss at batch 330 : 0.015620595775544643
Loss at batch 340 : 0.017335673794150352
Loss at batch 350 : 0.028912274166941643
Loss at batch 360 : 0.009882458485662937
Loss at batch 370 : 0.0229191891849041
epoch74 finished!

[2024-04-25 00:13:40.888980] Avg_PSNR: 19.48668055720754 dB, Avg_SSIM: 0.8651431625196001
[2024-04-25 00:13:40.932410] test start with snapshots1/DehazeNet_epoch1.pth
[2024-04-25 00:14:14.867777] test end with snapshots1/DehazeNet_epoch1.pth
[2024-04-25 00:16:01.129422] Avg_PSNR: 18.908516602524116 dB, Avg_SSIM: 0.8678599540780445
[2024-04-25 00:16:01.177757] test start with snapshots1/DehazeNet_epoch84.pth
[2024-04-25 00:16:35.112465] test end with snapshots1/DehazeNet_epoch84.pth
[2024-04-25 00:18:21.004684] Avg_PSNR: 19.380750023456923 dB, Avg_SSIM: 0.865801526741902
[2024-04-25 00:18:21.049971] test start with snapshots1/DehazeNet_epoch31.pth
[2024-04-25 00:18:54.578674] test end with snapshots1/DehazeNet_epoch31.pth
[2024-04-25 00:20:39.976624] Avg_PSNR: 19.118014941979933 dB, Avg_SSIM: 0.874705636295012
[2024-04-25 00:20:40.020407] test start with snapshots1/DehazeNet_epoch15.pth
[2024-04-25 00:21:13.507703] test end with snapshots1/DehazeNet_epoch15.pth
[2024-04-25 00:23:00.062987] Avg_PSNR: 19.029911500574364 dB, Avg_SSIM: 0.8709952613624024
[2024-04-25 00:23:00.102610] test start with snapshots1/DehazeNet_epoch47.pth
[2024-04-25 00:23:34.086963] test end with snapshots1/DehazeNet_epoch47.pth
[2024-04-25 00:25:20.028190] Avg_PSNR: 19.1010283669988 dB, Avg_SSIM: 0.8661581151450273
[2024-04-25 00:25:20.071661] test start with snapshots1/DehazeNet_epoch49.pth
[2024-04-25 00:25:53.870271] test end with snapshots1/DehazeNet_epoch49.pth
[2024-04-25 00:27:39.996105] Avg_PSNR: 19.19060945669835 dB, Avg_SSIM: 0.8683343040188826
[2024-04-25 00:27:40.037541] test start with snapshots1/DehazeNet_epoch68.pth
[2024-04-25 00:28:13.719918] test end with snapshots1/DehazeNet_epoch68.pth
[2024-04-25 00:29:59.316842] Avg_PSNR: 19.25936127180507 dB, Avg_SSIM: 0.8591071536282032
[2024-04-25 00:29:59.357999] test start with snapshots1/DehazeNet_epoch5.pth
[2024-04-25 00:30:33.021066] test end with snapshots1/DehazeNet_epoch5.pth
[2024-04-25 00:32:18.731083] Avg_PSNR: 18.80084311047298 dB, Avg_SSIM: 0.8703244507121473
[2024-04-25 00:32:18.774675] test start with snapshots1/DehazeNet_epoch156.pth
[2024-04-25 00:32:53.084853] test end with snapshots1/DehazeNet_epoch156.pth
[2024-04-25 00:34:42.591318] Avg_PSNR: 19.425503474260353 dB, Avg_SSIM: 0.8657679239847724
[2024-04-25 00:34:42.635724] test start with snapshots1/DehazeNet_epoch50.pth
[2024-04-25 00:35:16.202775] test end with snapshots1/DehazeNet_epoch50.pth
[2024-04-25 00:37:05.777609] Avg_PSNR: 19.02411816527116 dB, Avg_SSIM: 0.8618429906566274
[2024-04-25 00:37:05.828836] test start with snapshots1/DehazeNet_epoch128.pth
[2024-04-25 00:37:39.760191] test end with snapshots1/DehazeNet_epoch128.pth
[2024-04-25 00:39:26.271397] Avg_PSNR: 19.286818014967373 dB, Avg_SSIM: 0.8597674808431521
[2024-04-25 00:39:26.326193] test start with snapshots1/DehazeNet_epoch76.pth
[2024-04-25 00:40:00.482213] test end with snapshots1/DehazeNet_epoch76.pth
[2024-04-25 00:41:46.540567] Avg_PSNR: 19.26329918758187 dB, Avg_SSIM: 0.8613397477919797
[2024-04-25 00:41:46.583836] test start with snapshots1/DehazeNet_epoch88.pth
[2024-04-25 00:42:20.507794] test end with snapshots1/DehazeNet_epoch88.pth
[2024-04-25 00:44:06.627367] Avg_PSNR: 19.332815731793268 dB, Avg_SSIM: 0.8639193716158207
[2024-04-25 00:44:06.669294] test start with snapshots1/DehazeNet_epoch105.pth
[2024-04-25 00:44:40.563554] test end with snapshots1/DehazeNet_epoch105.pth
[2024-04-25 00:46:26.779461] Avg_PSNR: 19.38467201150036 dB, Avg_SSIM: 0.8664272841699711
[2024-04-25 00:46:26.824490] test start with snapshots1/DehazeNet_epoch120.pth
[2024-04-25 00:47:00.800634] test end with snapshots1/DehazeNet_epoch120.pth
[2024-04-25 00:48:47.019343] Avg_PSNR: 19.483700354811994 dB, Avg_SSIM: 0.8653584397193881
[2024-04-25 00:48:47.056585] test start with snapshots1/DehazeNet_epoch2.pth
[2024-04-25 00:49:20.794747] test end with snapshots1/DehazeNet_epoch2.pth
[2024-04-25 00:51:06.506102] Avg_PSNR: 18.96471503751561 dB, Avg_SSIM: 0.8667647187769475
[2024-04-25 00:51:06.552809] test start with snapshots1/DehazeNet_epoch17.pth
[2024-04-25 00:51:40.177487] test end with snapshots1/DehazeNet_epoch17.pth
[2024-04-25 00:53:25.675313] Avg_PSNR: 19.151201940074174 dB, Avg_SSIM: 0.8754146436953187
[2024-04-25 00:53:25.720772] test start with snapshots1/DehazeNet_epoch14.pth
[2024-04-25 00:53:59.028683] test end with snapshots1/DehazeNet_epoch14.pth
[2024-04-25 00:55:44.458862] Avg_PSNR: 19.16249072357676 dB, Avg_SSIM: 0.8744131580395421
[2024-04-25 00:55:44.500987] test start with snapshots1/DehazeNet_epoch34.pth
[2024-04-25 00:56:18.216935] test end with snapshots1/DehazeNet_epoch34.pth
[2024-04-25 00:58:04.182377] Avg_PSNR: 18.963094598259897 dB, Avg_SSIM: 0.8741769401849512
[2024-04-25 00:58:04.225746] test start with snapshots1/DehazeNet_epoch20.pth
[2024-04-25 00:58:38.189471] test end with snapshots1/DehazeNet_epoch20.pth
[2024-04-25 01:00:24.351795] Avg_PSNR: 19.127847753202577 dB, Avg_SSIM: 0.8753562620139749
[2024-04-25 01:00:24.405542] test start with snapshots1/DehazeNet_epoch38.pth
[2024-04-25 01:00:58.287152] test end with snapshots1/DehazeNet_epoch38.pth
[2024-04-25 01:02:43.599993] Avg_PSNR: 18.96350333454065 dB, Avg_SSIM: 0.8695031864946797
[2024-04-25 01:02:43.649444] test start with snapshots1/DehazeNet_epoch176.pth
[2024-04-25 01:03:17.325870] test end with snapshots1/DehazeNet_epoch176.pth
[2024-04-25 01:05:03.456446] Avg_PSNR: 19.313882177288832 dB, Avg_SSIM: 0.8612323264270585
[2024-04-25 01:05:03.504591] test start with snapshots1/DehazeNet_epoch118.pth
[2024-04-25 01:05:37.319566] test end with snapshots1/DehazeNet_epoch118.pth
[2024-04-25 01:07:23.765795] Avg_PSNR: 19.118184212221724 dB, Avg_SSIM: 0.8561553962047462
[2024-04-25 01:07:23.809562] test start with snapshots1/DehazeNet_epoch110.pth
[2024-04-25 01:07:57.770957] test end with snapshots1/DehazeNet_epoch110.pth
[2024-04-25 01:09:43.988299] Avg_PSNR: 19.409557597433462 dB, Avg_SSIM: 0.8635817376356407
[2024-04-25 01:09:44.032596] test start with snapshots1/DehazeNet_epoch134.pth
[2024-04-25 01:10:17.680708] test end with snapshots1/DehazeNet_epoch134.pth
[2024-04-25 01:12:04.084381] Avg_PSNR: 19.258978659218446 dB, Avg_SSIM: 0.864425110729328
[2024-04-25 01:12:04.125701] test start with snapshots1/DehazeNet_epoch143.pth
[2024-04-25 01:12:37.614981] test end with snapshots1/DehazeNet_epoch143.pth
[2024-04-25 01:14:23.788755] Avg_PSNR: 19.46664641003161 dB, Avg_SSIM: 0.8679315945111794
[2024-04-25 01:14:23.832193] test start with snapshots1/DehazeNet_epoch114.pth
[2024-04-25 01:14:57.946940] test end with snapshots1/DehazeNet_epoch114.pth
[2024-04-25 01:16:44.089403] Avg_PSNR: 19.531332173139745 dB, Avg_SSIM: 0.8651758518996776
[2024-04-25 01:16:44.133340] test start with snapshots1/DehazeNet_epoch145.pth
[2024-04-25 01:17:18.645939] test end with snapshots1/DehazeNet_epoch145.pth
[2024-04-25 01:19:04.969306] Avg_PSNR: 19.360763508148874 dB, Avg_SSIM: 0.8690010716806863
[2024-04-25 01:19:05.011506] test start with snapshots1/DehazeNet_epoch121.pth
[2024-04-25 01:19:38.810474] test end with snapshots1/DehazeNet_epoch121.pth
[2024-04-25 01:21:24.663814] Avg_PSNR: 19.564259634878194 dB, Avg_SSIM: 0.8673165186363189
[2024-04-25 01:21:24.705390] test start with snapshots1/DehazeNet_epoch67.pth
[2024-04-25 01:21:58.254284] test end with snapshots1/DehazeNet_epoch67.pth
[2024-04-25 01:23:43.797263] Avg_PSNR: 19.3473641272007 dB, Avg_SSIM: 0.8651734126038987
[2024-04-25 01:23:43.839808] test start with snapshots1/DehazeNet_epoch65.pth
[2024-04-25 01:24:17.523443] test end with snapshots1/DehazeNet_epoch65.pth
[2024-04-25 01:26:03.259468] Avg_PSNR: 19.351462540021764 dB, Avg_SSIM: 0.8643955044908906
[2024-04-25 01:26:03.300095] test start with snapshots1/DehazeNet_epoch4.pth
[2024-04-25 01:26:36.951628] test end with snapshots1/DehazeNet_epoch4.pth
[2024-04-25 01:28:22.849887] Avg_PSNR: 19.019643069311115 dB, Avg_SSIM: 0.8727432563511875
[2024-04-25 01:28:22.895395] test start with snapshots1/DehazeNet_epoch64.pth
[2024-04-25 01:28:56.661545] test end with snapshots1/DehazeNet_epoch64.pth
[2024-04-25 01:30:42.481883] Avg_PSNR: 19.15386422479735 dB, Avg_SSIM: 0.8572524700209233
[2024-04-25 01:30:42.522923] test start with snapshots1/DehazeNet_epoch93.pthLoss at batch 10 : 0.008960378356277943
Loss at batch 20 : 0.012947678565979004
Loss at batch 30 : 0.005463010165840387
Loss at batch 40 : 0.010474593378603458
Loss at batch 50 : 0.012062162160873413
Loss at batch 60 : 0.006742950528860092
Loss at batch 70 : 0.011449335142970085
Loss at batch 80 : 0.017866898328065872
Loss at batch 90 : 0.016296029090881348
Loss at batch 100 : 0.009642699733376503
Loss at batch 110 : 0.012911593541502953
Loss at batch 120 : 0.009334378875792027
Loss at batch 130 : 0.010503511875867844
Loss at batch 140 : 0.014503935351967812
Loss at batch 150 : 0.008670694194734097
Loss at batch 160 : 0.01204671896994114
Loss at batch 170 : 0.008470369502902031
Loss at batch 180 : 0.014460128732025623
Loss at batch 190 : 0.014353989623486996
Loss at batch 200 : 0.01686248555779457
Loss at batch 210 : 0.018953336402773857
Loss at batch 220 : 0.021884648129343987
Loss at batch 230 : 0.012036764994263649
Loss at batch 240 : 0.013220366090536118
Loss at batch 250 : 0.01052606850862503
Loss at batch 260 : 0.014609962701797485
Loss at batch 270 : 0.014942106790840626
Loss at batch 280 : 0.01775341108441353
Loss at batch 290 : 0.010759423486888409
Loss at batch 300 : 0.016154766082763672
Loss at batch 310 : 0.009108918718993664
Loss at batch 320 : 0.008794095367193222
Loss at batch 330 : 0.012015540152788162
Loss at batch 340 : 0.01885702647268772
Loss at batch 350 : 0.023593928664922714
Loss at batch 360 : 0.012416739948093891
Loss at batch 370 : 0.01138647086918354
epoch33 finished!
Loss at batch 10 : 0.018511412665247917
Loss at batch 20 : 0.018882624804973602
Loss at batch 30 : 0.016913769766688347
Loss at batch 40 : 0.01962205022573471
Loss at batch 50 : 0.018885189667344093
Loss at batch 60 : 0.00893180351704359
Loss at batch 70 : 0.014123107306659222
Loss at batch 80 : 0.016818569973111153
Loss at batch 90 : 0.014007355086505413
Loss at batch 100 : 0.0095335328951478
Loss at batch 110 : 0.01960131525993347
Loss at batch 120 : 0.016084788367152214
Loss at batch 130 : 0.020592354238033295
Loss at batch 140 : 0.013872126117348671
Loss at batch 150 : 0.0156577005982399
Loss at batch 160 : 0.009645713493227959
Loss at batch 170 : 0.020607203245162964
Loss at batch 180 : 0.016174569725990295
Loss at batch 190 : 0.009652973152697086
Loss at batch 200 : 0.014305640012025833
Loss at batch 210 : 0.014480190351605415
Loss at batch 220 : 0.014986278489232063
Loss at batch 230 : 0.02576480805873871
Loss at batch 240 : 0.009731551632285118
Loss at batch 250 : 0.016067974269390106
Loss at batch 260 : 0.02337089739739895
Loss at batch 270 : 0.012583132833242416
Loss at batch 280 : 0.02335822768509388
Loss at batch 290 : 0.027875913307070732
Loss at batch 300 : 0.012816019356250763
Loss at batch 310 : 0.024527791887521744
Loss at batch 320 : 0.026685252785682678
Loss at batch 330 : 0.01513116154819727
Loss at batch 340 : 0.013262622058391571
Loss at batch 350 : 0.007079831790179014
Loss at batch 360 : 0.011769115924835205
Loss at batch 370 : 0.019017336890101433
epoch33 finished!
Loss at batch 10 : 0.019072197377681732
Loss at batch 20 : 0.012539061717689037
Loss at batch 30 : 0.010692419484257698
Loss at batch 40 : 0.01700269617140293
Loss at batch 50 : 0.013637621887028217
Loss at batch 60 : 0.015515686012804508
Loss at batch 70 : 0.010849248617887497
Loss at batch 80 : 0.01008700579404831
Loss at batch 90 : 0.03424553573131561
Loss at batch 100 : 0.008763653226196766
Loss at batch 110 : 0.010632181540131569
Loss at batch 120 : 0.015527070499956608
Loss at batch 130 : 0.0179144199937582
Loss at batch 140 : 0.013867282308638096
Loss at batch 150 : 0.011557224206626415
Loss at batch 160 : 0.010877793654799461
Loss at batch 170 : 0.01401333138346672
Loss at batch 180 : 0.012813057750463486
Loss at batch 190 : 0.007213291712105274
Loss at batch 200 : 0.007658102549612522
Loss at batch 210 : 0.0077572595328092575
Loss at batch 220 : 0.013027015142142773
Loss at batch 230 : 0.009741928428411484
Loss at batch 240 : 0.01855524443089962
Loss at batch 250 : 0.007511804345995188
Loss at batch 260 : 0.02183585800230503
Loss at batch 270 : 0.014132186770439148
Loss at batch 280 : 0.018032938241958618
Loss at batch 290 : 0.009452495723962784
Loss at batch 300 : 0.007677944377064705
Loss at batch 310 : 0.015417942777276039
Loss at batch 320 : 0.02654544822871685
Loss at batch 330 : 0.010387588292360306
Loss at batch 340 : 0.019007617607712746
Loss at batch 350 : 0.010181306861341
Loss at batch 360 : 0.014094606973230839
Loss at batch 370 : 0.02015809714794159
epoch75 finished!
Loss at batch 10 : 0.008942026644945145
Loss at batch 20 : 0.017955860123038292
Loss at batch 30 : 0.013280779123306274
Loss at batch 40 : 0.01564977876842022
Loss at batch 50 : 0.010930347256362438
Loss at batch 60 : 0.017093297094106674
Loss at batch 70 : 0.02719808928668499
Loss at batch 80 : 0.017463495954871178
Loss at batch 90 : 0.016795367002487183
Loss at batch 100 : 0.009012674912810326
Loss at batch 110 : 0.022899340838193893
Loss at batch 120 : 0.012766151688992977
Loss at batch 130 : 0.011625967919826508
Loss at batch 140 : 0.012578188441693783
Loss at batch 150 : 0.015766367316246033
Loss at batch 160 : 0.015569641254842281
Loss at batch 170 : 0.012777063995599747
Loss at batch 180 : 0.011572151444852352
Loss at batch 190 : 0.01076969038695097
Loss at batch 200 : 0.014267846941947937
Loss at batch 210 : 0.01939694583415985
Loss at batch 220 : 0.01065826416015625
Loss at batch 230 : 0.0174824520945549
Loss at batch 240 : 0.012649551033973694
Loss at batch 250 : 0.024691568687558174
Loss at batch 260 : 0.017151309177279472
Loss at batch 270 : 0.009935892187058926
Loss at batch 280 : 0.01671636290848255
Loss at batch 290 : 0.019091526046395302
Loss at batch 300 : 0.014736933633685112
Loss at batch 310 : 0.012706244364380836
Loss at batch 320 : 0.018903758376836777
Loss at batch 330 : 0.01598673313856125
Loss at batch 340 : 0.014247138984501362
Loss at batch 350 : 0.009677764028310776
Loss at batch 360 : 0.018176985904574394
Loss at batch 370 : 0.01413318607956171
epoch76 finished!
Loss at batch 10 : 0.009076123125851154
Loss at batch 20 : 0.02060319297015667
Loss at batch 30 : 0.011505641974508762
Loss at batch 40 : 0.015340839512646198
Loss at batch 50 : 0.0226157084107399
Loss at batch 60 : 0.013643626123666763
Loss at batch 70 : 0.012164012528955936
Loss at batch 80 : 0.011000283993780613
Loss at batch 90 : 0.009406518191099167
Loss at batch 100 : 0.007668217644095421
Loss at batch 110 : 0.020608672872185707
Loss at batch 120 : 0.012205112725496292
Loss at batch 130 : 0.012553906999528408
Loss at batch 140 : 0.013873284682631493
Loss at batch 150 : 0.014240731485188007
Loss at batch 160 : 0.022567201405763626
Loss at batch 170 : 0.007766036782413721
Loss at batch 180 : 0.022226957604289055
Loss at batch 190 : 0.01351211965084076
Loss at batch 200 : 0.01291898638010025
Loss at batch 210 : 0.03189023584127426
Loss at batch 220 : 0.023829026147723198
Loss at batch 230 : 0.011899730190634727
Loss at batch 240 : 0.02501954510807991
Loss at batch 250 : 0.020131465047597885
Loss at batch 260 : 0.0216322410851717
Loss at batch 270 : 0.01593828573822975
Loss at batch 280 : 0.012692147865891457
Loss at batch 290 : 0.009672620333731174
Loss at batch 300 : 0.006901338696479797
Loss at batch 310 : 0.01028610672801733
Loss at batch 320 : 0.012232894077897072
Loss at batch 330 : 0.013730784878134727
Loss at batch 340 : 0.018111977726221085
Loss at batch 350 : 0.015488232485949993
Loss at batch 360 : 0.012851940467953682
Loss at batch 370 : 0.013933828100562096
epoch34 finished!
Loss at batch 10 : 0.015040241181850433
Loss at batch 20 : 0.013366945087909698
Loss at batch 30 : 0.01151270791888237
Loss at batch 40 : 0.006983165163546801
Loss at batch 50 : 0.007074923254549503
Loss at batch 60 : 0.010964835062623024
Loss at batch 70 : 0.020388513803482056
Loss at batch 80 : 0.018532097339630127
Loss at batch 90 : 0.009094880893826485
Loss at batch 100 : 0.014758470468223095
Loss at batch 110 : 0.016291160136461258
Loss at batch 120 : 0.006621466018259525
Loss at batch 130 : 0.012856312096118927
Loss at batch 140 : 0.010514790192246437
Loss at batch 150 : 0.008659371174871922
Loss at batch 160 : 0.008458270691335201
Loss at batch 170 : 0.016766801476478577
Loss at batch 180 : 0.01301978062838316
Loss at batch 190 : 0.011460340581834316
Loss at batch 200 : 0.014560572803020477
Loss at batch 210 : 0.012286294251680374
Loss at batch 220 : 0.014625957235693932
Loss at batch 230 : 0.02260422892868519
Loss at batch 240 : 0.017228756099939346
Loss at batch 250 : 0.01697631925344467
Loss at batch 260 : 0.015566720627248287
Loss at batch 270 : 0.010692086070775986
Loss at batch 280 : 0.008468005806207657
Loss at batch 290 : 0.009138361550867558
Loss at batch 300 : 0.010047472082078457
Loss at batch 310 : 0.013952186331152916
Loss at batch 320 : 0.015479562804102898
Loss at batch 330 : 0.0174051932990551
Loss at batch 340 : 0.012850829400122166
Loss at batch 350 : 0.01962371915578842
Loss at batch 360 : 0.01414747815579176
Loss at batch 370 : 0.015709487721323967
epoch77 finished!
Loss at batch 10 : 0.00983731634914875
Loss at batch 20 : 0.008822956122457981
Loss at batch 30 : 0.014056055806577206
Loss at batch 40 : 0.011916643008589745
Loss at batch 50 : 0.01614120788872242
Loss at batch 60 : 0.008476321585476398
Loss at batch 70 : 0.01320137269794941
Loss at batch 80 : 0.016014961525797844
Loss at batch 90 : 0.02166643552482128
Loss at batch 100 : 0.016377730295062065
Loss at batch 110 : 0.015033726580440998
Loss at batch 120 : 0.014661193825304508
Loss at batch 130 : 0.016241127625107765
Loss at batch 140 : 0.019573703408241272
Loss at batch 150 : 0.017427032813429832
Loss at batch 160 : 0.01700735092163086
Loss at batch 170 : 0.010607397183775902
Loss at batch 180 : 0.013855207711458206
Loss at batch 190 : 0.012235619127750397
Loss at batch 200 : 0.03201626241207123
Loss at batch 210 : 0.026919184252619743
Loss at batch 220 : 0.01204614993184805
Loss at batch 230 : 0.015371392481029034
Loss at batch 240 : 0.02300078608095646
Loss at batch 250 : 0.017093613743782043
Loss at batch 260 : 0.016287505626678467
Loss at batch 270 : 0.012155313976109028
Loss at batch 280 : 0.016241153702139854
Loss at batch 290 : 0.021022340282797813
Loss at batch 300 : 0.007024076301604509
Loss at batch 310 : 0.013207846321165562
Loss at batch 320 : 0.010658059269189835
Loss at batch 330 : 0.010602706111967564
Loss at batch 340 : 0.012414220720529556
Loss at batch 350 : 0.014940664172172546
Loss at batch 360 : 0.01299187820404768
Loss at batch 370 : 0.010835916735231876
epoch34 finished!
Loss at batch 10 : 0.014544878154993057
Loss at batch 20 : 0.01347456406801939
Loss at batch 30 : 0.020537694916129112
Loss at batch 40 : 0.016340922564268112
Loss at batch 50 : 0.01325956080108881
Loss at batch 60 : 0.015136411413550377
Loss at batch 70 : 0.014524223282933235
Loss at batch 80 : 0.018946753814816475
Loss at batch 90 : 0.020142683759331703
Loss at batch 100 : 0.014032097533345222
Loss at batch 110 : 0.01003762986510992
Loss at batch 120 : 0.010739048942923546
Loss at batch 130 : 0.009370318613946438
Loss at batch 140 : 0.0072962637059390545
Loss at batch 150 : 0.01044664066284895
Loss at batch 160 : 0.017123231664299965
Loss at batch 170 : 0.011063605546951294
Loss at batch 180 : 0.013505925424396992
Loss at batch 190 : 0.01833447441458702
Loss at batch 200 : 0.008933698758482933
Loss at batch 210 : 0.008567508310079575
Loss at batch 220 : 0.02033497579395771
Loss at batch 230 : 0.015515964478254318
Loss at batch 240 : 0.02969798631966114
Loss at batch 250 : 0.009241057559847832
Loss at batch 260 : 0.011032323352992535
Loss at batch 270 : 0.015791716054081917
Loss at batch 280 : 0.01684955507516861
Loss at batch 290 : 0.013907684944570065
Loss at batch 300 : 0.013243773020803928
Loss at batch 310 : 0.026373550295829773
Loss at batch 320 : 0.012351743876934052
Loss at batch 330 : 0.01891935057938099
Loss at batch 340 : 0.008288396522402763
Loss at batch 350 : 0.018405640497803688
Loss at batch 360 : 0.013831174932420254
Loss at batch 370 : 0.011326688341796398
epoch78 finished!
Loss at batch 10 : 0.010900427587330341
Loss at batch 20 : 0.007404896430671215
Loss at batch 30 : 0.009550509974360466
Loss at batch 40 : 0.014561637304723263
Loss at batch 50 : 0.015166603960096836
Loss at batch 60 : 0.012209341861307621
Loss at batch 70 : 0.0198046937584877
Loss at batch 80 : 0.024723859503865242
Loss at batch 90 : 0.013126352801918983
Loss at batch 100 : 0.009484604932367802
Loss at batch 110 : 0.01600060425698757
Loss at batch 120 : 0.011442258022725582
Loss at batch 130 : 0.017278514802455902
Loss at batch 140 : 0.011845279484987259
Loss at batch 150 : 0.01668267697095871
Loss at batch 160 : 0.013825112953782082
Loss at batch 170 : 0.014852730557322502
Loss at batch 180 : 0.01926993764936924
Loss at batch 190 : 0.014862105250358582
Loss at batch 200 : 0.014904429204761982
Loss at batch 210 : 0.013765407726168633
Loss at batch 220 : 0.012925909832119942
Loss at batch 230 : 0.01197885349392891
Loss at batch 240 : 0.011792905628681183
Loss at batch 250 : 0.01075520645827055
Loss at batch 260 : 0.016234060749411583
Loss at batch 270 : 0.015061694197356701
Loss at batch 280 : 0.01400086097419262
Loss at batch 290 : 0.011241010390222073
Loss at batch 300 : 0.008722389116883278
Loss at batch 310 : 0.011186596006155014
Loss at batch 320 : 0.010675467550754547
Loss at batch 330 : 0.009980947710573673
Loss at batch 340 : 0.010308155789971352
Loss at batch 350 : 0.009651015512645245
Loss at batch 360 : 0.016830509528517723
Loss at batch 370 : 0.007715273182839155
epoch79 finished!
Loss at batch 10 : 0.0153099549934268
Loss at batch 20 : 0.013594123534858227
Loss at batch 30 : 0.013392106629908085
Loss at batch 40 : 0.013886628672480583
Loss at batch 50 : 0.012155236676335335
Loss at batch 60 : 0.01863676682114601
Loss at batch 70 : 0.02221834659576416
Loss at batch 80 : 0.010345198214054108
Loss at batch 90 : 0.011937149800360203
Loss at batch 100 : 0.008904275484383106
Loss at batch 110 : 0.012845983728766441
Loss at batch 120 : 0.01954367756843567
Loss at batch 130 : 0.009729158133268356
Loss at batch 140 : 0.021822823211550713
Loss at batch 150 : 0.015641961246728897
Loss at batch 160 : 0.020093655213713646
Loss at batch 170 : 0.0131453238427639
Loss at batch 180 : 0.024202818050980568
Loss at batch 190 : 0.013565391302108765
Loss at batch 200 : 0.014565563760697842
Loss at batch 210 : 0.024432608857750893
Loss at batch 220 : 0.01915653981268406
Loss at batch 230 : 0.012918565422296524
Loss at batch 240 : 0.013579810038208961
Loss at batch 250 : 0.011799571104347706
Loss at batch 260 : 0.008588805794715881
Loss at batch 270 : 0.015922291204333305
Loss at batch 280 : 0.020842978730797768
Loss at batch 290 : 0.012063730508089066
Loss at batch 300 : 0.013644925318658352
Loss at batch 310 : 0.010234810411930084
Loss at batch 320 : 0.011293867602944374
Loss at batch 330 : 0.005466210190206766
Loss at batch 340 : 0.03433097526431084
Loss at batch 350 : 0.007657990790903568
Loss at batch 360 : 0.01375575177371502
Loss at batch 370 : 0.010981814935803413
epoch35 finished!
Loss at batch 10 : 0.010808795690536499
Loss at batch 20 : 0.017539622262120247
Loss at batch 30 : 0.011460653506219387
Loss at batch 40 : 0.01577799767255783
Loss at batch 50 : 0.018071845173835754
Loss at batch 60 : 0.016203641891479492
Loss at batch 70 : 0.014848205260932446
Loss at batch 80 : 0.008601523004472256
Loss at batch 90 : 0.013571575284004211
Loss at batch 100 : 0.012908180244266987
Loss at batch 110 : 0.020619351416826248
Loss at batch 120 : 0.015852974727749825
Loss at batch 130 : 0.007871010340750217
Loss at batch 140 : 0.014117253944277763
Loss at batch 150 : 0.01988227665424347
Loss at batch 160 : 0.010298158973455429
Loss at batch 170 : 0.010540158487856388
Loss at batch 180 : 0.01990775763988495
Loss at batch 190 : 0.022071892395615578
Loss at batch 200 : 0.015330410562455654
Loss at batch 210 : 0.012163904495537281
Loss at batch 220 : 0.01746823824942112
Loss at batch 230 : 0.009247886948287487
Loss at batch 240 : 0.014440273866057396
Loss at batch 250 : 0.013997890055179596
Loss at batch 260 : 0.018172811716794968
Loss at batch 270 : 0.018125897273421288
Loss at batch 280 : 0.01850251480937004
Loss at batch 290 : 0.016199687495827675
Loss at batch 300 : 0.024470677599310875
Loss at batch 310 : 0.006814684718847275
Loss at batch 320 : 0.017823033034801483
Loss at batch 330 : 0.02036428637802601
Loss at batch 340 : 0.011488125659525394
Loss at batch 350 : 0.012871475890278816
Loss at batch 360 : 0.013482194393873215
Loss at batch 370 : 0.029048526659607887
epoch35 finished!
Loss at batch 10 : 0.012695943005383015
Loss at batch 20 : 0.0238746739923954
Loss at batch 30 : 0.008542567491531372
Loss at batch 40 : 0.009525176137685776
Loss at batch 50 : 0.010339460335671902
Loss at batch 60 : 0.008611832745373249
Loss at batch 70 : 0.00981139950454235
Loss at batch 80 : 0.01567385159432888
Loss at batch 90 : 0.007114720530807972
Loss at batch 100 : 0.00993286445736885
Loss at batch 110 : 0.015751464292407036
Loss at batch 120 : 0.01215172465890646
Loss at batch 130 : 0.010035374201834202
Loss at batch 140 : 0.014476001262664795
Loss at batch 150 : 0.020591916516423225
Loss at batch 160 : 0.018229162320494652
Loss at batch 170 : 0.021206622943282127
Loss at batch 180 : 0.016612302511930466
Loss at batch 190 : 0.0058458163402974606
Loss at batch 200 : 0.01776033639907837
Loss at batch 210 : 0.01832442916929722
Loss at batch 220 : 0.013815033249557018
Loss at batch 230 : 0.017192499712109566
Loss at batch 240 : 0.01816973276436329
Loss at batch 250 : 0.007989589124917984
Loss at batch 260 : 0.01039637066423893
Loss at batch 270 : 0.020148616284132004
Loss at batch 280 : 0.02210639975965023
Loss at batch 290 : 0.010768517851829529
Loss at batch 300 : 0.020475363358855247
Loss at batch 310 : 0.014030734077095985
Loss at batch 320 : 0.009813236072659492
Loss at batch 330 : 0.009977606125175953
Loss at batch 340 : 0.014878629706799984
Loss at batch 350 : 0.01176054123789072
Loss at batch 360 : 0.006878572050482035
Loss at batch 370 : 0.012809221632778645
epoch80 finished!
Loss at batch 10 : 0.019002003595232964
Loss at batch 20 : 0.011514303274452686
Loss at batch 30 : 0.011483383364975452
Loss at batch 40 : 0.009498127736151218
Loss at batch 50 : 0.021645940840244293
Loss at batch 60 : 0.0175417959690094
Loss at batch 70 : 0.022200705483555794
Loss at batch 80 : 0.017340037971735
Loss at batch 90 : 0.01303880475461483
Loss at batch 100 : 0.019110742956399918
Loss at batch 110 : 0.012750301510095596
Loss at batch 120 : 0.016142643988132477
Loss at batch 130 : 0.021958589553833008
Loss at batch 140 : 0.013676363974809647
Loss at batch 150 : 0.019314464181661606
Loss at batch 160 : 0.015883224084973335
Loss at batch 170 : 0.0181005597114563
Loss at batch 180 : 0.011329458095133305
Loss at batch 190 : 0.019037114456295967
Loss at batch 200 : 0.019524667412042618
Loss at batch 210 : 0.021956102922558784
Loss at batch 220 : 0.008995394222438335
Loss at batch 230 : 0.014213815331459045
Loss at batch 240 : 0.0153225501999259
Loss at batch 250 : 0.020472876727581024
Loss at batch 260 : 0.01478599663823843
Loss at batch 270 : 0.01038981694728136
Loss at batch 280 : 0.01767609268426895
Loss at batch 290 : 0.025633085519075394
Loss at batch 300 : 0.009349278174340725
Loss at batch 310 : 0.01131717674434185
Loss at batch 320 : 0.006821128539741039
Loss at batch 330 : 0.00783773697912693
Loss at batch 340 : 0.013850077986717224
Loss at batch 350 : 0.015550309792160988
Loss at batch 360 : 0.01245019119232893
Loss at batch 370 : 0.02241942659020424
epoch81 finished!
Loss at batch 10 : 0.01152570080012083
Loss at batch 20 : 0.011679843999445438
Loss at batch 30 : 0.013713513500988483
Loss at batch 40 : 0.014586885459721088
Loss at batch 50 : 0.015560896135866642
Loss at batch 60 : 0.018122276291251183
Loss at batch 70 : 0.02657666616141796
Loss at batch 80 : 0.029996385797858238
Loss at batch 90 : 0.012878184206783772
Loss at batch 100 : 0.014142180792987347
Loss at batch 110 : 0.01661843992769718
Loss at batch 120 : 0.021060816943645477
Loss at batch 130 : 0.029484206810593605
Loss at batch 140 : 0.010757789015769958
Loss at batch 150 : 0.02536451257765293
Loss at batch 160 : 0.009383156895637512
Loss at batch 170 : 0.013596217148005962
Loss at batch 180 : 0.006436603143811226
Loss at batch 190 : 0.012211520224809647
Loss at batch 200 : 0.028056789189577103
Loss at batch 210 : 0.015711698681116104
Loss at batch 220 : 0.011364403180778027
Loss at batch 230 : 0.014059476554393768
Loss at batch 240 : 0.01960107684135437
Loss at batch 250 : 0.02384662814438343
Loss at batch 260 : 0.012781455181539059
Loss at batch 270 : 0.011130527593195438
Loss at batch 280 : 0.00904859323054552
Loss at batch 290 : 0.017876772210001945
Loss at batch 300 : 0.020728841423988342
Loss at batch 310 : 0.012777616269886494
Loss at batch 320 : 0.011002764105796814
Loss at batch 330 : 0.008195511065423489
Loss at batch 340 : 0.023488985374569893
Loss at batch 350 : 0.010760979726910591
Loss at batch 360 : 0.010576517321169376
Loss at batch 370 : 0.011027970351278782
epoch36 finished!
Loss at batch 10 : 0.009831094183027744
Loss at batch 20 : 0.025317678228020668
Loss at batch 30 : 0.011421370320022106
Loss at batch 40 : 0.020443467423319817
Loss at batch 50 : 0.01432075072079897
Loss at batch 60 : 0.012489567510783672
Loss at batch 70 : 0.0055311815813183784
Loss at batch 80 : 0.00904204323887825
Loss at batch 90 : 0.011217325925827026
Loss at batch 100 : 0.008661208674311638
Loss at batch 110 : 0.01771562360227108
Loss at batch 120 : 0.011894009076058865
Loss at batch 130 : 0.012894818559288979
Loss at batch 140 : 0.01402719784528017
Loss at batch 150 : 0.012613904662430286
Loss at batch 160 : 0.014057640917599201
Loss at batch 170 : 0.011015050113201141
Loss at batch 180 : 0.0272838082164526
Loss at batch 190 : 0.009741049259901047
Loss at batch 200 : 0.008491343818604946
Loss at batch 210 : 0.012484601698815823
Loss at batch 220 : 0.01593531109392643
Loss at batch 230 : 0.010689932852983475
Loss at batch 240 : 0.024109840393066406
Loss at batch 250 : 0.01850411295890808
Loss at batch 260 : 0.014094770886003971
Loss at batch 270 : 0.023124869912862778
Loss at batch 280 : 0.01759972982108593
Loss at batch 290 : 0.01711929403245449
Loss at batch 300 : 0.013719766400754452
Loss at batch 310 : 0.008644397370517254
Loss at batch 320 : 0.01522569265216589
Loss at batch 330 : 0.011799074709415436
Loss at batch 340 : 0.01767837628722191
Loss at batch 350 : 0.014712639153003693
Loss at batch 360 : 0.007887160405516624
Loss at batch 370 : 0.009180411696434021
epoch36 finished!
Loss at batch 10 : 0.007464257534593344
Loss at batch 20 : 0.01310750376433134
Loss at batch 30 : 0.017298342660069466
Loss at batch 40 : 0.023860329762101173
Loss at batch 50 : 0.009773699566721916
Loss at batch 60 : 0.020684098824858665
Loss at batch 70 : 0.015004991553723812
Loss at batch 80 : 0.010485420934855938
Loss at batch 90 : 0.015219702385365963
Loss at batch 100 : 0.01196817122399807
Loss at batch 110 : 0.013454155065119267
Loss at batch 120 : 0.010656848549842834
Loss at batch 130 : 0.011776799336075783
Loss at batch 140 : 0.011722967959940434
Loss at batch 150 : 0.011190221644937992
Loss at batch 160 : 0.01065702922642231
Loss at batch 170 : 0.01680736243724823
Loss at batch 180 : 0.018599633127450943
Loss at batch 190 : 0.0075049190782010555
Loss at batch 200 : 0.011554197408258915
Loss at batch 210 : 0.007540992461144924
Loss at batch 220 : 0.017550837248563766
Loss at batch 230 : 0.012539390474557877
Loss at batch 240 : 0.017064493149518967
Loss at batch 250 : 0.01297056209295988
Loss at batch 260 : 0.0152841005474329
Loss at batch 270 : 0.007449829950928688
Loss at batch 280 : 0.0182267427444458
Loss at batch 290 : 0.008474207483232021
Loss at batch 300 : 0.008100599981844425
Loss at batch 310 : 0.02868076041340828
Loss at batch 320 : 0.010125096887350082
Loss at batch 330 : 0.014145556837320328
Loss at batch 340 : 0.011637832038104534
Loss at batch 350 : 0.008714941330254078
Loss at batch 360 : 0.011325632221996784
Loss at batch 370 : 0.00757937366142869
epoch82 finished!
Loss at batch 10 : 0.017083100974559784
Loss at batch 20 : 0.013421292416751385
Loss at batch 30 : 0.02712300606071949
Loss at batch 40 : 0.01688903570175171
Loss at batch 50 : 0.009814197197556496
Loss at batch 60 : 0.01942085660994053
Loss at batch 70 : 0.01404578797519207
Loss at batch 80 : 0.013112968765199184
Loss at batch 90 : 0.017643362283706665
Loss at batch 100 : 0.014851207844913006
Loss at batch 110 : 0.014108478091657162
Loss at batch 120 : 0.014547266066074371
Loss at batch 130 : 0.01575648784637451
Loss at batch 140 : 0.013301699422299862
Loss at batch 150 : 0.017852161079645157
Loss at batch 160 : 0.017654309049248695
Loss at batch 170 : 0.010251879692077637
Loss at batch 180 : 0.02407442405819893
Loss at batch 190 : 0.0206091720610857
Loss at batch 200 : 0.006508987862616777
Loss at batch 210 : 0.014167321845889091
Loss at batch 220 : 0.03008216992020607
Loss at batch 230 : 0.016499469056725502
Loss at batch 240 : 0.01494488026946783
Loss at batch 250 : 0.011822416447103024
Loss at batch 260 : 0.010862750932574272
Loss at batch 270 : 0.012730495072901249
Loss at batch 280 : 0.0187840573489666
Loss at batch 290 : 0.015435487031936646
Loss at batch 300 : 0.007322547025978565
Loss at batch 310 : 0.01567293517291546
Loss at batch 320 : 0.01243076752871275
Loss at batch 330 : 0.008548624813556671
Loss at batch 340 : 0.012239689938724041
Loss at batch 350 : 0.00843062438070774
Loss at batch 360 : 0.012516981922090054
Loss at batch 370 : 0.016088705509901047
epoch83 finished!
Loss at batch 10 : 0.010737781412899494
Loss at batch 20 : 0.01154334656894207
Loss at batch 30 : 0.016005204990506172
Loss at batch 40 : 0.02459622733294964
Loss at batch 50 : 0.020449167117476463
Loss at batch 60 : 0.01180300209671259
Loss at batch 70 : 0.010449018329381943
Loss at batch 80 : 0.015463693998754025
Loss at batch 90 : 0.012086635455489159
Loss at batch 100 : 0.021513616666197777
Loss at batch 110 : 0.01789429970085621
Loss at batch 120 : 0.017265742644667625
Loss at batch 130 : 0.013142409734427929
Loss at batch 140 : 0.01338912919163704
Loss at batch 150 : 0.011985437013208866
Loss at batch 160 : 0.012018077075481415
Loss at batch 170 : 0.01674494706094265
Loss at batch 180 : 0.015878068283200264
Loss at batch 190 : 0.027827462181448936
Loss at batch 200 : 0.012285993434488773
Loss at batch 210 : 0.009678577072918415
Loss at batch 220 : 0.014655070379376411
Loss at batch 230 : 0.015362636186182499
Loss at batch 240 : 0.013059062883257866
Loss at batch 250 : 0.01060501765459776
Loss at batch 260 : 0.01333068311214447
Loss at batch 270 : 0.017206158488988876
Loss at batch 280 : 0.009929751977324486
Loss at batch 290 : 0.012457330711185932
Loss at batch 300 : 0.019927572458982468
Loss at batch 310 : 0.007538989651948214
Loss at batch 320 : 0.013384988531470299
Loss at batch 330 : 0.021580366417765617
Loss at batch 340 : 0.019176658242940903
Loss at batch 350 : 0.018269438296556473
Loss at batch 360 : 0.01855604350566864
Loss at batch 370 : 0.011717692948877811
epoch37 finished!
Loss at batch 10 : 0.010264258831739426
Loss at batch 20 : 0.011299246922135353
Loss at batch 30 : 0.021864868700504303
Loss at batch 40 : 0.011335845105350018
Loss at batch 50 : 0.01758749596774578
Loss at batch 60 : 0.012991153635084629
Loss at batch 70 : 0.01830940693616867
Loss at batch 80 : 0.007409329991787672
Loss at batch 90 : 0.017285184934735298
Loss at batch 100 : 0.016234230250120163
Loss at batch 110 : 0.009549200534820557
Loss at batch 120 : 0.013153322972357273
Loss at batch 130 : 0.01309465803205967
Loss at batch 140 : 0.011286252178251743
Loss at batch 150 : 0.011506578885018826
Loss at batch 160 : 0.009300890378654003
Loss at batch 170 : 0.019808519631624222
Loss at batch 180 : 0.013251762837171555
Loss at batch 190 : 0.0175502710044384
Loss at batch 200 : 0.019885139539837837
Loss at batch 210 : 0.017154665663838387
Loss at batch 220 : 0.02580360881984234
Loss at batch 230 : 0.014295633882284164
Loss at batch 240 : 0.025737902149558067
Loss at batch 250 : 0.01840299926698208
Loss at batch 260 : 0.011006823740899563
Loss at batch 270 : 0.013881265185773373
Loss at batch 280 : 0.01593780890107155
Loss at batch 290 : 0.02094382792711258
Loss at batch 300 : 0.017754079774022102
Loss at batch 310 : 0.01834702491760254
Loss at batch 320 : 0.013815929181873798
Loss at batch 330 : 0.022456366568803787
Loss at batch 340 : 0.016867410391569138
Loss at batch 350 : 0.013403872027993202
Loss at batch 360 : 0.020807983353734016
Loss at batch 370 : 0.01181670930236578
epoch37 finished!
Loss at batch 10 : 0.01594819873571396
Loss at batch 20 : 0.01529501099139452
Loss at batch 30 : 0.017609501257538795
Loss at batch 40 : 0.018320804461836815
Loss at batch 50 : 0.016866687685251236
Loss at batch 60 : 0.008404020220041275
Loss at batch 70 : 0.011062436737120152
Loss at batch 80 : 0.010324811562895775
Loss at batch 90 : 0.010406510904431343
Loss at batch 100 : 0.016586434096097946
Loss at batch 110 : 0.023621292784810066
Loss at batch 120 : 0.016569435596466064
Loss at batch 130 : 0.01852363720536232
Loss at batch 140 : 0.007368286140263081
Loss at batch 150 : 0.011001930572092533
Loss at batch 160 : 0.016553455963730812
Loss at batch 170 : 0.013245856389403343
Loss at batch 180 : 0.010959682054817677
Loss at batch 190 : 0.00533301243558526
Loss at batch 200 : 0.019511913880705833
Loss at batch 210 : 0.012095685116946697
Loss at batch 220 : 0.011326279491186142
Loss at batch 230 : 0.009747937321662903
Loss at batch 240 : 0.0199916809797287
Loss at batch 250 : 0.018254585564136505
Loss at batch 260 : 0.012831340543925762
Loss at batch 270 : 0.013032120652496815
Loss at batch 280 : 0.009708311408758163
Loss at batch 290 : 0.013279472477734089
Loss at batch 300 : 0.01353595219552517
Loss at batch 310 : 0.01248947810381651
Loss at batch 320 : 0.01010826975107193
Loss at batch 330 : 0.009480115957558155
Loss at batch 340 : 0.012697269208729267
Loss at batch 350 : 0.009815572760999203
Loss at batch 360 : 0.008575784973800182
Loss at batch 370 : 0.009057576768100262
epoch84 finished!
Loss at batch 10 : 0.02330678328871727
Loss at batch 20 : 0.01743672415614128
Loss at batch 30 : 0.018816817551851273
Loss at batch 40 : 0.01817302405834198
Loss at batch 50 : 0.02505655772984028
Loss at batch 60 : 0.019835002720355988
Loss at batch 70 : 0.017042305320501328
Loss at batch 80 : 0.01622091792523861
Loss at batch 90 : 0.007827798835933208
Loss at batch 100 : 0.011361981742084026
Loss at batch 110 : 0.015427364967763424
Loss at batch 120 : 0.011465680785477161
Loss at batch 130 : 0.012726780027151108
Loss at batch 140 : 0.017893245443701744
Loss at batch 150 : 0.009677788242697716
Loss at batch 160 : 0.013626419939100742
Loss at batch 170 : 0.01933646760880947
Loss at batch 180 : 0.011293181218206882
Loss at batch 190 : 0.01390036940574646
Loss at batch 200 : 0.015316340140998363
Loss at batch 210 : 0.010344533249735832
Loss at batch 220 : 0.008396461606025696
Loss at batch 230 : 0.01069602556526661
Loss at batch 240 : 0.01491721160709858
Loss at batch 250 : 0.014278221875429153
Loss at batch 260 : 0.009519263170659542
Loss at batch 270 : 0.016990553587675095
Loss at batch 280 : 0.012292362749576569
Loss at batch 290 : 0.011930900625884533
Loss at batch 300 : 0.022564977407455444
Loss at batch 310 : 0.009932822547852993
Loss at batch 320 : 0.02039586566388607
Loss at batch 330 : 0.009609576314687729
Loss at batch 340 : 0.007292412221431732
Loss at batch 350 : 0.01734476163983345
Loss at batch 360 : 0.011960071511566639
Loss at batch 370 : 0.016632677987217903
epoch85 finished!
Loss at batch 10 : 0.03478037193417549
Loss at batch 20 : 0.023318735882639885
Loss at batch 30 : 0.013409608975052834
Loss at batch 40 : 0.017675401642918587
Loss at batch 50 : 0.017185965552926064
Loss at batch 60 : 0.021191338077187538
Loss at batch 70 : 0.010748040862381458
Loss at batch 80 : 0.014653229154646397
Loss at batch 90 : 0.015501809306442738
Loss at batch 100 : 0.01975221559405327
Loss at batch 110 : 0.009285815991461277
Loss at batch 120 : 0.013970879837870598
Loss at batch 130 : 0.01503896526992321
Loss at batch 140 : 0.027434365823864937
Loss at batch 150 : 0.01749410666525364
Loss at batch 160 : 0.02776370197534561
Loss at batch 170 : 0.012494276277720928
Loss at batch 180 : 0.012698709033429623
Loss at batch 190 : 0.009298248216509819
Loss at batch 200 : 0.012090151198208332
Loss at batch 210 : 0.014518536627292633
Loss at batch 220 : 0.011923686601221561
Loss at batch 230 : 0.010822071693837643
Loss at batch 240 : 0.015301855280995369
Loss at batch 250 : 0.012714401818811893
Loss at batch 260 : 0.012481405399739742
Loss at batch 270 : 0.01477723941206932
Loss at batch 280 : 0.017973527312278748
Loss at batch 290 : 0.014046856202185154
Loss at batch 300 : 0.010719905607402325
Loss at batch 310 : 0.027348846197128296
Loss at batch 320 : 0.015137617476284504
Loss at batch 330 : 0.017863836139440536
Loss at batch 340 : 0.011792827397584915
Loss at batch 350 : 0.01956382766366005
Loss at batch 360 : 0.02286900393664837
Loss at batch 370 : 0.012023579329252243
epoch38 finished!
Loss at batch 10 : 0.012566318735480309
Loss at batch 20 : 0.016095664352178574
Loss at batch 30 : 0.020964253693819046
Loss at batch 40 : 0.012634657323360443
Loss at batch 50 : 0.012632844038307667
Loss at batch 60 : 0.01653238944709301
Loss at batch 70 : 0.01187694538384676
Loss at batch 80 : 0.013657672330737114
Loss at batch 90 : 0.014149538241326809
Loss at batch 100 : 0.017332643270492554
Loss at batch 110 : 0.007557332515716553
Loss at batch 120 : 0.017912665382027626
Loss at batch 130 : 0.02076711505651474
Loss at batch 140 : 0.013235277496278286
Loss at batch 150 : 0.013703609816730022
Loss at batch 160 : 0.02425055205821991
Loss at batch 170 : 0.0160975381731987
Loss at batch 180 : 0.0136298518627882
Loss at batch 190 : 0.010481975972652435
Loss at batch 200 : 0.016900692135095596
Loss at batch 210 : 0.009778635576367378
Loss at batch 220 : 0.015308436006307602
Loss at batch 230 : 0.011584587395191193
Loss at batch 240 : 0.013774815015494823
Loss at batch 250 : 0.0069736819714307785
Loss at batch 260 : 0.010341876186430454
Loss at batch 270 : 0.013148980215191841
Loss at batch 280 : 0.011858567595481873
Loss at batch 290 : 0.01672952249646187
Loss at batch 300 : 0.01767744868993759
Loss at batch 310 : 0.01896410621702671
Loss at batch 320 : 0.009987616911530495
Loss at batch 330 : 0.012558193877339363
Loss at batch 340 : 0.020472267642617226
Loss at batch 350 : 0.010502783581614494
Loss at batch 360 : 0.010124211199581623
Loss at batch 370 : 0.009483559988439083
epoch38 finished!
Loss at batch 10 : 0.021632980555295944
Loss at batch 20 : 0.019683847203850746
Loss at batch 30 : 0.008748995140194893
Loss at batch 40 : 0.008994418196380138
Loss at batch 50 : 0.017672240734100342
Loss at batch 60 : 0.02305651642382145
Loss at batch 70 : 0.008722132071852684
Loss at batch 80 : 0.014402084983885288
Loss at batch 90 : 0.009740859270095825
Loss at batch 100 : 0.017635827884078026
Loss at batch 110 : 0.013176769949495792
Loss at batch 120 : 0.0242548156529665
Loss at batch 130 : 0.011194583959877491
Loss at batch 140 : 0.012057546526193619
Loss at batch 150 : 0.010734602808952332
Loss at batch 160 : 0.014567104168236256
Loss at batch 170 : 0.021666772663593292
Loss at batch 180 : 0.015974512323737144
Loss at batch 190 : 0.021746119484305382
Loss at batch 200 : 0.006273860577493906
Loss at batch 210 : 0.010200784541666508
Loss at batch 220 : 0.022181091830134392
Loss at batch 230 : 0.013779712840914726
Loss at batch 240 : 0.011925894767045975
Loss at batch 250 : 0.011400857008993626
Loss at batch 260 : 0.01576538383960724
Loss at batch 270 : 0.014521588571369648
Loss at batch 280 : 0.020204221829771996
Loss at batch 290 : 0.015471765771508217
Loss at batch 300 : 0.015705158933997154
Loss at batch 310 : 0.01343176793307066
Loss at batch 320 : 0.0218230951577425
Loss at batch 330 : 0.018110765144228935
Loss at batch 340 : 0.01107239630073309
Loss at batch 350 : 0.013842365704476833
Loss at batch 360 : 0.00913609005510807
Loss at batch 370 : 0.013795234262943268
epoch86 finished!
Loss at batch 10 : 0.013092005625367165
Loss at batch 20 : 0.013130011036992073
Loss at batch 30 : 0.008637028746306896
Loss at batch 40 : 0.014892270788550377
Loss at batch 50 : 0.015343645587563515
Loss at batch 60 : 0.014019372873008251
Loss at batch 70 : 0.021542908623814583
Loss at batch 80 : 0.022998640313744545
Loss at batch 90 : 0.016262926161289215
Loss at batch 100 : 0.012238729745149612
Loss at batch 110 : 0.01268017292022705
Loss at batch 120 : 0.010313503444194794
Loss at batch 130 : 0.020861824974417686
Loss at batch 140 : 0.014236101880669594
Loss at batch 150 : 0.01939604990184307
Loss at batch 160 : 0.009191981516778469
Loss at batch 170 : 0.01240251213312149
Loss at batch 180 : 0.02021879330277443
Loss at batch 190 : 0.00755965244024992
Loss at batch 200 : 0.01765742152929306
Loss at batch 210 : 0.017832690849900246
Loss at batch 220 : 0.0124627985060215
Loss at batch 230 : 0.011357061564922333
Loss at batch 240 : 0.015085030347108841
Loss at batch 250 : 0.012707007117569447
Loss at batch 260 : 0.013372743502259254
Loss at batch 270 : 0.018326368182897568
Loss at batch 280 : 0.010900674387812614
Loss at batch 290 : 0.015242132358253002
Loss at batch 300 : 0.02072899043560028
Loss at batch 310 : 0.008730504661798477
Loss at batch 320 : 0.008035074919462204
Loss at batch 330 : 0.009566436521708965
Loss at batch 340 : 0.022263802587985992
Loss at batch 350 : 0.015790589153766632
Loss at batch 360 : 0.010897510685026646
Loss at batch 370 : 0.013499011285603046
epoch87 finished!
Loss at batch 10 : 0.015085580758750439
Loss at batch 20 : 0.018409373238682747
Loss at batch 30 : 0.016041254624724388
Loss at batch 40 : 0.007700599264353514
Loss at batch 50 : 0.011651539243757725
Loss at batch 60 : 0.009484490379691124
Loss at batch 70 : 0.012874902226030827
Loss at batch 80 : 0.0212972704321146
Loss at batch 90 : 0.00841283705085516
Loss at batch 100 : 0.011666206642985344
Loss at batch 110 : 0.030340207740664482
Loss at batch 120 : 0.008626006543636322
Loss at batch 130 : 0.019188813865184784
Loss at batch 140 : 0.019962770864367485
Loss at batch 150 : 0.01518972683697939
Loss at batch 160 : 0.01843484491109848
Loss at batch 170 : 0.015486160293221474
Loss at batch 180 : 0.01621786504983902
Loss at batch 190 : 0.016879841685295105
Loss at batch 200 : 0.016906674951314926
Loss at batch 210 : 0.011641642078757286
Loss at batch 220 : 0.01253919955343008
Loss at batch 230 : 0.01106717623770237
Loss at batch 240 : 0.016432981938123703
Loss at batch 250 : 0.019780663773417473
Loss at batch 260 : 0.019638583064079285
Loss at batch 270 : 0.01850687339901924
Loss at batch 280 : 0.02362450212240219
Loss at batch 290 : 0.014458276331424713
Loss at batch 300 : 0.008028188720345497
Loss at batch 310 : 0.01973015069961548
Loss at batch 320 : 0.01595498062670231
Loss at batch 330 : 0.012459439225494862
Loss at batch 340 : 0.008762391284108162
Loss at batch 350 : 0.013339865021407604
Loss at batch 360 : 0.015099589712917805
Loss at batch 370 : 0.01971287652850151
epoch39 finished!
Loss at batch 10 : 0.013451078906655312
Loss at batch 20 : 0.012272468768060207
Loss at batch 30 : 0.010543118230998516
Loss at batch 40 : 0.014937242493033409
Loss at batch 50 : 0.019133619964122772
Loss at batch 60 : 0.011391611769795418
Loss at batch 70 : 0.015320343896746635
Loss at batch 80 : 0.02251228131353855
Loss at batch 90 : 0.01039721630513668
Loss at batch 100 : 0.013118884526193142
Loss at batch 110 : 0.011938671581447124
Loss at batch 120 : 0.008926177397370338
Loss at batch 130 : 0.017930569127202034
Loss at batch 140 : 0.011064872145652771
Loss at batch 150 : 0.012810160405933857
Loss at batch 160 : 0.016473596915602684
Loss at batch 170 : 0.009622427634894848
Loss at batch 180 : 0.009146835654973984
Loss at batch 190 : 0.019649481400847435
Loss at batch 200 : 0.014710345305502415
Loss at batch 210 : 0.02123173512518406
Loss at batch 220 : 0.011434256099164486
Loss at batch 230 : 0.02122286893427372
Loss at batch 240 : 0.018093418329954147
Loss at batch 250 : 0.016043473035097122
Loss at batch 260 : 0.00781846884638071
Loss at batch 270 : 0.01368193794041872
Loss at batch 280 : 0.012761124409735203
Loss at batch 290 : 0.012848928570747375
Loss at batch 300 : 0.009828886017203331
Loss at batch 310 : 0.014743763022124767
Loss at batch 320 : 0.022994177415966988
Loss at batch 330 : 0.01150725968182087
Loss at batch 340 : 0.017216647043824196
Loss at batch 350 : 0.017189214006066322
Loss at batch 360 : 0.012305889278650284
Loss at batch 370 : 0.017705919221043587
epoch39 finished!
Loss at batch 10 : 0.013580458238720894
Loss at batch 20 : 0.012587997131049633
Loss at batch 30 : 0.01145824696868658
Loss at batch 40 : 0.008331273682415485
Loss at batch 50 : 0.011952908709645271
Loss at batch 60 : 0.011234929785132408
Loss at batch 70 : 0.02705790288746357
Loss at batch 80 : 0.0169198140501976
Loss at batch 90 : 0.01672070100903511
Loss at batch 100 : 0.02611435018479824
Loss at batch 110 : 0.010471154935657978
Loss at batch 120 : 0.01929931342601776
Loss at batch 130 : 0.010540955699980259
Loss at batch 140 : 0.01193795446306467
Loss at batch 150 : 0.023515840992331505
Loss at batch 160 : 0.016726266592741013
Loss at batch 170 : 0.014364085160195827
Loss at batch 180 : 0.010999642312526703
Loss at batch 190 : 0.01649933122098446
Loss at batch 200 : 0.011082765646278858
Loss at batch 210 : 0.012602693401277065
Loss at batch 220 : 0.01886720582842827
Loss at batch 230 : 0.017766861245036125
Loss at batch 240 : 0.01855115219950676
Loss at batch 250 : 0.013580684550106525
Loss at batch 260 : 0.023192260414361954
Loss at batch 270 : 0.01167315524071455
Loss at batch 280 : 0.014586164616048336
Loss at batch 290 : 0.01613881252706051
Loss at batch 300 : 0.01534239947795868
Loss at batch 310 : 0.013781947083771229
Loss at batch 320 : 0.014352946542203426
Loss at batch 330 : 0.010065109468996525
Loss at batch 340 : 0.011259075254201889
Loss at batch 350 : 0.009770815260708332
Loss at batch 360 : 0.02102162502706051
Loss at batch 370 : 0.012152055278420448
epoch88 finished!
Loss at batch 10 : 0.012745503336191177
Loss at batch 20 : 0.01597941480576992
Loss at batch 30 : 0.010153071954846382
Loss at batch 40 : 0.021561279892921448
Loss at batch 50 : 0.013643999584019184
Loss at batch 60 : 0.009407108649611473
Loss at batch 70 : 0.03436340019106865
Loss at batch 80 : 0.0088809784501791
Loss at batch 90 : 0.017436236143112183
Loss at batch 100 : 0.020501334220170975
Loss at batch 110 : 0.010733827948570251
Loss at batch 120 : 0.012796667404472828
Loss at batch 130 : 0.010977317579090595
Loss at batch 140 : 0.014738394878804684
Loss at batch 150 : 0.013066774234175682
Loss at batch 160 : 0.011315388604998589
Loss at batch 170 : 0.012031057849526405
Loss at batch 180 : 0.011144362390041351
Loss at batch 190 : 0.012208727188408375
Loss at batch 200 : 0.020005883648991585
Loss at batch 210 : 0.009911491535604
Loss at batch 220 : 0.010134630836546421
Loss at batch 230 : 0.012078947387635708
Loss at batch 240 : 0.01022729929536581
Loss at batch 250 : 0.013295087032020092
Loss at batch 260 : 0.013683037832379341
Loss at batch 270 : 0.01647506281733513
Loss at batch 280 : 0.012570114806294441
Loss at batch 290 : 0.01367498841136694
Loss at batch 300 : 0.013082880526781082
Loss at batch 310 : 0.010774281807243824
Loss at batch 320 : 0.012702071107923985
Loss at batch 330 : 0.016752148047089577
Loss at batch 340 : 0.009546053595840931
Loss at batch 350 : 0.008114911615848541
Loss at batch 360 : 0.016652163118124008
Loss at batch 370 : 0.015183988958597183
epoch89 finished!
Loss at batch 10 : 0.020115751773118973
Loss at batch 20 : 0.009203817695379257
Loss at batch 30 : 0.013704166747629642
Loss at batch 40 : 0.011741702444851398
Loss at batch 50 : 0.0176107045263052
Loss at batch 60 : 0.030603207647800446
Loss at batch 70 : 0.027080044150352478
Loss at batch 80 : 0.014577619731426239
Loss at batch 90 : 0.01818864606320858
Loss at batch 100 : 0.013652816414833069
Loss at batch 110 : 0.02241324819624424
Loss at batch 120 : 0.02019560895860195
Loss at batch 130 : 0.026089202612638474
Loss at batch 140 : 0.018498167395591736
Loss at batch 150 : 0.013144688680768013
Loss at batch 160 : 0.017684146761894226
Loss at batch 170 : 0.016202425584197044
Loss at batch 180 : 0.021374234929680824
Loss at batch 190 : 0.010416517965495586
Loss at batch 200 : 0.01819044165313244
Loss at batch 210 : 0.023600244894623756
Loss at batch 220 : 0.013116664253175259
Loss at batch 230 : 0.017155995592474937
Loss at batch 240 : 0.012227384373545647
Loss at batch 250 : 0.015020782127976418
Loss at batch 260 : 0.01709146611392498
Loss at batch 270 : 0.016869589686393738
Loss at batch 280 : 0.01806640438735485
Loss at batch 290 : 0.011300208047032356
Loss at batch 300 : 0.02671467326581478
Loss at batch 310 : 0.014462470076978207
Loss at batch 320 : 0.011762100271880627
Loss at batch 330 : 0.023332810029387474
Loss at batch 340 : 0.014338409528136253
Loss at batch 350 : 0.012151507660746574
Loss at batch 360 : 0.011535897850990295
Loss at batch 370 : 0.016018789261579514
epoch40 finished!
Loss at batch 10 : 0.01066274382174015
Loss at batch 20 : 0.015868907794356346
Loss at batch 30 : 0.009936003014445305
Loss at batch 40 : 0.011186298914253712
Loss at batch 50 : 0.018832029774785042
Loss at batch 60 : 0.013702443800866604
Loss at batch 70 : 0.023198088631033897
Loss at batch 80 : 0.019039735198020935
Loss at batch 90 : 0.010982383973896503
Loss at batch 100 : 0.007327700965106487
Loss at batch 110 : 0.008322404697537422
Loss at batch 120 : 0.011687942780554295
Loss at batch 130 : 0.020019756630063057
Loss at batch 140 : 0.013234136626124382
Loss at batch 150 : 0.024254566058516502
Loss at batch 160 : 0.010817067697644234
Loss at batch 170 : 0.011799496598541737
Loss at batch 180 : 0.014176424592733383
Loss at batch 190 : 0.01924002170562744
Loss at batch 200 : 0.01486608013510704
Loss at batch 210 : 0.010568209923803806
Loss at batch 220 : 0.006985072046518326
Loss at batch 230 : 0.017972759902477264
Loss at batch 240 : 0.018280096352100372
Loss at batch 250 : 0.012951619923114777
Loss at batch 260 : 0.010066661052405834
Loss at batch 270 : 0.010212680324912071
Loss at batch 280 : 0.009833965450525284
Loss at batch 290 : 0.011764421127736568
Loss at batch 300 : 0.013754613697528839
Loss at batch 310 : 0.011693297885358334
Loss at batch 320 : 0.01314321719110012
Loss at batch 330 : 0.010171597823500633
Loss at batch 340 : 0.01779598370194435
Loss at batch 350 : 0.007098966743797064
Loss at batch 360 : 0.023218363523483276
Loss at batch 370 : 0.013372180052101612
epoch90 finished!
Loss at batch 10 : 0.015869274735450745
Loss at batch 20 : 0.01809597946703434
Loss at batch 30 : 0.01161098387092352
Loss at batch 40 : 0.01800612173974514
Loss at batch 50 : 0.01635272614657879
Loss at batch 60 : 0.007713560946285725
Loss at batch 70 : 0.006888370495289564
Loss at batch 80 : 0.010446621105074883
Loss at batch 90 : 0.01408921368420124
Loss at batch 100 : 0.014460144564509392
Loss at batch 110 : 0.015326838940382004
Loss at batch 120 : 0.026017118245363235
Loss at batch 130 : 0.02039143070578575
Loss at batch 140 : 0.01505536213517189
Loss at batch 150 : 0.016435056924819946
Loss at batch 160 : 0.005999568849802017
Loss at batch 170 : 0.02212940715253353
Loss at batch 180 : 0.0174417607486248
Loss at batch 190 : 0.01807236671447754
Loss at batch 200 : 0.014746671542525291
Loss at batch 210 : 0.016380401328206062
Loss at batch 220 : 0.01601462997496128
Loss at batch 230 : 0.01634959504008293
Loss at batch 240 : 0.009659170173108578
Loss at batch 250 : 0.007781792897731066
Loss at batch 260 : 0.02140122652053833
Loss at batch 270 : 0.012589582242071629
Loss at batch 280 : 0.03334292769432068
Loss at batch 290 : 0.009601058438420296
Loss at batch 300 : 0.010579494759440422
Loss at batch 310 : 0.022504769265651703
Loss at batch 320 : 0.01396014541387558
Loss at batch 330 : 0.02071499265730381
Loss at batch 340 : 0.01648244634270668
Loss at batch 350 : 0.01961902156472206
Loss at batch 360 : 0.011723698116838932
Loss at batch 370 : 0.015501996502280235
epoch40 finished!
Loss at batch 10 : 0.013852817006409168
Loss at batch 20 : 0.028129667043685913
Loss at batch 30 : 0.026698017492890358
Loss at batch 40 : 0.010452334769070148
Loss at batch 50 : 0.020860619843006134
Loss at batch 60 : 0.01534807775169611
Loss at batch 70 : 0.025923479348421097
Loss at batch 80 : 0.006045366171747446
Loss at batch 90 : 0.00994957610964775
Loss at batch 100 : 0.014875066466629505
Loss at batch 110 : 0.019379181787371635
Loss at batch 120 : 0.016973894089460373
Loss at batch 130 : 0.015617738477885723
Loss at batch 140 : 0.009976196102797985
Loss at batch 150 : 0.010586590506136417
Loss at batch 160 : 0.013306261971592903
Loss at batch 170 : 0.026444660499691963
Loss at batch 180 : 0.012668199837207794
Loss at batch 190 : 0.023457765579223633
Loss at batch 200 : 0.018324628472328186
Loss at batch 210 : 0.02053326554596424
Loss at batch 220 : 0.010660956613719463
Loss at batch 230 : 0.008247903548181057
Loss at batch 240 : 0.00805005431175232
Loss at batch 250 : 0.012677039951086044
Loss at batch 260 : 0.013092409819364548
Loss at batch 270 : 0.01063709706068039
Loss at batch 280 : 0.017180515453219414
Loss at batch 290 : 0.009317534044384956
Loss at batch 300 : 0.01376958005130291
Loss at batch 310 : 0.016288498416543007
Loss at batch 320 : 0.010628581047058105
Loss at batch 330 : 0.015145433135330677
Loss at batch 340 : 0.009157640859484673
Loss at batch 350 : 0.010943620465695858
Loss at batch 360 : 0.015333754941821098
Loss at batch 370 : 0.018432702869176865
epoch91 finished!
Loss at batch 10 : 0.022659655660390854
Loss at batch 20 : 0.014400813728570938
Loss at batch 30 : 0.007900252938270569
Loss at batch 40 : 0.02350998856127262
Loss at batch 50 : 0.0116674043238163
Loss at batch 60 : 0.01340540498495102
Loss at batch 70 : 0.010888996534049511
Loss at batch 80 : 0.02015933208167553
Loss at batch 90 : 0.011602486483752728
Loss at batch 100 : 0.013889756053686142
Loss at batch 110 : 0.027955975383520126
Loss at batch 120 : 0.014603140763938427
Loss at batch 130 : 0.011313444934785366
Loss at batch 140 : 0.012923240661621094
Loss at batch 150 : 0.01705436408519745
Loss at batch 160 : 0.014745431020855904
Loss at batch 170 : 0.010695233009755611
Loss at batch 180 : 0.013120101764798164
Loss at batch 190 : 0.02030101977288723
Loss at batch 200 : 0.018411558121442795
Loss at batch 210 : 0.012424680404365063
Loss at batch 220 : 0.013351228088140488
Loss at batch 230 : 0.010740957222878933
Loss at batch 240 : 0.021271854639053345
Loss at batch 250 : 0.008610798045992851
Loss at batch 260 : 0.012581068091094494
Loss at batch 270 : 0.008813031017780304
Loss at batch 280 : 0.013494190759956837
Loss at batch 290 : 0.011799363419413567
Loss at batch 300 : 0.009553915821015835
Loss at batch 310 : 0.025199122726917267
Loss at batch 320 : 0.0069655245169997215
Loss at batch 330 : 0.023202190175652504
Loss at batch 340 : 0.016718866303563118
Loss at batch 350 : 0.013837434351444244
Loss at batch 360 : 0.018797116354107857
Loss at batch 370 : 0.028676021844148636
epoch41 finished!
Loss at batch 10 : 0.011094476096332073
Loss at batch 20 : 0.009154432453215122
Loss at batch 30 : 0.012606402859091759
Loss at batch 40 : 0.009354638867080212
Loss at batch 50 : 0.014347918331623077
Loss at batch 60 : 0.008371561765670776
Loss at batch 70 : 0.00948097463697195
Loss at batch 80 : 0.011469924822449684
Loss at batch 90 : 0.00793091394007206
Loss at batch 100 : 0.0138021195307374
Loss at batch 110 : 0.017196673899888992
Loss at batch 120 : 0.013902125880122185
Loss at batch 130 : 0.008815695531666279
Loss at batch 140 : 0.008862568065524101
Loss at batch 150 : 0.013235188089311123
Loss at batch 160 : 0.013619492761790752
Loss at batch 170 : 0.008332694880664349
Loss at batch 180 : 0.01045518834143877
Loss at batch 190 : 0.023040583357214928
Loss at batch 200 : 0.01407618261873722
Loss at batch 210 : 0.0240098275244236
Loss at batch 220 : 0.01965193822979927
Loss at batch 230 : 0.01632624864578247
Loss at batch 240 : 0.010511493310332298
Loss at batch 250 : 0.012569067068397999
Loss at batch 260 : 0.008612490259110928
Loss at batch 270 : 0.009255556389689445
Loss at batch 280 : 0.009675291366875172
Loss at batch 290 : 0.01736821047961712
Loss at batch 300 : 0.0240086130797863
Loss at batch 310 : 0.029007213190197945
Loss at batch 320 : 0.01623007096350193
Loss at batch 330 : 0.01565660536289215
Loss at batch 340 : 0.01400696486234665
Loss at batch 350 : 0.0109238987788558
Loss at batch 360 : 0.013064914382994175
Loss at batch 370 : 0.01645059883594513
epoch92 finished!
Loss at batch 10 : 0.011234253644943237
Loss at batch 20 : 0.011866570450365543
Loss at batch 30 : 0.010766786523163319
Loss at batch 40 : 0.007626937236636877
Loss at batch 50 : 0.010150444693863392
Loss at batch 60 : 0.008373003453016281
Loss at batch 70 : 0.013552299700677395
Loss at batch 80 : 0.017661791294813156
Loss at batch 90 : 0.01793898269534111
Loss at batch 100 : 0.012549888342618942
Loss at batch 110 : 0.015890421345829964
Loss at batch 120 : 0.01844172552227974
Loss at batch 130 : 0.0108789699152112
Loss at batch 140 : 0.010279394686222076
Loss at batch 150 : 0.02149609476327896
Loss at batch 160 : 0.015735086053609848
Loss at batch 170 : 0.013776879757642746
Loss at batch 180 : 0.011205485090613365
Loss at batch 190 : 0.019896384328603745
Loss at batch 200 : 0.014160824008286
Loss at batch 210 : 0.020228492096066475
Loss at batch 220 : 0.015455961227416992
Loss at batch 230 : 0.0139780193567276
Loss at batch 240 : 0.017613396048545837
Loss at batch 250 : 0.012464410625398159
Loss at batch 260 : 0.014249613508582115
Loss at batch 270 : 0.012712453491985798
Loss at batch 280 : 0.009335078299045563
Loss at batch 290 : 0.012573139742016792
Loss at batch 300 : 0.012991390191018581
Loss at batch 310 : 0.011538120917975903
Loss at batch 320 : 0.011297445744276047
Loss at batch 330 : 0.010656218975782394
Loss at batch 340 : 0.011250202544033527
Loss at batch 350 : 0.008452577516436577
Loss at batch 360 : 0.010015099309384823
Loss at batch 370 : 0.01452875416725874
epoch41 finished!
Loss at batch 10 : 0.010019809007644653
Loss at batch 20 : 0.02410636655986309
Loss at batch 30 : 0.02597011998295784
Loss at batch 40 : 0.013001730665564537
Loss at batch 50 : 0.0223112590610981
Loss at batch 60 : 0.01314926240593195
Loss at batch 70 : 0.022558866068720818
Loss at batch 80 : 0.01182264368981123
Loss at batch 90 : 0.007996251806616783
Loss at batch 100 : 0.017384033650159836
Loss at batch 110 : 0.014224017038941383
Loss at batch 120 : 0.007951335050165653
Loss at batch 130 : 0.009969986975193024
Loss at batch 140 : 0.010956075973808765
Loss at batch 150 : 0.012178754433989525
Loss at batch 160 : 0.008651056326925755
Loss at batch 170 : 0.013944520615041256
Loss at batch 180 : 0.014187338761985302
Loss at batch 190 : 0.013912955299019814
Loss at batch 200 : 0.01424237061291933
Loss at batch 210 : 0.01488502323627472
Loss at batch 220 : 0.009914250113070011
Loss at batch 230 : 0.017328014597296715
Loss at batch 240 : 0.009669112972915173
Loss at batch 250 : 0.02341795712709427
Loss at batch 260 : 0.00892625655978918
Loss at batch 270 : 0.008770016953349113
Loss at batch 280 : 0.01213832013309002
Loss at batch 290 : 0.009921490214765072
Loss at batch 300 : 0.018315454944968224
Loss at batch 310 : 0.011708901263773441
Loss at batch 320 : 0.024137575179338455
Loss at batch 330 : 0.013246120885014534
Loss at batch 340 : 0.01443391852080822
Loss at batch 350 : 0.020483123138546944
Loss at batch 360 : 0.021249964833259583
Loss at batch 370 : 0.010709036141633987
epoch93 finished!
Loss at batch 10 : 0.013005107641220093
Loss at batch 20 : 0.009786888025701046
Loss at batch 30 : 0.014140769839286804
Loss at batch 40 : 0.016023261472582817
Loss at batch 50 : 0.011071549728512764
Loss at batch 60 : 0.01584532856941223
Loss at batch 70 : 0.009543503634631634
Loss at batch 80 : 0.02395990677177906
Loss at batch 90 : 0.019504863768815994
Loss at batch 100 : 0.012891551479697227
Loss at batch 110 : 0.006917982827872038
Loss at batch 120 : 0.020522940903902054
Loss at batch 130 : 0.03504355996847153
Loss at batch 140 : 0.01074264757335186
Loss at batch 150 : 0.013126209378242493
Loss at batch 160 : 0.019894901663064957
Loss at batch 170 : 0.014586369507014751
Loss at batch 180 : 0.011950364336371422
Loss at batch 190 : 0.014865155331790447
Loss at batch 200 : 0.010362578555941582
Loss at batch 210 : 0.020329734310507774
Loss at batch 220 : 0.0117872916162014
Loss at batch 230 : 0.007755560334771872
Loss at batch 240 : 0.010893667116761208
Loss at batch 250 : 0.012448706664144993
Loss at batch 260 : 0.009504175744950771
Loss at batch 270 : 0.015922872349619865
Loss at batch 280 : 0.012364591471850872
Loss at batch 290 : 0.020791850984096527
Loss at batch 300 : 0.013596886768937111
Loss at batch 310 : 0.017573243007063866
Loss at batch 320 : 0.016064127907156944
Loss at batch 330 : 0.015456647612154484
Loss at batch 340 : 0.012461122125387192
Loss at batch 350 : 0.010130694136023521
Loss at batch 360 : 0.014941994100809097
Loss at batch 370 : 0.008174085058271885
epoch94 finished!
Loss at batch 10 : 0.020477645099163055
Loss at batch 20 : 0.02025732211768627
Loss at batch 30 : 0.018519572913646698
Loss at batch 40 : 0.01721392385661602
Loss at batch 50 : 0.012696138583123684
Loss at batch 60 : 0.01877870038151741
Loss at batch 70 : 0.010413452051579952
Loss at batch 80 : 0.008704346604645252
Loss at batch 90 : 0.018252462148666382
Loss at batch 100 : 0.015041769482195377
Loss at batch 110 : 0.012929839082062244
Loss at batch 120 : 0.020440353080630302
Loss at batch 130 : 0.014381419867277145
Loss at batch 140 : 0.01559224259108305
Loss at batch 150 : 0.01749635674059391
Loss at batch 160 : 0.011943023651838303
Loss at batch 170 : 0.020062575116753578
Loss at batch 180 : 0.013897065073251724
Loss at batch 190 : 0.02332307957112789
Loss at batch 200 : 0.013657127507030964
Loss at batch 210 : 0.014062055386602879
Loss at batch 220 : 0.01748756505548954
Loss at batch 230 : 0.021978328004479408
Loss at batch 240 : 0.020063217729330063
Loss at batch 250 : 0.015603400766849518
Loss at batch 260 : 0.00863873865455389
Loss at batch 270 : 0.01670311763882637
Loss at batch 280 : 0.013905654661357403
Loss at batch 290 : 0.023088131099939346
Loss at batch 300 : 0.013322669081389904
Loss at batch 310 : 0.025764059275388718
Loss at batch 320 : 0.01627403497695923
Loss at batch 330 : 0.01707584224641323
Loss at batch 340 : 0.009685351513326168
Loss at batch 350 : 0.021883605048060417
Loss at batch 360 : 0.02253565564751625
Loss at batch 370 : 0.015197583474218845
epoch42 finished!
Loss at batch 10 : 0.013801210559904575
Loss at batch 20 : 0.026741240173578262
Loss at batch 30 : 0.009843461215496063
Loss at batch 40 : 0.01657629944384098
Loss at batch 50 : 0.010312655940651894
Loss at batch 60 : 0.015888866037130356
Loss at batch 70 : 0.012042100541293621
Loss at batch 80 : 0.015076376497745514
Loss at batch 90 : 0.012735730968415737
Loss at batch 100 : 0.01617462746798992
Loss at batch 110 : 0.00971275381743908
Loss at batch 120 : 0.017403220757842064
Loss at batch 130 : 0.011102479882538319
Loss at batch 140 : 0.014514880254864693
Loss at batch 150 : 0.011992435902357101
Loss at batch 160 : 0.01386501919478178
Loss at batch 170 : 0.020666467025876045
Loss at batch 180 : 0.009929337538778782
Loss at batch 190 : 0.029509106650948524
Loss at batch 200 : 0.024816205725073814
Loss at batch 210 : 0.015363773331046104
Loss at batch 220 : 0.015415283851325512
Loss at batch 230 : 0.010698600672185421
Loss at batch 240 : 0.026712048798799515
Loss at batch 250 : 0.009971622377634048
Loss at batch 260 : 0.011114854365587234
Loss at batch 270 : 0.0079133166000247
Loss at batch 280 : 0.013523483648896217
Loss at batch 290 : 0.010327129624783993
Loss at batch 300 : 0.014887490309774876
Loss at batch 310 : 0.013812638819217682
Loss at batch 320 : 0.016957156360149384
Loss at batch 330 : 0.01839485578238964
Loss at batch 340 : 0.015941530466079712
Loss at batch 350 : 0.009393177926540375
Loss at batch 360 : 0.009803342632949352
Loss at batch 370 : 0.017152709886431694
epoch42 finished!
Loss at batch 10 : 0.02061314322054386
Loss at batch 20 : 0.01771700754761696
Loss at batch 30 : 0.011180893518030643
Loss at batch 40 : 0.008355877362191677
Loss at batch 50 : 0.01349391508847475
Loss at batch 60 : 0.02071462757885456
Loss at batch 70 : 0.014751952141523361
Loss at batch 80 : 0.011624732054769993
Loss at batch 90 : 0.017207998782396317
Loss at batch 100 : 0.011809341609477997
Loss at batch 110 : 0.010732301510870457
Loss at batch 120 : 0.0111321322619915
Loss at batch 130 : 0.014398463070392609
Loss at batch 140 : 0.011084252037107944
Loss at batch 150 : 0.009236316196620464
Loss at batch 160 : 0.022886093705892563
Loss at batch 170 : 0.01995079591870308
Loss at batch 180 : 0.009990082122385502
Loss at batch 190 : 0.021296417340636253
Loss at batch 200 : 0.018045134842395782
Loss at batch 210 : 0.011137601919472218
Loss at batch 220 : 0.012000033631920815
Loss at batch 230 : 0.01920410245656967
Loss at batch 240 : 0.013418471440672874
Loss at batch 250 : 0.007811450399458408
Loss at batch 260 : 0.016406534239649773
Loss at batch 270 : 0.013813521713018417
Loss at batch 280 : 0.015023799613118172
Loss at batch 290 : 0.015397765673696995
Loss at batch 300 : 0.01422437559813261
Loss at batch 310 : 0.015308170579373837
Loss at batch 320 : 0.008276527747511864
Loss at batch 330 : 0.0075960299000144005
Loss at batch 340 : 0.017147842794656754
Loss at batch 350 : 0.023849621415138245
Loss at batch 360 : 0.012679845094680786
Loss at batch 370 : 0.008807559497654438
epoch95 finished!
Loss at batch 10 : 0.014203020371496677
Loss at batch 20 : 0.016377948224544525
Loss at batch 30 : 0.013462361879646778
Loss at batch 40 : 0.010499458760023117
Loss at batch 50 : 0.020769743248820305
Loss at batch 60 : 0.01579674519598484
Loss at batch 70 : 0.017992960289120674
Loss at batch 80 : 0.014622830785810947
Loss at batch 90 : 0.012590414844453335
Loss at batch 100 : 0.010361331515014172
Loss at batch 110 : 0.012347408570349216
Loss at batch 120 : 0.011516936123371124
Loss at batch 130 : 0.015311483293771744
Loss at batch 140 : 0.023561645299196243
Loss at batch 150 : 0.012239661999046803
Loss at batch 160 : 0.01142452098429203
Loss at batch 170 : 0.0072629135102033615
Loss at batch 180 : 0.009003943763673306
Loss at batch 190 : 0.020755812525749207
Loss at batch 200 : 0.014401925727725029
Loss at batch 210 : 0.013214921578764915
Loss at batch 220 : 0.007229025475680828
Loss at batch 230 : 0.01047562062740326
Loss at batch 240 : 0.018495818600058556
Loss at batch 250 : 0.011616669595241547
Loss at batch 260 : 0.01555991917848587
Loss at batch 270 : 0.014837215654551983
Loss at batch 280 : 0.01636766456067562
Loss at batch 290 : 0.015558728948235512
Loss at batch 300 : 0.007612872868776321
Loss at batch 310 : 0.01968441903591156
Loss at batch 320 : 0.01489320583641529
Loss at batch 330 : 0.010996594093739986
Loss at batch 340 : 0.023163914680480957
Loss at batch 350 : 0.0203951895236969
Loss at batch 360 : 0.011957582086324692
Loss at batch 370 : 0.0165236946195364
epoch96 finished!
Loss at batch 10 : 0.013760646805167198
Loss at batch 20 : 0.012444599531590939
Loss at batch 30 : 0.026286715641617775
Loss at batch 40 : 0.015177318826317787
Loss at batch 50 : 0.008838851004838943
Loss at batch 60 : 0.011053304187953472
Loss at batch 70 : 0.013649898581206799
Loss at batch 80 : 0.01505949441343546
Loss at batch 90 : 0.012883629649877548
Loss at batch 100 : 0.013316905125975609
Loss at batch 110 : 0.010277656838297844
Loss at batch 120 : 0.013484898023307323
Loss at batch 130 : 0.016785863786935806
Loss at batch 140 : 0.0245682206004858
Loss at batch 150 : 0.011502893641591072
Loss at batch 160 : 0.016341499984264374
Loss at batch 170 : 0.022323086857795715
Loss at batch 180 : 0.00834022555500269
Loss at batch 190 : 0.01623687334358692
Loss at batch 200 : 0.01808064803481102
Loss at batch 210 : 0.014614497311413288
Loss at batch 220 : 0.0071805925108492374
Loss at batch 230 : 0.010945922695100307
Loss at batch 240 : 0.012283687479794025
Loss at batch 250 : 0.015668505802750587
Loss at batch 260 : 0.013291258364915848
Loss at batch 270 : 0.014901087619364262
Loss at batch 280 : 0.016206415370106697
Loss at batch 290 : 0.01824863813817501
Loss at batch 300 : 0.021288160234689713
Loss at batch 310 : 0.010093041695654392
Loss at batch 320 : 0.015043951570987701
Loss at batch 330 : 0.023157797753810883
Loss at batch 340 : 0.025829683989286423
Loss at batch 350 : 0.014370488002896309
Loss at batch 360 : 0.01153023261576891
Loss at batch 370 : 0.011371203698217869
epoch43 finished!
Loss at batch 10 : 0.016862409189343452
Loss at batch 20 : 0.01341794990003109
Loss at batch 30 : 0.014232114888727665
Loss at batch 40 : 0.013588824309408665
Loss at batch 50 : 0.013432791456580162
Loss at batch 60 : 0.013774361461400986
Loss at batch 70 : 0.012004509568214417
Loss at batch 80 : 0.01613100990653038
Loss at batch 90 : 0.02447368949651718
Loss at batch 100 : 0.011896775104105473
Loss at batch 110 : 0.014122739434242249
Loss at batch 120 : 0.0129450224339962
Loss at batch 130 : 0.010897773317992687
Loss at batch 140 : 0.01134520210325718
Loss at batch 150 : 0.008369022980332375
Loss at batch 160 : 0.01309477724134922
Loss at batch 170 : 0.03175833076238632
Loss at batch 180 : 0.011778853833675385
Loss at batch 190 : 0.010806147940456867
Loss at batch 200 : 0.015800002962350845
Loss at batch 210 : 0.01541128195822239
Loss at batch 220 : 0.010922415181994438
Loss at batch 230 : 0.007802246604114771
Loss at batch 240 : 0.015469680540263653
Loss at batch 250 : 0.00912002194672823
Loss at batch 260 : 0.013526096940040588
Loss at batch 270 : 0.011874480172991753
Loss at batch 280 : 0.01590072363615036
Loss at batch 290 : 0.01029863953590393
Loss at batch 300 : 0.022324329242110252
Loss at batch 310 : 0.026075070723891258
Loss at batch 320 : 0.00913082156330347
Loss at batch 330 : 0.013204606249928474
Loss at batch 340 : 0.012910407036542892
Loss at batch 350 : 0.015179299749433994
Loss at batch 360 : 0.009848063811659813
Loss at batch 370 : 0.017393892630934715
epoch43 finished!
Loss at batch 10 : 0.006455378141254187
Loss at batch 20 : 0.014115575700998306
Loss at batch 30 : 0.0052400450222194195
Loss at batch 40 : 0.016157077625393867
Loss at batch 50 : 0.014754755422472954
Loss at batch 60 : 0.023146362975239754
Loss at batch 70 : 0.01692431978881359
Loss at batch 80 : 0.007140131201595068
Loss at batch 90 : 0.00971071794629097
Loss at batch 100 : 0.014520478434860706
Loss at batch 110 : 0.01223723217844963
Loss at batch 120 : 0.02131316252052784
Loss at batch 130 : 0.0148026617243886
Loss at batch 140 : 0.013570512644946575
Loss at batch 150 : 0.01142274308949709
Loss at batch 160 : 0.012186353094875813
Loss at batch 170 : 0.019585097208619118
Loss at batch 180 : 0.014205966144800186
Loss at batch 190 : 0.01591360941529274
Loss at batch 200 : 0.014108250848948956
Loss at batch 210 : 0.012613116763532162
Loss at batch 220 : 0.013316408731043339
Loss at batch 230 : 0.014214333146810532
Loss at batch 240 : 0.014379489235579967
Loss at batch 250 : 0.011780285276472569
Loss at batch 260 : 0.0079712038859725
Loss at batch 270 : 0.011076103895902634
Loss at batch 280 : 0.017179161310195923
Loss at batch 290 : 0.01717911846935749
Loss at batch 300 : 0.008231431245803833
Loss at batch 310 : 0.018395818769931793
Loss at batch 320 : 0.01011895202100277
Loss at batch 330 : 0.012189011089503765
Loss at batch 340 : 0.011313929222524166
Loss at batch 350 : 0.01333093922585249
Loss at batch 360 : 0.01277721207588911
Loss at batch 370 : 0.01792258396744728
epoch97 finished!
Loss at batch 10 : 0.01052283588796854
Loss at batch 20 : 0.012815655209124088
Loss at batch 30 : 0.006904787849634886
Loss at batch 40 : 0.012707339599728584
Loss at batch 50 : 0.017361018806695938
Loss at batch 60 : 0.01506609097123146
Loss at batch 70 : 0.011751973070204258
Loss at batch 80 : 0.016703691333532333
Loss at batch 90 : 0.01199942734092474
Loss at batch 100 : 0.013424386270344257
Loss at batch 110 : 0.011818828992545605
Loss at batch 120 : 0.01753806881606579
Loss at batch 130 : 0.017125368118286133
Loss at batch 140 : 0.015772970393300056
Loss at batch 150 : 0.008405027911067009
Loss at batch 160 : 0.00971289537847042
Loss at batch 170 : 0.014812628738582134
Loss at batch 180 : 0.011516910046339035
Loss at batch 190 : 0.028498094528913498
Loss at batch 200 : 0.018284039571881294
Loss at batch 210 : 0.018347395583987236
Loss at batch 220 : 0.021841952577233315
Loss at batch 230 : 0.021337175741791725
Loss at batch 240 : 0.012758243829011917
Loss at batch 250 : 0.01716477982699871
Loss at batch 260 : 0.01815662905573845
Loss at batch 270 : 0.010006544180214405
Loss at batch 280 : 0.01750805415213108
Loss at batch 290 : 0.016665516421198845
Loss at batch 300 : 0.01786014810204506
Loss at batch 310 : 0.016190607100725174
Loss at batch 320 : 0.013559645041823387
Loss at batch 330 : 0.014575546607375145
Loss at batch 340 : 0.011334022507071495
Loss at batch 350 : 0.014254988171160221
Loss at batch 360 : 0.017295775935053825
Loss at batch 370 : 0.01933560147881508
epoch98 finished!
Loss at batch 10 : 0.012867975980043411
Loss at batch 20 : 0.009875897318124771
Loss at batch 30 : 0.01848473772406578
Loss at batch 40 : 0.01341739296913147
Loss at batch 50 : 0.023676617071032524
Loss at batch 60 : 0.014185228385031223
Loss at batch 70 : 0.012219442054629326
Loss at batch 80 : 0.021611303091049194
Loss at batch 90 : 0.0070746601559221745
Loss at batch 100 : 0.012065677903592587
Loss at batch 110 : 0.01633901707828045
Loss at batch 120 : 0.00843819510191679
Loss at batch 130 : 0.015386092476546764
Loss at batch 140 : 0.015225069597363472
Loss at batch 150 : 0.021611403673887253
Loss at batch 160 : 0.018161218613386154
Loss at batch 170 : 0.012506983242928982
Loss at batch 180 : 0.010298680514097214
Loss at batch 190 : 0.006364390719681978
Loss at batch 200 : 0.0169548150151968
Loss at batch 210 : 0.03381004557013512
Loss at batch 220 : 0.017507202923297882
Loss at batch 230 : 0.012333128601312637
Loss at batch 240 : 0.015283257700502872
Loss at batch 250 : 0.01746729202568531
Loss at batch 260 : 0.01440217811614275
Loss at batch 270 : 0.007226510904729366
Loss at batch 280 : 0.02799540013074875
Loss at batch 290 : 0.01618397980928421
Loss at batch 300 : 0.017092255875468254
Loss at batch 310 : 0.010446418076753616
Loss at batch 320 : 0.02228967472910881
Loss at batch 330 : 0.01699822023510933
Loss at batch 340 : 0.017913153395056725
Loss at batch 350 : 0.010457861237227917
Loss at batch 360 : 0.014074813574552536
Loss at batch 370 : 0.012688563205301762
epoch44 finished!
Loss at batch 10 : 0.011839624494314194
Loss at batch 20 : 0.030640318989753723
Loss at batch 30 : 0.014158069156110287
Loss at batch 40 : 0.027760760858654976
Loss at batch 50 : 0.01751909777522087
Loss at batch 60 : 0.011631494387984276
Loss at batch 70 : 0.011306613683700562
Loss at batch 80 : 0.011895290575921535
Loss at batch 90 : 0.015838002786040306
Loss at batch 100 : 0.008949477225542068
Loss at batch 110 : 0.01981794275343418
Loss at batch 120 : 0.012790517881512642
Loss at batch 130 : 0.016943996772170067
Loss at batch 140 : 0.02900458127260208
Loss at batch 150 : 0.014106517657637596
Loss at batch 160 : 0.014275928027927876
Loss at batch 170 : 0.014416608028113842
Loss at batch 180 : 0.025107312947511673
Loss at batch 190 : 0.008965778164565563
Loss at batch 200 : 0.013929334469139576
Loss at batch 210 : 0.015606905333697796
Loss at batch 220 : 0.014951951801776886
Loss at batch 230 : 0.016864830628037453
Loss at batch 240 : 0.0168649572879076
Loss at batch 250 : 0.010561546310782433
Loss at batch 260 : 0.02494153380393982
Loss at batch 270 : 0.013857543468475342
Loss at batch 280 : 0.013766853138804436
Loss at batch 290 : 0.016179757192730904
Loss at batch 300 : 0.010218457318842411
Loss at batch 310 : 0.010378132574260235
Loss at batch 320 : 0.015143269672989845
Loss at batch 330 : 0.017967404797673225
Loss at batch 340 : 0.013779107481241226
Loss at batch 350 : 0.014119709841907024
Loss at batch 360 : 0.013354884460568428
Loss at batch 370 : 0.014070962555706501
epoch44 finished!
Loss at batch 10 : 0.012429146096110344
Loss at batch 20 : 0.012361584231257439
Loss at batch 30 : 0.009539561346173286
Loss at batch 40 : 0.013263590633869171
Loss at batch 50 : 0.012737573124468327
Loss at batch 60 : 0.011707164347171783
Loss at batch 70 : 0.009395361877977848
Loss at batch 80 : 0.012449944391846657
Loss at batch 90 : 0.01720496639609337
Loss at batch 100 : 0.015710078179836273
Loss at batch 110 : 0.014327432960271835
Loss at batch 120 : 0.025260308757424355
Loss at batch 130 : 0.01757093518972397
Loss at batch 140 : 0.012990793213248253
Loss at batch 150 : 0.007913983426988125
Loss at batch 160 : 0.014449276961386204
Loss at batch 170 : 0.014923346228897572
Loss at batch 180 : 0.017354238778352737
Loss at batch 190 : 0.009759640321135521
Loss at batch 200 : 0.015510503202676773
Loss at batch 210 : 0.01014787144958973
Loss at batch 220 : 0.018441133201122284
Loss at batch 230 : 0.015375308692455292
Loss at batch 240 : 0.011634314432740211
Loss at batch 250 : 0.025411007925868034
Loss at batch 260 : 0.0120067298412323
Loss at batch 270 : 0.014705986715853214
Loss at batch 280 : 0.013188095763325691
Loss at batch 290 : 0.019561754539608955
Loss at batch 300 : 0.010029447264969349
Loss at batch 310 : 0.024128451943397522
Loss at batch 320 : 0.013615524396300316
Loss at batch 330 : 0.008505125530064106
Loss at batch 340 : 0.012461639009416103
Loss at batch 350 : 0.017389947548508644
Loss at batch 360 : 0.010492958128452301
Loss at batch 370 : 0.01687273569405079
epoch99 finished!
Loss at batch 10 : 0.02172069437801838
Loss at batch 20 : 0.01634906604886055
Loss at batch 30 : 0.010911890305578709
Loss at batch 40 : 0.019431449472904205
Loss at batch 50 : 0.012735681608319283
Loss at batch 60 : 0.007853465154767036
Loss at batch 70 : 0.013481689617037773
Loss at batch 80 : 0.009120555594563484
Loss at batch 90 : 0.016902083531022072
Loss at batch 100 : 0.010231885127723217
Loss at batch 110 : 0.016654808074235916
Loss at batch 120 : 0.014227244071662426
Loss at batch 130 : 0.013829769566655159
Loss at batch 140 : 0.025589102879166603
Loss at batch 150 : 0.009542955085635185
Loss at batch 160 : 0.012335792183876038
Loss at batch 170 : 0.012907435186207294
Loss at batch 180 : 0.020554086193442345
Loss at batch 190 : 0.013645537197589874
Loss at batch 200 : 0.017626017332077026
Loss at batch 210 : 0.011568238958716393
Loss at batch 220 : 0.010681573301553726
Loss at batch 230 : 0.012694797478616238
Loss at batch 240 : 0.017290636897087097
Loss at batch 250 : 0.017674976959824562
Loss at batch 260 : 0.013190661557018757
Loss at batch 270 : 0.013210012577474117
Loss at batch 280 : 0.021166468039155006
Loss at batch 290 : 0.013944869861006737
Loss at batch 300 : 0.01226818561553955
Loss at batch 310 : 0.011776757426559925
Loss at batch 320 : 0.014384565874934196
Loss at batch 330 : 0.008752912282943726
Loss at batch 340 : 0.01246581319719553
Loss at batch 350 : 0.013596564531326294
Loss at batch 360 : 0.00956806167960167
Loss at batch 370 : 0.011843308806419373
epoch100 finished!
Loss at batch 10 : 0.025732578709721565
Loss at batch 20 : 0.01289146114140749
Loss at batch 30 : 0.010030880570411682
Loss at batch 40 : 0.01477829646319151
Loss at batch 50 : 0.010770704597234726
Loss at batch 60 : 0.015117320232093334
Loss at batch 70 : 0.010538334958255291
Loss at batch 80 : 0.008729234337806702
Loss at batch 90 : 0.0054383776150643826
Loss at batch 100 : 0.017947284504771233
Loss at batch 110 : 0.02447282150387764
Loss at batch 120 : 0.019828520715236664
Loss at batch 130 : 0.018802406266331673
Loss at batch 140 : 0.019046321511268616
Loss at batch 150 : 0.01480726059526205
Loss at batch 160 : 0.009202531538903713
Loss at batch 170 : 0.012928093783557415
Loss at batch 180 : 0.02015209197998047
Loss at batch 190 : 0.021437320858240128
Loss at batch 200 : 0.012574361637234688
Loss at batch 210 : 0.009320693090558052
Loss at batch 220 : 0.019244369119405746
Loss at batch 230 : 0.02114545740187168
Loss at batch 240 : 0.013279053382575512
Loss at batch 250 : 0.01689090207219124
Loss at batch 260 : 0.01413569226861
Loss at batch 270 : 0.012850280851125717
Loss at batch 280 : 0.011674427427351475
Loss at batch 290 : 0.012774636968970299
Loss at batch 300 : 0.018491532653570175
Loss at batch 310 : 0.020441284403204918
Loss at batch 320 : 0.013176697306334972
Loss at batch 330 : 0.009030124172568321
Loss at batch 340 : 0.007777605205774307
Loss at batch 350 : 0.013185808435082436
Loss at batch 360 : 0.014453385956585407
Loss at batch 370 : 0.018595119938254356
epoch45 finished!
Loss at batch 10 : 0.009272626601159573
Loss at batch 20 : 0.00872503500431776
Loss at batch 30 : 0.010690861381590366
Loss at batch 40 : 0.017196400091052055
Loss at batch 50 : 0.011332469992339611
Loss at batch 60 : 0.011006212793290615
Loss at batch 70 : 0.01648217998445034
Loss at batch 80 : 0.00985511764883995
Loss at batch 90 : 0.008151056244969368
Loss at batch 100 : 0.009557054378092289
Loss at batch 110 : 0.013625229708850384
Loss at batch 120 : 0.009541153907775879
Loss at batch 130 : 0.009970094077289104
Loss at batch 140 : 0.019590949639678
Loss at batch 150 : 0.015555218793451786
Loss at batch 160 : 0.01207698043435812
Loss at batch 170 : 0.009842809289693832
Loss at batch 180 : 0.013763287104666233
Loss at batch 190 : 0.013937671668827534
Loss at batch 200 : 0.01547334250062704
Loss at batch 210 : 0.01875574141740799
Loss at batch 220 : 0.008776878006756306
Loss at batch 230 : 0.016301510855555534
Loss at batch 240 : 0.012320245616137981
Loss at batch 250 : 0.018949173390865326
Loss at batch 260 : 0.008099483326077461
Loss at batch 270 : 0.014628459699451923
Loss at batch 280 : 0.011317219585180283
Loss at batch 290 : 0.01865658350288868
Loss at batch 300 : 0.010561185888946056
Loss at batch 310 : 0.019948219880461693
Loss at batch 320 : 0.017285384237766266
Loss at batch 330 : 0.006611039862036705
Loss at batch 340 : 0.012262226082384586
Loss at batch 350 : 0.017128096893429756
Loss at batch 360 : 0.017058201134204865
Loss at batch 370 : 0.024564675986766815
epoch45 finished!
Loss at batch 10 : 0.013357152231037617
Loss at batch 20 : 0.005893330089747906
Loss at batch 30 : 0.012710302136838436
Loss at batch 40 : 0.008299967274069786
Loss at batch 50 : 0.023521292954683304
Loss at batch 60 : 0.022555992007255554
Loss at batch 70 : 0.015703463926911354
Loss at batch 80 : 0.012760361656546593
Loss at batch 90 : 0.019422199577093124
Loss at batch 100 : 0.017374373972415924
Loss at batch 110 : 0.019379056990146637
Loss at batch 120 : 0.030793391168117523
Loss at batch 130 : 0.013185112737119198
Loss at batch 140 : 0.012583442963659763
Loss at batch 150 : 0.01647346094250679
Loss at batch 160 : 0.01823584921658039
Loss at batch 170 : 0.011580212041735649
Loss at batch 180 : 0.01628546230494976
Loss at batch 190 : 0.017543910071253777
Loss at batch 200 : 0.011167755350470543
Loss at batch 210 : 0.01646368019282818
Loss at batch 220 : 0.01152819488197565
Loss at batch 230 : 0.01243452075868845
Loss at batch 240 : 0.027878329157829285
Loss at batch 250 : 0.011777208186686039
Loss at batch 260 : 0.007857361808419228
Loss at batch 270 : 0.01214439608156681
Loss at batch 280 : 0.009988099336624146
Loss at batch 290 : 0.0182594396173954
Loss at batch 300 : 0.01750227063894272
Loss at batch 310 : 0.018031861633062363
Loss at batch 320 : 0.010050519369542599
Loss at batch 330 : 0.013844276778399944
Loss at batch 340 : 0.011947909370064735
Loss at batch 350 : 0.015749409794807434
Loss at batch 360 : 0.017620794475078583
Loss at batch 370 : 0.014551147818565369
epoch101 finished!
Loss at batch 10 : 0.012343517504632473
Loss at batch 20 : 0.010211491957306862
Loss at batch 30 : 0.02145792916417122
Loss at batch 40 : 0.0101523632183671
Loss at batch 50 : 0.010514521040022373
Loss at batch 60 : 0.011523823253810406
Loss at batch 70 : 0.016606230288743973
Loss at batch 80 : 0.018721075728535652
Loss at batch 90 : 0.013764153234660625
Loss at batch 100 : 0.02499621920287609
Loss at batch 110 : 0.017309237271547318
Loss at batch 120 : 0.012637513689696789
Loss at batch 130 : 0.009502156637609005
Loss at batch 140 : 0.009579474106431007
Loss at batch 150 : 0.012910634279251099
Loss at batch 160 : 0.022540483623743057
Loss at batch 170 : 0.01099663507193327
Loss at batch 180 : 0.017580285668373108
Loss at batch 190 : 0.00996376946568489
Loss at batch 200 : 0.010590914636850357
Loss at batch 210 : 0.021723739802837372
Loss at batch 220 : 0.011729380115866661
Loss at batch 230 : 0.017931299284100533
Loss at batch 240 : 0.00761872623115778
Loss at batch 250 : 0.011229479685425758
Loss at batch 260 : 0.020189685747027397
Loss at batch 270 : 0.01251924317330122
Loss at batch 280 : 0.01671690307557583
Loss at batch 290 : 0.014885369688272476
Loss at batch 300 : 0.012309684418141842
Loss at batch 310 : 0.012890207581222057
Loss at batch 320 : 0.012457574717700481
Loss at batch 330 : 0.019089117646217346
Loss at batch 340 : 0.019406571984291077
Loss at batch 350 : 0.011688720434904099
Loss at batch 360 : 0.011397006921470165
Loss at batch 370 : 0.009676605463027954
epoch102 finished!
Loss at batch 10 : 0.009100541472434998
Loss at batch 20 : 0.012802439741790295
Loss at batch 30 : 0.012970291078090668
Loss at batch 40 : 0.016696985810995102
Loss at batch 50 : 0.024488314986228943
Loss at batch 60 : 0.01661650836467743
Loss at batch 70 : 0.021840034052729607
Loss at batch 80 : 0.013929207809269428
Loss at batch 90 : 0.01705053448677063
Loss at batch 100 : 0.014581030234694481
Loss at batch 110 : 0.020789479836821556
Loss at batch 120 : 0.018390526995062828
Loss at batch 130 : 0.014174316078424454
Loss at batch 140 : 0.017666984349489212
Loss at batch 150 : 0.019521813839673996
Loss at batch 160 : 0.023849371820688248
Loss at batch 170 : 0.010779811069369316
Loss at batch 180 : 0.009773792698979378
Loss at batch 190 : 0.024315012618899345
Loss at batch 200 : 0.012534694746136665
Loss at batch 210 : 0.00902404822409153
Loss at batch 220 : 0.008414817973971367
Loss at batch 230 : 0.009318273514509201
Loss at batch 240 : 0.019486838951706886
Loss at batch 250 : 0.018948324024677277
Loss at batch 260 : 0.014206036925315857
Loss at batch 270 : 0.015255328267812729
Loss at batch 280 : 0.01407967135310173
Loss at batch 290 : 0.016983618959784508
Loss at batch 300 : 0.022762099280953407
Loss at batch 310 : 0.009883377701044083
Loss at batch 320 : 0.011523452587425709
Loss at batch 330 : 0.007847982458770275
Loss at batch 340 : 0.016978172585368156
Loss at batch 350 : 0.02902131713926792
Loss at batch 360 : 0.017871573567390442
Loss at batch 370 : 0.011917213909327984
epoch46 finished!
Loss at batch 10 : 0.01817590929567814
Loss at batch 20 : 0.008335224352777004
Loss at batch 30 : 0.011229055002331734
Loss at batch 40 : 0.008876463398337364
Loss at batch 50 : 0.014499891549348831
Loss at batch 60 : 0.010439500212669373
Loss at batch 70 : 0.02094648964703083
Loss at batch 80 : 0.012609807774424553
Loss at batch 90 : 0.0096945995464921
Loss at batch 100 : 0.009232471697032452
Loss at batch 110 : 0.01559340488165617
Loss at batch 120 : 0.010022173635661602
Loss at batch 130 : 0.015933599323034286
Loss at batch 140 : 0.010972153395414352
Loss at batch 150 : 0.0066069019958376884
Loss at batch 160 : 0.012118536978960037
Loss at batch 170 : 0.01306468527764082
Loss at batch 180 : 0.024420030415058136
Loss at batch 190 : 0.012041187845170498
Loss at batch 200 : 0.01347357127815485
Loss at batch 210 : 0.010098804719746113
Loss at batch 220 : 0.01647273078560829
Loss at batch 230 : 0.013272460550069809
Loss at batch 240 : 0.01730206608772278
Loss at batch 250 : 0.019984200596809387
Loss at batch 260 : 0.012828738428652287
Loss at batch 270 : 0.009174242615699768
Loss at batch 280 : 0.01645614579319954
Loss at batch 290 : 0.015665395185351372
Loss at batch 300 : 0.01584225334227085
Loss at batch 310 : 0.02090226486325264
Loss at batch 320 : 0.023927951231598854
Loss at batch 330 : 0.00935958232730627
Loss at batch 340 : 0.011540559120476246
Loss at batch 350 : 0.013654062524437904
Loss at batch 360 : 0.010598009452223778
Loss at batch 370 : 0.013598064891994
epoch46 finished!
Loss at batch 10 : 0.008234168402850628
Loss at batch 20 : 0.007719286251813173
Loss at batch 30 : 0.013757044449448586
Loss at batch 40 : 0.012615508399903774
Loss at batch 50 : 0.012450174428522587
Loss at batch 60 : 0.015543842688202858
Loss at batch 70 : 0.010584483854472637
Loss at batch 80 : 0.007696008775383234
Loss at batch 90 : 0.009078987874090672
Loss at batch 100 : 0.016943471506237984
Loss at batch 110 : 0.010330424644052982
Loss at batch 120 : 0.019507354125380516
Loss at batch 130 : 0.019237082451581955
Loss at batch 140 : 0.022013848647475243
Loss at batch 150 : 0.0160899106413126
Loss at batch 160 : 0.017454665154218674
Loss at batch 170 : 0.020312704145908356
Loss at batch 180 : 0.009034483693540096
Loss at batch 190 : 0.016241038218140602
Loss at batch 200 : 0.02525976672768593
Loss at batch 210 : 0.027737075462937355
Loss at batch 220 : 0.007346589583903551
Loss at batch 230 : 0.015014461241662502
Loss at batch 240 : 0.011699958704411983
Loss at batch 250 : 0.005617040209472179
Loss at batch 260 : 0.013868207111954689
Loss at batch 270 : 0.025375911965966225
Loss at batch 280 : 0.011400880292057991
Loss at batch 290 : 0.014877846464514732
Loss at batch 300 : 0.011067994870245457
Loss at batch 310 : 0.011857747100293636
Loss at batch 320 : 0.016657931730151176
Loss at batch 330 : 0.014506321400403976
Loss at batch 340 : 0.014494762755930424
Loss at batch 350 : 0.011203638277947903
Loss at batch 360 : 0.016198426485061646
Loss at batch 370 : 0.017047761008143425
epoch103 finished!
Loss at batch 10 : 0.018216973170638084
Loss at batch 20 : 0.023663299158215523
Loss at batch 30 : 0.015152649022638798
Loss at batch 40 : 0.00972224771976471
Loss at batch 50 : 0.012025059200823307
Loss at batch 60 : 0.009164673276245594
Loss at batch 70 : 0.01970517821609974
Loss at batch 80 : 0.01514729205518961
Loss at batch 90 : 0.012681611813604832
Loss at batch 100 : 0.02074524015188217
Loss at batch 110 : 0.022420184686779976
Loss at batch 120 : 0.01887202076613903
Loss at batch 130 : 0.012513794004917145
Loss at batch 140 : 0.013807418756186962
Loss at batch 150 : 0.012945578433573246
Loss at batch 160 : 0.008080780506134033
Loss at batch 170 : 0.007062753662467003
Loss at batch 180 : 0.017316021025180817
Loss at batch 190 : 0.01016702689230442
Loss at batch 200 : 0.013170523568987846
Loss at batch 210 : 0.016855770722031593
Loss at batch 220 : 0.010394150391221046
Loss at batch 230 : 0.009894992224872112
Loss at batch 240 : 0.011041519232094288
Loss at batch 250 : 0.014762136153876781
Loss at batch 260 : 0.007981027476489544
Loss at batch 270 : 0.009742002934217453
Loss at batch 280 : 0.017561187967658043
Loss at batch 290 : 0.022332800552248955
Loss at batch 300 : 0.0141903692856431
Loss at batch 310 : 0.015587612986564636
Loss at batch 320 : 0.026715634390711784
Loss at batch 330 : 0.012787701562047005
Loss at batch 340 : 0.00793086364865303
Loss at batch 350 : 0.03012005425989628
Loss at batch 360 : 0.010900947265326977
Loss at batch 370 : 0.01921311393380165
epoch104 finished!
Loss at batch 10 : 0.015575208701193333
Loss at batch 20 : 0.017443493008613586
Loss at batch 30 : 0.011728852055966854
Loss at batch 40 : 0.011128949001431465
Loss at batch 50 : 0.022891974076628685
Loss at batch 60 : 0.00802134070545435
Loss at batch 70 : 0.00891236774623394
Loss at batch 80 : 0.01934581995010376
Loss at batch 90 : 0.010166523046791553
Loss at batch 100 : 0.029230285435914993
Loss at batch 110 : 0.010907154530286789
Loss at batch 120 : 0.023676104843616486
Loss at batch 130 : 0.008861405774950981
Loss at batch 140 : 0.01657988131046295
Loss at batch 150 : 0.013441688381135464
Loss at batch 160 : 0.01332874782383442
Loss at batch 170 : 0.009688254445791245
Loss at batch 180 : 0.012073982506990433
Loss at batch 190 : 0.024413546547293663
Loss at batch 200 : 0.014764624647796154
Loss at batch 210 : 0.013810121454298496
Loss at batch 220 : 0.022768201306462288
Loss at batch 230 : 0.02994011901319027
Loss at batch 240 : 0.03295448049902916
Loss at batch 250 : 0.01079331524670124
Loss at batch 260 : 0.0102462749928236
Loss at batch 270 : 0.006994479335844517
Loss at batch 280 : 0.015494681894779205
Loss at batch 290 : 0.025637725368142128
Loss at batch 300 : 0.009263780899345875
Loss at batch 310 : 0.009564829990267754
Loss at batch 320 : 0.029745446518063545
Loss at batch 330 : 0.017436835914850235
Loss at batch 340 : 0.01793844625353813
Loss at batch 350 : 0.018322184681892395
Loss at batch 360 : 0.017482228577136993
Loss at batch 370 : 0.02918059751391411
epoch47 finished!
Loss at batch 10 : 0.010287736542522907
Loss at batch 20 : 0.02417507953941822
Loss at batch 30 : 0.014864201657474041
Loss at batch 40 : 0.021152494475245476
Loss at batch 50 : 0.011017687618732452
Loss at batch 60 : 0.010905108414590359
Loss at batch 70 : 0.011840155348181725
Loss at batch 80 : 0.023252420127391815
Loss at batch 90 : 0.01748139038681984
Loss at batch 100 : 0.015878532081842422
Loss at batch 110 : 0.010262900963425636
Loss at batch 120 : 0.013735010288655758
Loss at batch 130 : 0.020811881870031357
Loss at batch 140 : 0.019958416000008583
Loss at batch 150 : 0.018491825088858604
Loss at batch 160 : 0.009952418506145477
Loss at batch 170 : 0.017701782286167145
Loss at batch 180 : 0.014579732902348042
Loss at batch 190 : 0.011492587625980377
Loss at batch 200 : 0.0069676670245826244
Loss at batch 210 : 0.01619087904691696
Loss at batch 220 : 0.01031446922570467
Loss at batch 230 : 0.012756953947246075
Loss at batch 240 : 0.014457429759204388
Loss at batch 250 : 0.01039655227214098
Loss at batch 260 : 0.013668233528733253
Loss at batch 270 : 0.024627968668937683
Loss at batch 280 : 0.021310562267899513
Loss at batch 290 : 0.0179001372307539
Loss at batch 300 : 0.013266746886074543
Loss at batch 310 : 0.01921558380126953
Loss at batch 320 : 0.014971479773521423
Loss at batch 330 : 0.017583154141902924
Loss at batch 340 : 0.020125914365053177
Loss at batch 350 : 0.01255298312753439
Loss at batch 360 : 0.015130988322198391
Loss at batch 370 : 0.00937514565885067
epoch47 finished!
Loss at batch 10 : 0.016210565343499184
Loss at batch 20 : 0.01568121463060379
Loss at batch 30 : 0.008274241350591183
Loss at batch 40 : 0.02066965401172638
Loss at batch 50 : 0.01583407260477543
Loss at batch 60 : 0.015169947408139706
Loss at batch 70 : 0.01357957348227501
Loss at batch 80 : 0.005459369160234928
Loss at batch 90 : 0.017812320962548256
Loss at batch 100 : 0.01336915697902441
Loss at batch 110 : 0.01379006914794445
Loss at batch 120 : 0.012960153631865978
Loss at batch 130 : 0.00966543611139059
Loss at batch 140 : 0.013882463797926903
Loss at batch 150 : 0.014202116057276726
Loss at batch 160 : 0.020428407937288284
Loss at batch 170 : 0.012935697101056576
Loss at batch 180 : 0.01981438882648945
Loss at batch 190 : 0.01404157280921936
Loss at batch 200 : 0.017502041533589363
Loss at batch 210 : 0.010844391770660877
Loss at batch 220 : 0.010311055928468704
Loss at batch 230 : 0.009638777934014797
Loss at batch 240 : 0.01718621701002121
Loss at batch 250 : 0.018140865489840508
Loss at batch 260 : 0.011761165224015713
Loss at batch 270 : 0.00902644731104374
Loss at batch 280 : 0.03270481154322624
Loss at batch 290 : 0.012274417094886303
Loss at batch 300 : 0.016261160373687744
Loss at batch 310 : 0.018572263419628143
Loss at batch 320 : 0.01610909216105938
Loss at batch 330 : 0.012885920703411102
Loss at batch 340 : 0.017344865947961807
Loss at batch 350 : 0.026136228814721107
Loss at batch 360 : 0.01580597646534443
Loss at batch 370 : 0.019896266981959343
epoch105 finished!
Loss at batch 10 : 0.008876465260982513
Loss at batch 20 : 0.02566554956138134
Loss at batch 30 : 0.010469095781445503
Loss at batch 40 : 0.010388133116066456
Loss at batch 50 : 0.01075545884668827
Loss at batch 60 : 0.012441994622349739
Loss at batch 70 : 0.017046544700860977
Loss at batch 80 : 0.007883942686021328
Loss at batch 90 : 0.017998866736888885
Loss at batch 100 : 0.013031571172177792
Loss at batch 110 : 0.008386174216866493
Loss at batch 120 : 0.007710147649049759
Loss at batch 130 : 0.016973255202174187
Loss at batch 140 : 0.01773208938539028
Loss at batch 150 : 0.01623396761715412
Loss at batch 160 : 0.020536616444587708
Loss at batch 170 : 0.014896759763360023
Loss at batch 180 : 0.010044405236840248
Loss at batch 190 : 0.025354240089654922
Loss at batch 200 : 0.017259059473872185
Loss at batch 210 : 0.021926650777459145
Loss at batch 220 : 0.021696876734495163
Loss at batch 230 : 0.0195891335606575
Loss at batch 240 : 0.009798387065529823
Loss at batch 250 : 0.015614465810358524
Loss at batch 260 : 0.018478846177458763
Loss at batch 270 : 0.018665332347154617
Loss at batch 280 : 0.016218600794672966
Loss at batch 290 : 0.01368482131510973
Loss at batch 300 : 0.02476697415113449
Loss at batch 310 : 0.013392128981649876
Loss at batch 320 : 0.025730924680829048
Loss at batch 330 : 0.01774280145764351
Loss at batch 340 : 0.00901806727051735
Loss at batch 350 : 0.024175839498639107
Loss at batch 360 : 0.01042609941214323
Loss at batch 370 : 0.01729760877788067
epoch106 finished!
Loss at batch 10 : 0.010535593144595623
Loss at batch 20 : 0.011433186009526253
Loss at batch 30 : 0.010092989541590214
Loss at batch 40 : 0.028590258210897446
Loss at batch 50 : 0.01376189012080431
Loss at batch 60 : 0.010634255595505238
Loss at batch 70 : 0.010108178481459618
Loss at batch 80 : 0.017950765788555145
Loss at batch 90 : 0.013513915240764618
Loss at batch 100 : 0.023340102285146713
Loss at batch 110 : 0.026812992990016937
Loss at batch 120 : 0.01374242827296257
Loss at batch 130 : 0.011970972642302513
Loss at batch 140 : 0.02399200014770031
Loss at batch 150 : 0.0104302316904068
Loss at batch 160 : 0.01699851267039776
Loss at batch 170 : 0.012933824211359024
Loss at batch 180 : 0.012390488758683205
Loss at batch 190 : 0.013202663511037827
Loss at batch 200 : 0.016833577305078506
Loss at batch 210 : 0.012256796471774578
Loss at batch 220 : 0.016571547836065292
Loss at batch 230 : 0.0076357354409992695
Loss at batch 240 : 0.01311125885695219
Loss at batch 250 : 0.017733072862029076
Loss at batch 260 : 0.014122052118182182
Loss at batch 270 : 0.029581062495708466
Loss at batch 280 : 0.018013756722211838
Loss at batch 290 : 0.014439565129578114
Loss at batch 300 : 0.013093075715005398
Loss at batch 310 : 0.01175959687680006
Loss at batch 320 : 0.012008482590317726
Loss at batch 330 : 0.028193004429340363
Loss at batch 340 : 0.009414366446435452
Loss at batch 350 : 0.014522843062877655
Loss at batch 360 : 0.008892018347978592
Loss at batch 370 : 0.010176759213209152
epoch48 finished!
Loss at batch 10 : 0.009214037097990513
Loss at batch 20 : 0.017402850091457367
Loss at batch 30 : 0.010335549712181091
Loss at batch 40 : 0.01753038726747036
Loss at batch 50 : 0.019593773409724236
Loss at batch 60 : 0.015934742987155914
Loss at batch 70 : 0.01260248851031065
Loss at batch 80 : 0.011268765665590763
Loss at batch 90 : 0.007184610236436129
Loss at batch 100 : 0.013290916569530964
Loss at batch 110 : 0.01017727330327034
Loss at batch 120 : 0.009400381706655025
Loss at batch 130 : 0.02326408214867115
Loss at batch 140 : 0.014534859918057919
Loss at batch 150 : 0.02128806710243225
Loss at batch 160 : 0.008031697943806648
Loss at batch 170 : 0.012992939911782742
Loss at batch 180 : 0.03405994176864624
Loss at batch 190 : 0.016576580703258514
Loss at batch 200 : 0.011663505807518959
Loss at batch 210 : 0.008542903698980808
Loss at batch 220 : 0.015439874492585659
Loss at batch 230 : 0.01924608275294304
Loss at batch 240 : 0.019670609384775162
Loss at batch 250 : 0.012025536969304085
Loss at batch 260 : 0.011909584514796734
Loss at batch 270 : 0.00837641954421997
Loss at batch 280 : 0.02185129001736641
Loss at batch 290 : 0.011877788230776787
Loss at batch 300 : 0.016050897538661957
Loss at batch 310 : 0.01870267279446125
Loss at batch 320 : 0.010344764217734337
Loss at batch 330 : 0.01525846030563116
Loss at batch 340 : 0.011412658728659153
Loss at batch 350 : 0.01103832945227623
Loss at batch 360 : 0.022219916805624962
Loss at batch 370 : 0.008591185323894024
epoch107 finished!
Loss at batch 10 : 0.013654668815433979
Loss at batch 20 : 0.015482529997825623
Loss at batch 30 : 0.009456965140998363
Loss at batch 40 : 0.008693809621036053
Loss at batch 50 : 0.018458805978298187
Loss at batch 60 : 0.013061466626822948
Loss at batch 70 : 0.014643542468547821
Loss at batch 80 : 0.008150666020810604
Loss at batch 90 : 0.012020861729979515
Loss at batch 100 : 0.009886406362056732
Loss at batch 110 : 0.009217722341418266
Loss at batch 120 : 0.009546433575451374
Loss at batch 130 : 0.01888187788426876
Loss at batch 140 : 0.01974376104772091
Loss at batch 150 : 0.027328362688422203
Loss at batch 160 : 0.010026250034570694
Loss at batch 170 : 0.008092055097222328
Loss at batch 180 : 0.015294581651687622
Loss at batch 190 : 0.009841804392635822
Loss at batch 200 : 0.017709653824567795
Loss at batch 210 : 0.009823475033044815
Loss at batch 220 : 0.012253189459443092
Loss at batch 230 : 0.018027372658252716
Loss at batch 240 : 0.017898956313729286
Loss at batch 250 : 0.011171048507094383
Loss at batch 260 : 0.02906116098165512
Loss at batch 270 : 0.009409532882273197
Loss at batch 280 : 0.01516806147992611
Loss at batch 290 : 0.020951300859451294
Loss at batch 300 : 0.023411884903907776
Loss at batch 310 : 0.024192968383431435
Loss at batch 320 : 0.008185225538909435
Loss at batch 330 : 0.008484488353133202
Loss at batch 340 : 0.008360348641872406
Loss at batch 350 : 0.00971605721861124
Loss at batch 360 : 0.011954559944570065
Loss at batch 370 : 0.013897277414798737
epoch48 finished!
Loss at batch 10 : 0.017721230164170265
Loss at batch 20 : 0.008515172637999058
Loss at batch 30 : 0.015135621652007103
Loss at batch 40 : 0.006830323487520218
Loss at batch 50 : 0.012340161018073559
Loss at batch 60 : 0.010928712785243988
Loss at batch 70 : 0.012036807835102081
Loss at batch 80 : 0.00578717514872551
Loss at batch 90 : 0.007418486289680004
Loss at batch 100 : 0.009086960926651955
Loss at batch 110 : 0.028614375740289688
Loss at batch 120 : 0.016724316403269768
Loss at batch 130 : 0.020120738074183464
Loss at batch 140 : 0.009936845861375332
Loss at batch 150 : 0.012465586885809898
Loss at batch 160 : 0.013219382613897324
Loss at batch 170 : 0.024513360112905502
Loss at batch 180 : 0.010937671177089214
Loss at batch 190 : 0.013418201357126236
Loss at batch 200 : 0.006853155791759491
Loss at batch 210 : 0.02345575951039791
Loss at batch 220 : 0.009895856492221355
Loss at batch 230 : 0.025611454620957375
Loss at batch 240 : 0.01244285423308611
Loss at batch 250 : 0.01258082315325737
Loss at batch 260 : 0.01603030227124691
Loss at batch 270 : 0.011634916067123413
Loss at batch 280 : 0.01635405793786049
Loss at batch 290 : 0.011432378552854061
Loss at batch 300 : 0.011670451611280441
Loss at batch 310 : 0.023791572079062462
Loss at batch 320 : 0.011449193581938744
Loss at batch 330 : 0.02023005671799183
Loss at batch 340 : 0.01182552333921194
Loss at batch 350 : 0.01056861411780119
Loss at batch 360 : 0.012601636350154877
Loss at batch 370 : 0.012186292558908463
epoch108 finished!
Loss at batch 10 : 0.013664303347468376
Loss at batch 20 : 0.013131339102983475
Loss at batch 30 : 0.013853147625923157
Loss at batch 40 : 0.011927956715226173
Loss at batch 50 : 0.014186921529471874
Loss at batch 60 : 0.010313194245100021
Loss at batch 70 : 0.01282521802932024
Loss at batch 80 : 0.021995408460497856
Loss at batch 90 : 0.021884674206376076
Loss at batch 100 : 0.01150955818593502
Loss at batch 110 : 0.01500280387699604
Loss at batch 120 : 0.015941167250275612
Loss at batch 130 : 0.010296717286109924
Loss at batch 140 : 0.025400079786777496
Loss at batch 150 : 0.008079662919044495
Loss at batch 160 : 0.019261835142970085
Loss at batch 170 : 0.012890047393739223
Loss at batch 180 : 0.014836975373327732
Loss at batch 190 : 0.01708231307566166
Loss at batch 200 : 0.01863909885287285
Loss at batch 210 : 0.011050189845263958
Loss at batch 220 : 0.01941823773086071
Loss at batch 230 : 0.01193351112306118
Loss at batch 240 : 0.010441455990076065
Loss at batch 250 : 0.015928445383906364
Loss at batch 260 : 0.011669127270579338
Loss at batch 270 : 0.01593368500471115
Loss at batch 280 : 0.01353221945464611
Loss at batch 290 : 0.012572954408824444
Loss at batch 300 : 0.011455249041318893
Loss at batch 310 : 0.016767386347055435
Loss at batch 320 : 0.014290282502770424
Loss at batch 330 : 0.014741144143044949
Loss at batch 340 : 0.007033694535493851
Loss at batch 350 : 0.022389249876141548
Loss at batch 360 : 0.014620745554566383
Loss at batch 370 : 0.011055376380681992
epoch109 finished!
Loss at batch 10 : 0.023392708972096443
Loss at batch 20 : 0.012884345836937428
Loss at batch 30 : 0.019216863438487053
Loss at batch 40 : 0.009968113154172897
Loss at batch 50 : 0.022621888667345047
Loss at batch 60 : 0.03084811568260193
Loss at batch 70 : 0.015687013044953346
Loss at batch 80 : 0.011469033546745777
Loss at batch 90 : 0.013805897906422615
Loss at batch 100 : 0.022470623254776
Loss at batch 110 : 0.011869406327605247
Loss at batch 120 : 0.01106445025652647
Loss at batch 130 : 0.012309269979596138
Loss at batch 140 : 0.0112284105271101
Loss at batch 150 : 0.012317490763962269
Loss at batch 160 : 0.016599858179688454
Loss at batch 170 : 0.012091048061847687
Loss at batch 180 : 0.016125338152050972
Loss at batch 190 : 0.01762799359858036
Loss at batch 200 : 0.01670810766518116
Loss at batch 210 : 0.018540041521191597
Loss at batch 220 : 0.011049122549593449
Loss at batch 230 : 0.021900460124015808
Loss at batch 240 : 0.017795778810977936
Loss at batch 250 : 0.009271509945392609
Loss at batch 260 : 0.01132187433540821
Loss at batch 270 : 0.010871073231101036
Loss at batch 280 : 0.016885321587324142
Loss at batch 290 : 0.02625269442796707
Loss at batch 300 : 0.015716932713985443
Loss at batch 310 : 0.011818481609225273
Loss at batch 320 : 0.009278854355216026
Loss at batch 330 : 0.01893729344010353
Loss at batch 340 : 0.00865861214697361
Loss at batch 350 : 0.014432944357395172
Loss at batch 360 : 0.010877561755478382
Loss at batch 370 : 0.014334739185869694
epoch49 finished!
Loss at batch 10 : 0.012135512195527554
Loss at batch 20 : 0.019871948286890984
Loss at batch 30 : 0.031326811760663986
Loss at batch 40 : 0.011403268203139305
Loss at batch 50 : 0.007574171759188175
Loss at batch 60 : 0.017000216990709305
Loss at batch 70 : 0.009988921694457531
Loss at batch 80 : 0.01604316383600235
Loss at batch 90 : 0.025498688220977783
Loss at batch 100 : 0.020800573751330376
Loss at batch 110 : 0.014258273877203465
Loss at batch 120 : 0.011946848593652248
Loss at batch 130 : 0.016126440837979317
Loss at batch 140 : 0.01762036234140396
Loss at batch 150 : 0.012896614149212837
Loss at batch 160 : 0.026780124753713608
Loss at batch 170 : 0.013054910115897655
Loss at batch 180 : 0.008617582730948925
Loss at batch 190 : 0.0112849036231637
Loss at batch 200 : 0.01603337563574314
Loss at batch 210 : 0.011882945895195007
Loss at batch 220 : 0.012995535507798195
Loss at batch 230 : 0.015388787724077702
Loss at batch 240 : 0.01201553549617529
Loss at batch 250 : 0.010019305162131786
Loss at batch 260 : 0.022628813982009888
Loss at batch 270 : 0.010661023668944836
Loss at batch 280 : 0.016446053981781006
Loss at batch 290 : 0.021039031445980072
Loss at batch 300 : 0.009128140285611153
Loss at batch 310 : 0.01723170466721058
Loss at batch 320 : 0.0072392974980175495
Loss at batch 330 : 0.01225912943482399
Loss at batch 340 : 0.011137455701828003
Loss at batch 350 : 0.02372051030397415
Loss at batch 360 : 0.010642928071320057
Loss at batch 370 : 0.012884875759482384
epoch49 finished!
Loss at batch 10 : 0.012606448493897915
Loss at batch 20 : 0.010438795201480389
Loss at batch 30 : 0.016433076933026314
Loss at batch 40 : 0.015969283878803253
Loss at batch 50 : 0.015598797239363194
Loss at batch 60 : 0.009424002841114998
Loss at batch 70 : 0.013063217513263226
Loss at batch 80 : 0.010050720535218716
Loss at batch 90 : 0.012560968287289143
Loss at batch 100 : 0.012078845873475075
Loss at batch 110 : 0.006327544339001179
Loss at batch 120 : 0.021783705800771713
Loss at batch 130 : 0.010775496251881123
Loss at batch 140 : 0.012289882637560368
Loss at batch 150 : 0.01607513800263405
Loss at batch 160 : 0.009327213279902935
Loss at batch 170 : 0.013935617171227932
Loss at batch 180 : 0.016443917527794838
Loss at batch 190 : 0.014820744283497334
Loss at batch 200 : 0.011710655875504017
Loss at batch 210 : 0.0185529887676239
Loss at batch 220 : 0.017444469034671783
Loss at batch 230 : 0.011611578054726124
Loss at batch 240 : 0.018582019954919815
Loss at batch 250 : 0.01371737290173769
Loss at batch 260 : 0.014351243153214455
Loss at batch 270 : 0.010580463334918022
Loss at batch 280 : 0.013296852819621563
Loss at batch 290 : 0.010800548829138279
Loss at batch 300 : 0.008261916227638721
Loss at batch 310 : 0.009675631299614906
Loss at batch 320 : 0.01083658542484045
Loss at batch 330 : 0.009423554874956608
Loss at batch 340 : 0.010862399823963642
Loss at batch 350 : 0.016086431220173836
Loss at batch 360 : 0.013214142993092537
Loss at batch 370 : 0.012627784162759781
epoch110 finished!
Loss at batch 10 : 0.009933345951139927
Loss at batch 20 : 0.027819693088531494
Loss at batch 30 : 0.018005885183811188
Loss at batch 40 : 0.01143595576286316
Loss at batch 50 : 0.014475998468697071
Loss at batch 60 : 0.02347247488796711
Loss at batch 70 : 0.017456678673624992
Loss at batch 80 : 0.016953248530626297
Loss at batch 90 : 0.008029801771044731
Loss at batch 100 : 0.01347094215452671
Loss at batch 110 : 0.008832903578877449
Loss at batch 120 : 0.023720309138298035
Loss at batch 130 : 0.017952177673578262
Loss at batch 140 : 0.01592119038105011
Loss at batch 150 : 0.02101600356400013
Loss at batch 160 : 0.010772926732897758
Loss at batch 170 : 0.008684382773935795
Loss at batch 180 : 0.015881001949310303
Loss at batch 190 : 0.011149766854941845
Loss at batch 200 : 0.012340961024165154
Loss at batch 210 : 0.012024540454149246
Loss at batch 220 : 0.011274558492004871
Loss at batch 230 : 0.011483103968203068
Loss at batch 240 : 0.016085362061858177
Loss at batch 250 : 0.018521269783377647
Loss at batch 260 : 0.015508481301367283
Loss at batch 270 : 0.0062820627354085445
Loss at batch 280 : 0.02762317657470703
Loss at batch 290 : 0.014578054659068584
Loss at batch 300 : 0.010705823078751564
Loss at batch 310 : 0.017503028735518456
Loss at batch 320 : 0.016650274395942688
Loss at batch 330 : 0.011399089358747005
Loss at batch 340 : 0.011654720641672611
Loss at batch 350 : 0.005409355740994215
Loss at batch 360 : 0.012366153299808502
Loss at batch 370 : 0.009473088197410107
epoch111 finished!
Loss at batch 10 : 0.019750341773033142
Loss at batch 20 : 0.02465633861720562
Loss at batch 30 : 0.010346818715333939
Loss at batch 40 : 0.012867442332208157
Loss at batch 50 : 0.016864487901329994
Loss at batch 60 : 0.016789143905043602
Loss at batch 70 : 0.012652616016566753
Loss at batch 80 : 0.014862067066133022
Loss at batch 90 : 0.005304859019815922
Loss at batch 100 : 0.012861067429184914
Loss at batch 110 : 0.00995184388011694
Loss at batch 120 : 0.013553558848798275
Loss at batch 130 : 0.018281996250152588
Loss at batch 140 : 0.018475515767931938
Loss at batch 150 : 0.013717993162572384
Loss at batch 160 : 0.019010057672858238
Loss at batch 170 : 0.013240956701338291
Loss at batch 180 : 0.023222045972943306
Loss at batch 190 : 0.013342013582587242
Loss at batch 200 : 0.014457262121140957
Loss at batch 210 : 0.01779118925333023
Loss at batch 220 : 0.015043794177472591
Loss at batch 230 : 0.021753158420324326
Loss at batch 240 : 0.017128581181168556
Loss at batch 250 : 0.015706876292824745
Loss at batch 260 : 0.014385498128831387
Loss at batch 270 : 0.018154798075556755
Loss at batch 280 : 0.014231833629310131
Loss at batch 290 : 0.02198563702404499
Loss at batch 300 : 0.014958537183701992
Loss at batch 310 : 0.01309874001890421
Loss at batch 320 : 0.008102811872959137
Loss at batch 330 : 0.014474456198513508
Loss at batch 340 : 0.013916293159127235
Loss at batch 350 : 0.010537254624068737
Loss at batch 360 : 0.0123812360689044
Loss at batch 370 : 0.012016885913908482
epoch50 finished!
Loss at batch 10 : 0.010059257969260216
Loss at batch 20 : 0.017371241003274918
Loss at batch 30 : 0.015244542621076107
Loss at batch 40 : 0.011623945087194443
Loss at batch 50 : 0.011171065270900726
Loss at batch 60 : 0.015940483659505844
Loss at batch 70 : 0.02423350140452385
Loss at batch 80 : 0.014583629556000233
Loss at batch 90 : 0.019321879372000694
Loss at batch 100 : 0.013520438224077225
Loss at batch 110 : 0.014253444969654083
Loss at batch 120 : 0.013184449635446072
Loss at batch 130 : 0.009192060679197311
Loss at batch 140 : 0.017244165763258934
Loss at batch 150 : 0.011247342452406883
Loss at batch 160 : 0.013546857051551342
Loss at batch 170 : 0.011664601974189281
Loss at batch 180 : 0.012975488789379597
Loss at batch 190 : 0.012981793843209743
Loss at batch 200 : 0.025498559698462486
Loss at batch 210 : 0.014636155217885971
Loss at batch 220 : 0.011022811755537987
Loss at batch 230 : 0.026224806904792786
Loss at batch 240 : 0.012519738636910915
Loss at batch 250 : 0.01623670756816864
Loss at batch 260 : 0.01833360455930233
Loss at batch 270 : 0.013133030384778976
Loss at batch 280 : 0.016736414283514023
Loss at batch 290 : 0.013943902216851711
Loss at batch 300 : 0.011790781281888485
Loss at batch 310 : 0.011260529980063438
Loss at batch 320 : 0.017700813710689545
Loss at batch 330 : 0.025491422042250633
Loss at batch 340 : 0.017089968547225
Loss at batch 350 : 0.012600170448422432
Loss at batch 360 : 0.008945051580667496
Loss at batch 370 : 0.00885551143437624
epoch50 finished!
Loss at batch 10 : 0.017236856743693352
Loss at batch 20 : 0.015178248286247253
Loss at batch 30 : 0.016155820339918137
Loss at batch 40 : 0.01448492519557476
Loss at batch 50 : 0.0202260073274374
Loss at batch 60 : 0.01785724237561226
Loss at batch 70 : 0.014502632431685925
Loss at batch 80 : 0.00836868304759264
Loss at batch 90 : 0.012380415573716164
Loss at batch 100 : 0.014690132811665535
Loss at batch 110 : 0.008886015973985195
Loss at batch 120 : 0.010109100490808487
Loss at batch 130 : 0.020870132371783257
Loss at batch 140 : 0.013528275303542614
Loss at batch 150 : 0.016589395701885223
Loss at batch 160 : 0.013890737667679787
Loss at batch 170 : 0.017620285972952843
Loss at batch 180 : 0.01752779632806778
Loss at batch 190 : 0.011364265345036983
Loss at batch 200 : 0.012226559221744537
Loss at batch 210 : 0.013791294768452644
Loss at batch 220 : 0.00559452036395669
Loss at batch 230 : 0.018371745944023132
Loss at batch 240 : 0.013482470996677876
Loss at batch 250 : 0.01364576444029808
Loss at batch 260 : 0.015430660918354988
Loss at batch 270 : 0.010313178412616253
Loss at batch 280 : 0.011863676831126213
Loss at batch 290 : 0.011868569068610668
Loss at batch 300 : 0.012463250197470188
Loss at batch 310 : 0.010967008769512177
Loss at batch 320 : 0.011304394342005253
Loss at batch 330 : 0.01558843906968832
Loss at batch 340 : 0.017608430236577988
Loss at batch 350 : 0.010219630785286427
Loss at batch 360 : 0.010274051688611507
Loss at batch 370 : 0.013964410871267319
epoch112 finished!
Loss at batch 10 : 0.016164742410182953
Loss at batch 20 : 0.010758823715150356
Loss at batch 30 : 0.010609063319861889
Loss at batch 40 : 0.015899041667580605
Loss at batch 50 : 0.03125331550836563
Loss at batch 60 : 0.011135363951325417
Loss at batch 70 : 0.012500428594648838
Loss at batch 80 : 0.015052414499223232
Loss at batch 90 : 0.014424719847738743
Loss at batch 100 : 0.012273846194148064
Loss at batch 110 : 0.006751690525561571
Loss at batch 120 : 0.012199126183986664
Loss at batch 130 : 0.02170391194522381
Loss at batch 140 : 0.013494563288986683
Loss at batch 150 : 0.019261982291936874
Loss at batch 160 : 0.02225131168961525
Loss at batch 170 : 0.015056386590003967
Loss at batch 180 : 0.012196009047329426
Loss at batch 190 : 0.006537006702274084
Loss at batch 200 : 0.02004271186888218
Loss at batch 210 : 0.01645289734005928
Loss at batch 220 : 0.010265802033245564
Loss at batch 230 : 0.017056988552212715
Loss at batch 240 : 0.014367260970175266
Loss at batch 250 : 0.009137442335486412
Loss at batch 260 : 0.020221685990691185
Loss at batch 270 : 0.01378856785595417
Loss at batch 280 : 0.02087409235537052
Loss at batch 290 : 0.0348140113055706
Loss at batch 300 : 0.008759225718677044
Loss at batch 310 : 0.01075757760554552
Loss at batch 320 : 0.015152857638895512
Loss at batch 330 : 0.016842354089021683
Loss at batch 340 : 0.011118787340819836
Loss at batch 350 : 0.0141376918181777
Loss at batch 360 : 0.015560673549771309
Loss at batch 370 : 0.013894625008106232
epoch113 finished!
Loss at batch 10 : 0.0070485700853168964
Loss at batch 20 : 0.018559666350483894
Loss at batch 30 : 0.012087693437933922
Loss at batch 40 : 0.023510048165917397
Loss at batch 50 : 0.01949925906956196
Loss at batch 60 : 0.01553867757320404
Loss at batch 70 : 0.015323054976761341
Loss at batch 80 : 0.016453418880701065
Loss at batch 90 : 0.01387371402233839
Loss at batch 100 : 0.01980941742658615
Loss at batch 110 : 0.026846619322896004
Loss at batch 120 : 0.015570515766739845
Loss at batch 130 : 0.012431778013706207
Loss at batch 140 : 0.010818039067089558
Loss at batch 150 : 0.015511361882090569
Loss at batch 160 : 0.020114848390221596
Loss at batch 170 : 0.007104459684342146
Loss at batch 180 : 0.019531866535544395
Loss at batch 190 : 0.015300704166293144
Loss at batch 200 : 0.011217361316084862
Loss at batch 210 : 0.03666570782661438
Loss at batch 220 : 0.01570224203169346
Loss at batch 230 : 0.014736467972397804
Loss at batch 240 : 0.013892896473407745
Loss at batch 250 : 0.01575239934027195
Loss at batch 260 : 0.016357436776161194
Loss at batch 270 : 0.017515145242214203
Loss at batch 280 : 0.008497261442244053
Loss at batch 290 : 0.01564731076359749
Loss at batch 300 : 0.022203663364052773
Loss at batch 310 : 0.0125248022377491
Loss at batch 320 : 0.019170010462403297
Loss at batch 330 : 0.012698665261268616
Loss at batch 340 : 0.013190294615924358
Loss at batch 350 : 0.022176766768097878
Loss at batch 360 : 0.01122176181524992
Loss at batch 370 : 0.01040347758680582
epoch51 finished!
Loss at batch 10 : 0.013010661117732525
Loss at batch 20 : 0.022429127246141434
Loss at batch 30 : 0.01396318431943655
Loss at batch 40 : 0.026962026953697205
Loss at batch 50 : 0.0073716542683541775
Loss at batch 60 : 0.012517568655312061
Loss at batch 70 : 0.013714509084820747
Loss at batch 80 : 0.014305674470961094
Loss at batch 90 : 0.017151547595858574
Loss at batch 100 : 0.02282954379916191
Loss at batch 110 : 0.007464593276381493
Loss at batch 120 : 0.021900499239563942
Loss at batch 130 : 0.01838509924709797
Loss at batch 140 : 0.011657880619168282
Loss at batch 150 : 0.01503270398825407
Loss at batch 160 : 0.0156254842877388
Loss at batch 170 : 0.02010503225028515
Loss at batch 180 : 0.012056448496878147
Loss at batch 190 : 0.017167622223496437
Loss at batch 200 : 0.007777388207614422
Loss at batch 210 : 0.017312319949269295
Loss at batch 220 : 0.01040345337241888
Loss at batch 230 : 0.017167584970593452
Loss at batch 240 : 0.008815711364150047
Loss at batch 250 : 0.015264072455465794
Loss at batch 260 : 0.01510404422879219
Loss at batch 270 : 0.014197148382663727
Loss at batch 280 : 0.012122705578804016
Loss at batch 290 : 0.013019371777772903
Loss at batch 300 : 0.011143334209918976
Loss at batch 310 : 0.013624449260532856
Loss at batch 320 : 0.010657679289579391
Loss at batch 330 : 0.013210735283792019
Loss at batch 340 : 0.012544019147753716
Loss at batch 350 : 0.01635001040995121
Loss at batch 360 : 0.011181386187672615
Loss at batch 370 : 0.016617605462670326
epoch51 finished!
Loss at batch 10 : 0.00888838991522789
Loss at batch 20 : 0.010090135037899017
Loss at batch 30 : 0.00962686538696289
Loss at batch 40 : 0.01536615751683712
Loss at batch 50 : 0.009149700403213501
Loss at batch 60 : 0.015843810513615608
Loss at batch 70 : 0.018922051414847374
Loss at batch 80 : 0.017037266865372658
Loss at batch 90 : 0.009100032970309258
Loss at batch 100 : 0.017498690634965897
Loss at batch 110 : 0.013061877340078354
Loss at batch 120 : 0.01943647861480713
Loss at batch 130 : 0.01080484502017498
Loss at batch 140 : 0.02522463910281658
Loss at batch 150 : 0.016232365742325783
Loss at batch 160 : 0.02256513386964798
Loss at batch 170 : 0.009104597382247448
Loss at batch 180 : 0.010823379270732403
Loss at batch 190 : 0.015397314913570881
Loss at batch 200 : 0.012808121740818024
Loss at batch 210 : 0.017812509089708328
Loss at batch 220 : 0.009160415269434452
Loss at batch 230 : 0.01279887929558754
Loss at batch 240 : 0.03237238898873329
Loss at batch 250 : 0.006976902950555086
Loss at batch 260 : 0.012976174242794514
Loss at batch 270 : 0.018583044409751892
Loss at batch 280 : 0.01608208939433098
Loss at batch 290 : 0.019083701074123383
Loss at batch 300 : 0.01222700159996748
Loss at batch 310 : 0.01616702787578106
Loss at batch 320 : 0.012459149584174156
Loss at batch 330 : 0.0075555481016635895
Loss at batch 340 : 0.016255632042884827
Loss at batch 350 : 0.01273972075432539
Loss at batch 360 : 0.022469181567430496
Loss at batch 370 : 0.015190384350717068
epoch114 finished!
Loss at batch 10 : 0.0093934191390872
Loss at batch 20 : 0.013810352422297001
Loss at batch 30 : 0.007059917319566011
Loss at batch 40 : 0.01116118486970663
Loss at batch 50 : 0.019812647253274918
Loss at batch 60 : 0.011346787214279175
Loss at batch 70 : 0.01864183321595192
Loss at batch 80 : 0.013145063072443008
Loss at batch 90 : 0.014895092695951462
Loss at batch 100 : 0.00844587478786707
Loss at batch 110 : 0.01432525273412466
Loss at batch 120 : 0.013921840116381645
Loss at batch 130 : 0.011650952510535717
Loss at batch 140 : 0.00699127372354269
Loss at batch 150 : 0.007398578338325024
Loss at batch 160 : 0.012419614009559155
Loss at batch 170 : 0.010915720835328102
Loss at batch 180 : 0.014078781940042973
Loss at batch 190 : 0.010573051869869232
Loss at batch 200 : 0.011779568158090115
Loss at batch 210 : 0.012542453594505787
Loss at batch 220 : 0.016709858551621437
Loss at batch 230 : 0.012275480665266514
Loss at batch 240 : 0.006723207887262106
Loss at batch 250 : 0.009588590823113918
Loss at batch 260 : 0.01406742725521326
Loss at batch 270 : 0.012577731162309647
Loss at batch 280 : 0.02221384271979332
Loss at batch 290 : 0.017199702560901642
Loss at batch 300 : 0.017643848434090614
Loss at batch 310 : 0.007873701862990856
Loss at batch 320 : 0.014314496889710426
Loss at batch 330 : 0.010449599474668503
Loss at batch 340 : 0.010221165604889393
Loss at batch 350 : 0.016587257385253906
Loss at batch 360 : 0.018256621435284615
Loss at batch 370 : 0.015817318111658096
epoch115 finished!
Loss at batch 10 : 0.0185503251850605
Loss at batch 20 : 0.015998074784874916
Loss at batch 30 : 0.02662699483335018
Loss at batch 40 : 0.016509244218468666
Loss at batch 50 : 0.009344378486275673
Loss at batch 60 : 0.017481669783592224
Loss at batch 70 : 0.009318212978541851
Loss at batch 80 : 0.01317738275974989
Loss at batch 90 : 0.01682390458881855
Loss at batch 100 : 0.018603771924972534
Loss at batch 110 : 0.013411043211817741
Loss at batch 120 : 0.021433774381875992
Loss at batch 130 : 0.031283654272556305
Loss at batch 140 : 0.01000912394374609
Loss at batch 150 : 0.023292889818549156
Loss at batch 160 : 0.0081550981849432
Loss at batch 170 : 0.016624843701720238
Loss at batch 180 : 0.010852491483092308
Loss at batch 190 : 0.013611262664198875
Loss at batch 200 : 0.025910204276442528
Loss at batch 210 : 0.015109797939658165
Loss at batch 220 : 0.011467893607914448
Loss at batch 230 : 0.01615704596042633
Loss at batch 240 : 0.0190841443836689
Loss at batch 250 : 0.012612919323146343
Loss at batch 260 : 0.00975061859935522
Loss at batch 270 : 0.012319306842982769
Loss at batch 280 : 0.020017052069306374
Loss at batch 290 : 0.014078768901526928
Loss at batch 300 : 0.008044895716011524
Loss at batch 310 : 0.016605164855718613
Loss at batch 320 : 0.006329244002699852
Loss at batch 330 : 0.010545972734689713
Loss at batch 340 : 0.013539696112275124
Loss at batch 350 : 0.017532747238874435
Loss at batch 360 : 0.014159421436488628
Loss at batch 370 : 0.021048076450824738
epoch52 finished!
Loss at batch 10 : 0.016186954453587532
Loss at batch 20 : 0.0173556599766016
Loss at batch 30 : 0.010678598657250404
Loss at batch 40 : 0.011845877394080162
Loss at batch 50 : 0.00839852076023817
Loss at batch 60 : 0.013039135374128819
Loss at batch 70 : 0.011494764126837254
Loss at batch 80 : 0.014548228122293949
Loss at batch 90 : 0.013707883656024933
Loss at batch 100 : 0.01619899272918701
Loss at batch 110 : 0.010808476246893406
Loss at batch 120 : 0.012405971996486187
Loss at batch 130 : 0.01855887472629547
Loss at batch 140 : 0.008647289127111435
Loss at batch 150 : 0.012015831656754017
Loss at batch 160 : 0.013647640123963356
Loss at batch 170 : 0.015093148685991764
Loss at batch 180 : 0.008705762214958668
Loss at batch 190 : 0.012401050888001919
Loss at batch 200 : 0.011391683481633663
Loss at batch 210 : 0.016851304098963737
Loss at batch 220 : 0.016003748401999474
Loss at batch 230 : 0.016093401238322258
Loss at batch 240 : 0.016140621155500412
Loss at batch 250 : 0.02166018821299076
Loss at batch 260 : 0.010703708045184612
Loss at batch 270 : 0.0189382191747427
Loss at batch 280 : 0.012484049424529076
Loss at batch 290 : 0.012544327415525913
Loss at batch 300 : 0.0207452941685915
Loss at batch 310 : 0.014372500590980053
Loss at batch 320 : 0.009847030974924564
Loss at batch 330 : 0.0112014040350914
Loss at batch 340 : 0.017749376595020294
Loss at batch 350 : 0.013734794221818447
Loss at batch 360 : 0.008211229927837849
Loss at batch 370 : 0.008707389235496521
epoch52 finished!
Loss at batch 10 : 0.008073054254055023
Loss at batch 20 : 0.03157542273402214
Loss at batch 30 : 0.016557225957512856
Loss at batch 40 : 0.02454405464231968
Loss at batch 50 : 0.015553818084299564
Loss at batch 60 : 0.013739231042563915
Loss at batch 70 : 0.0072898222133517265
Loss at batch 80 : 0.018513871356844902
Loss at batch 90 : 0.012670310214161873
Loss at batch 100 : 0.01178964413702488
Loss at batch 110 : 0.0065332334488630295
Loss at batch 120 : 0.02364972047507763
Loss at batch 130 : 0.007011012174189091
Loss at batch 140 : 0.00487107178196311
Loss at batch 150 : 0.00759118003770709
Loss at batch 160 : 0.0066656856797635555
Loss at batch 170 : 0.013045815750956535
Loss at batch 180 : 0.014832274056971073
Loss at batch 190 : 0.025340331718325615
Loss at batch 200 : 0.02084353007376194
Loss at batch 210 : 0.01053713820874691
Loss at batch 220 : 0.01495685800909996
Loss at batch 230 : 0.022474505007267
Loss at batch 240 : 0.009646020829677582
Loss at batch 250 : 0.012434598989784718
Loss at batch 260 : 0.015028036199510098
Loss at batch 270 : 0.019012875854969025
Loss at batch 280 : 0.013592274859547615
Loss at batch 290 : 0.01187586598098278
Loss at batch 300 : 0.025988543406128883
Loss at batch 310 : 0.024395380169153214
Loss at batch 320 : 0.014826032333076
Loss at batch 330 : 0.010828406549990177
Loss at batch 340 : 0.016080278903245926
Loss at batch 350 : 0.012537716887891293
Loss at batch 360 : 0.01493489183485508
Loss at batch 370 : 0.014343773014843464
epoch116 finished!
Loss at batch 10 : 0.013908201828598976
Loss at batch 20 : 0.015469657257199287
Loss at batch 30 : 0.026216566562652588
Loss at batch 40 : 0.010915741324424744
Loss at batch 50 : 0.008029643446207047
Loss at batch 60 : 0.020365124568343163
Loss at batch 70 : 0.009663164615631104
Loss at batch 80 : 0.015406619757413864
Loss at batch 90 : 0.023003706708550453
Loss at batch 100 : 0.017868008464574814
Loss at batch 110 : 0.010015053674578667
Loss at batch 120 : 0.01761796697974205
Loss at batch 130 : 0.02218933217227459
Loss at batch 140 : 0.0072753592394292355
Loss at batch 150 : 0.01600208319723606
Loss at batch 160 : 0.0073905522003769875
Loss at batch 170 : 0.01338962186127901
Loss at batch 180 : 0.019331863150000572
Loss at batch 190 : 0.020140614360570908
Loss at batch 200 : 0.018188675865530968
Loss at batch 210 : 0.02374737337231636
Loss at batch 220 : 0.00915780384093523
Loss at batch 230 : 0.009889037348330021
Loss at batch 240 : 0.011469753459095955
Loss at batch 250 : 0.015693729743361473
Loss at batch 260 : 0.015023354440927505
Loss at batch 270 : 0.02394215203821659
Loss at batch 280 : 0.026408454403281212
Loss at batch 290 : 0.012248005717992783
Loss at batch 300 : 0.01730937696993351
Loss at batch 310 : 0.025259461253881454
Loss at batch 320 : 0.015789253637194633
Loss at batch 330 : 0.016562283039093018
Loss at batch 340 : 0.014309212565422058
Loss at batch 350 : 0.008690731599926949
Loss at batch 360 : 0.010356788523495197
Loss at batch 370 : 0.0173531174659729
epoch117 finished!
Loss at batch 10 : 0.012264352291822433
Loss at batch 20 : 0.012029318138957024
Loss at batch 30 : 0.010476091876626015
Loss at batch 40 : 0.022048717364668846
Loss at batch 50 : 0.011158496141433716
Loss at batch 60 : 0.02078396826982498
Loss at batch 70 : 0.014113066717982292
Loss at batch 80 : 0.00973872747272253
Loss at batch 90 : 0.013457122258841991
Loss at batch 100 : 0.011079571209847927
Loss at batch 110 : 0.016304951161146164
Loss at batch 120 : 0.021610073745250702
Loss at batch 130 : 0.011405924335122108
Loss at batch 140 : 0.015379778109490871
Loss at batch 150 : 0.023083310574293137
Loss at batch 160 : 0.009412617422640324
Loss at batch 170 : 0.010992775671184063
Loss at batch 180 : 0.013091497123241425
Loss at batch 190 : 0.017732776701450348
Loss at batch 200 : 0.023381512612104416
Loss at batch 210 : 0.021623801440000534
Loss at batch 220 : 0.017200550064444542
Loss at batch 230 : 0.025414511561393738
Loss at batch 240 : 0.012998019345104694
Loss at batch 250 : 0.009806077927350998
Loss at batch 260 : 0.01569530926644802
Loss at batch 270 : 0.014866931363940239
Loss at batch 280 : 0.012712608091533184
Loss at batch 290 : 0.016319144517183304
Loss at batch 300 : 0.021370133385062218
Loss at batch 310 : 0.00940080638974905
Loss at batch 320 : 0.013538159430027008
Loss at batch 330 : 0.007693945895880461
Loss at batch 340 : 0.015769053250551224
Loss at batch 350 : 0.006319945678114891
Loss at batch 360 : 0.031475331634283066
Loss at batch 370 : 0.01355873141437769
epoch53 finished!

[2024-04-25 01:31:16.292846] test end with snapshots1/DehazeNet_epoch93.pth
[2024-04-25 01:33:02.179199] Avg_PSNR: 19.28196868838461 dB, Avg_SSIM: 0.8598735197694057
[2024-04-25 01:33:02.215301] test start with snapshots1/DehazeNet_epoch160.pth
[2024-04-25 01:33:36.194608] test end with snapshots1/DehazeNet_epoch160.pth
[2024-04-25 01:35:22.309088] Avg_PSNR: 19.407563664856962 dB, Avg_SSIM: 0.8658620062113855
[2024-04-25 01:35:22.352349] test start with snapshots1/DehazeNet_epoch10.pth
[2024-04-25 01:35:56.087262] test end with snapshots1/DehazeNet_epoch10.pth
[2024-04-25 01:37:41.262945] Avg_PSNR: 19.055328989210903 dB, Avg_SSIM: 0.8764435881060274
[2024-04-25 01:37:41.306882] test start with snapshots1/DehazeNet_epoch61.pth
[2024-04-25 01:38:14.746724] test end with snapshots1/DehazeNet_epoch61.pth
[2024-04-25 01:40:00.718440] Avg_PSNR: 19.28381595262309 dB, Avg_SSIM: 0.8635454017239274
[2024-04-25 01:40:00.767349] test start with snapshots1/DehazeNet_epoch191.pth
[2024-04-25 01:40:34.771223] test end with snapshots1/DehazeNet_epoch191.pth
[2024-04-25 01:42:21.027939] Avg_PSNR: 19.14023661760944 dB, Avg_SSIM: 0.8581918333906158
[2024-04-25 01:42:21.070928] test start with snapshots1/DehazeNet_epoch36.pth
[2024-04-25 01:42:55.210702] test end with snapshots1/DehazeNet_epoch36.pth
[2024-04-25 01:44:41.345832] Avg_PSNR: 19.209876569884166 dB, Avg_SSIM: 0.8758523399142029
[2024-04-25 01:44:41.397338] test start with snapshots1/DehazeNet_epoch95.pth
[2024-04-25 01:45:15.207856] test end with snapshots1/DehazeNet_epoch95.pth
[2024-04-25 01:47:00.985550] Avg_PSNR: 19.38923716104436 dB, Avg_SSIM: 0.8631731421240638
[2024-04-25 01:47:01.024848] test start with snapshots1/DehazeNet_epoch179.pth
[2024-04-25 01:47:35.022549] test end with snapshots1/DehazeNet_epoch179.pth
[2024-04-25 01:49:20.925022] Avg_PSNR: 19.514357091365493 dB, Avg_SSIM: 0.8668583438086029
[2024-04-25 01:49:20.975067] test start with snapshots1/DehazeNet_epoch140.pth
[2024-04-25 01:49:54.703363] test end with snapshots1/DehazeNet_epoch140.pth
[2024-04-25 01:51:40.237307] Avg_PSNR: 19.34601921808734 dB, Avg_SSIM: 0.8623399663186537
[2024-04-25 01:51:40.267795] test start with snapshots1/DehazeNet_epoch189.pth
[2024-04-25 01:52:13.844683] test end with snapshots1/DehazeNet_epoch189.pth
[2024-04-25 01:53:59.180680] Avg_PSNR: 19.466377067137255 dB, Avg_SSIM: 0.8637859626297452
[2024-04-25 01:53:59.222214] test start with snapshots1/DehazeNet_epoch13.pth
[2024-04-25 01:54:33.298886] test end with snapshots1/DehazeNet_epoch13.pth
[2024-04-25 01:56:19.394158] Avg_PSNR: 19.11723169006968 dB, Avg_SSIM: 0.8760770384044716
[2024-04-25 01:56:19.437238] test start with snapshots1/DehazeNet_epoch102.pth
[2024-04-25 01:56:53.474098] test end with snapshots1/DehazeNet_epoch102.pth
[2024-04-25 01:58:39.416748] Avg_PSNR: 19.477492448657646 dB, Avg_SSIM: 0.8690478355786726
[2024-04-25 01:58:39.461512] test start with snapshots1/DehazeNet_epoch174.pth
[2024-04-25 01:59:13.533126] test end with snapshots1/DehazeNet_epoch174.pth
[2024-04-25 02:00:59.775987] Avg_PSNR: 19.135450037238634 dB, Avg_SSIM: 0.8578447684062114
[2024-04-25 02:00:59.817291] test start with snapshots1/DehazeNet_epoch141.pth
[2024-04-25 02:01:33.492385] test end with snapshots1/DehazeNet_epoch141.pth
[2024-04-25 02:03:19.603263] Avg_PSNR: 19.32379175633399 dB, Avg_SSIM: 0.8641386767020338
[2024-04-25 02:03:19.656497] test start with snapshots1/DehazeNet_epoch16.pth
[2024-04-25 02:03:54.029884] test end with snapshots1/DehazeNet_epoch16.pth
[2024-04-25 02:05:40.773483] Avg_PSNR: 18.897197668255913 dB, Avg_SSIM: 0.8698517871674206
[2024-04-25 02:05:40.816105] test start with snapshots1/DehazeNet_epoch198.pth
[2024-04-25 02:06:14.940150] test end with snapshots1/DehazeNet_epoch198.pth
[2024-04-25 02:08:01.510675] Avg_PSNR: 19.477923135917944 dB, Avg_SSIM: 0.8660328517639764
[2024-04-25 02:08:01.558919] test start with snapshots1/DehazeNet_epoch157.pth
[2024-04-25 02:08:35.472169] test end with snapshots1/DehazeNet_epoch157.pth
[2024-04-25 02:10:21.811613] Avg_PSNR: 19.382490132270814 dB, Avg_SSIM: 0.8643808552171441
[2024-04-25 02:10:21.861296] test start with snapshots1/DehazeNet_epoch32.pth
[2024-04-25 02:10:56.001528] test end with snapshots1/DehazeNet_epoch32.pth
[2024-04-25 02:12:42.106436] Avg_PSNR: 19.07084544971859 dB, Avg_SSIM: 0.8739177043944611
[2024-04-25 02:12:42.147997] test start with snapshots1/DehazeNet_epoch19.pth
[2024-04-25 02:13:16.106873] test end with snapshots1/DehazeNet_epoch19.pth
[2024-04-25 02:15:01.864953] Avg_PSNR: 19.15080131711804 dB, Avg_SSIM: 0.8747405762963727
[2024-04-25 02:15:01.905763] test start with snapshots1/DehazeNet_epoch190.pth
[2024-04-25 02:15:35.778193] test end with snapshots1/DehazeNet_epoch190.pth
[2024-04-25 02:17:21.895131] Avg_PSNR: 19.474685093723505 dB, Avg_SSIM: 0.8666376393468002
[2024-04-25 02:17:21.933222] test start with snapshots1/DehazeNet_epoch125.pth
[2024-04-25 02:17:55.728707] test end with snapshots1/DehazeNet_epoch125.pth
[2024-04-25 02:19:41.919751] Avg_PSNR: 19.440957951029787 dB, Avg_SSIM: 0.867740147861325
[2024-04-25 02:19:41.979687] test start with snapshots1/DehazeNet_epoch86.pth
[2024-04-25 02:20:15.851788] test end with snapshots1/DehazeNet_epoch86.pth
[2024-04-25 02:22:01.517867] Avg_PSNR: 19.41766687806839 dB, Avg_SSIM: 0.8659237159100798
[2024-04-25 02:22:01.561886] test start with snapshots1/DehazeNet_epoch52.pth
[2024-04-25 02:22:35.251223] test end with snapshots1/DehazeNet_epoch52.pth
[2024-04-25 02:24:21.508500] Avg_PSNR: 19.077888929132445 dB, Avg_SSIM: 0.8589155039228932
[2024-04-25 02:24:21.550892] test start with snapshots1/DehazeNet_epoch24.pth
[2024-04-25 02:24:55.317976] test end with snapshots1/DehazeNet_epoch24.pth
[2024-04-25 02:26:41.447430] Avg_PSNR: 19.127587433598382 dB, Avg_SSIM: 0.8757559422325644
[2024-04-25 02:26:41.488086] test start with snapshots1/DehazeNet_epoch75.pth
[2024-04-25 02:27:15.152253] test end with snapshots1/DehazeNet_epoch75.pth
[2024-04-25 02:29:01.060386] Avg_PSNR: 19.368462785045352 dB, Avg_SSIM: 0.8652809943984147
[2024-04-25 02:29:01.110076] test start with snapshots1/DehazeNet_epoch59.pth
[2024-04-25 02:29:35.023641] test end with snapshots1/DehazeNet_epoch59.pth
[2024-04-25 02:31:20.965360] Avg_PSNR: 19.273977474411353 dB, Avg_SSIM: 0.8633458609595921
[2024-04-25 02:31:21.009588] test start with snapshots1/DehazeNet_epoch8.pth
[2024-04-25 02:31:54.673439] test end with snapshots1/DehazeNet_epoch8.pth
[2024-04-25 02:33:39.622465] Avg_PSNR: 19.03133323043215 dB, Avg_SSIM: 0.8751856846037526
[2024-04-25 02:33:39.676040] test start with snapshots1/DehazeNet_epoch187.pth
[2024-04-25 02:34:13.304717] test end with snapshots1/DehazeNet_epoch187.pth
[2024-04-25 02:35:58.852442] Avg_PSNR: 19.339718912348573 dB, Avg_SSIM: 0.8647139570476533
[2024-04-25 02:35:58.893843] test start with snapshots1/DehazeNet_epoch151.pth
[2024-04-25 02:36:32.833065] test end with snapshots1/DehazeNet_epoch151.pth
[2024-04-25 02:38:18.603722] Avg_PSNR: 19.287778256824925 dB, Avg_SSIM: 0.8643120757039612
[2024-04-25 02:38:18.646212] test start with snapshots1/DehazeNet_epoch25.pth
[2024-04-25 02:38:52.302752] test end with snapshots1/DehazeNet_epoch25.pth
[2024-04-25 02:40:37.708074] Avg_PSNR: 18.52153718821241 dB, Avg_SSIM: 0.85838753593828
[2024-04-25 02:40:37.748088] test start with snapshots1/DehazeNet_epoch144.pth
[2024-04-25 02:41:11.477901] test end with snapshots1/DehazeNet_epoch144.pth
[2024-04-25 02:42:57.453613] Avg_PSNR: 19.30757931265952 dB, Avg_SSIM: 0.8612424976525819
[2024-04-25 02:42:57.498285] test start with snapshots1/DehazeNet_epoch70.pth
[2024-04-25 02:43:31.482894] test end with snapshots1/DehazeNet_epoch70.pth
[2024-04-25 02:45:17.615592] Avg_PSNR: 19.258451631485812 dB, Avg_SSIM: 0.8609084627617352
[2024-04-25 02:45:17.667029] test start with snapshots1/DehazeNet_epoch43.pth
[2024-04-25 02:45:51.619042] test end with snapshots1/DehazeNet_epoch43.pth
[2024-04-25 02:47:37.793807] Avg_PSNR: 19.10740230018647 dB, Avg_SSIM: 0.8684934254361991
[2024-04-25 02:47:37.837460] test start with snapshots1/DehazeNet_epoch35.pth
[2024-04-25 02:48:11.809547] test end with snapshots1/DehazeNet_epoch35.pth
[2024-04-25 02:49:58.275174] Avg_PSNR: 19.179620731775174 dB, Avg_SSIM: 0.8764154751716502Loss at batch 10 : 0.006098883226513863
Loss at batch 20 : 0.011576972901821136
Loss at batch 30 : 0.0148940933868289
Loss at batch 40 : 0.01123551931232214
Loss at batch 50 : 0.016095902770757675
Loss at batch 60 : 0.020366620272397995
Loss at batch 70 : 0.009580069221556187
Loss at batch 80 : 0.012642713263630867
Loss at batch 90 : 0.018214205279946327
Loss at batch 100 : 0.01014687679708004
Loss at batch 110 : 0.010193058289587498
Loss at batch 120 : 0.01594524085521698
Loss at batch 130 : 0.012234620749950409
Loss at batch 140 : 0.019034117460250854
Loss at batch 150 : 0.015268339775502682
Loss at batch 160 : 0.015446591190993786
Loss at batch 170 : 0.02181483432650566
Loss at batch 180 : 0.014107977040112019
Loss at batch 190 : 0.008861362002789974
Loss at batch 200 : 0.018631553277373314
Loss at batch 210 : 0.013079392723739147
Loss at batch 220 : 0.007577566895633936
Loss at batch 230 : 0.00851526390761137
Loss at batch 240 : 0.012410675175487995
Loss at batch 250 : 0.020638102665543556
Loss at batch 260 : 0.010811340063810349
Loss at batch 270 : 0.014592466875910759
Loss at batch 280 : 0.010098792612552643
Loss at batch 290 : 0.012826030142605305
Loss at batch 300 : 0.02304990589618683
Loss at batch 310 : 0.011473670601844788
Loss at batch 320 : 0.01161564327776432
Loss at batch 330 : 0.009304086677730083
Loss at batch 340 : 0.01238621398806572
Loss at batch 350 : 0.0083369892090559
Loss at batch 360 : 0.015576477162539959
Loss at batch 370 : 0.009034926071763039
epoch53 finished!
Loss at batch 10 : 0.017914477735757828
Loss at batch 20 : 0.01256625633686781
Loss at batch 30 : 0.010902542620897293
Loss at batch 40 : 0.014469519257545471
Loss at batch 50 : 0.010058901272714138
Loss at batch 60 : 0.018822308629751205
Loss at batch 70 : 0.011345276609063148
Loss at batch 80 : 0.016133245080709457
Loss at batch 90 : 0.024086948484182358
Loss at batch 100 : 0.024789726361632347
Loss at batch 110 : 0.012331876903772354
Loss at batch 120 : 0.01434873417019844
Loss at batch 130 : 0.011733769439160824
Loss at batch 140 : 0.010081697255373001
Loss at batch 150 : 0.017438586801290512
Loss at batch 160 : 0.020936304703354836
Loss at batch 170 : 0.016181236132979393
Loss at batch 180 : 0.015020215883851051
Loss at batch 190 : 0.018690945580601692
Loss at batch 200 : 0.011576991528272629
Loss at batch 210 : 0.011624835431575775
Loss at batch 220 : 0.006582499947398901
Loss at batch 230 : 0.020211253315210342
Loss at batch 240 : 0.009221147745847702
Loss at batch 250 : 0.0141950948163867
Loss at batch 260 : 0.01866726763546467
Loss at batch 270 : 0.014868817292153835
Loss at batch 280 : 0.013598334044218063
Loss at batch 290 : 0.012807960622012615
Loss at batch 300 : 0.010453530587255955
Loss at batch 310 : 0.01225983165204525
Loss at batch 320 : 0.02209317870438099
Loss at batch 330 : 0.02365042082965374
Loss at batch 340 : 0.0176981333643198
Loss at batch 350 : 0.008377007208764553
Loss at batch 360 : 0.0148702347651124
Loss at batch 370 : 0.0176889318972826
epoch118 finished!
Loss at batch 10 : 0.02980332262814045
Loss at batch 20 : 0.014632121659815311
Loss at batch 30 : 0.016135601326823235
Loss at batch 40 : 0.012211357243359089
Loss at batch 50 : 0.01354705449193716
Loss at batch 60 : 0.017497984692454338
Loss at batch 70 : 0.009555422700941563
Loss at batch 80 : 0.01503236498683691
Loss at batch 90 : 0.008543599396944046
Loss at batch 100 : 0.01195210125297308
Loss at batch 110 : 0.011237905360758305
Loss at batch 120 : 0.019104771316051483
Loss at batch 130 : 0.02390472963452339
Loss at batch 140 : 0.024453438818454742
Loss at batch 150 : 0.015663454309105873
Loss at batch 160 : 0.011713062413036823
Loss at batch 170 : 0.01144117396324873
Loss at batch 180 : 0.019630588591098785
Loss at batch 190 : 0.012115399353206158
Loss at batch 200 : 0.009609265252947807
Loss at batch 210 : 0.017945000901818275
Loss at batch 220 : 0.017628930509090424
Loss at batch 230 : 0.009311719797551632
Loss at batch 240 : 0.012425703927874565
Loss at batch 250 : 0.011010773479938507
Loss at batch 260 : 0.015596972778439522
Loss at batch 270 : 0.026523612439632416
Loss at batch 280 : 0.019156934693455696
Loss at batch 290 : 0.016004230827093124
Loss at batch 300 : 0.009865093044936657
Loss at batch 310 : 0.010154370218515396
Loss at batch 320 : 0.015792468562722206
Loss at batch 330 : 0.009330453351140022
Loss at batch 340 : 0.01660258136689663
Loss at batch 350 : 0.011392194777727127
Loss at batch 360 : 0.025960911065340042
Loss at batch 370 : 0.011134197004139423
epoch119 finished!
Loss at batch 10 : 0.033154748380184174
Loss at batch 20 : 0.01468328945338726
Loss at batch 30 : 0.01465263869613409
Loss at batch 40 : 0.015089266002178192
Loss at batch 50 : 0.010626135393977165
Loss at batch 60 : 0.016761858016252518
Loss at batch 70 : 0.018967457115650177
Loss at batch 80 : 0.017642362043261528
Loss at batch 90 : 0.009947813116014004
Loss at batch 100 : 0.01578838750720024
Loss at batch 110 : 0.01593422330915928
Loss at batch 120 : 0.01133102085441351
Loss at batch 130 : 0.015879275277256966
Loss at batch 140 : 0.019515452906489372
Loss at batch 150 : 0.01631115935742855
Loss at batch 160 : 0.013018637895584106
Loss at batch 170 : 0.009151512756943703
Loss at batch 180 : 0.012314623221755028
Loss at batch 190 : 0.015031539835035801
Loss at batch 200 : 0.015224626287817955
Loss at batch 210 : 0.02413671277463436
Loss at batch 220 : 0.014981342479586601
Loss at batch 230 : 0.01854308508336544
Loss at batch 240 : 0.015245126560330391
Loss at batch 250 : 0.020194601267576218
Loss at batch 260 : 0.014092925004661083
Loss at batch 270 : 0.014799832366406918
Loss at batch 280 : 0.028759757056832314
Loss at batch 290 : 0.016246765851974487
Loss at batch 300 : 0.01585649698972702
Loss at batch 310 : 0.01748228259384632
Loss at batch 320 : 0.014886955730617046
Loss at batch 330 : 0.0124891996383667
Loss at batch 340 : 0.02556684985756874
Loss at batch 350 : 0.012773602269589901
Loss at batch 360 : 0.012814589776098728
Loss at batch 370 : 0.00914357602596283
epoch54 finished!
Loss at batch 10 : 0.01451451238244772
Loss at batch 20 : 0.011240154504776001
Loss at batch 30 : 0.0128847761079669
Loss at batch 40 : 0.017968788743019104
Loss at batch 50 : 0.00794452428817749
Loss at batch 60 : 0.00924257468432188
Loss at batch 70 : 0.010287049226462841
Loss at batch 80 : 0.020862741395831108
Loss at batch 90 : 0.015438860282301903
Loss at batch 100 : 0.010783232748508453
Loss at batch 110 : 0.008687988854944706
Loss at batch 120 : 0.010098787024617195
Loss at batch 130 : 0.016896646469831467
Loss at batch 140 : 0.007520048413425684
Loss at batch 150 : 0.017115430906414986
Loss at batch 160 : 0.018128588795661926
Loss at batch 170 : 0.023908400908112526
Loss at batch 180 : 0.01391336414963007
Loss at batch 190 : 0.010414444841444492
Loss at batch 200 : 0.00813286192715168
Loss at batch 210 : 0.007061873562633991
Loss at batch 220 : 0.013254149816930294
Loss at batch 230 : 0.015482835471630096
Loss at batch 240 : 0.013993821106851101
Loss at batch 250 : 0.008601096458733082
Loss at batch 260 : 0.01149696670472622
Loss at batch 270 : 0.014080544002354145
Loss at batch 280 : 0.023035461083054543
Loss at batch 290 : 0.010263493284583092
Loss at batch 300 : 0.015146451070904732
Loss at batch 310 : 0.007130223326385021
Loss at batch 320 : 0.013312870636582375
Loss at batch 330 : 0.013144796714186668
Loss at batch 340 : 0.013047277927398682
Loss at batch 350 : 0.01815563254058361
Loss at batch 360 : 0.012726398184895515
Loss at batch 370 : 0.01517882663756609
epoch120 finished!
Loss at batch 10 : 0.013587516732513905
Loss at batch 20 : 0.01651911810040474
Loss at batch 30 : 0.030471116304397583
Loss at batch 40 : 0.012882805429399014
Loss at batch 50 : 0.011491434648633003
Loss at batch 60 : 0.015348542481660843
Loss at batch 70 : 0.022268429398536682
Loss at batch 80 : 0.012650634162127972
Loss at batch 90 : 0.009894456714391708
Loss at batch 100 : 0.0159313902258873
Loss at batch 110 : 0.012208327651023865
Loss at batch 120 : 0.01898324303328991
Loss at batch 130 : 0.022592535242438316
Loss at batch 140 : 0.015077066607773304
Loss at batch 150 : 0.00772818922996521
Loss at batch 160 : 0.012872012332081795
Loss at batch 170 : 0.00998219195753336
Loss at batch 180 : 0.014865654520690441
Loss at batch 190 : 0.01386931911110878
Loss at batch 200 : 0.013200809247791767
Loss at batch 210 : 0.009633705951273441
Loss at batch 220 : 0.019140100106596947
Loss at batch 230 : 0.009743825532495975
Loss at batch 240 : 0.013366017490625381
Loss at batch 250 : 0.008874248713254929
Loss at batch 260 : 0.009440611116588116
Loss at batch 270 : 0.019597219303250313
Loss at batch 280 : 0.010842430405318737
Loss at batch 290 : 0.007631555199623108
Loss at batch 300 : 0.019045334309339523
Loss at batch 310 : 0.01165623590350151
Loss at batch 320 : 0.014554722234606743
Loss at batch 330 : 0.011717953719198704
Loss at batch 340 : 0.021572526544332504
Loss at batch 350 : 0.009877344593405724
Loss at batch 360 : 0.012141219340264797
Loss at batch 370 : 0.007962177507579327
epoch54 finished!
Loss at batch 10 : 0.012967887334525585
Loss at batch 20 : 0.012516280636191368
Loss at batch 30 : 0.012736459262669086
Loss at batch 40 : 0.016518309712409973
Loss at batch 50 : 0.024858646094799042
Loss at batch 60 : 0.008904775604605675
Loss at batch 70 : 0.010350579395890236
Loss at batch 80 : 0.007588040083646774
Loss at batch 90 : 0.010399158112704754
Loss at batch 100 : 0.009546402841806412
Loss at batch 110 : 0.013008748181164265
Loss at batch 120 : 0.014111402444541454
Loss at batch 130 : 0.01880049519240856
Loss at batch 140 : 0.018637171015143394
Loss at batch 150 : 0.010528814978897572
Loss at batch 160 : 0.01165429875254631
Loss at batch 170 : 0.011684494093060493
Loss at batch 180 : 0.014325126074254513
Loss at batch 190 : 0.019750896841287613
Loss at batch 200 : 0.01874997839331627
Loss at batch 210 : 0.01030102651566267
Loss at batch 220 : 0.01117496844381094
Loss at batch 230 : 0.016896585002541542
Loss at batch 240 : 0.012353732250630856
Loss at batch 250 : 0.008141286671161652
Loss at batch 260 : 0.00848456472158432
Loss at batch 270 : 0.010775326751172543
Loss at batch 280 : 0.011683330871164799
Loss at batch 290 : 0.014258557930588722
Loss at batch 300 : 0.00915615726262331
Loss at batch 310 : 0.00873185507953167
Loss at batch 320 : 0.020703444257378578
Loss at batch 330 : 0.005800527986139059
Loss at batch 340 : 0.015236890874803066
Loss at batch 350 : 0.012365532107651234
Loss at batch 360 : 0.010178674943745136
Loss at batch 370 : 0.019906193017959595
epoch121 finished!
Loss at batch 10 : 0.015720685943961143
Loss at batch 20 : 0.014302067458629608
Loss at batch 30 : 0.010764372535049915
Loss at batch 40 : 0.01826811023056507
Loss at batch 50 : 0.019541915506124496
Loss at batch 60 : 0.015613344497978687
Loss at batch 70 : 0.0133284917101264
Loss at batch 80 : 0.017106985673308372
Loss at batch 90 : 0.014195699244737625
Loss at batch 100 : 0.01623709127306938
Loss at batch 110 : 0.010842138901352882
Loss at batch 120 : 0.011160753667354584
Loss at batch 130 : 0.008863145485520363
Loss at batch 140 : 0.010521815158426762
Loss at batch 150 : 0.01622791588306427
Loss at batch 160 : 0.010174787603318691
Loss at batch 170 : 0.022397097200155258
Loss at batch 180 : 0.01262703351676464
Loss at batch 190 : 0.0130137475207448
Loss at batch 200 : 0.025300972163677216
Loss at batch 210 : 0.010658533312380314
Loss at batch 220 : 0.013986085541546345
Loss at batch 230 : 0.00878692977130413
Loss at batch 240 : 0.012065531685948372
Loss at batch 250 : 0.0096520921215415
Loss at batch 260 : 0.011762498877942562
Loss at batch 270 : 0.019362201914191246
Loss at batch 280 : 0.018320869654417038
Loss at batch 290 : 0.010947946459054947
Loss at batch 300 : 0.011470083147287369
Loss at batch 310 : 0.016271885484457016
Loss at batch 320 : 0.013535590842366219
Loss at batch 330 : 0.018560800701379776
Loss at batch 340 : 0.00978176761418581
Loss at batch 350 : 0.015118208713829517
Loss at batch 360 : 0.017824266105890274
Loss at batch 370 : 0.009167910553514957
epoch122 finished!
Loss at batch 10 : 0.023491382598876953
Loss at batch 20 : 0.007139788009226322
Loss at batch 30 : 0.008299744687974453
Loss at batch 40 : 0.019376534968614578
Loss at batch 50 : 0.02073400840163231
Loss at batch 60 : 0.006922543048858643
Loss at batch 70 : 0.020949246361851692
Loss at batch 80 : 0.017399605363607407
Loss at batch 90 : 0.014120377600193024
Loss at batch 100 : 0.025485340505838394
Loss at batch 110 : 0.009716871194541454
Loss at batch 120 : 0.009090718813240528
Loss at batch 130 : 0.014482647180557251
Loss at batch 140 : 0.011224488727748394
Loss at batch 150 : 0.024777330458164215
Loss at batch 160 : 0.015671120956540108
Loss at batch 170 : 0.013420342467725277
Loss at batch 180 : 0.016598908230662346
Loss at batch 190 : 0.008809231221675873
Loss at batch 200 : 0.014736032113432884
Loss at batch 210 : 0.012312034144997597
Loss at batch 220 : 0.012714836746454239
Loss at batch 230 : 0.018739594146609306
Loss at batch 240 : 0.01767105981707573
Loss at batch 250 : 0.01642858237028122
Loss at batch 260 : 0.015860827639698982
Loss at batch 270 : 0.008798258379101753
Loss at batch 280 : 0.020326713100075722
Loss at batch 290 : 0.01758398674428463
Loss at batch 300 : 0.019163891673088074
Loss at batch 310 : 0.013698482885956764
Loss at batch 320 : 0.008756933733820915
Loss at batch 330 : 0.041030459105968475
Loss at batch 340 : 0.014284655451774597
Loss at batch 350 : 0.005862746853381395
Loss at batch 360 : 0.01746651716530323
Loss at batch 370 : 0.018228992819786072
epoch55 finished!
Loss at batch 10 : 0.016943762078881264
Loss at batch 20 : 0.022042034193873405
Loss at batch 30 : 0.022178031504154205
Loss at batch 40 : 0.014852689579129219
Loss at batch 50 : 0.01822175830602646
Loss at batch 60 : 0.015697063878178596
Loss at batch 70 : 0.018483886495232582
Loss at batch 80 : 0.02793685533106327
Loss at batch 90 : 0.017725784331560135
Loss at batch 100 : 0.02161554805934429
Loss at batch 110 : 0.01521153561770916
Loss at batch 120 : 0.018077217042446136
Loss at batch 130 : 0.008098267018795013
Loss at batch 140 : 0.008976451121270657
Loss at batch 150 : 0.02792724221944809
Loss at batch 160 : 0.008784710429608822
Loss at batch 170 : 0.02237219735980034
Loss at batch 180 : 0.012567772530019283
Loss at batch 190 : 0.021036114543676376
Loss at batch 200 : 0.009435320273041725
Loss at batch 210 : 0.01868220418691635
Loss at batch 220 : 0.014359550550580025
Loss at batch 230 : 0.02014361135661602
Loss at batch 240 : 0.02888253517448902
Loss at batch 250 : 0.009332808665931225
Loss at batch 260 : 0.012958629056811333
Loss at batch 270 : 0.012361891567707062
Loss at batch 280 : 0.014116683974862099
Loss at batch 290 : 0.013527192175388336
Loss at batch 300 : 0.021182434633374214
Loss at batch 310 : 0.020096465945243835
Loss at batch 320 : 0.009902998805046082
Loss at batch 330 : 0.015705358237028122
Loss at batch 340 : 0.017313091084361076
Loss at batch 350 : 0.01649485155940056
Loss at batch 360 : 0.015926362946629524
Loss at batch 370 : 0.01729760318994522
epoch55 finished!
Loss at batch 10 : 0.011984816752374172
Loss at batch 20 : 0.013132010586559772
Loss at batch 30 : 0.006724038626998663
Loss at batch 40 : 0.009912364184856415
Loss at batch 50 : 0.01237002108246088
Loss at batch 60 : 0.012903301045298576
Loss at batch 70 : 0.01415343303233385
Loss at batch 80 : 0.016518069431185722
Loss at batch 90 : 0.015563846565783024
Loss at batch 100 : 0.01324083749204874
Loss at batch 110 : 0.02509564720094204
Loss at batch 120 : 0.013501047156751156
Loss at batch 130 : 0.013311631977558136
Loss at batch 140 : 0.013855419121682644
Loss at batch 150 : 0.014741893857717514
Loss at batch 160 : 0.007507448550313711
Loss at batch 170 : 0.00453706132248044
Loss at batch 180 : 0.010614163242280483
Loss at batch 190 : 0.01571919582784176
Loss at batch 200 : 0.009605946019291878
Loss at batch 210 : 0.015533401630818844
Loss at batch 220 : 0.015653839334845543
Loss at batch 230 : 0.017603490501642227
Loss at batch 240 : 0.01035186555236578
Loss at batch 250 : 0.009486144408583641
Loss at batch 260 : 0.020543785765767097
Loss at batch 270 : 0.010497544892132282
Loss at batch 280 : 0.011368559673428535
Loss at batch 290 : 0.0165951419621706
Loss at batch 300 : 0.012417346239089966
Loss at batch 310 : 0.009880615398287773
Loss at batch 320 : 0.02331388369202614
Loss at batch 330 : 0.01255427859723568
Loss at batch 340 : 0.01428738422691822
Loss at batch 350 : 0.01522962935268879
Loss at batch 360 : 0.015796823427081108
Loss at batch 370 : 0.016772277653217316
epoch123 finished!
Loss at batch 10 : 0.012648338451981544
Loss at batch 20 : 0.020482709631323814
Loss at batch 30 : 0.013210519216954708
Loss at batch 40 : 0.01084033865481615
Loss at batch 50 : 0.010741844773292542
Loss at batch 60 : 0.017188457772135735
Loss at batch 70 : 0.010758434422314167
Loss at batch 80 : 0.013365982100367546
Loss at batch 90 : 0.022425556555390358
Loss at batch 100 : 0.019589124247431755
Loss at batch 110 : 0.014033859595656395
Loss at batch 120 : 0.012001119554042816
Loss at batch 130 : 0.009875083342194557
Loss at batch 140 : 0.024986736476421356
Loss at batch 150 : 0.012708861380815506
Loss at batch 160 : 0.01227989885956049
Loss at batch 170 : 0.01890418864786625
Loss at batch 180 : 0.013637703843414783
Loss at batch 190 : 0.015459236688911915
Loss at batch 200 : 0.012314287945628166
Loss at batch 210 : 0.01795511320233345
Loss at batch 220 : 0.014354648999869823
Loss at batch 230 : 0.01726423390209675
Loss at batch 240 : 0.008300529792904854
Loss at batch 250 : 0.013454395346343517
Loss at batch 260 : 0.024374809116125107
Loss at batch 270 : 0.009991046972572803
Loss at batch 280 : 0.007774540223181248
Loss at batch 290 : 0.01212186086922884
Loss at batch 300 : 0.019190127030014992
Loss at batch 310 : 0.015275065787136555
Loss at batch 320 : 0.012740323320031166
Loss at batch 330 : 0.008198007009923458
Loss at batch 340 : 0.007443252485245466
Loss at batch 350 : 0.017399195581674576
Loss at batch 360 : 0.017448769882321358
Loss at batch 370 : 0.01772942766547203
epoch124 finished!
Loss at batch 10 : 0.020345456898212433
Loss at batch 20 : 0.01800789125263691
Loss at batch 30 : 0.011966880410909653
Loss at batch 40 : 0.01564909890294075
Loss at batch 50 : 0.01513747964054346
Loss at batch 60 : 0.016377674415707588
Loss at batch 70 : 0.010231608524918556
Loss at batch 80 : 0.009522444568574429
Loss at batch 90 : 0.018470386043190956
Loss at batch 100 : 0.019594663754105568
Loss at batch 110 : 0.009562057442963123
Loss at batch 120 : 0.021633943542838097
Loss at batch 130 : 0.01667001098394394
Loss at batch 140 : 0.013058946467936039
Loss at batch 150 : 0.02205570973455906
Loss at batch 160 : 0.006957391742616892
Loss at batch 170 : 0.01125872228294611
Loss at batch 180 : 0.024849189445376396
Loss at batch 190 : 0.011837264522910118
Loss at batch 200 : 0.015895336866378784
Loss at batch 210 : 0.024151692166924477
Loss at batch 220 : 0.015867333859205246
Loss at batch 230 : 0.012047111056745052
Loss at batch 240 : 0.023677071556448936
Loss at batch 250 : 0.009257773868739605
Loss at batch 260 : 0.016589611768722534
Loss at batch 270 : 0.03246506676077843
Loss at batch 280 : 0.016418641433119774
Loss at batch 290 : 0.010592753067612648
Loss at batch 300 : 0.013917151838541031
Loss at batch 310 : 0.016317058354616165
Loss at batch 320 : 0.011486280709505081
Loss at batch 330 : 0.012938211672008038
Loss at batch 340 : 0.011959763243794441
Loss at batch 350 : 0.011430412530899048
Loss at batch 360 : 0.018361616879701614
Loss at batch 370 : 0.009354877285659313
epoch56 finished!
Loss at batch 10 : 0.007968711666762829
Loss at batch 20 : 0.010567506775259972
Loss at batch 30 : 0.009944566525518894
Loss at batch 40 : 0.012560244649648666
Loss at batch 50 : 0.01840827986598015
Loss at batch 60 : 0.01037320401519537
Loss at batch 70 : 0.013836666941642761
Loss at batch 80 : 0.017290586605668068
Loss at batch 90 : 0.014792099595069885
Loss at batch 100 : 0.01390787772834301
Loss at batch 110 : 0.011245116591453552
Loss at batch 120 : 0.011681790463626385
Loss at batch 130 : 0.0156799778342247
Loss at batch 140 : 0.01288590021431446
Loss at batch 150 : 0.02284645102918148
Loss at batch 160 : 0.008857003413140774
Loss at batch 170 : 0.008971956558525562
Loss at batch 180 : 0.021304070949554443
Loss at batch 190 : 0.010505682788789272
Loss at batch 200 : 0.010370366275310516
Loss at batch 210 : 0.011517460457980633
Loss at batch 220 : 0.016550404950976372
Loss at batch 230 : 0.009990044869482517
Loss at batch 240 : 0.01348202396184206
Loss at batch 250 : 0.013887050561606884
Loss at batch 260 : 0.007524557411670685
Loss at batch 270 : 0.005799385719001293
Loss at batch 280 : 0.0230218805372715
Loss at batch 290 : 0.010355296544730663
Loss at batch 300 : 0.011918795295059681
Loss at batch 310 : 0.010978157632052898
Loss at batch 320 : 0.02194884419441223
Loss at batch 330 : 0.021107017993927002
Loss at batch 340 : 0.01585816591978073
Loss at batch 350 : 0.01013149507343769
Loss at batch 360 : 0.009641479700803757
Loss at batch 370 : 0.021389609202742577
epoch56 finished!
Loss at batch 10 : 0.009314130060374737
Loss at batch 20 : 0.014394896104931831
Loss at batch 30 : 0.01366947777569294
Loss at batch 40 : 0.016277538612484932
Loss at batch 50 : 0.015710562467575073
Loss at batch 60 : 0.015719575807452202
Loss at batch 70 : 0.010728993453085423
Loss at batch 80 : 0.016106678172945976
Loss at batch 90 : 0.02215004153549671
Loss at batch 100 : 0.01843062974512577
Loss at batch 110 : 0.010296878404915333
Loss at batch 120 : 0.00929819792509079
Loss at batch 130 : 0.011946161277592182
Loss at batch 140 : 0.007725292816758156
Loss at batch 150 : 0.025804948061704636
Loss at batch 160 : 0.012138557620346546
Loss at batch 170 : 0.011410670354962349
Loss at batch 180 : 0.019474778324365616
Loss at batch 190 : 0.009952257387340069
Loss at batch 200 : 0.016737930476665497
Loss at batch 210 : 0.01578591950237751
Loss at batch 220 : 0.011330768465995789
Loss at batch 230 : 0.022994784638285637
Loss at batch 240 : 0.016925472766160965
Loss at batch 250 : 0.015446336939930916
Loss at batch 260 : 0.014834968373179436
Loss at batch 270 : 0.009838925674557686
Loss at batch 280 : 0.008917368948459625
Loss at batch 290 : 0.018327588215470314
Loss at batch 300 : 0.010332135483622551
Loss at batch 310 : 0.008611705154180527
Loss at batch 320 : 0.01969812996685505
Loss at batch 330 : 0.02007298916578293
Loss at batch 340 : 0.00987462978810072
Loss at batch 350 : 0.014064920134842396
Loss at batch 360 : 0.012927282601594925
Loss at batch 370 : 0.011608249507844448
epoch125 finished!
Loss at batch 10 : 0.010698745958507061
Loss at batch 20 : 0.018496252596378326
Loss at batch 30 : 0.013385693542659283
Loss at batch 40 : 0.022358635440468788
Loss at batch 50 : 0.01963023841381073
Loss at batch 60 : 0.03126148879528046
Loss at batch 70 : 0.019058948382735252
Loss at batch 80 : 0.011237910017371178
Loss at batch 90 : 0.014658539555966854
Loss at batch 100 : 0.01799626275897026
Loss at batch 110 : 0.011644951067864895
Loss at batch 120 : 0.01983698084950447
Loss at batch 130 : 0.007930985651910305
Loss at batch 140 : 0.01262714248150587
Loss at batch 150 : 0.015598258003592491
Loss at batch 160 : 0.013508733361959457
Loss at batch 170 : 0.021868692710995674
Loss at batch 180 : 0.024828657507896423
Loss at batch 190 : 0.016424205154180527
Loss at batch 200 : 0.01970032788813114
Loss at batch 210 : 0.008173185400664806
Loss at batch 220 : 0.010214117355644703
Loss at batch 230 : 0.006570321507751942
Loss at batch 240 : 0.010213998146355152
Loss at batch 250 : 0.013000886887311935
Loss at batch 260 : 0.013998889364302158
Loss at batch 270 : 0.012978261336684227
Loss at batch 280 : 0.014886387623846531
Loss at batch 290 : 0.012839438393712044
Loss at batch 300 : 0.01811770536005497
Loss at batch 310 : 0.014751874841749668
Loss at batch 320 : 0.006371644791215658
Loss at batch 330 : 0.011632965877652168
Loss at batch 340 : 0.012638965621590614
Loss at batch 350 : 0.01670455001294613
Loss at batch 360 : 0.009326230734586716
Loss at batch 370 : 0.022771518677473068
epoch126 finished!
Loss at batch 10 : 0.00918874703347683
Loss at batch 20 : 0.012924650683999062
Loss at batch 30 : 0.00878812000155449
Loss at batch 40 : 0.011645558290183544
Loss at batch 50 : 0.011780897155404091
Loss at batch 60 : 0.012364822439849377
Loss at batch 70 : 0.01718173362314701
Loss at batch 80 : 0.02173830382525921
Loss at batch 90 : 0.02025439776480198
Loss at batch 100 : 0.019633471965789795
Loss at batch 110 : 0.010859169997274876
Loss at batch 120 : 0.011237191036343575
Loss at batch 130 : 0.010531838983297348
Loss at batch 140 : 0.015238051302731037
Loss at batch 150 : 0.012394055724143982
Loss at batch 160 : 0.00964348204433918
Loss at batch 170 : 0.020406024530529976
Loss at batch 180 : 0.006535765714943409
Loss at batch 190 : 0.01703954115509987
Loss at batch 200 : 0.013152574189007282
Loss at batch 210 : 0.01845463737845421
Loss at batch 220 : 0.0199649129062891
Loss at batch 230 : 0.011991181410849094
Loss at batch 240 : 0.013192323036491871
Loss at batch 250 : 0.022573310881853104
Loss at batch 260 : 0.011665736325085163
Loss at batch 270 : 0.016819946467876434
Loss at batch 280 : 0.01291447039693594
Loss at batch 290 : 0.007332415319979191
Loss at batch 300 : 0.019179390743374825
Loss at batch 310 : 0.006984462030231953
Loss at batch 320 : 0.01020824909210205
Loss at batch 330 : 0.03073912300169468
Loss at batch 340 : 0.006423913408070803
Loss at batch 350 : 0.012617634609341621
Loss at batch 360 : 0.010033003985881805
Loss at batch 370 : 0.014205671846866608
epoch57 finished!
Loss at batch 10 : 0.018915005028247833
Loss at batch 20 : 0.012097757309675217
Loss at batch 30 : 0.018257994204759598
Loss at batch 40 : 0.019263746216893196
Loss at batch 50 : 0.018920637667179108
Loss at batch 60 : 0.007870412431657314
Loss at batch 70 : 0.019072847440838814
Loss at batch 80 : 0.007348466664552689
Loss at batch 90 : 0.010421155951917171
Loss at batch 100 : 0.009642394259572029
Loss at batch 110 : 0.01533503271639347
Loss at batch 120 : 0.014369756914675236
Loss at batch 130 : 0.02009442262351513
Loss at batch 140 : 0.009782587178051472
Loss at batch 150 : 0.0196992140263319
Loss at batch 160 : 0.025134537369012833
Loss at batch 170 : 0.016372602432966232
Loss at batch 180 : 0.011933977715671062
Loss at batch 190 : 0.014269066974520683
Loss at batch 200 : 0.012442382052540779
Loss at batch 210 : 0.009256943129003048
Loss at batch 220 : 0.015672070905566216
Loss at batch 230 : 0.010187134146690369
Loss at batch 240 : 0.008373910561203957
Loss at batch 250 : 0.010048608295619488
Loss at batch 260 : 0.011150541715323925
Loss at batch 270 : 0.017042499035596848
Loss at batch 280 : 0.01261198241263628
Loss at batch 290 : 0.020799489691853523
Loss at batch 300 : 0.013548387214541435
Loss at batch 310 : 0.015778450295329094
Loss at batch 320 : 0.009354996494948864
Loss at batch 330 : 0.02223925292491913
Loss at batch 340 : 0.020118726417422295
Loss at batch 350 : 0.022117478772997856
Loss at batch 360 : 0.010692646726965904
Loss at batch 370 : 0.01127012912184
epoch57 finished!
Loss at batch 10 : 0.009640644304454327
Loss at batch 20 : 0.010469483211636543
Loss at batch 30 : 0.018668141216039658
Loss at batch 40 : 0.016777368262410164
Loss at batch 50 : 0.015496487729251385
Loss at batch 60 : 0.010646378621459007
Loss at batch 70 : 0.02232874557375908
Loss at batch 80 : 0.020319795235991478
Loss at batch 90 : 0.011151797138154507
Loss at batch 100 : 0.009298699907958508
Loss at batch 110 : 0.008719501085579395
Loss at batch 120 : 0.012062333524227142
Loss at batch 130 : 0.02283008024096489
Loss at batch 140 : 0.015964752063155174
Loss at batch 150 : 0.017232514917850494
Loss at batch 160 : 0.021424930542707443
Loss at batch 170 : 0.021769443526864052
Loss at batch 180 : 0.009219052270054817
Loss at batch 190 : 0.009809978306293488
Loss at batch 200 : 0.008438154123723507
Loss at batch 210 : 0.0077814748510718346
Loss at batch 220 : 0.00706983357667923
Loss at batch 230 : 0.018776172772049904
Loss at batch 240 : 0.00926461536437273
Loss at batch 250 : 0.013581161387264729
Loss at batch 260 : 0.013261736370623112
Loss at batch 270 : 0.0233272984623909
Loss at batch 280 : 0.011241041123867035
Loss at batch 290 : 0.012114785611629486
Loss at batch 300 : 0.009510907344520092
Loss at batch 310 : 0.014257310889661312
Loss at batch 320 : 0.017664572224020958
Loss at batch 330 : 0.016584543511271477
Loss at batch 340 : 0.018729694187641144
Loss at batch 350 : 0.011181547306478024
Loss at batch 360 : 0.014710335992276669
Loss at batch 370 : 0.012097765691578388
epoch127 finished!
Loss at batch 10 : 0.010876293294131756
Loss at batch 20 : 0.011546526104211807
Loss at batch 30 : 0.00951166171580553
Loss at batch 40 : 0.01043262705206871
Loss at batch 50 : 0.017386261373758316
Loss at batch 60 : 0.021619895473122597
Loss at batch 70 : 0.007822157815098763
Loss at batch 80 : 0.00808345153927803
Loss at batch 90 : 0.009945112280547619
Loss at batch 100 : 0.009111818857491016
Loss at batch 110 : 0.022638745605945587
Loss at batch 120 : 0.01127767562866211
Loss at batch 130 : 0.013253369368612766
Loss at batch 140 : 0.01088663935661316
Loss at batch 150 : 0.01568654552102089
Loss at batch 160 : 0.01589430868625641
Loss at batch 170 : 0.01529773324728012
Loss at batch 180 : 0.013158448971807957
Loss at batch 190 : 0.007873965427279472
Loss at batch 200 : 0.015820685774087906
Loss at batch 210 : 0.012020622380077839
Loss at batch 220 : 0.014927953481674194
Loss at batch 230 : 0.01617457903921604
Loss at batch 240 : 0.02330382913351059
Loss at batch 250 : 0.017767732962965965
Loss at batch 260 : 0.006906389258801937
Loss at batch 270 : 0.02837270125746727
Loss at batch 280 : 0.012624775059521198
Loss at batch 290 : 0.014364740811288357
Loss at batch 300 : 0.009620633907616138
Loss at batch 310 : 0.008564334362745285
Loss at batch 320 : 0.019186368212103844
Loss at batch 330 : 0.016175854951143265
Loss at batch 340 : 0.015450636856257915
Loss at batch 350 : 0.011651897802948952
Loss at batch 360 : 0.010643001645803452
Loss at batch 370 : 0.01273682527244091
epoch128 finished!
Loss at batch 10 : 0.02322288416326046
Loss at batch 20 : 0.018212003633379936
Loss at batch 30 : 0.013991006650030613
Loss at batch 40 : 0.01496824063360691
Loss at batch 50 : 0.015591481700539589
Loss at batch 60 : 0.03027932159602642
Loss at batch 70 : 0.013622674159705639
Loss at batch 80 : 0.02396462857723236
Loss at batch 90 : 0.012089195661246777
Loss at batch 100 : 0.01850641891360283
Loss at batch 110 : 0.014325172640383244
Loss at batch 120 : 0.011882662773132324
Loss at batch 130 : 0.012003271840512753
Loss at batch 140 : 0.01915636658668518
Loss at batch 150 : 0.017053982242941856
Loss at batch 160 : 0.016349567100405693
Loss at batch 170 : 0.01308982539921999
Loss at batch 180 : 0.010446419008076191
Loss at batch 190 : 0.010974250733852386
Loss at batch 200 : 0.02193167805671692
Loss at batch 210 : 0.015509495511651039
Loss at batch 220 : 0.014053788036108017
Loss at batch 230 : 0.016879865899682045
Loss at batch 240 : 0.009219172410666943
Loss at batch 250 : 0.013738513924181461
Loss at batch 260 : 0.02289862371981144
Loss at batch 270 : 0.012743856757879257
Loss at batch 280 : 0.02180936187505722
Loss at batch 290 : 0.02346264012157917
Loss at batch 300 : 0.010216808877885342
Loss at batch 310 : 0.03043532930314541
Loss at batch 320 : 0.01171030942350626
Loss at batch 330 : 0.01568523794412613
Loss at batch 340 : 0.013095807284116745
Loss at batch 350 : 0.013548496179282665
Loss at batch 360 : 0.018692705780267715
Loss at batch 370 : 0.016298875212669373
epoch58 finished!
Loss at batch 10 : 0.009413164108991623
Loss at batch 20 : 0.009884658269584179
Loss at batch 30 : 0.012939771637320518
Loss at batch 40 : 0.008959976024925709
Loss at batch 50 : 0.021879730746150017
Loss at batch 60 : 0.00702691962942481
Loss at batch 70 : 0.008387279696762562
Loss at batch 80 : 0.013970011845231056
Loss at batch 90 : 0.012071243487298489
Loss at batch 100 : 0.008573509752750397
Loss at batch 110 : 0.011212644167244434
Loss at batch 120 : 0.022446809336543083
Loss at batch 130 : 0.01758362352848053
Loss at batch 140 : 0.012081997469067574
Loss at batch 150 : 0.029355816543102264
Loss at batch 160 : 0.011512478813529015
Loss at batch 170 : 0.010176523588597775
Loss at batch 180 : 0.014344168826937675
Loss at batch 190 : 0.016469433903694153
Loss at batch 200 : 0.020987557247281075
Loss at batch 210 : 0.025605669245123863
Loss at batch 220 : 0.016457119956612587
Loss at batch 230 : 0.01746489480137825
Loss at batch 240 : 0.010654618963599205
Loss at batch 250 : 0.007903349585831165
Loss at batch 260 : 0.02269064262509346
Loss at batch 270 : 0.014595553278923035
Loss at batch 280 : 0.012380505912005901
Loss at batch 290 : 0.01230913307517767
Loss at batch 300 : 0.01188272051513195
Loss at batch 310 : 0.015933604910969734
Loss at batch 320 : 0.011692152358591557
Loss at batch 330 : 0.015671880915760994
Loss at batch 340 : 0.013659422285854816
Loss at batch 350 : 0.01015559583902359
Loss at batch 360 : 0.010666156187653542
Loss at batch 370 : 0.012694915756583214
epoch58 finished!
Loss at batch 10 : 0.017744679003953934
Loss at batch 20 : 0.01386072114109993
Loss at batch 30 : 0.013029448688030243
Loss at batch 40 : 0.01047807652503252
Loss at batch 50 : 0.010499426163733006
Loss at batch 60 : 0.014051559381186962
Loss at batch 70 : 0.02037491649389267
Loss at batch 80 : 0.01714477315545082
Loss at batch 90 : 0.007520965300500393
Loss at batch 100 : 0.011907019652426243
Loss at batch 110 : 0.009115835651755333
Loss at batch 120 : 0.014795076102018356
Loss at batch 130 : 0.012104457244277
Loss at batch 140 : 0.016771908849477768
Loss at batch 150 : 0.011558842845261097
Loss at batch 160 : 0.011670902371406555
Loss at batch 170 : 0.008700359612703323
Loss at batch 180 : 0.008000984787940979
Loss at batch 190 : 0.016293799504637718
Loss at batch 200 : 0.014320350252091885
Loss at batch 210 : 0.009279351681470871
Loss at batch 220 : 0.010214013047516346
Loss at batch 230 : 0.022187381982803345
Loss at batch 240 : 0.01696251891553402
Loss at batch 250 : 0.008843045681715012
Loss at batch 260 : 0.01662488281726837
Loss at batch 270 : 0.011821516789495945
Loss at batch 280 : 0.016498863697052002
Loss at batch 290 : 0.01572224497795105
Loss at batch 300 : 0.013506688177585602
Loss at batch 310 : 0.01193580124527216
Loss at batch 320 : 0.013708074577152729
Loss at batch 330 : 0.02033057063817978
Loss at batch 340 : 0.010035084560513496
Loss at batch 350 : 0.017375878989696503
Loss at batch 360 : 0.014351950027048588
Loss at batch 370 : 0.019430961459875107
epoch129 finished!
Loss at batch 10 : 0.013492302969098091
Loss at batch 20 : 0.010798483155667782
Loss at batch 30 : 0.011086968705058098
Loss at batch 40 : 0.011825292371213436
Loss at batch 50 : 0.0213382076472044
Loss at batch 60 : 0.01764458604156971
Loss at batch 70 : 0.01151246391236782
Loss at batch 80 : 0.017806969583034515
Loss at batch 90 : 0.00801838655024767
Loss at batch 100 : 0.0222589373588562
Loss at batch 110 : 0.012952297925949097
Loss at batch 120 : 0.010061894543468952
Loss at batch 130 : 0.009749769233167171
Loss at batch 140 : 0.012582028284668922
Loss at batch 150 : 0.010890007019042969
Loss at batch 160 : 0.012920746579766273
Loss at batch 170 : 0.020855365321040154
Loss at batch 180 : 0.01451567281037569
Loss at batch 190 : 0.014590851031243801
Loss at batch 200 : 0.007746682036668062
Loss at batch 210 : 0.015971938148140907
Loss at batch 220 : 0.012512682005763054
Loss at batch 230 : 0.03944939747452736
Loss at batch 240 : 0.015298960730433464
Loss at batch 250 : 0.009020067751407623
Loss at batch 260 : 0.009412267245352268
Loss at batch 270 : 0.009055029600858688
Loss at batch 280 : 0.02291165105998516
Loss at batch 290 : 0.01622304879128933
Loss at batch 300 : 0.008293021470308304
Loss at batch 310 : 0.012814774177968502
Loss at batch 320 : 0.01196327991783619
Loss at batch 330 : 0.01960509642958641
Loss at batch 340 : 0.017193004488945007
Loss at batch 350 : 0.017225606366991997
Loss at batch 360 : 0.007214011158794165
Loss at batch 370 : 0.01331210695207119
epoch130 finished!
Loss at batch 10 : 0.007852865383028984
Loss at batch 20 : 0.017423253506422043
Loss at batch 30 : 0.023083709180355072
Loss at batch 40 : 0.014878523536026478
Loss at batch 50 : 0.017850693315267563
Loss at batch 60 : 0.012238577008247375
Loss at batch 70 : 0.018663328140974045
Loss at batch 80 : 0.010110416449606419
Loss at batch 90 : 0.010267986916005611
Loss at batch 100 : 0.009589776396751404
Loss at batch 110 : 0.017731523141264915
Loss at batch 120 : 0.01875588484108448
Loss at batch 130 : 0.012959986925125122
Loss at batch 140 : 0.01888076402246952
Loss at batch 150 : 0.014250257983803749
Loss at batch 160 : 0.022191276773810387
Loss at batch 170 : 0.0066145327873528
Loss at batch 180 : 0.02169753424823284
Loss at batch 190 : 0.014255104586482048
Loss at batch 200 : 0.009493976831436157
Loss at batch 210 : 0.023388464003801346
Loss at batch 220 : 0.017542188987135887
Loss at batch 230 : 0.014193164184689522
Loss at batch 240 : 0.011045452207326889
Loss at batch 250 : 0.017172008752822876
Loss at batch 260 : 0.015418563969433308
Loss at batch 270 : 0.020483123138546944
Loss at batch 280 : 0.013686031103134155
Loss at batch 290 : 0.01012226939201355
Loss at batch 300 : 0.012016024440526962
Loss at batch 310 : 0.023392802104353905
Loss at batch 320 : 0.020907895639538765
Loss at batch 330 : 0.017090240493416786
Loss at batch 340 : 0.010080006904900074
Loss at batch 350 : 0.02075747586786747
Loss at batch 360 : 0.01374226063489914
Loss at batch 370 : 0.011097840033471584
epoch59 finished!
Loss at batch 10 : 0.0125149916857481
Loss at batch 20 : 0.011677734553813934
Loss at batch 30 : 0.014532794244587421
Loss at batch 40 : 0.009591224603354931
Loss at batch 50 : 0.018270207569003105
Loss at batch 60 : 0.011198691092431545
Loss at batch 70 : 0.013268939219415188
Loss at batch 80 : 0.010228686966001987
Loss at batch 90 : 0.015569297596812248
Loss at batch 100 : 0.014270616695284843
Loss at batch 110 : 0.019300920888781548
Loss at batch 120 : 0.009345184080302715
Loss at batch 130 : 0.012251137755811214
Loss at batch 140 : 0.018875431269407272
Loss at batch 150 : 0.01339168380945921
Loss at batch 160 : 0.011293388903141022
Loss at batch 170 : 0.01129799336194992
Loss at batch 180 : 0.019416723400354385
Loss at batch 190 : 0.011288904584944248
Loss at batch 200 : 0.013247545808553696
Loss at batch 210 : 0.018133115023374557
Loss at batch 220 : 0.006121782120317221
Loss at batch 230 : 0.013278728350996971
Loss at batch 240 : 0.010117013938724995
Loss at batch 250 : 0.013433528132736683
Loss at batch 260 : 0.02069254405796528
Loss at batch 270 : 0.01999104954302311
Loss at batch 280 : 0.027223782613873482
Loss at batch 290 : 0.013951755128800869
Loss at batch 300 : 0.015901589766144753
Loss at batch 310 : 0.011022660881280899
Loss at batch 320 : 0.010200205259025097
Loss at batch 330 : 0.008085343986749649
Loss at batch 340 : 0.013344203121960163
Loss at batch 350 : 0.009624038822948933
Loss at batch 360 : 0.006516848225146532
Loss at batch 370 : 0.007748482283204794
epoch59 finished!
Loss at batch 10 : 0.011245742440223694
Loss at batch 20 : 0.015317115001380444
Loss at batch 30 : 0.016039611771702766
Loss at batch 40 : 0.011342098005115986
Loss at batch 50 : 0.024129867553710938
Loss at batch 60 : 0.015127855353057384
Loss at batch 70 : 0.013164904899895191
Loss at batch 80 : 0.014281722716987133
Loss at batch 90 : 0.01560622826218605
Loss at batch 100 : 0.012929975986480713
Loss at batch 110 : 0.018099956214427948
Loss at batch 120 : 0.011063499376177788
Loss at batch 130 : 0.009249050170183182
Loss at batch 140 : 0.01009895745664835
Loss at batch 150 : 0.008119504898786545
Loss at batch 160 : 0.01258521806448698
Loss at batch 170 : 0.021482497453689575
Loss at batch 180 : 0.013102622702717781
Loss at batch 190 : 0.0161955077201128
Loss at batch 200 : 0.008924952708184719
Loss at batch 210 : 0.007913338951766491
Loss at batch 220 : 0.009460457600653172
Loss at batch 230 : 0.022540532052516937
Loss at batch 240 : 0.0076619707979261875
Loss at batch 250 : 0.01762492209672928
Loss at batch 260 : 0.012517751194536686
Loss at batch 270 : 0.016988923773169518
Loss at batch 280 : 0.01649720035493374
Loss at batch 290 : 0.016368182376027107
Loss at batch 300 : 0.011002026498317719
Loss at batch 310 : 0.010652480646967888
Loss at batch 320 : 0.013094747439026833
Loss at batch 330 : 0.01438948791474104
Loss at batch 340 : 0.0070053949020802975
Loss at batch 350 : 0.01279159914702177
Loss at batch 360 : 0.007839608006179333
Loss at batch 370 : 0.01294487901031971
epoch131 finished!
Loss at batch 10 : 0.010752198286354542
Loss at batch 20 : 0.011328425258398056
Loss at batch 30 : 0.018193939700722694
Loss at batch 40 : 0.023727472871541977
Loss at batch 50 : 0.011586439795792103
Loss at batch 60 : 0.013908492401242256
Loss at batch 70 : 0.01184296514838934
Loss at batch 80 : 0.0160476416349411
Loss at batch 90 : 0.014433729462325573
Loss at batch 100 : 0.02510286681354046
Loss at batch 110 : 0.010753647424280643
Loss at batch 120 : 0.019164560362696648
Loss at batch 130 : 0.00558888865634799
Loss at batch 140 : 0.007697871886193752
Loss at batch 150 : 0.007113239262253046
Loss at batch 160 : 0.010955093428492546
Loss at batch 170 : 0.011603042483329773
Loss at batch 180 : 0.016895519569516182
Loss at batch 190 : 0.0088258758187294
Loss at batch 200 : 0.01980474218726158
Loss at batch 210 : 0.01647079549729824
Loss at batch 220 : 0.012187158688902855
Loss at batch 230 : 0.018904654309153557
Loss at batch 240 : 0.008342830464243889
Loss at batch 250 : 0.013140276074409485
Loss at batch 260 : 0.015051579102873802
Loss at batch 270 : 0.012543928809463978
Loss at batch 280 : 0.010549784637987614
Loss at batch 290 : 0.011917646043002605
Loss at batch 300 : 0.014670422300696373
Loss at batch 310 : 0.020123690366744995
Loss at batch 320 : 0.021271655336022377
Loss at batch 330 : 0.009988331235945225
Loss at batch 340 : 0.019217072054743767
Loss at batch 350 : 0.01643974706530571
Loss at batch 360 : 0.023313011974096298
Loss at batch 370 : 0.017038458958268166
epoch132 finished!
Loss at batch 10 : 0.018173784017562866
Loss at batch 20 : 0.014318233355879784
Loss at batch 30 : 0.01961609721183777
Loss at batch 40 : 0.008964890614151955
Loss at batch 50 : 0.007325082551687956
Loss at batch 60 : 0.010263602249324322
Loss at batch 70 : 0.02329712174832821
Loss at batch 80 : 0.0231991745531559
Loss at batch 90 : 0.01936575211584568
Loss at batch 100 : 0.009302723221480846
Loss at batch 110 : 0.009770644828677177
Loss at batch 120 : 0.0102955037727952
Loss at batch 130 : 0.011312014423310757
Loss at batch 140 : 0.03146776556968689
Loss at batch 150 : 0.010566815733909607
Loss at batch 160 : 0.030623897910118103
Loss at batch 170 : 0.015673495829105377
Loss at batch 180 : 0.012028113938868046
Loss at batch 190 : 0.02847544476389885
Loss at batch 200 : 0.014499999582767487
Loss at batch 210 : 0.010702981613576412
Loss at batch 220 : 0.010886188596487045
Loss at batch 230 : 0.01528120692819357
Loss at batch 240 : 0.020814934745430946
Loss at batch 250 : 0.009162907488644123
Loss at batch 260 : 0.01752084493637085
Loss at batch 270 : 0.012243443168699741
Loss at batch 280 : 0.014136149547994137
Loss at batch 290 : 0.010328346863389015
Loss at batch 300 : 0.02134484425187111
Loss at batch 310 : 0.018219219520688057
Loss at batch 320 : 0.008896342478692532
Loss at batch 330 : 0.01054767519235611
Loss at batch 340 : 0.00858023390173912
Loss at batch 350 : 0.012908401899039745
Loss at batch 360 : 0.012433328665792942
Loss at batch 370 : 0.007839354686439037
epoch60 finished!
Loss at batch 10 : 0.01011593546718359
Loss at batch 20 : 0.013049163855612278
Loss at batch 30 : 0.016113782301545143
Loss at batch 40 : 0.013183251954615116
Loss at batch 50 : 0.018140817061066628
Loss at batch 60 : 0.01073029637336731
Loss at batch 70 : 0.01272678468376398
Loss at batch 80 : 0.017625179141759872
Loss at batch 90 : 0.01400007028132677
Loss at batch 100 : 0.008209132589399815
Loss at batch 110 : 0.00916049350053072
Loss at batch 120 : 0.008593101985752583
Loss at batch 130 : 0.01190969068557024
Loss at batch 140 : 0.010095898993313313
Loss at batch 150 : 0.010768353007733822
Loss at batch 160 : 0.015081454999744892
Loss at batch 170 : 0.02303454279899597
Loss at batch 180 : 0.01873597502708435
Loss at batch 190 : 0.015929682180285454
Loss at batch 200 : 0.012091741897165775
Loss at batch 210 : 0.011704929172992706
Loss at batch 220 : 0.008461719378829002
Loss at batch 230 : 0.02202899567782879
Loss at batch 240 : 0.023795688524842262
Loss at batch 250 : 0.008235123939812183
Loss at batch 260 : 0.011607532389461994
Loss at batch 270 : 0.02410830184817314
Loss at batch 280 : 0.011711571365594864
Loss at batch 290 : 0.013056378811597824
Loss at batch 300 : 0.007303815800696611
Loss at batch 310 : 0.016192864626646042
Loss at batch 320 : 0.0174600500613451
Loss at batch 330 : 0.01064067892730236
Loss at batch 340 : 0.012501985765993595
Loss at batch 350 : 0.010136163793504238
Loss at batch 360 : 0.013652526773512363
Loss at batch 370 : 0.016824940219521523
epoch60 finished!
Loss at batch 10 : 0.013578668236732483
Loss at batch 20 : 0.00979593489319086
Loss at batch 30 : 0.011248650960624218
Loss at batch 40 : 0.009681835770606995
Loss at batch 50 : 0.012121770530939102
Loss at batch 60 : 0.00971609354019165
Loss at batch 70 : 0.014282661490142345
Loss at batch 80 : 0.014611233957111835
Loss at batch 90 : 0.005863395519554615
Loss at batch 100 : 0.010197642259299755
Loss at batch 110 : 0.011798507533967495
Loss at batch 120 : 0.010351371951401234
Loss at batch 130 : 0.020598435774445534
Loss at batch 140 : 0.009602345526218414
Loss at batch 150 : 0.013025191612541676
Loss at batch 160 : 0.01946483924984932
Loss at batch 170 : 0.014397473074495792
Loss at batch 180 : 0.013372639194130898
Loss at batch 190 : 0.008425635285675526
Loss at batch 200 : 0.01386332605034113
Loss at batch 210 : 0.009726702235639095
Loss at batch 220 : 0.01942935399711132
Loss at batch 230 : 0.011473073624074459
Loss at batch 240 : 0.007388832978904247
Loss at batch 250 : 0.01294955424964428
Loss at batch 260 : 0.012506205588579178
Loss at batch 270 : 0.014889138750731945
Loss at batch 280 : 0.011003361083567142
Loss at batch 290 : 0.015560095198452473
Loss at batch 300 : 0.011531292460858822
Loss at batch 310 : 0.01936151087284088
Loss at batch 320 : 0.014356286264955997
Loss at batch 330 : 0.011543584056198597
Loss at batch 340 : 0.013833858072757721
Loss at batch 350 : 0.027693940326571465
Loss at batch 360 : 0.014589393511414528
Loss at batch 370 : 0.009769675321877003
epoch133 finished!
Loss at batch 10 : 0.012530663050711155
Loss at batch 20 : 0.009542673826217651
Loss at batch 30 : 0.015126841142773628
Loss at batch 40 : 0.016500702127814293
Loss at batch 50 : 0.01234283298254013
Loss at batch 60 : 0.008968966081738472
Loss at batch 70 : 0.011414512991905212
Loss at batch 80 : 0.01785655878484249
Loss at batch 90 : 0.014918976463377476
Loss at batch 100 : 0.00755644403398037
Loss at batch 110 : 0.014034301042556763
Loss at batch 120 : 0.011677668429911137
Loss at batch 130 : 0.012264953926205635
Loss at batch 140 : 0.021418454125523567
Loss at batch 150 : 0.0070321462117135525
Loss at batch 160 : 0.016198068857192993
Loss at batch 170 : 0.010960935615003109
Loss at batch 180 : 0.011966035701334476
Loss at batch 190 : 0.031829606741666794
Loss at batch 200 : 0.018394989892840385
Loss at batch 210 : 0.00853162445127964
Loss at batch 220 : 0.02759031392633915
Loss at batch 230 : 0.009037742391228676
Loss at batch 240 : 0.02048293873667717
Loss at batch 250 : 0.008851797319948673
Loss at batch 260 : 0.01160783413797617
Loss at batch 270 : 0.01825580932199955
Loss at batch 280 : 0.01840253733098507
Loss at batch 290 : 0.007685061544179916
Loss at batch 300 : 0.015793314203619957
Loss at batch 310 : 0.017410997301340103
Loss at batch 320 : 0.01043720729649067
Loss at batch 330 : 0.020974989980459213
Loss at batch 340 : 0.01967597007751465
Loss at batch 350 : 0.020840810611844063
Loss at batch 360 : 0.014570043422281742
Loss at batch 370 : 0.012299325317144394
epoch134 finished!
Loss at batch 10 : 0.021343858912587166
Loss at batch 20 : 0.013103199191391468
Loss at batch 30 : 0.01312723197042942
Loss at batch 40 : 0.026949405670166016
Loss at batch 50 : 0.01210248377174139
Loss at batch 60 : 0.023780720308423042
Loss at batch 70 : 0.0228456761687994
Loss at batch 80 : 0.02497495897114277
Loss at batch 90 : 0.01682579144835472
Loss at batch 100 : 0.009440130554139614
Loss at batch 110 : 0.005524849519133568
Loss at batch 120 : 0.009746454656124115
Loss at batch 130 : 0.011374812573194504
Loss at batch 140 : 0.02408541925251484
Loss at batch 150 : 0.01154849398881197
Loss at batch 160 : 0.011959606781601906
Loss at batch 170 : 0.013167976401746273
Loss at batch 180 : 0.021206602454185486
Loss at batch 190 : 0.011844363063573837
Loss at batch 200 : 0.01576046273112297
Loss at batch 210 : 0.023087916895747185
Loss at batch 220 : 0.01657125912606716
Loss at batch 230 : 0.014562816359102726
Loss at batch 240 : 0.011261029168963432
Loss at batch 250 : 0.009485147893428802
Loss at batch 260 : 0.010311608202755451
Loss at batch 270 : 0.007843044586479664
Loss at batch 280 : 0.017795350402593613
Loss at batch 290 : 0.019460517913103104
Loss at batch 300 : 0.01770753040909767
Loss at batch 310 : 0.010795513167977333
Loss at batch 320 : 0.009458822198212147
Loss at batch 330 : 0.012088057585060596
Loss at batch 340 : 0.012485259212553501
Loss at batch 350 : 0.008123463951051235
Loss at batch 360 : 0.010919497348368168
Loss at batch 370 : 0.018468251451849937
epoch61 finished!
Loss at batch 10 : 0.017263095825910568
Loss at batch 20 : 0.009659567847847939
Loss at batch 30 : 0.009811200201511383
Loss at batch 40 : 0.012931641191244125
Loss at batch 50 : 0.013079965487122536
Loss at batch 60 : 0.009520045481622219
Loss at batch 70 : 0.019504832103848457
Loss at batch 80 : 0.023551039397716522
Loss at batch 90 : 0.013745454140007496
Loss at batch 100 : 0.008779644966125488
Loss at batch 110 : 0.010552745312452316
Loss at batch 120 : 0.013650167733430862
Loss at batch 130 : 0.009704886935651302
Loss at batch 140 : 0.008620795793831348
Loss at batch 150 : 0.01572374254465103
Loss at batch 160 : 0.01233726181089878
Loss at batch 170 : 0.010942196473479271
Loss at batch 180 : 0.008641962893307209
Loss at batch 190 : 0.020351592451334
Loss at batch 200 : 0.013300481252372265
Loss at batch 210 : 0.010107139125466347
Loss at batch 220 : 0.018624652177095413
Loss at batch 230 : 0.012450949288904667
Loss at batch 240 : 0.01683773286640644
Loss at batch 250 : 0.02575463056564331
Loss at batch 260 : 0.014458897523581982
Loss at batch 270 : 0.010504044592380524
Loss at batch 280 : 0.016099071130156517
Loss at batch 290 : 0.00945978332310915
Loss at batch 300 : 0.013373017311096191
Loss at batch 310 : 0.02468392811715603
Loss at batch 320 : 0.024602679535746574
Loss at batch 330 : 0.01484196912497282
Loss at batch 340 : 0.01554354839026928
Loss at batch 350 : 0.009011180140078068
Loss at batch 360 : 0.010581685230135918
Loss at batch 370 : 0.014908891171216965
epoch135 finished!
Loss at batch 10 : 0.0158193651586771
Loss at batch 20 : 0.0070430501364171505
Loss at batch 30 : 0.009750581346452236
Loss at batch 40 : 0.010069292038679123
Loss at batch 50 : 0.016858195886015892
Loss at batch 60 : 0.018388403579592705
Loss at batch 70 : 0.012498168274760246
Loss at batch 80 : 0.012180529534816742
Loss at batch 90 : 0.011254608631134033
Loss at batch 100 : 0.01658026874065399
Loss at batch 110 : 0.014031690545380116
Loss at batch 120 : 0.02261369116604328
Loss at batch 130 : 0.013902072794735432
Loss at batch 140 : 0.01104642916470766
Loss at batch 150 : 0.012509986758232117
Loss at batch 160 : 0.016847696155309677
Loss at batch 170 : 0.012698880396783352
Loss at batch 180 : 0.015430396422743797
Loss at batch 190 : 0.016228506341576576
Loss at batch 200 : 0.015776855871081352
Loss at batch 210 : 0.01107925083488226
Loss at batch 220 : 0.010687647387385368
Loss at batch 230 : 0.012003856711089611
Loss at batch 240 : 0.01570427045226097
Loss at batch 250 : 0.02065940573811531
Loss at batch 260 : 0.018702145665884018
Loss at batch 270 : 0.008345551788806915
Loss at batch 280 : 0.026577232405543327
Loss at batch 290 : 0.011195478960871696
Loss at batch 300 : 0.014606802724301815
Loss at batch 310 : 0.015849489718675613
Loss at batch 320 : 0.01140248030424118
Loss at batch 330 : 0.012028099969029427
Loss at batch 340 : 0.009937794879078865
Loss at batch 350 : 0.013645874336361885
Loss at batch 360 : 0.020050756633281708
Loss at batch 370 : 0.01638965681195259
epoch61 finished!
Loss at batch 10 : 0.02129669301211834
Loss at batch 20 : 0.009610998444259167
Loss at batch 30 : 0.007974839769303799
Loss at batch 40 : 0.017667362466454506
Loss at batch 50 : 0.02225097268819809
Loss at batch 60 : 0.012840010225772858
Loss at batch 70 : 0.012206791900098324
Loss at batch 80 : 0.009496882557868958
Loss at batch 90 : 0.016900883987545967
Loss at batch 100 : 0.013930167071521282
Loss at batch 110 : 0.008283399045467377
Loss at batch 120 : 0.02990565448999405
Loss at batch 130 : 0.01219912339001894
Loss at batch 140 : 0.010575191117823124
Loss at batch 150 : 0.008982304483652115
Loss at batch 160 : 0.014393730089068413
Loss at batch 170 : 0.026780791580677032
Loss at batch 180 : 0.01402327325195074
Loss at batch 190 : 0.006503387354314327
Loss at batch 200 : 0.010427151806652546
Loss at batch 210 : 0.02174958400428295
Loss at batch 220 : 0.013689174316823483
Loss at batch 230 : 0.02256336621940136
Loss at batch 240 : 0.01838577724993229
Loss at batch 250 : 0.012162897735834122
Loss at batch 260 : 0.00797742698341608
Loss at batch 270 : 0.015772540122270584
Loss at batch 280 : 0.014821354299783707
Loss at batch 290 : 0.025717049837112427
Loss at batch 300 : 0.015416127629578114
Loss at batch 310 : 0.016226541250944138
Loss at batch 320 : 0.011383702047169209
Loss at batch 330 : 0.010214244946837425
Loss at batch 340 : 0.013399497605860233
Loss at batch 350 : 0.01471798587590456
Loss at batch 360 : 0.01170892734080553
Loss at batch 370 : 0.01412961259484291
epoch136 finished!
Loss at batch 10 : 0.015545619651675224
Loss at batch 20 : 0.007742885034531355
Loss at batch 30 : 0.012291250750422478
Loss at batch 40 : 0.01117380615323782
Loss at batch 50 : 0.023731091991066933
Loss at batch 60 : 0.011748893186450005
Loss at batch 70 : 0.013454532250761986
Loss at batch 80 : 0.022268155589699745
Loss at batch 90 : 0.014268429018557072
Loss at batch 100 : 0.02061992697417736
Loss at batch 110 : 0.010432175360620022
Loss at batch 120 : 0.014949064701795578
Loss at batch 130 : 0.021564146503806114
Loss at batch 140 : 0.016263674944639206
Loss at batch 150 : 0.007023368496447802
Loss at batch 160 : 0.012224084697663784
Loss at batch 170 : 0.010473985224962234
Loss at batch 180 : 0.020780814811587334
Loss at batch 190 : 0.01380699872970581
Loss at batch 200 : 0.01828179880976677
Loss at batch 210 : 0.017097976058721542
Loss at batch 220 : 0.025426102802157402
Loss at batch 230 : 0.0211511068046093
Loss at batch 240 : 0.021677369251847267
Loss at batch 250 : 0.020889727398753166
Loss at batch 260 : 0.011100838892161846
Loss at batch 270 : 0.011280178092420101
Loss at batch 280 : 0.01204422116279602
Loss at batch 290 : 0.01337368693202734
Loss at batch 300 : 0.011819782666862011
Loss at batch 310 : 0.008344712667167187
Loss at batch 320 : 0.014377748593688011
Loss at batch 330 : 0.012546411715447903
Loss at batch 340 : 0.012442720122635365
Loss at batch 350 : 0.012240390293300152
Loss at batch 360 : 0.009051700122654438
Loss at batch 370 : 0.015125622972846031
epoch137 finished!
Loss at batch 10 : 0.022399092093110085
Loss at batch 20 : 0.01648445427417755
Loss at batch 30 : 0.018706640228629112
Loss at batch 40 : 0.011075633578002453
Loss at batch 50 : 0.02063858136534691
Loss at batch 60 : 0.016098566353321075
Loss at batch 70 : 0.022363822907209396
Loss at batch 80 : 0.008041988126933575
Loss at batch 90 : 0.015907863155007362
Loss at batch 100 : 0.02842973917722702
Loss at batch 110 : 0.010944893583655357
Loss at batch 120 : 0.01427136454731226
Loss at batch 130 : 0.03113347291946411
Loss at batch 140 : 0.015217692591249943
Loss at batch 150 : 0.023513304069638252
Loss at batch 160 : 0.01137388776987791
Loss at batch 170 : 0.012393664568662643
Loss at batch 180 : 0.015590601600706577
Loss at batch 190 : 0.01744914799928665
Loss at batch 200 : 0.010199349373579025
Loss at batch 210 : 0.013011970557272434
Loss at batch 220 : 0.014281272888183594
Loss at batch 230 : 0.020323993638157845
Loss at batch 240 : 0.01477826852351427
Loss at batch 250 : 0.03452860191464424
Loss at batch 260 : 0.01233693864196539
Loss at batch 270 : 0.015683799982070923
Loss at batch 280 : 0.020382970571517944
Loss at batch 290 : 0.026719307526946068
Loss at batch 300 : 0.018128085881471634
Loss at batch 310 : 0.014836031012237072
Loss at batch 320 : 0.01172985415905714
Loss at batch 330 : 0.006479935254901648
Loss at batch 340 : 0.021705741062760353
Loss at batch 350 : 0.014282053336501122
Loss at batch 360 : 0.019560353830456734
Loss at batch 370 : 0.0120024299249053
epoch62 finished!
Loss at batch 10 : 0.01335815992206335
Loss at batch 20 : 0.017806146293878555
Loss at batch 30 : 0.012067562900483608
Loss at batch 40 : 0.014415215700864792
Loss at batch 50 : 0.008443574421107769
Loss at batch 60 : 0.013313454575836658
Loss at batch 70 : 0.0088571198284626
Loss at batch 80 : 0.016032826155424118
Loss at batch 90 : 0.03197791799902916
Loss at batch 100 : 0.02043704316020012
Loss at batch 110 : 0.014438372105360031
Loss at batch 120 : 0.01800905540585518
Loss at batch 130 : 0.019784552976489067
Loss at batch 140 : 0.01995171047747135
Loss at batch 150 : 0.016926763579249382
Loss at batch 160 : 0.01510303933173418
Loss at batch 170 : 0.017835786566138268
Loss at batch 180 : 0.018768858164548874
Loss at batch 190 : 0.02428917959332466
Loss at batch 200 : 0.011931303888559341
Loss at batch 210 : 0.011435888707637787
Loss at batch 220 : 0.010906348936259747
Loss at batch 230 : 0.010187080129981041
Loss at batch 240 : 0.009036394767463207
Loss at batch 250 : 0.008499551564455032
Loss at batch 260 : 0.012436694465577602
Loss at batch 270 : 0.016188453882932663
Loss at batch 280 : 0.014585970900952816
Loss at batch 290 : 0.017788873985409737
Loss at batch 300 : 0.02027149870991707
Loss at batch 310 : 0.020225150510668755
Loss at batch 320 : 0.014638262800872326
Loss at batch 330 : 0.018594149500131607
Loss at batch 340 : 0.01900571398437023
Loss at batch 350 : 0.008069622330367565
Loss at batch 360 : 0.015164341777563095
Loss at batch 370 : 0.011478549800813198
epoch62 finished!
Loss at batch 10 : 0.010003888979554176
Loss at batch 20 : 0.014213341288268566
Loss at batch 30 : 0.012523812241852283
Loss at batch 40 : 0.018507933244109154
Loss at batch 50 : 0.01315851416438818
Loss at batch 60 : 0.00833671260625124
Loss at batch 70 : 0.014179153367877007
Loss at batch 80 : 0.00835510715842247
Loss at batch 90 : 0.014094912447035313
Loss at batch 100 : 0.018877115100622177
Loss at batch 110 : 0.019664498046040535
Loss at batch 120 : 0.01233743503689766
Loss at batch 130 : 0.011649721302092075
Loss at batch 140 : 0.010883045382797718
Loss at batch 150 : 0.01908046007156372
Loss at batch 160 : 0.00881934817880392
Loss at batch 170 : 0.016046665608882904
Loss at batch 180 : 0.012532055377960205
Loss at batch 190 : 0.00915632676333189
Loss at batch 200 : 0.008412736468017101
Loss at batch 210 : 0.010877788998186588
Loss at batch 220 : 0.018214639276266098
Loss at batch 230 : 0.012582989409565926
Loss at batch 240 : 0.012108800932765007
Loss at batch 250 : 0.02468746528029442
Loss at batch 260 : 0.012640323489904404
Loss at batch 270 : 0.018979908898472786
Loss at batch 280 : 0.011877370066940784
Loss at batch 290 : 0.021580692380666733
Loss at batch 300 : 0.013239329680800438
Loss at batch 310 : 0.01609068363904953
Loss at batch 320 : 0.012553613632917404
Loss at batch 330 : 0.015533845871686935
Loss at batch 340 : 0.013737737201154232
Loss at batch 350 : 0.009598937816917896
Loss at batch 360 : 0.014949909411370754
Loss at batch 370 : 0.022171007469296455
epoch138 finished!
Loss at batch 10 : 0.012599187903106213
Loss at batch 20 : 0.023424699902534485
Loss at batch 30 : 0.012820498086512089
Loss at batch 40 : 0.010257928632199764
Loss at batch 50 : 0.016610004007816315
Loss at batch 60 : 0.007780678104609251
Loss at batch 70 : 0.01149670034646988
Loss at batch 80 : 0.014805796556174755
Loss at batch 90 : 0.016497712582349777
Loss at batch 100 : 0.017170999199151993
Loss at batch 110 : 0.008051697164773941
Loss at batch 120 : 0.01943339966237545
Loss at batch 130 : 0.016312502324581146
Loss at batch 140 : 0.015093695372343063
Loss at batch 150 : 0.014166351407766342
Loss at batch 160 : 0.018307993188500404
Loss at batch 170 : 0.009965458884835243
Loss at batch 180 : 0.01696469821035862
Loss at batch 190 : 0.0125392135232687
Loss at batch 200 : 0.009854492731392384
Loss at batch 210 : 0.008834486827254295
Loss at batch 220 : 0.023897921666502953
Loss at batch 230 : 0.026299506425857544
Loss at batch 240 : 0.011523823253810406
Loss at batch 250 : 0.030935848131775856
Loss at batch 260 : 0.0117654362693429
Loss at batch 270 : 0.015606509521603584
Loss at batch 280 : 0.014964010566473007
Loss at batch 290 : 0.009749193675816059
Loss at batch 300 : 0.007119619753211737
Loss at batch 310 : 0.023067506030201912
Loss at batch 320 : 0.021795950829982758
Loss at batch 330 : 0.014779317192733288
Loss at batch 340 : 0.014071110635995865
Loss at batch 350 : 0.020541947335004807
Loss at batch 360 : 0.009413914754986763
Loss at batch 370 : 0.012640678323805332
epoch139 finished!
Loss at batch 10 : 0.015765441581606865
Loss at batch 20 : 0.01792997121810913
Loss at batch 30 : 0.008553856052458286
Loss at batch 40 : 0.006529690697789192
Loss at batch 50 : 0.011369835585355759
Loss at batch 60 : 0.014536944217979908
Loss at batch 70 : 0.014925929717719555
Loss at batch 80 : 0.011537858285009861
Loss at batch 90 : 0.013608044013381004
Loss at batch 100 : 0.016599740833044052
Loss at batch 110 : 0.01574748195707798
Loss at batch 120 : 0.017968008294701576
Loss at batch 130 : 0.014333229511976242
Loss at batch 140 : 0.010287325829267502
Loss at batch 150 : 0.014466039836406708
Loss at batch 160 : 0.010692977346479893
Loss at batch 170 : 0.016823861747980118
Loss at batch 180 : 0.015997303649783134
Loss at batch 190 : 0.025515714660286903
Loss at batch 200 : 0.012057662941515446
Loss at batch 210 : 0.010340004228055477
Loss at batch 220 : 0.012109593488276005
Loss at batch 230 : 0.015238733030855656
Loss at batch 240 : 0.012777157127857208
Loss at batch 250 : 0.017703352496027946
Loss at batch 260 : 0.008981587365269661
Loss at batch 270 : 0.00821260642260313
Loss at batch 280 : 0.02305525355041027
Loss at batch 290 : 0.017259081825613976
Loss at batch 300 : 0.01573856733739376
Loss at batch 310 : 0.011529384180903435
Loss at batch 320 : 0.011743886396288872
Loss at batch 330 : 0.021954476833343506
Loss at batch 340 : 0.014488773420453072
Loss at batch 350 : 0.006852149963378906
Loss at batch 360 : 0.01588485948741436
Loss at batch 370 : 0.016427623108029366
epoch63 finished!
Loss at batch 10 : 0.01665271259844303
Loss at batch 20 : 0.012851588428020477
Loss at batch 30 : 0.014830638654530048
Loss at batch 40 : 0.012189121916890144
Loss at batch 50 : 0.013763186521828175
Loss at batch 60 : 0.011428937315940857
Loss at batch 70 : 0.017085416242480278
Loss at batch 80 : 0.011620601639151573
Loss at batch 90 : 0.009785324335098267
Loss at batch 100 : 0.010489284060895443
Loss at batch 110 : 0.0065381391905248165
Loss at batch 120 : 0.014181927777826786
Loss at batch 130 : 0.017943352460861206
Loss at batch 140 : 0.008468412794172764
Loss at batch 150 : 0.022717716172337532
Loss at batch 160 : 0.01394403725862503
Loss at batch 170 : 0.01795525662600994
Loss at batch 180 : 0.014499077573418617
Loss at batch 190 : 0.008732814341783524
Loss at batch 200 : 0.01425166055560112
Loss at batch 210 : 0.011969238519668579
Loss at batch 220 : 0.01694808155298233
Loss at batch 230 : 0.009535671211779118
Loss at batch 240 : 0.015550448559224606
Loss at batch 250 : 0.017398351803421974
Loss at batch 260 : 0.026568803936243057
Loss at batch 270 : 0.02038429118692875
Loss at batch 280 : 0.013282998465001583
Loss at batch 290 : 0.009335976094007492
Loss at batch 300 : 0.01677863858640194
Loss at batch 310 : 0.018486810848116875
Loss at batch 320 : 0.015982000157237053
Loss at batch 330 : 0.015351553447544575
Loss at batch 340 : 0.018113162368535995
Loss at batch 350 : 0.012839154340326786
Loss at batch 360 : 0.01216488890349865
Loss at batch 370 : 0.009183752350509167
epoch63 finished!
Loss at batch 10 : 0.017149033024907112
Loss at batch 20 : 0.016906285658478737
Loss at batch 30 : 0.015610375441610813
Loss at batch 40 : 0.017996296286582947
Loss at batch 50 : 0.010247373953461647
Loss at batch 60 : 0.014637147076427937
Loss at batch 70 : 0.02542119473218918
Loss at batch 80 : 0.024785049259662628
Loss at batch 90 : 0.015173998661339283
Loss at batch 100 : 0.014209775254130363
Loss at batch 110 : 0.025214295834302902
Loss at batch 120 : 0.02062767930328846
Loss at batch 130 : 0.019059980288147926
Loss at batch 140 : 0.01530742458999157
Loss at batch 150 : 0.010361754335463047
Loss at batch 160 : 0.02116943709552288
Loss at batch 170 : 0.013001903891563416
Loss at batch 180 : 0.019323209300637245
Loss at batch 190 : 0.009632134810090065
Loss at batch 200 : 0.01391997653990984
Loss at batch 210 : 0.018644023686647415
Loss at batch 220 : 0.014262604527175426
Loss at batch 230 : 0.010232147760689259
Loss at batch 240 : 0.012486577033996582
Loss at batch 250 : 0.013267862610518932
Loss at batch 260 : 0.00944032147526741
Loss at batch 270 : 0.010822883807122707
Loss at batch 280 : 0.015988657251000404
Loss at batch 290 : 0.009145520627498627
Loss at batch 300 : 0.00949231069535017
Loss at batch 310 : 0.015447603538632393
Loss at batch 320 : 0.014558454044163227
Loss at batch 330 : 0.015644367784261703
Loss at batch 340 : 0.015704352408647537
Loss at batch 350 : 0.012424290180206299
Loss at batch 360 : 0.014190240763127804
Loss at batch 370 : 0.009865600615739822
epoch140 finished!
Loss at batch 10 : 0.009825351648032665
Loss at batch 20 : 0.018360186368227005
Loss at batch 30 : 0.01207133661955595
Loss at batch 40 : 0.011619050987064838
Loss at batch 50 : 0.02553919143974781
Loss at batch 60 : 0.017466597259044647
Loss at batch 70 : 0.014465351589024067
Loss at batch 80 : 0.007661197334527969
Loss at batch 90 : 0.01698363572359085
Loss at batch 100 : 0.016631824895739555
Loss at batch 110 : 0.014275334775447845
Loss at batch 120 : 0.008144755847752094
Loss at batch 130 : 0.01207207515835762
Loss at batch 140 : 0.015181423164904118
Loss at batch 150 : 0.018858376890420914
Loss at batch 160 : 0.01319109182804823
Loss at batch 170 : 0.020818445831537247
Loss at batch 180 : 0.020022807642817497
Loss at batch 190 : 0.019307592883706093
Loss at batch 200 : 0.009285741485655308
Loss at batch 210 : 0.012329879216849804
Loss at batch 220 : 0.030225714668631554
Loss at batch 230 : 0.012760522775352001
Loss at batch 240 : 0.01619136892259121
Loss at batch 250 : 0.011639587581157684
Loss at batch 260 : 0.019019030034542084
Loss at batch 270 : 0.014242324978113174
Loss at batch 280 : 0.009869016706943512
Loss at batch 290 : 0.01703817956149578
Loss at batch 300 : 0.0165218785405159
Loss at batch 310 : 0.013979741372168064
Loss at batch 320 : 0.012949070893228054
Loss at batch 330 : 0.007477059494704008
Loss at batch 340 : 0.009218449704349041
Loss at batch 350 : 0.01238993275910616
Loss at batch 360 : 0.010109719820320606
Loss at batch 370 : 0.014152584597468376
epoch141 finished!
Loss at batch 10 : 0.01567862741649151
Loss at batch 20 : 0.008971896022558212
Loss at batch 30 : 0.01592816226184368
Loss at batch 40 : 0.03672930225729942
Loss at batch 50 : 0.011778845451772213
Loss at batch 60 : 0.010521991178393364
Loss at batch 70 : 0.014039296656847
Loss at batch 80 : 0.009529880248010159
Loss at batch 90 : 0.0209150742739439
Loss at batch 100 : 0.012648808769881725
Loss at batch 110 : 0.017604636028409004
Loss at batch 120 : 0.018359582871198654
Loss at batch 130 : 0.013227149844169617
Loss at batch 140 : 0.01403551734983921
Loss at batch 150 : 0.009460498578846455
Loss at batch 160 : 0.010871266946196556
Loss at batch 170 : 0.021482890471816063
Loss at batch 180 : 0.010108020156621933
Loss at batch 190 : 0.02319793775677681
Loss at batch 200 : 0.010701528750360012
Loss at batch 210 : 0.015122219920158386
Loss at batch 220 : 0.010997625067830086
Loss at batch 230 : 0.03280995041131973
Loss at batch 240 : 0.00807727687060833
Loss at batch 250 : 0.013928192667663097
Loss at batch 260 : 0.017276490107178688
Loss at batch 270 : 0.01088524330407381
Loss at batch 280 : 0.011740131303668022
Loss at batch 290 : 0.02181829698383808
Loss at batch 300 : 0.011072025634348392
Loss at batch 310 : 0.013348085805773735
Loss at batch 320 : 0.01699427329003811
Loss at batch 330 : 0.016851870343089104
Loss at batch 340 : 0.010715296491980553
Loss at batch 350 : 0.011277529411017895
Loss at batch 360 : 0.011588772758841515
Loss at batch 370 : 0.013519001193344593
epoch64 finished!
Loss at batch 10 : 0.01685290038585663
Loss at batch 20 : 0.008382760919630527
Loss at batch 30 : 0.010370714589953423
Loss at batch 40 : 0.01870179921388626
Loss at batch 50 : 0.012939127162098885
Loss at batch 60 : 0.009241646155714989
Loss at batch 70 : 0.009641415439546108
Loss at batch 80 : 0.009812969714403152
Loss at batch 90 : 0.0321386344730854
Loss at batch 100 : 0.01754545234143734
Loss at batch 110 : 0.012654351070523262
Loss at batch 120 : 0.016304131597280502
Loss at batch 130 : 0.017412204295396805
Loss at batch 140 : 0.00998392328619957
Loss at batch 150 : 0.011107821948826313
Loss at batch 160 : 0.012330684810876846
Loss at batch 170 : 0.010042842477560043
Loss at batch 180 : 0.006643752101808786
Loss at batch 190 : 0.008754844777286053
Loss at batch 200 : 0.010833914391696453
Loss at batch 210 : 0.007958167232573032
Loss at batch 220 : 0.010971972718834877
Loss at batch 230 : 0.011464357376098633
Loss at batch 240 : 0.022677842527627945
Loss at batch 250 : 0.019406236708164215
Loss at batch 260 : 0.01385943777859211
Loss at batch 270 : 0.01723126322031021
Loss at batch 280 : 0.014141048304736614
Loss at batch 290 : 0.011561010032892227
Loss at batch 300 : 0.014771245419979095
Loss at batch 310 : 0.011488152667880058
Loss at batch 320 : 0.016220292076468468
Loss at batch 330 : 0.01723756454885006
Loss at batch 340 : 0.01916312426328659
Loss at batch 350 : 0.015735020861029625
Loss at batch 360 : 0.012214655987918377
Loss at batch 370 : 0.008436963893473148
epoch64 finished!
Loss at batch 10 : 0.012154856696724892
Loss at batch 20 : 0.01168846059590578
Loss at batch 30 : 0.01481972262263298
Loss at batch 40 : 0.015673605725169182
Loss at batch 50 : 0.013707896694540977
Loss at batch 60 : 0.013549561612308025
Loss at batch 70 : 0.011410016566514969
Loss at batch 80 : 0.016059041023254395
Loss at batch 90 : 0.016406873241066933
Loss at batch 100 : 0.012855244800448418
Loss at batch 110 : 0.018073420971632004
Loss at batch 120 : 0.012524177320301533
Loss at batch 130 : 0.009121570736169815
Loss at batch 140 : 0.011045437306165695
Loss at batch 150 : 0.01282606553286314
Loss at batch 160 : 0.01386457309126854
Loss at batch 170 : 0.01634867861866951
Loss at batch 180 : 0.011293737217783928
Loss at batch 190 : 0.014250091277062893
Loss at batch 200 : 0.014907470904290676
Loss at batch 210 : 0.027242114767432213
Loss at batch 220 : 0.009237565100193024
Loss at batch 230 : 0.010823025368154049
Loss at batch 240 : 0.022101694718003273
Loss at batch 250 : 0.016750916838645935
Loss at batch 260 : 0.017349068075418472
Loss at batch 270 : 0.01181887648999691
Loss at batch 280 : 0.015391593798995018
Loss at batch 290 : 0.006969137582927942
Loss at batch 300 : 0.016010183840990067
Loss at batch 310 : 0.018373684957623482
Loss at batch 320 : 0.015084064565598965
Loss at batch 330 : 0.020861079916357994
Loss at batch 340 : 0.02515842206776142
Loss at batch 350 : 0.013239637948572636
Loss at batch 360 : 0.007725146133452654
Loss at batch 370 : 0.02177933230996132
epoch142 finished!
Loss at batch 10 : 0.01246166042983532
Loss at batch 20 : 0.015672901645302773
Loss at batch 30 : 0.019348908215761185
Loss at batch 40 : 0.028065016493201256
Loss at batch 50 : 0.014287395402789116
Loss at batch 60 : 0.02004833333194256
Loss at batch 70 : 0.019430046901106834
Loss at batch 80 : 0.012172668240964413
Loss at batch 90 : 0.017305515706539154
Loss at batch 100 : 0.012582032941281796
Loss at batch 110 : 0.009706508368253708
Loss at batch 120 : 0.02715768851339817
Loss at batch 130 : 0.012411629781126976
Loss at batch 140 : 0.011370970867574215
Loss at batch 150 : 0.027327952906489372
Loss at batch 160 : 0.02052651159465313
Loss at batch 170 : 0.008742409758269787
Loss at batch 180 : 0.010450674220919609
Loss at batch 190 : 0.016002284362912178
Loss at batch 200 : 0.015992728993296623
Loss at batch 210 : 0.012364307418465614
Loss at batch 220 : 0.01739121973514557
Loss at batch 230 : 0.008165436796844006
Loss at batch 240 : 0.016341134905815125
Loss at batch 250 : 0.01745223067700863
Loss at batch 260 : 0.02249828353524208
Loss at batch 270 : 0.015056867152452469
Loss at batch 280 : 0.019892532378435135
Loss at batch 290 : 0.019507955759763718
Loss at batch 300 : 0.015041390433907509
Loss at batch 310 : 0.014719166792929173
Loss at batch 320 : 0.018328804522752762
Loss at batch 330 : 0.01003124937415123
Loss at batch 340 : 0.015009647235274315
Loss at batch 350 : 0.012609077617526054
Loss at batch 360 : 0.012694541364908218
Loss at batch 370 : 0.015565593726933002
epoch143 finished!
Loss at batch 10 : 0.018339863047003746
Loss at batch 20 : 0.01445726864039898
Loss at batch 30 : 0.01336597092449665
Loss at batch 40 : 0.01862095482647419
Loss at batch 50 : 0.012027555145323277
Loss at batch 60 : 0.023265423253178596
Loss at batch 70 : 0.010538913309574127
Loss at batch 80 : 0.022940222173929214
Loss at batch 90 : 0.01806856133043766
Loss at batch 100 : 0.009793569333851337
Loss at batch 110 : 0.015797575935721397
Loss at batch 120 : 0.02583501674234867
Loss at batch 130 : 0.013376902788877487
Loss at batch 140 : 0.0118707912042737
Loss at batch 150 : 0.01267167553305626
Loss at batch 160 : 0.014771849848330021
Loss at batch 170 : 0.015187284909188747
Loss at batch 180 : 0.015997732058167458
Loss at batch 190 : 0.01394286472350359
Loss at batch 200 : 0.009562975727021694
Loss at batch 210 : 0.011643312871456146
Loss at batch 220 : 0.012523356825113297
Loss at batch 230 : 0.013609900139272213
Loss at batch 240 : 0.011045594699680805
Loss at batch 250 : 0.017722824588418007
Loss at batch 260 : 0.013479478657245636
Loss at batch 270 : 0.01223642099648714
Loss at batch 280 : 0.009252948686480522
Loss at batch 290 : 0.017870992422103882
Loss at batch 300 : 0.011709987185895443
Loss at batch 310 : 0.01104667130857706
Loss at batch 320 : 0.012454204261302948
Loss at batch 330 : 0.011470849625766277
Loss at batch 340 : 0.012780123390257359
Loss at batch 350 : 0.011779685504734516
Loss at batch 360 : 0.012028505094349384
Loss at batch 370 : 0.015754999592900276
epoch65 finished!
Loss at batch 10 : 0.009431682527065277
Loss at batch 20 : 0.01568860560655594
Loss at batch 30 : 0.025816844776272774
Loss at batch 40 : 0.014302078634500504
Loss at batch 50 : 0.015687528997659683
Loss at batch 60 : 0.014551212079823017
Loss at batch 70 : 0.011716491542756557
Loss at batch 80 : 0.007605392020195723
Loss at batch 90 : 0.019036181271076202
Loss at batch 100 : 0.006359328981488943
Loss at batch 110 : 0.019661135971546173
Loss at batch 120 : 0.017329378053545952
Loss at batch 130 : 0.014577754773199558
Loss at batch 140 : 0.014527162536978722
Loss at batch 150 : 0.008139760233461857
Loss at batch 160 : 0.014388729818165302
Loss at batch 170 : 0.013781183399260044
Loss at batch 180 : 0.01527395285665989
Loss at batch 190 : 0.005791531875729561
Loss at batch 200 : 0.005631655920296907
Loss at batch 210 : 0.008602266199886799
Loss at batch 220 : 0.014777407050132751
Loss at batch 230 : 0.007678611669689417
Loss at batch 240 : 0.021005580201745033
Loss at batch 250 : 0.012755496427416801
Loss at batch 260 : 0.009577993303537369
Loss at batch 270 : 0.015846604481339455
Loss at batch 280 : 0.010979164391756058
Loss at batch 290 : 0.009881437756121159
Loss at batch 300 : 0.011719814501702785
Loss at batch 310 : 0.020607266575098038
Loss at batch 320 : 0.009653197601437569
Loss at batch 330 : 0.010629300028085709
Loss at batch 340 : 0.011226139031350613
Loss at batch 350 : 0.011151764541864395
Loss at batch 360 : 0.009364471770823002
Loss at batch 370 : 0.015983330085873604
epoch65 finished!
Loss at batch 10 : 0.006086166948080063
Loss at batch 20 : 0.009006175212562084
Loss at batch 30 : 0.01970275118947029
Loss at batch 40 : 0.017053011804819107
Loss at batch 50 : 0.01787593960762024
Loss at batch 60 : 0.010937854647636414
Loss at batch 70 : 0.012052807956933975
Loss at batch 80 : 0.019503463059663773
Loss at batch 90 : 0.008678033947944641
Loss at batch 100 : 0.0067156217992305756
Loss at batch 110 : 0.014732363633811474
Loss at batch 120 : 0.009816883131861687
Loss at batch 130 : 0.015454050153493881
Loss at batch 140 : 0.01893782429397106
Loss at batch 150 : 0.0145083237439394
Loss at batch 160 : 0.014037142507731915
Loss at batch 170 : 0.016165301203727722
Loss at batch 180 : 0.018218884244561195
Loss at batch 190 : 0.014136550948023796
Loss at batch 200 : 0.007189439609646797
Loss at batch 210 : 0.014440738596022129
Loss at batch 220 : 0.02771894820034504
Loss at batch 230 : 0.015303462743759155
Loss at batch 240 : 0.011768141761422157
Loss at batch 250 : 0.02187071368098259
Loss at batch 260 : 0.00809137150645256
Loss at batch 270 : 0.010526392608880997
Loss at batch 280 : 0.011979744769632816
Loss at batch 290 : 0.007442239671945572
Loss at batch 300 : 0.01924426667392254
Loss at batch 310 : 0.010542532429099083
Loss at batch 320 : 0.010444637387990952
Loss at batch 330 : 0.011217745952308178
Loss at batch 340 : 0.009177275002002716
Loss at batch 350 : 0.01078192237764597
Loss at batch 360 : 0.010534939356148243
Loss at batch 370 : 0.012129364535212517
epoch144 finished!
Loss at batch 10 : 0.016749706119298935
Loss at batch 20 : 0.011657560244202614
Loss at batch 30 : 0.009009575471282005
Loss at batch 40 : 0.020269725471735
Loss at batch 50 : 0.007894483394920826
Loss at batch 60 : 0.013015620410442352
Loss at batch 70 : 0.01637406274676323
Loss at batch 80 : 0.011476404964923859
Loss at batch 90 : 0.023984398692846298
Loss at batch 100 : 0.012028873898088932
Loss at batch 110 : 0.014436867088079453
Loss at batch 120 : 0.01669151708483696
Loss at batch 130 : 0.018530679866671562
Loss at batch 140 : 0.009390152990818024
Loss at batch 150 : 0.0063395132310688496
Loss at batch 160 : 0.012118992395699024
Loss at batch 170 : 0.010611487552523613
Loss at batch 180 : 0.014599992893636227
Loss at batch 190 : 0.015124117024242878
Loss at batch 200 : 0.01442540530115366
Loss at batch 210 : 0.009489375166594982
Loss at batch 220 : 0.023147575557231903
Loss at batch 230 : 0.011735542677342892
Loss at batch 240 : 0.023263508453965187
Loss at batch 250 : 0.010902199894189835
Loss at batch 260 : 0.011981622315943241
Loss at batch 270 : 0.0058763655833899975
Loss at batch 280 : 0.015475007705390453
Loss at batch 290 : 0.010052946396172047
Loss at batch 300 : 0.01606675237417221
Loss at batch 310 : 0.013200166635215282
Loss at batch 320 : 0.012484868057072163
Loss at batch 330 : 0.013002872467041016
Loss at batch 340 : 0.013651113957166672
Loss at batch 350 : 0.014993852004408836
Loss at batch 360 : 0.018077656626701355
Loss at batch 370 : 0.007132053375244141
epoch145 finished!
Loss at batch 10 : 0.011193763464689255
Loss at batch 20 : 0.015564476139843464
Loss at batch 30 : 0.015360293909907341
Loss at batch 40 : 0.013741991482675076
Loss at batch 50 : 0.02140728011727333
Loss at batch 60 : 0.013501041568815708
Loss at batch 70 : 0.01178409717977047
Loss at batch 80 : 0.01374212745577097
Loss at batch 90 : 0.025288837030529976
Loss at batch 100 : 0.008040279150009155
Loss at batch 110 : 0.006267583929002285
Loss at batch 120 : 0.011834650300443172
Loss at batch 130 : 0.012132697738707066
Loss at batch 140 : 0.022533077746629715
Loss at batch 150 : 0.01244055014103651
Loss at batch 160 : 0.03232665732502937
Loss at batch 170 : 0.015748729929327965
Loss at batch 180 : 0.015549594536423683
Loss at batch 190 : 0.008543564938008785
Loss at batch 200 : 0.013730178587138653
Loss at batch 210 : 0.007716847117990255
Loss at batch 220 : 0.009763832204043865
Loss at batch 230 : 0.01136092096567154
Loss at batch 240 : 0.008992004208266735
Loss at batch 250 : 0.022355088964104652
Loss at batch 260 : 0.017577601596713066
Loss at batch 270 : 0.020541014149785042
Loss at batch 280 : 0.020777113735675812
Loss at batch 290 : 0.02284998632967472
Loss at batch 300 : 0.01777014508843422
Loss at batch 310 : 0.03156770020723343
Loss at batch 320 : 0.010586734861135483
Loss at batch 330 : 0.015203827992081642
Loss at batch 340 : 0.008640382438898087
Loss at batch 350 : 0.011012587696313858
Loss at batch 360 : 0.019236598163843155
Loss at batch 370 : 0.014494124799966812
epoch66 finished!
Loss at batch 10 : 0.009809648618102074
Loss at batch 20 : 0.0114689189940691
Loss at batch 30 : 0.03255058079957962
Loss at batch 40 : 0.01607205905020237
Loss at batch 50 : 0.006101449951529503
Loss at batch 60 : 0.01826721802353859
Loss at batch 70 : 0.026108000427484512
Loss at batch 80 : 0.013154049403965473
Loss at batch 90 : 0.014043183997273445
Loss at batch 100 : 0.013461213558912277
Loss at batch 110 : 0.012522281147539616
Loss at batch 120 : 0.0145804388448596
Loss at batch 130 : 0.01173222716897726
Loss at batch 140 : 0.013465357944369316
Loss at batch 150 : 0.01168692484498024
Loss at batch 160 : 0.014464391395449638
Loss at batch 170 : 0.01263327244669199
Loss at batch 180 : 0.011905575171113014
Loss at batch 190 : 0.01591597869992256
Loss at batch 200 : 0.015681490302085876
Loss at batch 210 : 0.013532210141420364
Loss at batch 220 : 0.010641875676810741
Loss at batch 230 : 0.02167355827987194
Loss at batch 240 : 0.009877116419374943
Loss at batch 250 : 0.006069828290492296
Loss at batch 260 : 0.010811343789100647
Loss at batch 270 : 0.011165734380483627
Loss at batch 280 : 0.01948101818561554
Loss at batch 290 : 0.012552429921925068
Loss at batch 300 : 0.00921870768070221
Loss at batch 310 : 0.018526600673794746
Loss at batch 320 : 0.009327095001935959
Loss at batch 330 : 0.012162715196609497
Loss at batch 340 : 0.01441040076315403
Loss at batch 350 : 0.009690679609775543
Loss at batch 360 : 0.023981280624866486
Loss at batch 370 : 0.01565931923687458
epoch66 finished!
Loss at batch 10 : 0.018230773508548737
Loss at batch 20 : 0.011939375661313534
Loss at batch 30 : 0.016533372923731804
Loss at batch 40 : 0.015109652653336525
Loss at batch 50 : 0.010181526653468609
Loss at batch 60 : 0.009736639447510242
Loss at batch 70 : 0.009595501236617565
Loss at batch 80 : 0.015187336131930351
Loss at batch 90 : 0.010794362053275108
Loss at batch 100 : 0.01655217632651329
Loss at batch 110 : 0.01282216515392065
Loss at batch 120 : 0.025121593847870827
Loss at batch 130 : 0.012445583939552307
Loss at batch 140 : 0.008574682287871838
Loss at batch 150 : 0.014249294064939022
Loss at batch 160 : 0.008572093211114407
Loss at batch 170 : 0.01766003668308258
Loss at batch 180 : 0.020451761782169342
Loss at batch 190 : 0.016870345920324326
Loss at batch 200 : 0.018720559775829315
Loss at batch 210 : 0.006888278294354677
Loss at batch 220 : 0.008317838422954082
Loss at batch 230 : 0.013491217978298664
Loss at batch 240 : 0.005327379796653986
Loss at batch 250 : 0.011316261254251003
Loss at batch 260 : 0.021220646798610687
Loss at batch 270 : 0.017659250646829605
Loss at batch 280 : 0.00801050290465355
Loss at batch 290 : 0.011315897107124329
Loss at batch 300 : 0.015649929642677307
Loss at batch 310 : 0.012377037666738033
Loss at batch 320 : 0.020941896364092827
Loss at batch 330 : 0.009855697862803936
Loss at batch 340 : 0.011697881855070591
Loss at batch 350 : 0.00967718381434679
Loss at batch 360 : 0.0089438296854496
Loss at batch 370 : 0.021546900272369385
epoch146 finished!
Loss at batch 10 : 0.013307050801813602
Loss at batch 20 : 0.014181339181959629
Loss at batch 30 : 0.013934384100139141
Loss at batch 40 : 0.01083113718777895
Loss at batch 50 : 0.01589835062623024
Loss at batch 60 : 0.01959032379090786
Loss at batch 70 : 0.017296679317951202
Loss at batch 80 : 0.012560360133647919
Loss at batch 90 : 0.011267324909567833
Loss at batch 100 : 0.0243543554097414
Loss at batch 110 : 0.007727703545242548
Loss at batch 120 : 0.01259390078485012
Loss at batch 130 : 0.01522721629589796
Loss at batch 140 : 0.011530227959156036
Loss at batch 150 : 0.008338604122400284
Loss at batch 160 : 0.012500619515776634
Loss at batch 170 : 0.011331361718475819
Loss at batch 180 : 0.00853007473051548
Loss at batch 190 : 0.00940968282520771
Loss at batch 200 : 0.007524311076849699
Loss at batch 210 : 0.014361858367919922
Loss at batch 220 : 0.01818826049566269
Loss at batch 230 : 0.011403058655560017
Loss at batch 240 : 0.008348217234015465
Loss at batch 250 : 0.005517382640391588
Loss at batch 260 : 0.01030111126601696
Loss at batch 270 : 0.0103050721809268
Loss at batch 280 : 0.011808283627033234
Loss at batch 290 : 0.010461089201271534
Loss at batch 300 : 0.021509677171707153
Loss at batch 310 : 0.012736182659864426
Loss at batch 320 : 0.012565087527036667
Loss at batch 330 : 0.01868840493261814
Loss at batch 340 : 0.011653343215584755
Loss at batch 350 : 0.00916201714426279
Loss at batch 360 : 0.01620696671307087
Loss at batch 370 : 0.008857729844748974
epoch147 finished!
Loss at batch 10 : 0.01644929125905037
Loss at batch 20 : 0.009892448782920837
Loss at batch 30 : 0.010038715787231922
Loss at batch 40 : 0.015213701874017715
Loss at batch 50 : 0.015051724389195442
Loss at batch 60 : 0.010065091773867607
Loss at batch 70 : 0.011800665408372879
Loss at batch 80 : 0.013076841831207275
Loss at batch 90 : 0.00977514311671257
Loss at batch 100 : 0.009874324314296246
Loss at batch 110 : 0.018614476546645164
Loss at batch 120 : 0.012864090502262115
Loss at batch 130 : 0.014466220512986183
Loss at batch 140 : 0.026806749403476715
Loss at batch 150 : 0.01670270599424839
Loss at batch 160 : 0.015308242291212082
Loss at batch 170 : 0.01915469765663147
Loss at batch 180 : 0.014981688000261784
Loss at batch 190 : 0.0095945093780756
Loss at batch 200 : 0.014683471992611885
Loss at batch 210 : 0.009371493011713028
Loss at batch 220 : 0.008041106164455414
Loss at batch 230 : 0.010690935887396336
Loss at batch 240 : 0.010400560684502125
Loss at batch 250 : 0.008687340654432774
Loss at batch 260 : 0.030596699565649033
Loss at batch 270 : 0.009444519877433777
Loss at batch 280 : 0.012672427110373974
Loss at batch 290 : 0.03923799470067024
Loss at batch 300 : 0.03779873996973038
Loss at batch 310 : 0.009347840212285519
Loss at batch 320 : 0.00986653845757246
Loss at batch 330 : 0.02998804859817028
Loss at batch 340 : 0.011271238327026367
Loss at batch 350 : 0.014178463257849216
Loss at batch 360 : 0.009597862139344215
Loss at batch 370 : 0.018302708864212036
epoch67 finished!
Loss at batch 10 : 0.010397542268037796
Loss at batch 20 : 0.017427686601877213
Loss at batch 30 : 0.018825840204954147
Loss at batch 40 : 0.010543758049607277
Loss at batch 50 : 0.009660137817263603
Loss at batch 60 : 0.01431991159915924
Loss at batch 70 : 0.032479576766490936
Loss at batch 80 : 0.005724512971937656
Loss at batch 90 : 0.012590964324772358
Loss at batch 100 : 0.01489245891571045
Loss at batch 110 : 0.01711149886250496
Loss at batch 120 : 0.009791349060833454
Loss at batch 130 : 0.018591787666082382
Loss at batch 140 : 0.009410474449396133
Loss at batch 150 : 0.021148012951016426
Loss at batch 160 : 0.02087780088186264
Loss at batch 170 : 0.024137461557984352
Loss at batch 180 : 0.011931735090911388
Loss at batch 190 : 0.016003165394067764
Loss at batch 200 : 0.014829033054411411
Loss at batch 210 : 0.012304764240980148
Loss at batch 220 : 0.014322678558528423
Loss at batch 230 : 0.011414358392357826
Loss at batch 240 : 0.020282773301005363
Loss at batch 250 : 0.013969083316624165
Loss at batch 260 : 0.01055798027664423
Loss at batch 270 : 0.0214059017598629
Loss at batch 280 : 0.016229460015892982
Loss at batch 290 : 0.017926601693034172
Loss at batch 300 : 0.009172159247100353
Loss at batch 310 : 0.017876507714390755
Loss at batch 320 : 0.012497327290475368
Loss at batch 330 : 0.013361848890781403
Loss at batch 340 : 0.014038806781172752
Loss at batch 350 : 0.011982259340584278
Loss at batch 360 : 0.0159714724868536
Loss at batch 370 : 0.017337575554847717
epoch148 finished!
Loss at batch 10 : 0.016690772026777267
Loss at batch 20 : 0.022495223209261894
Loss at batch 30 : 0.01849311962723732
Loss at batch 40 : 0.01574067212641239
Loss at batch 50 : 0.019274936988949776
Loss at batch 60 : 0.014281079173088074
Loss at batch 70 : 0.013712097890675068
Loss at batch 80 : 0.012703802436590195
Loss at batch 90 : 0.009478031657636166
Loss at batch 100 : 0.014301314949989319
Loss at batch 110 : 0.006740371230989695
Loss at batch 120 : 0.015520619228482246
Loss at batch 130 : 0.013963122852146626
Loss at batch 140 : 0.013520820066332817
Loss at batch 150 : 0.02205044962465763
Loss at batch 160 : 0.018555598333477974
Loss at batch 170 : 0.03148078918457031
Loss at batch 180 : 0.014036767184734344
Loss at batch 190 : 0.01721014827489853
Loss at batch 200 : 0.005660136695951223
Loss at batch 210 : 0.009805431589484215
Loss at batch 220 : 0.013416672125458717
Loss at batch 230 : 0.01185584720224142
Loss at batch 240 : 0.021050432696938515
Loss at batch 250 : 0.020513419061899185
Loss at batch 260 : 0.015675494447350502
Loss at batch 270 : 0.01397068053483963
Loss at batch 280 : 0.016267351806163788
Loss at batch 290 : 0.017839465290308
Loss at batch 300 : 0.00781738106161356
Loss at batch 310 : 0.009359924122691154
Loss at batch 320 : 0.008540580049157143
Loss at batch 330 : 0.01199243776500225
Loss at batch 340 : 0.013910439796745777
Loss at batch 350 : 0.013862917199730873
Loss at batch 360 : 0.01873456872999668
Loss at batch 370 : 0.009032702073454857
epoch67 finished!
Loss at batch 10 : 0.01114750374108553
Loss at batch 20 : 0.011845882050693035
Loss at batch 30 : 0.012915202416479588
Loss at batch 40 : 0.0219558198004961
Loss at batch 50 : 0.018339142203330994
Loss at batch 60 : 0.0077119022607803345
Loss at batch 70 : 0.01038428209722042
Loss at batch 80 : 0.025353139266371727
Loss at batch 90 : 0.019029829651117325
Loss at batch 100 : 0.011998427100479603
Loss at batch 110 : 0.01618620567023754
Loss at batch 120 : 0.01734163612127304
Loss at batch 130 : 0.013677549548447132
Loss at batch 140 : 0.014326355420053005
Loss at batch 150 : 0.01664419285953045
Loss at batch 160 : 0.01935814879834652
Loss at batch 170 : 0.024794338271021843
Loss at batch 180 : 0.018562719225883484
Loss at batch 190 : 0.011844531632959843
Loss at batch 200 : 0.01680001989006996
Loss at batch 210 : 0.008962095715105534
Loss at batch 220 : 0.011653308756649494
Loss at batch 230 : 0.021340852603316307
Loss at batch 240 : 0.02170211263000965
Loss at batch 250 : 0.01910952664911747
Loss at batch 260 : 0.011809309013187885
Loss at batch 270 : 0.009902208112180233
Loss at batch 280 : 0.00976576842367649
Loss at batch 290 : 0.007838373072445393
Loss at batch 300 : 0.011714235879480839
Loss at batch 310 : 0.026759929955005646
Loss at batch 320 : 0.022104784846305847
Loss at batch 330 : 0.00787399336695671
Loss at batch 340 : 0.014636999927461147
Loss at batch 350 : 0.007603401318192482
Loss at batch 360 : 0.016447843983769417
Loss at batch 370 : 0.026262478902935982
epoch149 finished!
Loss at batch 10 : 0.01706164889037609
Loss at batch 20 : 0.016045432537794113
Loss at batch 30 : 0.009815553203225136
Loss at batch 40 : 0.019531741738319397
Loss at batch 50 : 0.017138617113232613
Loss at batch 60 : 0.01793827675282955
Loss at batch 70 : 0.009636103175580502
Loss at batch 80 : 0.009714341722428799
Loss at batch 90 : 0.01241458859294653
Loss at batch 100 : 0.020229894667863846
Loss at batch 110 : 0.017540670931339264
Loss at batch 120 : 0.0167622622102499
Loss at batch 130 : 0.012939595617353916
Loss at batch 140 : 0.012819420546293259
Loss at batch 150 : 0.018069634214043617
Loss at batch 160 : 0.009577762335538864
Loss at batch 170 : 0.010720435529947281
Loss at batch 180 : 0.0073533738031983376
Loss at batch 190 : 0.01759304292500019
Loss at batch 200 : 0.013137568719685078
Loss at batch 210 : 0.008191141299903393
Loss at batch 220 : 0.01301262155175209
Loss at batch 230 : 0.014457018114626408
Loss at batch 240 : 0.008606145158410072
Loss at batch 250 : 0.009622610174119473
Loss at batch 260 : 0.014625638723373413
Loss at batch 270 : 0.02006521448493004
Loss at batch 280 : 0.008218381553888321
Loss at batch 290 : 0.015601706691086292
Loss at batch 300 : 0.022126290947198868
Loss at batch 310 : 0.017619453370571136
Loss at batch 320 : 0.016558565199375153
Loss at batch 330 : 0.013344182632863522
Loss at batch 340 : 0.02218671701848507
Loss at batch 350 : 0.01656481809914112
Loss at batch 360 : 0.011380757205188274
Loss at batch 370 : 0.011974208988249302
epoch150 finished!
Loss at batch 10 : 0.007838047109544277
Loss at batch 20 : 0.010653045028448105
Loss at batch 30 : 0.01579204946756363
Loss at batch 40 : 0.011261570267379284
Loss at batch 50 : 0.008042030036449432
Loss at batch 60 : 0.016589798033237457
Loss at batch 70 : 0.011888832785189152
Loss at batch 80 : 0.03355155140161514
Loss at batch 90 : 0.020516108721494675
Loss at batch 100 : 0.017420638352632523
Loss at batch 110 : 0.008445098996162415
Loss at batch 120 : 0.026624659076333046
Loss at batch 130 : 0.020227881148457527
Loss at batch 140 : 0.01955302245914936
Loss at batch 150 : 0.010820101015269756
Loss at batch 160 : 0.011603361926972866
Loss at batch 170 : 0.006344163790345192
Loss at batch 180 : 0.02196607179939747
Loss at batch 190 : 0.018081067129969597
Loss at batch 200 : 0.011776776053011417
Loss at batch 210 : 0.016499226912856102
Loss at batch 220 : 0.012605336494743824
Loss at batch 230 : 0.013554144650697708
Loss at batch 240 : 0.025180106982588768
Loss at batch 250 : 0.010899770073592663
Loss at batch 260 : 0.005314751993864775
Loss at batch 270 : 0.015446345321834087
Loss at batch 280 : 0.018178535625338554
Loss at batch 290 : 0.015168839134275913
Loss at batch 300 : 0.016324980184435844
Loss at batch 310 : 0.010586551390588284
Loss at batch 320 : 0.015588374808430672
Loss at batch 330 : 0.01126439031213522
Loss at batch 340 : 0.021075358614325523
Loss at batch 350 : 0.022541753947734833
Loss at batch 360 : 0.0107771847397089
Loss at batch 370 : 0.012134970165789127
epoch68 finished!
Loss at batch 10 : 0.016811825335025787
Loss at batch 20 : 0.012284480035305023
Loss at batch 30 : 0.010490084998309612
Loss at batch 40 : 0.010170572437345982
Loss at batch 50 : 0.013398931361734867
Loss at batch 60 : 0.00868378859013319
Loss at batch 70 : 0.013532170094549656
Loss at batch 80 : 0.011122103780508041
Loss at batch 90 : 0.017357563599944115
Loss at batch 100 : 0.006819870788604021
Loss at batch 110 : 0.011613182723522186
Loss at batch 120 : 0.012476624920964241
Loss at batch 130 : 0.007568811997771263
Loss at batch 140 : 0.007627599872648716
Loss at batch 150 : 0.010429952293634415
Loss at batch 160 : 0.010070644319057465
Loss at batch 170 : 0.008048925548791885
Loss at batch 180 : 0.021363331004977226
Loss at batch 190 : 0.025163786485791206
Loss at batch 200 : 0.0078148627653718
Loss at batch 210 : 0.014217034913599491
Loss at batch 220 : 0.008787592872977257
Loss at batch 230 : 0.009242265485227108
Loss at batch 240 : 0.014923552051186562
Loss at batch 250 : 0.022977229207754135
Loss at batch 260 : 0.00878200400620699
Loss at batch 270 : 0.03544643148779869
Loss at batch 280 : 0.017824722453951836
Loss at batch 290 : 0.009592047892510891
Loss at batch 300 : 0.008534816093742847
Loss at batch 310 : 0.020891113206744194
Loss at batch 320 : 0.010573317296802998
Loss at batch 330 : 0.008864072151482105
Loss at batch 340 : 0.00884972047060728
Loss at batch 350 : 0.010652942582964897
Loss at batch 360 : 0.013386430218815804
Loss at batch 370 : 0.008788303472101688
epoch68 finished!
Loss at batch 10 : 0.0128388786688447
Loss at batch 20 : 0.014518184587359428
Loss at batch 30 : 0.027936454862356186
Loss at batch 40 : 0.009435824118554592
Loss at batch 50 : 0.017122818157076836
Loss at batch 60 : 0.0085988100618124
Loss at batch 70 : 0.02005220390856266
Loss at batch 80 : 0.014784174039959908
Loss at batch 90 : 0.011330670677125454
Loss at batch 100 : 0.00843923632055521
Loss at batch 110 : 0.008774716407060623
Loss at batch 120 : 0.022166095674037933
Loss at batch 130 : 0.018903668969869614
Loss at batch 140 : 0.019574685022234917
Loss at batch 150 : 0.012565326876938343
Loss at batch 160 : 0.014484815299510956
Loss at batch 170 : 0.01025991328060627
Loss at batch 180 : 0.01354182604700327
Loss at batch 190 : 0.014326371252536774
Loss at batch 200 : 0.024961495772004128
Loss at batch 210 : 0.018175872042775154
Loss at batch 220 : 0.01647247187793255
Loss at batch 230 : 0.015852881595492363
Loss at batch 240 : 0.010676476173102856
Loss at batch 250 : 0.016501575708389282
Loss at batch 260 : 0.01588016375899315
Loss at batch 270 : 0.013641518540680408
Loss at batch 280 : 0.02118954434990883
Loss at batch 290 : 0.02154497057199478
Loss at batch 300 : 0.01314727682620287
Loss at batch 310 : 0.019470257684588432
Loss at batch 320 : 0.01957985758781433
Loss at batch 330 : 0.013361564837396145
Loss at batch 340 : 0.012010032311081886
Loss at batch 350 : 0.013075027614831924
Loss at batch 360 : 0.014854121953248978
Loss at batch 370 : 0.013502166606485844
epoch151 finished!
Loss at batch 10 : 0.008970728144049644
Loss at batch 20 : 0.012490236200392246
Loss at batch 30 : 0.01588638313114643
Loss at batch 40 : 0.01693155989050865
Loss at batch 50 : 0.011270970106124878
Loss at batch 60 : 0.013666433282196522
Loss at batch 70 : 0.012003556825220585
Loss at batch 80 : 0.013627252541482449
Loss at batch 90 : 0.019026044756174088
Loss at batch 100 : 0.01041949912905693
Loss at batch 110 : 0.014679042622447014
Loss at batch 120 : 0.016746332868933678
Loss at batch 130 : 0.019166769459843636
Loss at batch 140 : 0.009512859396636486
Loss at batch 150 : 0.014744680374860764
Loss at batch 160 : 0.015707509592175484
Loss at batch 170 : 0.011586089618504047
Loss at batch 180 : 0.017905717715620995
Loss at batch 190 : 0.01608804054558277
Loss at batch 200 : 0.02358604408800602
Loss at batch 210 : 0.009144812822341919
Loss at batch 220 : 0.01788572408258915
Loss at batch 230 : 0.008769436739385128
Loss at batch 240 : 0.01121467538177967
Loss at batch 250 : 0.013233492150902748
Loss at batch 260 : 0.00825597532093525
Loss at batch 270 : 0.016577497124671936
Loss at batch 280 : 0.02361292578279972
Loss at batch 290 : 0.024113882333040237
Loss at batch 300 : 0.021760379895567894
Loss at batch 310 : 0.01365033071488142
Loss at batch 320 : 0.012965450994670391
Loss at batch 330 : 0.02980116568505764
Loss at batch 340 : 0.017724445089697838
Loss at batch 350 : 0.009029996581375599
Loss at batch 360 : 0.015019911341369152
Loss at batch 370 : 0.011117508634924889
epoch152 finished!
Loss at batch 10 : 0.010720223188400269
Loss at batch 20 : 0.008110573515295982
Loss at batch 30 : 0.012227391824126244
Loss at batch 40 : 0.010176260024309158
Loss at batch 50 : 0.021520767360925674
Loss at batch 60 : 0.007913465611636639
Loss at batch 70 : 0.02291160263121128
Loss at batch 80 : 0.014546975493431091
Loss at batch 90 : 0.011083811521530151
Loss at batch 100 : 0.008379505015909672
Loss at batch 110 : 0.01266175415366888
Loss at batch 120 : 0.01341470330953598
Loss at batch 130 : 0.012972603552043438
Loss at batch 140 : 0.016997890546917915
Loss at batch 150 : 0.013972335495054722
Loss at batch 160 : 0.01469390094280243
Loss at batch 170 : 0.01314422208815813
Loss at batch 180 : 0.023092757910490036
Loss at batch 190 : 0.011713819578289986
Loss at batch 200 : 0.010926039889454842
Loss at batch 210 : 0.008600400760769844
Loss at batch 220 : 0.013725977391004562
Loss at batch 230 : 0.014716343022882938
Loss at batch 240 : 0.02234063111245632
Loss at batch 250 : 0.018793055787682533
Loss at batch 260 : 0.011086739599704742
Loss at batch 270 : 0.011008737608790398
Loss at batch 280 : 0.01612263359129429
Loss at batch 290 : 0.00899418257176876
Loss at batch 300 : 0.008705885149538517
Loss at batch 310 : 0.0118046710267663
Loss at batch 320 : 0.009649055078625679
Loss at batch 330 : 0.017899014055728912
Loss at batch 340 : 0.011707949452102184
Loss at batch 350 : 0.017108328640460968
Loss at batch 360 : 0.015919387340545654
Loss at batch 370 : 0.012993253767490387
epoch69 finished!
Loss at batch 10 : 0.015556151047348976
Loss at batch 20 : 0.009988832287490368
Loss at batch 30 : 0.013604172505438328
Loss at batch 40 : 0.016384996473789215
Loss at batch 50 : 0.014802355319261551
Loss at batch 60 : 0.010926664806902409
Loss at batch 70 : 0.013557801954448223
Loss at batch 80 : 0.02555900253355503
Loss at batch 90 : 0.009190087206661701
Loss at batch 100 : 0.01401700172573328
Loss at batch 110 : 0.019825443625450134
Loss at batch 120 : 0.009073862805962563
Loss at batch 130 : 0.008683363907039165
Loss at batch 140 : 0.015153463929891586
Loss at batch 150 : 0.0123215327039361
Loss at batch 160 : 0.019550107419490814
Loss at batch 170 : 0.01987697184085846
Loss at batch 180 : 0.0067245992831885815
Loss at batch 190 : 0.0116288335993886
Loss at batch 200 : 0.013848785310983658
Loss at batch 210 : 0.01280215848237276
Loss at batch 220 : 0.014526461251080036
Loss at batch 230 : 0.025412853807210922
Loss at batch 240 : 0.017438871785998344
Loss at batch 250 : 0.012852444313466549
Loss at batch 260 : 0.014883510768413544
Loss at batch 270 : 0.009135831147432327
Loss at batch 280 : 0.0213254913687706
Loss at batch 290 : 0.025033459067344666
Loss at batch 300 : 0.009523364715278149
Loss at batch 310 : 0.012543784454464912
Loss at batch 320 : 0.019122840836644173
Loss at batch 330 : 0.00912096444517374
Loss at batch 340 : 0.011058553121984005
Loss at batch 350 : 0.008624667301774025
Loss at batch 360 : 0.00940797571092844
Loss at batch 370 : 0.014852957800030708
epoch69 finished!
Loss at batch 10 : 0.018751708790659904
Loss at batch 20 : 0.012096582911908627
Loss at batch 30 : 0.009711253456771374
Loss at batch 40 : 0.01155931781977415
Loss at batch 50 : 0.007982810027897358
Loss at batch 60 : 0.015926087275147438
Loss at batch 70 : 0.011908532120287418
Loss at batch 80 : 0.014996016398072243
Loss at batch 90 : 0.021159613505005836
Loss at batch 100 : 0.013021198101341724
Loss at batch 110 : 0.00997763592749834
Loss at batch 120 : 0.013060195371508598
Loss at batch 130 : 0.007328638806939125
Loss at batch 140 : 0.011809726245701313
Loss at batch 150 : 0.02067270688712597
Loss at batch 160 : 0.020095616579055786
Loss at batch 170 : 0.01710430346429348
Loss at batch 180 : 0.014536737464368343
Loss at batch 190 : 0.015596774406731129
Loss at batch 200 : 0.016303032636642456
Loss at batch 210 : 0.011881000362336636
Loss at batch 220 : 0.013778265565633774
Loss at batch 230 : 0.02042722888290882
Loss at batch 240 : 0.012073192745447159
Loss at batch 250 : 0.010966518893837929
Loss at batch 260 : 0.0112864775583148
Loss at batch 270 : 0.0089423768222332
Loss at batch 280 : 0.017996255308389664
Loss at batch 290 : 0.010667111724615097
Loss at batch 300 : 0.010393316857516766
Loss at batch 310 : 0.015419406816363335
Loss at batch 320 : 0.019395707175135612
Loss at batch 330 : 0.019400883466005325
Loss at batch 340 : 0.016774486750364304
Loss at batch 350 : 0.012980977073311806
Loss at batch 360 : 0.02131802588701248
Loss at batch 370 : 0.01740219257771969
epoch153 finished!
Loss at batch 10 : 0.010023790411651134
Loss at batch 20 : 0.02806195244193077
Loss at batch 30 : 0.01809823140501976
Loss at batch 40 : 0.011453003622591496
Loss at batch 50 : 0.01393955759704113
Loss at batch 60 : 0.013792617246508598
Loss at batch 70 : 0.023956676945090294
Loss at batch 80 : 0.010220163501799107
Loss at batch 90 : 0.012160765938460827
Loss at batch 100 : 0.01944182626903057
Loss at batch 110 : 0.010619869455695152
Loss at batch 120 : 0.017080705612897873
Loss at batch 130 : 0.012249898165464401
Loss at batch 140 : 0.01012993324548006
Loss at batch 150 : 0.015585483983159065
Loss at batch 160 : 0.008383716456592083
Loss at batch 170 : 0.027020560577511787
Loss at batch 180 : 0.018723774701356888
Loss at batch 190 : 0.017008956521749496
Loss at batch 200 : 0.018608419224619865
Loss at batch 210 : 0.009386860765516758
Loss at batch 220 : 0.017795978114008904
Loss at batch 230 : 0.014245175756514072
Loss at batch 240 : 0.01400526612997055
Loss at batch 250 : 0.00995602086186409
Loss at batch 260 : 0.02026287280023098
Loss at batch 270 : 0.012488223612308502
Loss at batch 280 : 0.01372190285474062
Loss at batch 290 : 0.010231327265501022
Loss at batch 300 : 0.017858199775218964
Loss at batch 310 : 0.010702631436288357
Loss at batch 320 : 0.022606492042541504
Loss at batch 330 : 0.016791850328445435
Loss at batch 340 : 0.017861587926745415
Loss at batch 350 : 0.01125517301261425
Loss at batch 360 : 0.017234547063708305
Loss at batch 370 : 0.010989217087626457
epoch154 finished!
Loss at batch 10 : 0.013336383737623692
Loss at batch 20 : 0.013882010243833065
Loss at batch 30 : 0.010831679217517376
Loss at batch 40 : 0.015409458428621292
Loss at batch 50 : 0.011927017942070961
Loss at batch 60 : 0.014748779125511646
Loss at batch 70 : 0.008756563998758793
Loss at batch 80 : 0.019883254542946815
Loss at batch 90 : 0.012862329371273518
Loss at batch 100 : 0.014396343380212784
Loss at batch 110 : 0.020124217495322227
Loss at batch 120 : 0.01672477088868618
Loss at batch 130 : 0.01399954129010439
Loss at batch 140 : 0.01959620788693428
Loss at batch 150 : 0.01185810100287199
Loss at batch 160 : 0.010691032744944096
Loss at batch 170 : 0.01675831526517868
Loss at batch 180 : 0.01615365594625473
Loss at batch 190 : 0.012081882916390896
Loss at batch 200 : 0.02296231873333454
Loss at batch 210 : 0.018571175634860992
Loss at batch 220 : 0.0207915510982275
Loss at batch 230 : 0.012501068413257599
Loss at batch 240 : 0.021624485030770302
Loss at batch 250 : 0.014998666942119598
Loss at batch 260 : 0.021281657740473747
Loss at batch 270 : 0.008313188329339027
Loss at batch 280 : 0.02713175117969513
Loss at batch 290 : 0.008527366444468498
Loss at batch 300 : 0.016049763187766075
Loss at batch 310 : 0.015238849446177483
Loss at batch 320 : 0.00799774844199419
Loss at batch 330 : 0.017933864146471024
Loss at batch 340 : 0.013556393794715405
Loss at batch 350 : 0.019473904743790627
Loss at batch 360 : 0.014124223962426186
Loss at batch 370 : 0.013778075575828552
epoch70 finished!
Loss at batch 10 : 0.011436719447374344
Loss at batch 20 : 0.010937544517219067
Loss at batch 30 : 0.015006269328296185
Loss at batch 40 : 0.035049475729465485
Loss at batch 50 : 0.01350591704249382
Loss at batch 60 : 0.013363374397158623
Loss at batch 70 : 0.026080358773469925
Loss at batch 80 : 0.011831079609692097
Loss at batch 90 : 0.017391862347722054
Loss at batch 100 : 0.010961356572806835
Loss at batch 110 : 0.01861424557864666
Loss at batch 120 : 0.01255309209227562
Loss at batch 130 : 0.008425933308899403
Loss at batch 140 : 0.021075986325740814
Loss at batch 150 : 0.02112099714577198
Loss at batch 160 : 0.013460138812661171
Loss at batch 170 : 0.01057298481464386
Loss at batch 180 : 0.017288614064455032
Loss at batch 190 : 0.006638586055487394
Loss at batch 200 : 0.01266238372772932
Loss at batch 210 : 0.011245416477322578
Loss at batch 220 : 0.018456777557730675
Loss at batch 230 : 0.014771750196814537
Loss at batch 240 : 0.016765130683779716
Loss at batch 250 : 0.00877702422440052
Loss at batch 260 : 0.01959124207496643
Loss at batch 270 : 0.017926272004842758
Loss at batch 280 : 0.010318183340132236
Loss at batch 290 : 0.012825986370444298
Loss at batch 300 : 0.013868046924471855
Loss at batch 310 : 0.010789057239890099
Loss at batch 320 : 0.012574606575071812
Loss at batch 330 : 0.01480621937662363
Loss at batch 340 : 0.008504427038133144
Loss at batch 350 : 0.016704842448234558
Loss at batch 360 : 0.01545221358537674
Loss at batch 370 : 0.012148496694862843
epoch70 finished!
Loss at batch 10 : 0.0076635717414319515
Loss at batch 20 : 0.01137524750083685
Loss at batch 30 : 0.006696203723549843
Loss at batch 40 : 0.008911713026463985
Loss at batch 50 : 0.007012750953435898
Loss at batch 60 : 0.018538804724812508
Loss at batch 70 : 0.012413370423018932
Loss at batch 80 : 0.00958791933953762
Loss at batch 90 : 0.01528901420533657
Loss at batch 100 : 0.021830694749951363
Loss at batch 110 : 0.0126592256128788
Loss at batch 120 : 0.01895647868514061
Loss at batch 130 : 0.012844645418226719
Loss at batch 140 : 0.009978805668652058
Loss at batch 150 : 0.010708030313253403
Loss at batch 160 : 0.017228662967681885
Loss at batch 170 : 0.018743664026260376
Loss at batch 180 : 0.014003467746078968
Loss at batch 190 : 0.01043665874749422
Loss at batch 200 : 0.010781854391098022
Loss at batch 210 : 0.00933267641812563
Loss at batch 220 : 0.02361997961997986
Loss at batch 230 : 0.00848055724054575
Loss at batch 240 : 0.008764349855482578
Loss at batch 250 : 0.01669779233634472
Loss at batch 260 : 0.01101579237729311
Loss at batch 270 : 0.01612655632197857
Loss at batch 280 : 0.008623963221907616
Loss at batch 290 : 0.014966095797717571
Loss at batch 300 : 0.019137181341648102
Loss at batch 310 : 0.03221580758690834
Loss at batch 320 : 0.017098937183618546
Loss at batch 330 : 0.024748099967837334
Loss at batch 340 : 0.014141341671347618
Loss at batch 350 : 0.009293889626860619
Loss at batch 360 : 0.009165318682789803
Loss at batch 370 : 0.017047876492142677
epoch155 finished!
Loss at batch 10 : 0.023443089798092842
Loss at batch 20 : 0.01191689632833004
Loss at batch 30 : 0.015044555999338627
Loss at batch 40 : 0.011510550044476986
Loss at batch 50 : 0.006923684384673834
Loss at batch 60 : 0.01367102563381195
Loss at batch 70 : 0.01856766641139984
Loss at batch 80 : 0.012752927839756012
Loss at batch 90 : 0.012737022712826729
Loss at batch 100 : 0.010594196617603302
Loss at batch 110 : 0.012027612887322903
Loss at batch 120 : 0.01572245918214321
Loss at batch 130 : 0.014020510949194431
Loss at batch 140 : 0.015469673089683056
Loss at batch 150 : 0.018282713368535042
Loss at batch 160 : 0.02798335626721382
Loss at batch 170 : 0.01570325344800949
Loss at batch 180 : 0.012458762153983116
Loss at batch 190 : 0.006332093384116888
Loss at batch 200 : 0.018872609362006187
Loss at batch 210 : 0.011976949870586395
Loss at batch 220 : 0.01389740314334631
Loss at batch 230 : 0.013718116097152233
Loss at batch 240 : 0.012499203905463219
Loss at batch 250 : 0.004818743094801903
Loss at batch 260 : 0.01430876087397337
Loss at batch 270 : 0.009920493699610233
Loss at batch 280 : 0.015239695087075233
Loss at batch 290 : 0.013593332841992378
Loss at batch 300 : 0.010471305809915066
Loss at batch 310 : 0.013830076903104782
Loss at batch 320 : 0.015687517821788788
Loss at batch 330 : 0.007727053016424179
Loss at batch 340 : 0.02162165567278862
Loss at batch 350 : 0.01293774414807558
Loss at batch 360 : 0.009336257353425026
Loss at batch 370 : 0.014151192270219326
epoch156 finished!
Loss at batch 10 : 0.008916221559047699
Loss at batch 20 : 0.014125998131930828
Loss at batch 30 : 0.010245542041957378
Loss at batch 40 : 0.010466194711625576
Loss at batch 50 : 0.00906102079898119
Loss at batch 60 : 0.010548890568315983
Loss at batch 70 : 0.009954112581908703
Loss at batch 80 : 0.012699015438556671
Loss at batch 90 : 0.01110246405005455
Loss at batch 100 : 0.013161180540919304
Loss at batch 110 : 0.006447098683565855
Loss at batch 120 : 0.018890991806983948
Loss at batch 130 : 0.008706741966307163
Loss at batch 140 : 0.024671990424394608
Loss at batch 150 : 0.013983331620693207
Loss at batch 160 : 0.015275220386683941
Loss at batch 170 : 0.008851764723658562
Loss at batch 180 : 0.012548803351819515
Loss at batch 190 : 0.014474121853709221
Loss at batch 200 : 0.012678103521466255
Loss at batch 210 : 0.022624686360359192
Loss at batch 220 : 0.016887713223695755
Loss at batch 230 : 0.023939816281199455
Loss at batch 240 : 0.0132637619972229
Loss at batch 250 : 0.008867858909070492
Loss at batch 260 : 0.02612760104238987
Loss at batch 270 : 0.01406041719019413
Loss at batch 280 : 0.02161901816725731
Loss at batch 290 : 0.012913293205201626
Loss at batch 300 : 0.01641017757356167
Loss at batch 310 : 0.010303270071744919
Loss at batch 320 : 0.013704282231628895
Loss at batch 330 : 0.012396630831062794
Loss at batch 340 : 0.011404736898839474
Loss at batch 350 : 0.0189613476395607
Loss at batch 360 : 0.008816119283437729
Loss at batch 370 : 0.01176248025149107
epoch71 finished!
Loss at batch 10 : 0.008733531460165977
Loss at batch 20 : 0.026996120810508728
Loss at batch 30 : 0.014360392466187477
Loss at batch 40 : 0.014630144461989403
Loss at batch 50 : 0.01035059243440628
Loss at batch 60 : 0.00853442121297121
Loss at batch 70 : 0.014057657681405544
Loss at batch 80 : 0.01582513004541397
Loss at batch 90 : 0.01767888478934765
Loss at batch 100 : 0.012773806229233742
Loss at batch 110 : 0.011155467480421066
Loss at batch 120 : 0.0153285451233387
Loss at batch 130 : 0.011252104304730892
Loss at batch 140 : 0.01768440753221512
Loss at batch 150 : 0.012753209099173546
Loss at batch 160 : 0.010504945181310177
Loss at batch 170 : 0.01923382841050625
Loss at batch 180 : 0.01861700229346752
Loss at batch 190 : 0.012196816504001617
Loss at batch 200 : 0.010016604326665401
Loss at batch 210 : 0.009457884356379509
Loss at batch 220 : 0.014387650415301323
Loss at batch 230 : 0.006510923150926828
Loss at batch 240 : 0.016620498150587082
Loss at batch 250 : 0.02579737827181816
Loss at batch 260 : 0.013433776795864105
Loss at batch 270 : 0.00988954957574606
Loss at batch 280 : 0.020723389461636543
Loss at batch 290 : 0.01335145067423582
Loss at batch 300 : 0.009223519824445248
Loss at batch 310 : 0.008498034439980984
Loss at batch 320 : 0.013536076992750168
Loss at batch 330 : 0.005306039936840534
Loss at batch 340 : 0.014936220832169056
Loss at batch 350 : 0.018900003284215927
Loss at batch 360 : 0.010754932649433613
Loss at batch 370 : 0.010815788991749287
epoch71 finished!
Loss at batch 10 : 0.007321435958147049
Loss at batch 20 : 0.01264152117073536
Loss at batch 30 : 0.012325706891715527
Loss at batch 40 : 0.0130240423604846
Loss at batch 50 : 0.013563740998506546
Loss at batch 60 : 0.017943933606147766
Loss at batch 70 : 0.01246892660856247
Loss at batch 80 : 0.013708526268601418
Loss at batch 90 : 0.021990783512592316
Loss at batch 100 : 0.005892119370400906
Loss at batch 110 : 0.01982603408396244
Loss at batch 120 : 0.01259030681103468
Loss at batch 130 : 0.014304994605481625
Loss at batch 140 : 0.014362865127623081
Loss at batch 150 : 0.01890568621456623
Loss at batch 160 : 0.015681713819503784
Loss at batch 170 : 0.009888116270303726
Loss at batch 180 : 0.010327937081456184
Loss at batch 190 : 0.00901034940034151
Loss at batch 200 : 0.010659201070666313
Loss at batch 210 : 0.010714800097048283
Loss at batch 220 : 0.012970497831702232
Loss at batch 230 : 0.014467190951108932
Loss at batch 240 : 0.019590839743614197
Loss at batch 250 : 0.016760287806391716
Loss at batch 260 : 0.013967571780085564
Loss at batch 270 : 0.010639475658535957
Loss at batch 280 : 0.027346594259142876
Loss at batch 290 : 0.012630844488739967
Loss at batch 300 : 0.011283031664788723
Loss at batch 310 : 0.010656638070940971
Loss at batch 320 : 0.017277555540204048
Loss at batch 330 : 0.012228586710989475
Loss at batch 340 : 0.014183327555656433
Loss at batch 350 : 0.01679617166519165
Loss at batch 360 : 0.01796332746744156
Loss at batch 370 : 0.020353203639388084
epoch157 finished!
Loss at batch 10 : 0.01234735082834959
Loss at batch 20 : 0.007746977265924215
Loss at batch 30 : 0.017513912171125412
Loss at batch 40 : 0.027890106663107872
Loss at batch 50 : 0.00848236121237278
Loss at batch 60 : 0.017410961911082268
Loss at batch 70 : 0.018003277480602264
Loss at batch 80 : 0.01573091186583042
Loss at batch 90 : 0.01931355893611908
Loss at batch 100 : 0.011734955944120884
Loss at batch 110 : 0.016033824533224106
Loss at batch 120 : 0.01107344776391983
Loss at batch 130 : 0.0114813894033432
Loss at batch 140 : 0.011260638944804668
Loss at batch 150 : 0.008105475455522537
Loss at batch 160 : 0.013945348560810089
Loss at batch 170 : 0.012460539117455482
Loss at batch 180 : 0.008363098837435246
Loss at batch 190 : 0.016966866329312325
Loss at batch 200 : 0.00976936612278223
Loss at batch 210 : 0.007157377898693085
Loss at batch 220 : 0.009057564660906792
Loss at batch 230 : 0.006419299636036158
Loss at batch 240 : 0.01959492824971676
Loss at batch 250 : 0.01839352957904339
Loss at batch 260 : 0.011867363937199116
Loss at batch 270 : 0.011186627671122551
Loss at batch 280 : 0.012211702764034271
Loss at batch 290 : 0.008370522409677505
Loss at batch 300 : 0.016908077523112297
Loss at batch 310 : 0.016179392114281654
Loss at batch 320 : 0.012747540138661861
Loss at batch 330 : 0.01479399111121893
Loss at batch 340 : 0.01447464432567358
Loss at batch 350 : 0.01715533435344696
Loss at batch 360 : 0.016790591180324554
Loss at batch 370 : 0.013536432757973671
epoch158 finished!
Loss at batch 10 : 0.011561833322048187
Loss at batch 20 : 0.017834516242146492
Loss at batch 30 : 0.02498769946396351
Loss at batch 40 : 0.014693094417452812
Loss at batch 50 : 0.015335224568843842
Loss at batch 60 : 0.012223273515701294
Loss at batch 70 : 0.010344774462282658
Loss at batch 80 : 0.010981685481965542
Loss at batch 90 : 0.011105118319392204
Loss at batch 100 : 0.012233993038535118
Loss at batch 110 : 0.010494059883058071
Loss at batch 120 : 0.020940275862812996
Loss at batch 130 : 0.015635119751095772
Loss at batch 140 : 0.007754169404506683
Loss at batch 150 : 0.01139722391963005
Loss at batch 160 : 0.012337742373347282
Loss at batch 170 : 0.01377062313258648
Loss at batch 180 : 0.011348996311426163
Loss at batch 190 : 0.023126278072595596
Loss at batch 200 : 0.011433644220232964
Loss at batch 210 : 0.008074052631855011
Loss at batch 220 : 0.007925698533654213
Loss at batch 230 : 0.014530355110764503
Loss at batch 240 : 0.01997414045035839
Loss at batch 250 : 0.011466803960502148
Loss at batch 260 : 0.01275623869150877
Loss at batch 270 : 0.017641915008425713
Loss at batch 280 : 0.032166365534067154
Loss at batch 290 : 0.02089356817305088
Loss at batch 300 : 0.0074522485956549644
Loss at batch 310 : 0.009387873113155365
Loss at batch 320 : 0.010772572830319405
Loss at batch 330 : 0.023956431075930595
Loss at batch 340 : 0.008561302907764912
Loss at batch 350 : 0.012172741815447807
Loss at batch 360 : 0.014034180901944637
Loss at batch 370 : 0.011556695215404034
epoch72 finished!
Loss at batch 10 : 0.015079142525792122
Loss at batch 20 : 0.02291526459157467
Loss at batch 30 : 0.013052127324044704
Loss at batch 40 : 0.011737700551748276
Loss at batch 50 : 0.009056620299816132
Loss at batch 60 : 0.014875014312565327
Loss at batch 70 : 0.01850827969610691
Loss at batch 80 : 0.01941334269940853
Loss at batch 90 : 0.016649628058075905
Loss at batch 100 : 0.01270343828946352
Loss at batch 110 : 0.012569169513881207
Loss at batch 120 : 0.019273672252893448
Loss at batch 130 : 0.019378067925572395
Loss at batch 140 : 0.011950734071433544
Loss at batch 150 : 0.012385665439069271
Loss at batch 160 : 0.019235290586948395
Loss at batch 170 : 0.0085226371884346
Loss at batch 180 : 0.01321603637188673
Loss at batch 190 : 0.008599618449807167
Loss at batch 200 : 0.016486821696162224
Loss at batch 210 : 0.01332068257033825
Loss at batch 220 : 0.015665065497159958
Loss at batch 230 : 0.0121364276856184
Loss at batch 240 : 0.011249957606196404
Loss at batch 250 : 0.01706421747803688
Loss at batch 260 : 0.019032495096325874
Loss at batch 270 : 0.019497329369187355
Loss at batch 280 : 0.008693350479006767
Loss at batch 290 : 0.014942540787160397
Loss at batch 300 : 0.017364751547574997
Loss at batch 310 : 0.009937392547726631
Loss at batch 320 : 0.01409798301756382
Loss at batch 330 : 0.009786141104996204
Loss at batch 340 : 0.01484574656933546
Loss at batch 350 : 0.013231629505753517
Loss at batch 360 : 0.00937426183372736
Loss at batch 370 : 0.03251003846526146
epoch72 finished!
Loss at batch 10 : 0.013131260871887207
Loss at batch 20 : 0.010012361221015453
Loss at batch 30 : 0.017001712694764137
Loss at batch 40 : 0.01216130144894123
Loss at batch 50 : 0.012619071640074253
Loss at batch 60 : 0.014736341312527657
Loss at batch 70 : 0.007979704067111015
Loss at batch 80 : 0.011660919524729252
Loss at batch 90 : 0.013483391143381596
Loss at batch 100 : 0.012729060836136341
Loss at batch 110 : 0.013813444413244724
Loss at batch 120 : 0.015265440568327904
Loss at batch 130 : 0.011875852011144161
Loss at batch 140 : 0.016913430765271187
Loss at batch 150 : 0.008678811602294445
Loss at batch 160 : 0.010377918370068073
Loss at batch 170 : 0.0065188780426979065
Loss at batch 180 : 0.012248270213603973
Loss at batch 190 : 0.008450247347354889
Loss at batch 200 : 0.011652293615043163
Loss at batch 210 : 0.01875540055334568
Loss at batch 220 : 0.01613585092127323
Loss at batch 230 : 0.013210668228566647
Loss at batch 240 : 0.025964025408029556
Loss at batch 250 : 0.012860019691288471
Loss at batch 260 : 0.015508877113461494
Loss at batch 270 : 0.015155265107750893
Loss at batch 280 : 0.012476133182644844
Loss at batch 290 : 0.01252476591616869
Loss at batch 300 : 0.01614505797624588
Loss at batch 310 : 0.017662199214100838
Loss at batch 320 : 0.021780820563435555
Loss at batch 330 : 0.007218218874186277
Loss at batch 340 : 0.005900675896555185
Loss at batch 350 : 0.030108945444226265
Loss at batch 360 : 0.008481341414153576
Loss at batch 370 : 0.024779798462986946
epoch159 finished!
Loss at batch 10 : 0.00873615313321352
Loss at batch 20 : 0.018755260854959488
Loss at batch 30 : 0.017267165705561638
Loss at batch 40 : 0.010961582884192467
Loss at batch 50 : 0.009903287515044212
Loss at batch 60 : 0.019484087824821472
Loss at batch 70 : 0.01542234793305397
Loss at batch 80 : 0.01801767572760582
Loss at batch 90 : 0.010370654985308647
Loss at batch 100 : 0.016315048560500145
Loss at batch 110 : 0.0072825211100280285
Loss at batch 120 : 0.014451764523983002
Loss at batch 130 : 0.023780319839715958
Loss at batch 140 : 0.00937189906835556
Loss at batch 150 : 0.012849976308643818
Loss at batch 160 : 0.016956953331828117
Loss at batch 170 : 0.016586197540163994
Loss at batch 180 : 0.007360068615525961
Loss at batch 190 : 0.013993977569043636
Loss at batch 200 : 0.012250798754394054
Loss at batch 210 : 0.007907556369900703
Loss at batch 220 : 0.011595847085118294
Loss at batch 230 : 0.012041803449392319
Loss at batch 240 : 0.016164055094122887
Loss at batch 250 : 0.010186429135501385
Loss at batch 260 : 0.010292017832398415
Loss at batch 270 : 0.008143638260662556
Loss at batch 280 : 0.006277740467339754
Loss at batch 290 : 0.014525962062180042
Loss at batch 300 : 0.010883376933634281
Loss at batch 310 : 0.012699193321168423
Loss at batch 320 : 0.016093594953417778
Loss at batch 330 : 0.009486692026257515
Loss at batch 340 : 0.008144490420818329
Loss at batch 350 : 0.016574997454881668
Loss at batch 360 : 0.015072556212544441
Loss at batch 370 : 0.017380105331540108
epoch160 finished!

[2024-04-25 02:49:58.321364] test start with snapshots1/DehazeNet_epoch42.pth
[2024-04-25 02:50:32.047755] test end with snapshots1/DehazeNet_epoch42.pth
[2024-04-25 02:52:17.840616] Avg_PSNR: 19.324716671786643 dB, Avg_SSIM: 0.8733371667450904
[2024-04-25 02:52:17.886453] test start with snapshots1/DehazeNet_epoch131.pth
[2024-04-25 02:52:51.679229] test end with snapshots1/DehazeNet_epoch131.pth
[2024-04-25 02:54:37.233239] Avg_PSNR: 19.20807886981927 dB, Avg_SSIM: 0.8577087429626413
[2024-04-25 02:54:37.280008] test start with snapshots1/DehazeNet_epoch107.pth
[2024-04-25 02:55:10.733352] test end with snapshots1/DehazeNet_epoch107.pth
[2024-04-25 02:56:56.951284] Avg_PSNR: 19.426270854193525 dB, Avg_SSIM: 0.8638521332502195
[2024-04-25 02:56:57.003174] test start with snapshots1/DehazeNet_epoch98.pth
[2024-04-25 02:57:30.884340] test end with snapshots1/DehazeNet_epoch98.pth
[2024-04-25 02:59:16.699177] Avg_PSNR: 19.32374743590944 dB, Avg_SSIM: 0.865869415964067
[2024-04-25 02:59:16.750656] test start with snapshots1/DehazeNet_epoch185.pth
[2024-04-25 02:59:50.528638] test end with snapshots1/DehazeNet_epoch185.pth
[2024-04-25 03:01:36.322478] Avg_PSNR: 19.31934296278257 dB, Avg_SSIM: 0.8630313019626182
[2024-04-25 03:01:36.372910] test start with snapshots1/DehazeNet_epoch63.pth
[2024-04-25 03:02:09.957150] test end with snapshots1/DehazeNet_epoch63.pth
[2024-04-25 03:03:55.762984] Avg_PSNR: 19.369731672444008 dB, Avg_SSIM: 0.866308521957003
[2024-04-25 03:03:55.807816] test start with snapshots1/DehazeNet_epoch129.pth
[2024-04-25 03:04:29.667109] test end with snapshots1/DehazeNet_epoch129.pth
[2024-04-25 03:06:16.177087] Avg_PSNR: 19.453515343209872 dB, Avg_SSIM: 0.8697750484059984
[2024-04-25 03:06:16.220942] test start with snapshots1/DehazeNet_epoch58.pth
[2024-04-25 03:06:49.854258] test end with snapshots1/DehazeNet_epoch58.pth
[2024-04-25 03:08:36.426187] Avg_PSNR: 19.25313841053266 dB, Avg_SSIM: 0.8637732948406985
[2024-04-25 03:08:36.475293] test start with snapshots1/DehazeNet_epoch194.pth
[2024-04-25 03:09:10.395583] test end with snapshots1/DehazeNet_epoch194.pth
[2024-04-25 03:10:56.157507] Avg_PSNR: 19.566303459964598 dB, Avg_SSIM: 0.8658895861115116
[2024-04-25 03:10:56.207077] test start with snapshots1/DehazeNet_epoch186.pth
[2024-04-25 03:11:30.002528] test end with snapshots1/DehazeNet_epoch186.pth
[2024-04-25 03:13:16.394646] Avg_PSNR: 19.42371347744095 dB, Avg_SSIM: 0.8655463634016879
[2024-04-25 03:13:16.436594] test start with snapshots1/DehazeNet_epoch164.pth
[2024-04-25 03:13:50.029282] test end with snapshots1/DehazeNet_epoch164.pth
[2024-04-25 03:15:36.546327] Avg_PSNR: 19.40740809305018 dB, Avg_SSIM: 0.8688556309202188
[2024-04-25 03:15:36.587879] test start with snapshots1/DehazeNet_epoch51.pth
[2024-04-25 03:16:10.637421] test end with snapshots1/DehazeNet_epoch51.pth
[2024-04-25 03:17:56.612647] Avg_PSNR: 19.144546175754137 dB, Avg_SSIM: 0.8647373343039955
[2024-04-25 03:17:56.656852] test start with snapshots1/DehazeNet_epoch60.pth
[2024-04-25 03:18:30.045618] test end with snapshots1/DehazeNet_epoch60.pth
[2024-04-25 03:20:15.860549] Avg_PSNR: 19.114317287946673 dB, Avg_SSIM: 0.857713854409233
[2024-04-25 03:20:15.909044] test start with snapshots1/DehazeNet_epoch171.pth
[2024-04-25 03:20:49.515426] test end with snapshots1/DehazeNet_epoch171.pth
[2024-04-25 03:22:35.041260] Avg_PSNR: 19.556854021783693 dB, Avg_SSIM: 0.8678343699891765
[2024-04-25 03:22:35.085802] test start with snapshots1/DehazeNet_epoch46.pth
[2024-04-25 03:23:08.465106] test end with snapshots1/DehazeNet_epoch46.pth
[2024-04-25 03:24:54.567843] Avg_PSNR: 19.28034030205349 dB, Avg_SSIM: 0.8726432565561569
[2024-04-25 03:24:54.610386] test start with snapshots1/DehazeNet_epoch127.pth
[2024-04-25 03:25:28.428651] test end with snapshots1/DehazeNet_epoch127.pth
[2024-04-25 03:27:14.380043] Avg_PSNR: 19.17516274949765 dB, Avg_SSIM: 0.8613643846730237
[2024-04-25 03:27:14.425361] test start with snapshots1/DehazeNet_epoch7.pth
[2024-04-25 03:27:48.236529] test end with snapshots1/DehazeNet_epoch7.pth
[2024-04-25 03:29:34.267668] Avg_PSNR: 19.054299752242425 dB, Avg_SSIM: 0.8762326216756994
[2024-04-25 03:29:34.302278] test start with snapshots1/DehazeNet_epoch188.pth
[2024-04-25 03:30:08.295131] test end with snapshots1/DehazeNet_epoch188.pth
[2024-04-25 03:31:54.444000] Avg_PSNR: 19.40896371592007 dB, Avg_SSIM: 0.8641783258195955
[2024-04-25 03:31:54.485583] test start with snapshots1/DehazeNet_epoch165.pth
[2024-04-25 03:32:28.543186] test end with snapshots1/DehazeNet_epoch165.pth
[2024-04-25 03:34:14.581625] Avg_PSNR: 19.447979832707876 dB, Avg_SSIM: 0.8674273243696553
[2024-04-25 03:34:14.625206] test start with snapshots1/DehazeNet_epoch167.pth
[2024-04-25 03:34:48.252361] test end with snapshots1/DehazeNet_epoch167.pth
[2024-04-25 03:36:34.541107] Avg_PSNR: 19.31393915876334 dB, Avg_SSIM: 0.8654984549178667
[2024-04-25 03:36:34.590269] test start with snapshots1/DehazeNet_epoch55.pth
[2024-04-25 03:37:08.562169] test end with snapshots1/DehazeNet_epoch55.pth
[2024-04-25 03:38:54.289214] Avg_PSNR: 19.234543876897796 dB, Avg_SSIM: 0.8640462536264215
[2024-04-25 03:38:54.322735] test start with snapshots1/DehazeNet_epoch192.pth
[2024-04-25 03:39:27.873686] test end with snapshots1/DehazeNet_epoch192.pth
[2024-04-25 03:41:13.974001] Avg_PSNR: 19.2161269896468 dB, Avg_SSIM: 0.8577197658380065
[2024-04-25 03:41:14.015807] test start with snapshots1/DehazeNet_epoch29.pth
[2024-04-25 03:41:48.044495] test end with snapshots1/DehazeNet_epoch29.pth
[2024-04-25 03:43:34.040316] Avg_PSNR: 19.071885158566516 dB, Avg_SSIM: 0.8756587191370795
[2024-04-25 03:43:34.091947] test start with snapshots1/DehazeNet_epoch132.pth
[2024-04-25 03:44:07.952890] test end with snapshots1/DehazeNet_epoch132.pth
[2024-04-25 03:45:53.861434] Avg_PSNR: 19.32793515964019 dB, Avg_SSIM: 0.861159057696392
[2024-04-25 03:45:53.905991] test start with snapshots1/DehazeNet_epoch112.pth
[2024-04-25 03:46:28.095416] test end with snapshots1/DehazeNet_epoch112.pth
[2024-04-25 03:48:14.291479] Avg_PSNR: 19.433343330814587 dB, Avg_SSIM: 0.8652828251053831
[2024-04-25 03:48:14.341224] test start with snapshots1/DehazeNet_epoch106.pth
[2024-04-25 03:48:48.283281] test end with snapshots1/DehazeNet_epoch106.pth
[2024-04-25 03:50:34.494646] Avg_PSNR: 19.330956053203955 dB, Avg_SSIM: 0.8640957884688371
[2024-04-25 03:50:34.540502] test start with snapshots1/DehazeNet_epoch69.pth
[2024-04-25 03:51:08.202806] test end with snapshots1/DehazeNet_epoch69.pth
[2024-04-25 03:52:54.460229] Avg_PSNR: 19.31436325092673 dB, Avg_SSIM: 0.8635518800950872
[2024-04-25 03:52:54.504044] test start with snapshots1/DehazeNet_epoch150.pth
[2024-04-25 03:53:28.729659] test end with snapshots1/DehazeNet_epoch150.pth
[2024-04-25 03:55:15.252147] Avg_PSNR: 19.579403266863487 dB, Avg_SSIM: 0.8642799202526967
[2024-04-25 03:55:15.293763] test start with snapshots1/DehazeNet_epoch153.pth
[2024-04-25 03:55:49.139101] test end with snapshots1/DehazeNet_epoch153.pth
[2024-04-25 03:57:35.106641] Avg_PSNR: 19.322017299203914 dB, Avg_SSIM: 0.8599550736347946
[2024-04-25 03:57:35.156029] test start with snapshots1/DehazeNet_epoch78.pth
[2024-04-25 03:58:08.931052] test end with snapshots1/DehazeNet_epoch78.pth
[2024-04-25 03:59:54.967043] Avg_PSNR: 19.265405720699892 dB, Avg_SSIM: 0.8612193219347025
[2024-04-25 03:59:55.005368] test start with snapshots1/DehazeNet_epoch109.pth
[2024-04-25 04:00:28.672280] test end with snapshots1/DehazeNet_epoch109.pth
[2024-04-25 04:02:14.830675] Avg_PSNR: 19.333836975330808 dB, Avg_SSIM: 0.8622886854037991
[2024-04-25 04:02:14.896150] test start with snapshots1/DehazeNet_epoch193.pth
[2024-04-25 04:02:48.552425] test end with snapshots1/DehazeNet_epoch193.pth
[2024-04-25 04:04:34.645243] Avg_PSNR: 19.385092463299312 dB, Avg_SSIM: 0.864648607425685
[2024-04-25 04:04:34.690558] test start with snapshots1/DehazeNet_epoch152.pth
[2024-04-25 04:05:08.580507] test end with snapshots1/DehazeNet_epoch152.pth
[2024-04-25 04:06:54.600250] Avg_PSNR: 19.47927987691633 dB, Avg_SSIM: 0.8642647272449612
[2024-04-25 04:06:54.635362] test start with snapshots1/DehazeNet_epoch199.pth
[2024-04-25 04:07:28.689629] test end with snapshots1/DehazeNet_epoch199.pth
[2024-04-25 04:09:14.835457] Avg_PSNR: 19.408277160082722 dB, Avg_SSIM: 0.8619338401625675
[2024-04-25 04:09:14.880601] test start with snapshots1/DehazeNet_epoch3.pth
[2024-04-25 04:09:48.662404] test end with snapshots1/DehazeNet_epoch3.pth
[2024-04-25 04:11:34.041458] Avg_PSNR: 18.9474869193368 dB, Avg_SSIM: 0.8723624610157581
[2024-04-25 04:11:34.092024] test start with snapshots1/DehazeNet_epoch40.pth
[2024-04-25 04:12:07.810074] test end with snapshots1/DehazeNet_epoch40.pth
[2024-04-25 04:13:53.721067] Avg_PSNR: 19.133810578885107 dB, Avg_SSIM: 0.8752681389800677
[2024-04-25 04:13:53.763779] test start with snapshots1/DehazeNet_epoch138.pth
[2024-04-25 04:14:27.551011] test end with snapshots1/DehazeNet_epoch138.pth
[2024-04-25 04:16:13.246322] Avg_PSNR: 19.40409823438543 dB, Avg_SSIM: 0.8629694015782208
[2024-04-25 04:16:13.290940] test start with snapshots1/DehazeNet_epoch30.pth
[2024-04-25 04:16:47.181734] test end with snapshots1/DehazeNet_epoch30.pth
[2024-04-25 04:18:33.162836] Avg_PSNR: 18.970282779598932 dB, Avg_SSIM: 0.8722749146729504
[2024-04-25 04:18:33.205630] test start with snapshots1/DehazeNet_epoch53.pth
[2024-04-25 04:19:07.235498] test end with snapshots1/DehazeNet_epoch53.pth
[2024-04-25 04:20:53.111054] Avg_PSNR: 19.27737684056144 dB, Avg_SSIM: 0.8647996483890643
[2024-04-25 04:20:53.157038] test start with snapshots1/DehazeNet_epoch175.pth
[2024-04-25 04:21:26.964622] test end with snapshots1/DehazeNet_epoch175.pth
[2024-04-25 04:23:13.158560] Avg_PSNR: 19.514445209516243 dB, Avg_SSIM: 0.8653370240822147
[2024-04-25 04:23:13.204563] test start with snapshots1/DehazeNet_epoch183.pth
[2024-04-25 04:23:47.086337] test end with snapshots1/DehazeNet_epoch183.pth
[2024-04-25 04:25:32.890493] Avg_PSNR: 19.592947126960667 dB, Avg_SSIM: 0.8663517481211316
[2024-04-25 04:25:32.932838] test start with snapshots1/DehazeNet_epoch115.pth
[2024-04-25 04:26:07.151385] test end with snapshots1/DehazeNet_epoch115.pth
[2024-04-25 04:27:53.302497] Avg_PSNR: 19.5988875176523 dB, Avg_SSIM: 0.8674442112044713
[2024-04-25 04:27:53.344578] test start with snapshots1/DehazeNet_epoch159.pth
[2024-04-25 04:28:27.321982] test end with snapshots1/DehazeNet_epoch159.pth
[2024-04-25 04:30:13.749953] Avg_PSNR: 19.23697333964832 dB, Avg_SSIM: 0.8629232171916402
[2024-04-25 04:30:13.797517] test start with snapshots1/DehazeNet_epoch133.pth
[2024-04-25 04:30:47.904631] test end with snapshots1/DehazeNet_epoch133.pth
[2024-04-25 04:32:34.008463] Avg_PSNR: 19.153236594515263 dB, Avg_SSIM: 0.8567847797434006
[2024-04-25 04:32:34.057530] test start with snapshots1/DehazeNet_epoch85.pth
[2024-04-25 04:33:07.969023] test end with snapshots1/DehazeNet_epoch85.pth
[2024-04-25 04:34:54.563664] Avg_PSNR: 19.457265637646138 dB, Avg_SSIM: 0.8664684657471122
[2024-04-25 04:34:54.613760] test start with snapshots1/DehazeNet_epoch126.pth
[2024-04-25 04:35:28.469662] test end with snapshots1/DehazeNet_epoch126.pth
[2024-04-25 04:37:14.706716] Avg_PSNR: 19.399091151628323 dB, Avg_SSIM: 0.8660585224960585
[2024-04-25 04:37:14.752677] test start with snapshots1/DehazeNet_epoch162.pth
[2024-04-25 04:37:48.866069] test end with snapshots1/DehazeNet_epoch162.pth
[2024-04-25 04:39:34.979762] Avg_PSNR: 19.51279546015808 dB, Avg_SSIM: 0.8664044342954533
[2024-04-25 04:39:35.023745] test start with snapshots1/DehazeNet_epoch12.pth
[2024-04-25 04:40:08.770976] test end with snapshots1/DehazeNet_epoch12.pth
[2024-04-25 04:41:55.005287] Avg_PSNR: 19.113813420458452 dB, Avg_SSIM: 0.8751901308990099
[2024-04-25 04:41:55.053053] test start with snapshots1/DehazeNet_epoch139.pth
[2024-04-25 04:42:29.003157] test end with snapshots1/DehazeNet_epoch139.pth
[2024-04-25 04:44:14.320204] Avg_PSNR: 19.50098794712164 dB, Avg_SSIM: 0.8670763182094186
[2024-04-25 04:44:14.360176] test start with snapshots1/DehazeNet_epoch137.pth
[2024-04-25 04:44:48.033231] test end with snapshots1/DehazeNet_epoch137.pth
[2024-04-25 04:46:34.279241] Avg_PSNR: 19.39516714250505 dB, Avg_SSIM: 0.8650805304912603
[2024-04-25 04:46:34.320373] test start with snapshots1/DehazeNet_epoch37.pth
[2024-04-25 04:47:08.104738] test end with snapshots1/DehazeNet_epoch37.pth
[2024-04-25 04:48:54.141078] Avg_PSNR: 19.154533063483363 dB, Avg_SSIM: 0.8769721078558983
[2024-04-25 04:48:54.184372] test start with snapshots1/DehazeNet_epoch178.pth
[2024-04-25 04:49:27.990767] test end with snapshots1/DehazeNet_epoch178.pth
[2024-04-25 04:51:13.700813] Avg_PSNR: 19.266381511472748 dB, Avg_SSIM: 0.8619474725815736
[2024-04-25 04:51:13.744072] test start with snapshots1/DehazeNet_epoch173.pth
[2024-04-25 04:51:47.950498] test end with snapshots1/DehazeNet_epoch173.pth
[2024-04-25 04:53:34.099797] Avg_PSNR: 19.345046523649 dB, Avg_SSIM: 0.8626352384915179
[2024-04-25 04:53:34.141763] test start with snapshots1/DehazeNet_epoch135.pth
[2024-04-25 04:54:07.964201] test end with snapshots1/DehazeNet_epoch135.pth
[2024-04-25 04:55:53.758781] Avg_PSNR: 19.15836600180739 dB, Avg_SSIM: 0.859183607267722
[2024-04-25 04:55:53.802781] test start with snapshots1/DehazeNet_epoch81.pth
[2024-04-25 04:56:27.515876] test end with snapshots1/DehazeNet_epoch81.pth
[2024-04-25 04:58:13.394461] Avg_PSNR: 19.239362930770657 dB, Avg_SSIM: 0.8610412455449162
[2024-04-25 04:58:13.438555] test start with snapshots1/DehazeNet_epoch181.pth
[2024-04-25 04:58:47.257679] test end with snapshots1/DehazeNet_epoch181.pth
[2024-04-25 05:00:33.038385] Avg_PSNR: 19.404381710871416 dB, Avg_SSIM: 0.8618813319817763
[2024-04-25 05:00:33.082903] test start with snapshots1/DehazeNet_epoch21.pth
[2024-04-25 05:01:06.893407] test end with snapshots1/DehazeNet_epoch21.pth
[2024-04-25 05:02:51.835952] Avg_PSNR: 18.954414285549852 dB, Avg_SSIM: 0.8736596866396836
[2024-04-25 05:02:51.893668] test start with snapshots1/DehazeNet_epoch72.pth
[2024-04-25 05:03:25.750124] test end with snapshots1/DehazeNet_epoch72.pth
[2024-04-25 05:05:11.926195] Avg_PSNR: 19.333596571326957 dB, Avg_SSIM: 0.8651549128364513
[2024-04-25 05:05:11.974336] test start with snapshots1/DehazeNet_epoch166.pth
[2024-04-25 05:05:45.935509] test end with snapshots1/DehazeNet_epoch166.pth
[2024-04-25 05:07:31.852697] Avg_PSNR: 19.566619738788518 dB, Avg_SSIM: 0.8675956686527412
[2024-04-25 05:07:31.897824] test start with snapshots1/DehazeNet_epoch158.pth
[2024-04-25 05:08:05.345202] test end with snapshots1/DehazeNet_epoch158.pth
[2024-04-25 05:09:51.519094] Avg_PSNR: 19.534326970362464 dB, Avg_SSIM: 0.8677555739058703
[2024-04-25 05:09:51.566906] test start with snapshots1/DehazeNet_epoch177.pth
[2024-04-25 05:10:25.607138] test end with snapshots1/DehazeNet_epoch177.pth
[2024-04-25 05:12:11.562089] Avg_PSNR: 19.3864807699123 dB, Avg_SSIM: 0.8650741312708906
[2024-04-25 05:12:11.603932] test start with snapshots1/DehazeNet_epoch130.pth
[2024-04-25 05:12:45.342825] test end with snapshots1/DehazeNet_epoch130.pth
[2024-04-25 05:14:31.790343] Avg_PSNR: 19.29219379889739 dB, Avg_SSIM: 0.8628604822663529
[2024-04-25 05:14:31.831626] test start with snapshots1/DehazeNet_epoch6.pth
[2024-04-25 05:15:05.477010] test end with snapshots1/DehazeNet_epoch6.pth
[2024-04-25 05:16:51.626813] Avg_PSNR: 19.0337468783692 dB, Avg_SSIM: 0.8740747834434146
[2024-04-25 05:16:51.672675] test start with snapshots1/DehazeNet_epoch108.pth
[2024-04-25 05:17:25.297688] test end with snapshots1/DehazeNet_epoch108.pth
[2024-04-25 05:19:05.202427] Avg_PSNR: 19.40259459815486 dB, Avg_SSIM: 0.864381766643916
[2024-04-25 05:19:05.243256] test start with snapshots1/DehazeNet_epoch22.pth
[2024-04-25 05:19:36.055827] test end with snapshots1/DehazeNet_epoch22.pth
[2024-04-25 05:21:12.107812] Avg_PSNR: 19.03582506538166 dB, Avg_SSIM: 0.8713099294312705
[2024-04-25 05:21:12.150846] test start with snapshots1/DehazeNet_epoch184.pth
[2024-04-25 05:21:43.187967] test end with snapshots1/DehazeNet_epoch184.pth
[2024-04-25 05:23:19.423191] Avg_PSNR: 19.518674601757535 dB, Avg_SSIM: 0.8686775803674633
[2024-04-25 05:23:19.460420] test start with snapshots1/DehazeNet_epoch23.pth
[2024-04-25 05:23:50.302375] test end with snapshots1/DehazeNet_epoch23.pth
[2024-04-25 05:25:26.526463] Avg_PSNR: 18.91957773583439 dB, Avg_SSIM: 0.8728611464846379
[2024-04-25 05:25:26.568999] test start with snapshots1/DehazeNet_epoch142.pthLoss at batch 10 : 0.01367300096899271
[2024-04-24 22:57:30.810423] test start with snapshots1/DehazeNet_epoch0.pth
[2024-04-24 22:58:00.264454] test end with snapshots1/DehazeNet_epoch0.pth
[2024-04-24 22:59:29.895211] Avg_PSNR: 18.79798457622806 dB, Avg_SSIM: 0.8656816424441612
[2024-04-24 22:59:29.921426] test start with snapshots1/record-DehazeNet_epoch30.pth
[2024-04-24 22:59:59.099733] test end with snapshots1/record-DehazeNet_epoch30.pth
[2024-04-24 23:01:28.727070] Avg_PSNR: 18.82702041347954 dB, Avg_SSIM: 0.8606343243785589
[2024-04-24 23:01:28.753359] test start with snapshots1/DehazeNet_epoch99.pth
[2024-04-24 23:01:58.003787] test end with snapshots1/DehazeNet_epoch99.pth
[2024-04-24 23:03:28.088590] Avg_PSNR: 19.388905799393758 dB, Avg_SSIM: 0.8652947818768609
[2024-04-24 23:03:28.129907] test start with snapshots1/DehazeNet_epoch92.pth
[2024-04-24 23:03:57.651809] test end with snapshots1/DehazeNet_epoch92.pth
[2024-04-24 23:05:27.537485] Avg_PSNR: 19.268548220351335 dB, Avg_SSIM: 0.8648350495050625
[2024-04-24 23:05:27.575129] test start with snapshots1/DehazeNet_epoch100.pth
[2024-04-24 23:05:57.051301] test end with snapshots1/DehazeNet_epoch100.pth
[2024-04-24 23:07:26.759532] Avg_PSNR: 19.3125331441198 dB, Avg_SSIM: 0.864698312240791
[2024-04-24 23:07:26.797771] test start with snapshots1/DehazeNet_epoch197.pth
[2024-04-24 23:07:56.052238] test end with snapshots1/DehazeNet_epoch197.pth
[2024-04-24 23:09:25.696302] Avg_PSNR: 19.358370295319506 dB, Avg_SSIM: 0.8647406812421798
[2024-04-24 23:09:25.738716] test start with snapshots1/DehazeNet_epoch54.pth
[2024-04-24 23:09:54.898480] test end with snapshots1/DehazeNet_epoch54.pth
[2024-04-24 23:11:25.582675] Avg_PSNR: 19.301245636109588 dB, Avg_SSIM: 0.8645922891571739
[2024-04-24 23:11:25.604811] test start with snapshots1/DehazeNet_epoch33.pth
[2024-04-24 23:11:54.859974] test end with snapshots1/DehazeNet_epoch33.pth
[2024-04-24 23:13:28.746815] Avg_PSNR: 19.00696501539684 dB, Avg_SSIM: 0.8739075511847213
[2024-04-24 23:13:28.772632] test start with snapshots1/DehazeNet_epoch94.pth
[2024-04-24 23:13:59.462469] test end with snapshots1/DehazeNet_epoch94.pth
[2024-04-24 23:15:34.888034] Avg_PSNR: 19.285174827408156 dB, Avg_SSIM: 0.863013682545166
[2024-04-24 23:15:34.909570] test start with snapshots1/DehazeNet_epoch154.pth
[2024-04-24 23:16:05.985469] test end with snapshots1/DehazeNet_epoch154.pth
[2024-04-24 23:17:42.813333] Avg_PSNR: 19.600018516970696 dB, Avg_SSIM: 0.8656923597169706
[2024-04-24 23:17:42.839216] test start with snapshots1/DehazeNet_epoch180.pth
[2024-04-24 23:18:14.266570] test end with snapshots1/DehazeNet_epoch180.pth
[2024-04-24 23:19:59.686632] Avg_PSNR: 19.26366224928087 dB, Avg_SSIM: 0.8594549382433783
[2024-04-24 23:19:59.727769] test start with snapshots1/DehazeNet_epoch73.pth
[2024-04-24 23:20:33.652089] test end with snapshots1/DehazeNet_epoch73.pth
[2024-04-24 23:22:20.281563] Avg_PSNR: 19.188566489394027 dB, Avg_SSIM: 0.8586057651555045
[2024-04-24 23:22:20.326733] test start with snapshots1/DehazeNet_epoch77.pth
[2024-04-24 23:22:54.032257] test end with snapshots1/DehazeNet_epoch77.pth
[2024-04-24 23:24:39.672428] Avg_PSNR: 19.234739874777254 dB, Avg_SSIM: 0.8600300626524799
[2024-04-24 23:24:39.719272] test start with snapshots1/DehazeNet_epoch90.pth
[2024-04-24 23:25:13.294079] test end with snapshots1/DehazeNet_epoch90.pth
[2024-04-24 23:26:59.046032] Avg_PSNR: 19.515171062921848 dB, Avg_SSIM: 0.8675238312870391
[2024-04-24 23:26:59.086436] test start with snapshots1/DehazeNet_epoch39.pth
[2024-04-24 23:27:32.910535] test end with snapshots1/DehazeNet_epoch39.pth
[2024-04-24 23:29:19.125810] Avg_PSNR: 19.23661595808432 dB, Avg_SSIM: 0.8755663081770377
[2024-04-24 23:29:19.157717] test start with snapshots1/DehazeNet_epoch182.pth
[2024-04-24 23:29:52.855049] test end with snapshots1/DehazeNet_epoch182.pth
[2024-04-24 23:31:38.791079] Avg_PSNR: 19.447976276074918 dB, Avg_SSIM: 0.8619570544274766
[2024-04-24 23:31:38.837918] test start with snapshots1/DehazeNet_epoch101.pth
[2024-04-24 23:32:12.505922] test end with snapshots1/DehazeNet_epoch101.pth
[2024-04-24 23:33:58.221371] Avg_PSNR: 19.34591436848286 dB, Avg_SSIM: 0.8633762859934158
[2024-04-24 23:33:58.275328] test start with snapshots1/DehazeNet_epoch89.pth
[2024-04-24 23:34:32.298673] test end with snapshots1/DehazeNet_epoch89.pth
[2024-04-24 23:36:18.473650] Avg_PSNR: 19.385725344274643 dB, Avg_SSIM: 0.8605710662265452
[2024-04-24 23:36:18.515799] test start with snapshots1/DehazeNet_epoch41.pth
[2024-04-24 23:36:52.592698] test end with snapshots1/DehazeNet_epoch41.pth
[2024-04-24 23:38:39.005696] Avg_PSNR: 19.264893911949205 dB, Avg_SSIM: 0.8752555197976432
[2024-04-24 23:38:39.051621] test start with snapshots1/DehazeNet_epoch116.pth
[2024-04-24 23:39:12.997258] test end with snapshots1/DehazeNet_epoch116.pth
[2024-04-24 23:40:59.900756] Avg_PSNR: 19.30598855623742 dB, Avg_SSIM: 0.8638613738306727
[2024-04-24 23:40:59.954759] test start with snapshots1/DehazeNet_epoch195.pth
[2024-04-24 23:41:33.936151] test end with snapshots1/DehazeNet_epoch195.pth
[2024-04-24 23:43:20.251177] Avg_PSNR: 19.164646921108204 dB, Avg_SSIM: 0.8560151705844172
[2024-04-24 23:43:20.294186] test start with snapshots1/DehazeNet_epoch122.pth
[2024-04-24 23:43:54.159648] test end with snapshots1/DehazeNet_epoch122.pth
[2024-04-24 23:45:40.383816] Avg_PSNR: 19.473495343648917 dB, Avg_SSIM: 0.8688353523197498
[2024-04-24 23:45:40.426599] test start with snapshots1/DehazeNet_epoch97.pth
[2024-04-24 23:46:14.107040] test end with snapshots1/DehazeNet_epoch97.pth
[2024-04-24 23:48:00.393339] Avg_PSNR: 19.227386912142098 dB, Avg_SSIM: 0.8622676113597416
[2024-04-24 23:48:00.444555] test start with snapshots1/DehazeNet_epoch9.pth
[2024-04-24 23:48:34.442635] test end with snapshots1/DehazeNet_epoch9.pth
[2024-04-24 23:50:20.839416] Avg_PSNR: 19.098889374558087 dB, Avg_SSIM: 0.8756182839228103
[2024-04-24 23:50:20.887879] test start with snapshots1/DehazeNet_epoch82.pth
[2024-04-24 23:50:55.114493] test end with snapshots1/DehazeNet_epoch82.pth
[2024-04-24 23:52:41.000695] Avg_PSNR: 19.376336762896905 dB, Avg_SSIM: 0.8634910373532616
[2024-04-24 23:52:41.047738] test start with snapshots1/DehazeNet_epoch48.pth
[2024-04-24 23:53:15.418710] test end with snapshots1/DehazeNet_epoch48.pth
[2024-04-24 23:55:01.684062] Avg_PSNR: 19.30359606008779 dB, Avg_SSIM: 0.8692518028817522
[2024-04-24 23:55:01.732522] test start with snapshots1/DehazeNet_epoch103.pth
[2024-04-24 23:55:35.697528] test end with snapshots1/DehazeNet_epoch103.pth
[2024-04-24 23:57:21.908826] Avg_PSNR: 19.40761078581017 dB, Avg_SSIM: 0.8652526567922475
[2024-04-24 23:57:21.952230] test start with snapshots1/DehazeNet_epoch136.pth
[2024-04-24 23:57:55.845593] test end with snapshots1/DehazeNet_epoch136.pth
[2024-04-24 23:59:42.386919] Avg_PSNR: 19.273178748654022 dB, Avg_SSIM: 0.8615793448736059
[2024-04-24 23:59:42.427272] test start with snapshots1/DehazeNet_epoch26.pth
[2024-04-25 00:00:16.433134] test end with snapshots1/DehazeNet_epoch26.pth
[2024-04-25 00:02:02.650690] Avg_PSNR: 18.942176794882258 dB, Avg_SSIM: 0.8678965280504428
[2024-04-25 00:02:02.690667] test start with snapshots1/DehazeNet_epoch148.pth
[2024-04-25 00:02:36.359812] test end with snapshots1/DehazeNet_epoch148.pth
[2024-04-25 00:04:21.718972] Avg_PSNR: 19.296910371981014 dB, Avg_SSIM: 0.862030001822018
[2024-04-25 00:04:21.760140] test start with snapshots1/DehazeNet_epoch146.pth
[2024-04-25 00:04:55.465274] test end with snapshots1/DehazeNet_epoch146.pth
[2024-04-25 00:06:41.836367] Avg_PSNR: 19.466125335676306 dB, Avg_SSIM: 0.8652944796623129
[2024-04-25 00:06:41.877430] test start with snapshots1/DehazeNet_epoch45.pth
[2024-04-25 00:07:15.691676] test end with snapshots1/DehazeNet_epoch45.pth
[2024-04-25 00:09:01.786037] Avg_PSNR: 19.24728819865463 dB, Avg_SSIM: 0.8725924908104765
[2024-04-25 00:09:01.833319] test start with snapshots1/DehazeNet_epoch161.pth
[2024-04-25 00:09:35.660748] test end with snapshots1/DehazeNet_epoch161.pth
[2024-04-25 00:11:21.184739] Avg_PSNR: 19.36162598156995 dB, Avg_SSIM: 0.8659673383612195
[2024-04-25 00:11:21.230011] test start with snapshots1/DehazeNet_epoch196.pth
[2024-04-25 00:11:54.979329] test end with snapshots1/DehazeNet_epoch196.pth
Loss at batch 10 : 0.017923427745699883

Loss at batch 10 : 0.014285348355770111
Loss at batch 20 : 0.011399710550904274
Loss at batch 30 : 0.018497182056307793
Loss at batch 40 : 0.01133942324668169
Loss at batch 50 : 0.011248703114688396
Loss at batch 60 : 0.018181463703513145
Loss at batch 70 : 0.01238183118402958
Loss at batch 80 : 0.012953417375683784
Loss at batch 90 : 0.02034708857536316
Loss at batch 100 : 0.0148618808016181
Loss at batch 110 : 0.013821094296872616
Loss at batch 120 : 0.010055216029286385
Loss at batch 130 : 0.009998755529522896
Loss at batch 140 : 0.012023136019706726
Loss at batch 150 : 0.02363612689077854
Loss at batch 160 : 0.012666289694607258
Loss at batch 170 : 0.01767737977206707
Loss at batch 180 : 0.021602485328912735
Loss at batch 190 : 0.012587091885507107
Loss at batch 200 : 0.0189879909157753
Loss at batch 210 : 0.012377108447253704
Loss at batch 220 : 0.014925544150173664
Loss at batch 230 : 0.009577197022736073
Loss at batch 240 : 0.007722238544374704
Loss at batch 250 : 0.020624695345759392
Loss at batch 260 : 0.012947955168783665
Loss at batch 270 : 0.010487064719200134
Loss at batch 280 : 0.017346898093819618
Loss at batch 290 : 0.014050670899450779
Loss at batch 300 : 0.022127516567707062
Loss at batch 310 : 0.014477620832622051
Loss at batch 320 : 0.011640576645731926
Loss at batch 330 : 0.007594586815685034
Loss at batch 340 : 0.01438919734209776
Loss at batch 350 : 0.016333943232893944
Loss at batch 360 : 0.01968015730381012
Loss at batch 370 : 0.0102046187967062
epoch73 finished!
Loss at batch 10 : 0.011606946587562561
Loss at batch 20 : 0.007669166196137667
Loss at batch 30 : 0.013217627070844173
Loss at batch 40 : 0.012919165194034576
Loss at batch 50 : 0.014869599603116512
Loss at batch 60 : 0.021471280604600906
Loss at batch 70 : 0.014262356795370579
Loss at batch 80 : 0.010177576914429665
Loss at batch 90 : 0.013196396641433239
Loss at batch 100 : 0.015216944739222527
Loss at batch 110 : 0.020709415897727013
Loss at batch 120 : 0.019729427993297577
Loss at batch 130 : 0.008619488216936588
Loss at batch 140 : 0.018193844705820084
Loss at batch 150 : 0.009767168201506138
Loss at batch 160 : 0.00669096177443862
Loss at batch 170 : 0.011438840068876743
Loss at batch 180 : 0.01182804349809885
Loss at batch 190 : 0.008497342467308044
Loss at batch 200 : 0.013842301443219185
Loss at batch 210 : 0.007845054380595684
Loss at batch 220 : 0.011871536262333393
Loss at batch 230 : 0.015831120312213898
Loss at batch 240 : 0.008782738819718361
Loss at batch 250 : 0.014980967156589031
Loss at batch 260 : 0.01226047147065401
Loss at batch 270 : 0.01842615380883217
Loss at batch 280 : 0.01976529136300087
Loss at batch 290 : 0.011744598858058453
Loss at batch 300 : 0.02469254471361637
Loss at batch 310 : 0.017691489309072495
Loss at batch 320 : 0.009269233793020248
Loss at batch 330 : 0.013676242902874947
Loss at batch 340 : 0.010272005572915077
Loss at batch 350 : 0.010758215561509132
Loss at batch 360 : 0.008671720512211323
Loss at batch 370 : 0.01336743962019682
epoch73 finished!
Loss at batch 10 : 0.009972208179533482
Loss at batch 20 : 0.010052868165075779
Loss at batch 30 : 0.009235857054591179
Loss at batch 40 : 0.010196499526500702
Loss at batch 50 : 0.010928190313279629
Loss at batch 60 : 0.013314024545252323
Loss at batch 70 : 0.011095206253230572
Loss at batch 80 : 0.020689086988568306
Loss at batch 90 : 0.016552938148379326
Loss at batch 100 : 0.012386738322675228
Loss at batch 110 : 0.024382570758461952
Loss at batch 120 : 0.013763993047177792
Loss at batch 130 : 0.01273124199360609
Loss at batch 140 : 0.012144171632826328
Loss at batch 150 : 0.013904565945267677
Loss at batch 160 : 0.01528678648173809
Loss at batch 170 : 0.012077893130481243
Loss at batch 180 : 0.022433994337916374
Loss at batch 190 : 0.03743093088269234
Loss at batch 200 : 0.014329133555293083
Loss at batch 210 : 0.021394478157162666
Loss at batch 220 : 0.014106477610766888
Loss at batch 230 : 0.013919999822974205
Loss at batch 240 : 0.011616691946983337
Loss at batch 250 : 0.013345343992114067
Loss at batch 260 : 0.012007190845906734
Loss at batch 270 : 0.017015142366290092
Loss at batch 280 : 0.018483063206076622
Loss at batch 290 : 0.01071759220212698
Loss at batch 300 : 0.011520166881382465
Loss at batch 310 : 0.012725898064672947
Loss at batch 320 : 0.017068201676011086
Loss at batch 330 : 0.007645066827535629
Loss at batch 340 : 0.012204831466078758
Loss at batch 350 : 0.016515295952558517
Loss at batch 360 : 0.03471479192376137
Loss at batch 370 : 0.02685360424220562
epoch161 finished!
Loss at batch 10 : 0.014809668995440006
Loss at batch 20 : 0.01710600219666958
Loss at batch 30 : 0.011204835958778858
Loss at batch 40 : 0.012044781818985939
Loss at batch 50 : 0.016428815200924873
Loss at batch 60 : 0.01006240677088499
Loss at batch 70 : 0.011320660822093487
Loss at batch 80 : 0.0084587587043643
Loss at batch 90 : 0.00878636073321104
Loss at batch 100 : 0.024211984127759933
Loss at batch 110 : 0.015496774576604366
Loss at batch 120 : 0.016252141445875168
Loss at batch 130 : 0.018375065177679062
Loss at batch 140 : 0.012544088996946812
Loss at batch 150 : 0.012103715911507607
Loss at batch 160 : 0.011161853559315205
Loss at batch 170 : 0.007692592218518257
Loss at batch 180 : 0.01367027498781681
Loss at batch 190 : 0.008198481053113937
Loss at batch 200 : 0.012636988423764706
Loss at batch 210 : 0.012785280123353004
Loss at batch 220 : 0.008150315843522549
Loss at batch 230 : 0.007342603988945484
Loss at batch 240 : 0.010931640863418579
Loss at batch 250 : 0.010547034442424774
Loss at batch 260 : 0.008808051235973835
Loss at batch 270 : 0.017082292586565018
Loss at batch 280 : 0.009445528499782085
Loss at batch 290 : 0.008871443569660187
Loss at batch 300 : 0.009333202615380287
Loss at batch 310 : 0.015774810686707497
Loss at batch 320 : 0.013377579860389233
Loss at batch 330 : 0.018644919618964195
Loss at batch 340 : 0.016580907627940178
Loss at batch 350 : 0.02395503595471382
Loss at batch 360 : 0.008717818185687065
Loss at batch 370 : 0.013453016988933086
epoch162 finished!
Loss at batch 10 : 0.011996165849268436
Loss at batch 20 : 0.015834465622901917
Loss at batch 30 : 0.016341863200068474
Loss at batch 40 : 0.02178730070590973
Loss at batch 50 : 0.010683310218155384
Loss at batch 60 : 0.013132737949490547
Loss at batch 70 : 0.012939618900418282
Loss at batch 80 : 0.011932500638067722
Loss at batch 90 : 0.01543662790209055
Loss at batch 100 : 0.015127738006412983
Loss at batch 110 : 0.011710804887115955
Loss at batch 120 : 0.015902606770396233
Loss at batch 130 : 0.013042335398495197
Loss at batch 140 : 0.011846973560750484
Loss at batch 150 : 0.02547328546643257
Loss at batch 160 : 0.016390515491366386
Loss at batch 170 : 0.02454974688589573
Loss at batch 180 : 0.01839185506105423
Loss at batch 190 : 0.016186140477657318
Loss at batch 200 : 0.008900989778339863
Loss at batch 210 : 0.021358782425522804
Loss at batch 220 : 0.013122111558914185
Loss at batch 230 : 0.01580456830561161
Loss at batch 240 : 0.008281675167381763
Loss at batch 250 : 0.011300447396934032
Loss at batch 260 : 0.018846480175852776
Loss at batch 270 : 0.008781109005212784
Loss at batch 280 : 0.016847867518663406
Loss at batch 290 : 0.007952621206641197
Loss at batch 300 : 0.01063158456236124
Loss at batch 310 : 0.0170905701816082
Loss at batch 320 : 0.01320119109004736
Loss at batch 330 : 0.010068732313811779
Loss at batch 340 : 0.015402653254568577
Loss at batch 350 : 0.013161951676011086
Loss at batch 360 : 0.011942215263843536
Loss at batch 370 : 0.031634457409381866
epoch74 finished!
Loss at batch 10 : 0.013292043469846249
Loss at batch 20 : 0.009875772520899773
Loss at batch 30 : 0.013240701518952847
Loss at batch 40 : 0.017459915950894356
Loss at batch 50 : 0.018438829109072685
Loss at batch 60 : 0.008886922150850296
Loss at batch 70 : 0.015544194728136063
Loss at batch 80 : 0.017228925600647926
Loss at batch 90 : 0.010905096307396889
Loss at batch 100 : 0.0169904213398695
Loss at batch 110 : 0.01347716711461544
Loss at batch 120 : 0.008344796486198902
Loss at batch 130 : 0.009481220506131649
Loss at batch 140 : 0.01915900781750679
Loss at batch 150 : 0.013952030800282955
Loss at batch 160 : 0.012404907494783401
Loss at batch 170 : 0.010222486220300198
Loss at batch 180 : 0.015396514907479286
Loss at batch 190 : 0.014294062741100788
Loss at batch 200 : 0.018410569056868553
Loss at batch 210 : 0.011782074347138405
Loss at batch 220 : 0.017235562205314636
Loss at batch 230 : 0.016651729121804237
Loss at batch 240 : 0.008626861497759819
Loss at batch 250 : 0.014339173212647438
Loss at batch 260 : 0.012908988632261753
Loss at batch 270 : 0.006015040446072817
Loss at batch 280 : 0.008195816539227962
Loss at batch 290 : 0.016966592520475388
Loss at batch 300 : 0.010110020637512207
Loss at batch 310 : 0.022906113415956497
Loss at batch 320 : 0.015771327540278435
Loss at batch 330 : 0.01217591855674982
Loss at batch 340 : 0.010362682864069939
Loss at batch 350 : 0.023021601140499115
Loss at batch 360 : 0.011287863366305828
Loss at batch 370 : 0.017305253073573112
epoch74 finished!
Loss at batch 10 : 0.019393328577280045
Loss at batch 20 : 0.01588914729654789
Loss at batch 30 : 0.02285235933959484
Loss at batch 40 : 0.019618216902017593
Loss at batch 50 : 0.012562672607600689
Loss at batch 60 : 0.00948654767125845
Loss at batch 70 : 0.025861114263534546
Loss at batch 80 : 0.013889782130718231
Loss at batch 90 : 0.007177743129432201
Loss at batch 100 : 0.007571697235107422
Loss at batch 110 : 0.014636393636465073
Loss at batch 120 : 0.014056994579732418
Loss at batch 130 : 0.01470023300498724
Loss at batch 140 : 0.010038903914391994
Loss at batch 150 : 0.013785186223685741
Loss at batch 160 : 0.015396330505609512
Loss at batch 170 : 0.010841792449355125
Loss at batch 180 : 0.010916362516582012
Loss at batch 190 : 0.01969214342534542
Loss at batch 200 : 0.007169817108660936
Loss at batch 210 : 0.01187229435890913
Loss at batch 220 : 0.01819680631160736
Loss at batch 230 : 0.01207104790955782
Loss at batch 240 : 0.013435527682304382
Loss at batch 250 : 0.015877794474363327
Loss at batch 260 : 0.010895305313169956
Loss at batch 270 : 0.011072058230638504
Loss at batch 280 : 0.00972569640725851
Loss at batch 290 : 0.013265547342598438
Loss at batch 300 : 0.01600329577922821
Loss at batch 310 : 0.010896170511841774
Loss at batch 320 : 0.018392760306596756
Loss at batch 330 : 0.008974124677479267
Loss at batch 340 : 0.015032882802188396
Loss at batch 350 : 0.01282731257379055
Loss at batch 360 : 0.009543071500957012
Loss at batch 370 : 0.022478653118014336
epoch163 finished!
Loss at batch 10 : 0.012915910221636295
Loss at batch 20 : 0.02469046600162983
Loss at batch 30 : 0.015635285526514053
Loss at batch 40 : 0.014055895619094372
Loss at batch 50 : 0.01303689181804657
Loss at batch 60 : 0.016424309462308884
Loss at batch 70 : 0.011208218522369862
Loss at batch 80 : 0.008490434847772121
Loss at batch 90 : 0.01798800192773342
Loss at batch 100 : 0.02369389496743679
Loss at batch 110 : 0.023963622748851776
Loss at batch 120 : 0.013757146894931793
Loss at batch 130 : 0.01961011067032814
Loss at batch 140 : 0.00974756944924593
Loss at batch 150 : 0.013699161820113659
Loss at batch 160 : 0.010812466032803059
Loss at batch 170 : 0.010811121203005314
Loss at batch 180 : 0.014170569367706776
Loss at batch 190 : 0.016404451802372932
Loss at batch 200 : 0.020455509424209595
Loss at batch 210 : 0.009662460535764694
Loss at batch 220 : 0.016892272979021072
Loss at batch 230 : 0.027433527633547783
Loss at batch 240 : 0.008000573143362999
Loss at batch 250 : 0.008406562730669975
Loss at batch 260 : 0.014122740365564823
Loss at batch 270 : 0.010085901245474815
Loss at batch 280 : 0.008794065564870834
Loss at batch 290 : 0.00859716348350048
Loss at batch 300 : 0.009982611984014511
Loss at batch 310 : 0.015055614523589611
Loss at batch 320 : 0.015681320801377296
Loss at batch 330 : 0.017538901418447495
Loss at batch 340 : 0.011403455398976803
Loss at batch 350 : 0.013400088995695114
Loss at batch 360 : 0.020794615149497986
Loss at batch 370 : 0.011229579336941242
epoch164 finished!
Loss at batch 10 : 0.01876007206737995
Loss at batch 20 : 0.014232776127755642
Loss at batch 30 : 0.010526827536523342
Loss at batch 40 : 0.009115364402532578
Loss at batch 50 : 0.012296643108129501
Loss at batch 60 : 0.014466146007180214
Loss at batch 70 : 0.011814046651124954
Loss at batch 80 : 0.014999141916632652
Loss at batch 90 : 0.03029748797416687
Loss at batch 100 : 0.011617762967944145
Loss at batch 110 : 0.010944871231913567
Loss at batch 120 : 0.01131382118910551
Loss at batch 130 : 0.019589293748140335
Loss at batch 140 : 0.018070390447974205
Loss at batch 150 : 0.01890849508345127
Loss at batch 160 : 0.01512104831635952
Loss at batch 170 : 0.009722854010760784
Loss at batch 180 : 0.011328477412462234
Loss at batch 190 : 0.00946973916143179
Loss at batch 200 : 0.02078031748533249
Loss at batch 210 : 0.01382361352443695
Loss at batch 220 : 0.021133791655302048
Loss at batch 230 : 0.009874252602458
Loss at batch 240 : 0.01414397731423378
Loss at batch 250 : 0.010982867330312729
Loss at batch 260 : 0.012556680478155613
Loss at batch 270 : 0.02023903839290142
Loss at batch 280 : 0.020157473161816597
Loss at batch 290 : 0.01209167204797268
Loss at batch 300 : 0.01466043945401907
Loss at batch 310 : 0.01850411482155323
Loss at batch 320 : 0.009858174249529839
Loss at batch 330 : 0.015708239749073982
Loss at batch 340 : 0.010393732227385044
Loss at batch 350 : 0.013589511625468731
Loss at batch 360 : 0.010321141220629215
Loss at batch 370 : 0.014997798018157482
epoch75 finished!
Loss at batch 10 : 0.021134890615940094
Loss at batch 20 : 0.02385488711297512
Loss at batch 30 : 0.020448461174964905
Loss at batch 40 : 0.009976175613701344
Loss at batch 50 : 0.015301342122256756
Loss at batch 60 : 0.013497388921678066
Loss at batch 70 : 0.01579044573009014
Loss at batch 80 : 0.01355354767292738
Loss at batch 90 : 0.015277983620762825
Loss at batch 100 : 0.01197253167629242
Loss at batch 110 : 0.010385981760919094
Loss at batch 120 : 0.01651977002620697
Loss at batch 130 : 0.01665753684937954
Loss at batch 140 : 0.010867872275412083
Loss at batch 150 : 0.009108281694352627
Loss at batch 160 : 0.01049222331494093
Loss at batch 170 : 0.012310177087783813
Loss at batch 180 : 0.014277583919465542
Loss at batch 190 : 0.015475770458579063
Loss at batch 200 : 0.014619833789765835
Loss at batch 210 : 0.01660558395087719
Loss at batch 220 : 0.013143529184162617
Loss at batch 230 : 0.008730120025575161
Loss at batch 240 : 0.0130091467872262
Loss at batch 250 : 0.008389892987906933
Loss at batch 260 : 0.027351396158337593
Loss at batch 270 : 0.013408097438514233
Loss at batch 280 : 0.009211672469973564
Loss at batch 290 : 0.009291864931583405
Loss at batch 300 : 0.011702876538038254
Loss at batch 310 : 0.012558842077851295
Loss at batch 320 : 0.01797083579003811
Loss at batch 330 : 0.023437000811100006
Loss at batch 340 : 0.011247077956795692
Loss at batch 350 : 0.008538598194718361
Loss at batch 360 : 0.01865369826555252
Loss at batch 370 : 0.01635540835559368
epoch165 finished!
Loss at batch 10 : 0.01443580910563469
Loss at batch 20 : 0.025333600118756294
Loss at batch 30 : 0.01629060134291649
Loss at batch 40 : 0.01475303340703249
Loss at batch 50 : 0.01181792002171278
Loss at batch 60 : 0.013800416141748428
Loss at batch 70 : 0.03478064388036728
Loss at batch 80 : 0.01409001462161541
Loss at batch 90 : 0.014166278764605522
Loss at batch 100 : 0.015417955815792084
Loss at batch 110 : 0.013271228410303593
Loss at batch 120 : 0.02589367888867855
Loss at batch 130 : 0.012631005607545376
Loss at batch 140 : 0.009023098275065422
Loss at batch 150 : 0.009757193736732006
Loss at batch 160 : 0.008571929298341274
Loss at batch 170 : 0.011030644178390503
Loss at batch 180 : 0.015471351332962513
Loss at batch 190 : 0.013140142895281315
Loss at batch 200 : 0.009965012781322002
Loss at batch 210 : 0.0203840434551239
Loss at batch 220 : 0.011875920929014683
Loss at batch 230 : 0.009296903386712074
Loss at batch 240 : 0.009023604914546013
Loss at batch 250 : 0.012759406119585037
Loss at batch 260 : 0.011469191871583462
Loss at batch 270 : 0.027727847918868065
Loss at batch 280 : 0.01163930632174015
Loss at batch 290 : 0.015916569158434868
Loss at batch 300 : 0.012952292338013649
Loss at batch 310 : 0.010639856569468975
Loss at batch 320 : 0.013257470913231373
Loss at batch 330 : 0.012570911087095737
Loss at batch 340 : 0.0164702869951725
Loss at batch 350 : 0.017479656264185905
Loss at batch 360 : 0.01792418211698532
Loss at batch 370 : 0.027973730117082596
epoch75 finished!
Loss at batch 10 : 0.01153205893933773
Loss at batch 20 : 0.012591111473739147
Loss at batch 30 : 0.017155887559056282
Loss at batch 40 : 0.014323865063488483
Loss at batch 50 : 0.02159346453845501
Loss at batch 60 : 0.01457085832953453
Loss at batch 70 : 0.016089962795376778
Loss at batch 80 : 0.015216747298836708
Loss at batch 90 : 0.007070387247949839
Loss at batch 100 : 0.020615601912140846
Loss at batch 110 : 0.007401708047837019
Loss at batch 120 : 0.014874896965920925
Loss at batch 130 : 0.015485640615224838
Loss at batch 140 : 0.014820324257016182
Loss at batch 150 : 0.01448038313537836
Loss at batch 160 : 0.01806594245135784
Loss at batch 170 : 0.015546409413218498
Loss at batch 180 : 0.01578175462782383
Loss at batch 190 : 0.010650028474628925
Loss at batch 200 : 0.012422183528542519
Loss at batch 210 : 0.018509088084101677
Loss at batch 220 : 0.02230260521173477
Loss at batch 230 : 0.012121831998229027
Loss at batch 240 : 0.015539398416876793
Loss at batch 250 : 0.020628761500120163
Loss at batch 260 : 0.00714458804577589
Loss at batch 270 : 0.017021095380187035
Loss at batch 280 : 0.009594041854143143
Loss at batch 290 : 0.00994773767888546
Loss at batch 300 : 0.011982975527644157
Loss at batch 310 : 0.013953630812466145
Loss at batch 320 : 0.00985717587172985
Loss at batch 330 : 0.011642055585980415
Loss at batch 340 : 0.010646076872944832
Loss at batch 350 : 0.009272264316678047
Loss at batch 360 : 0.01736762933433056
Loss at batch 370 : 0.011253014206886292
epoch166 finished!
Loss at batch 10 : 0.01049004029482603
Loss at batch 20 : 0.010515347123146057
Loss at batch 30 : 0.013898608274757862
Loss at batch 40 : 0.010517156682908535
Loss at batch 50 : 0.013412467204034328
Loss at batch 60 : 0.010098853148519993
Loss at batch 70 : 0.01336166076362133
Loss at batch 80 : 0.012192906811833382
Loss at batch 90 : 0.01850835047662258
Loss at batch 100 : 0.015164756216108799
Loss at batch 110 : 0.013509286567568779
Loss at batch 120 : 0.015128007158637047
Loss at batch 130 : 0.022137625142931938
Loss at batch 140 : 0.015014875680208206
Loss at batch 150 : 0.010019605979323387
Loss at batch 160 : 0.019736705347895622
Loss at batch 170 : 0.008564810268580914
Loss at batch 180 : 0.008609998039901257
Loss at batch 190 : 0.010890640318393707
Loss at batch 200 : 0.011410774663090706
Loss at batch 210 : 0.01779722422361374
Loss at batch 220 : 0.034192636609077454
Loss at batch 230 : 0.012588467448949814
Loss at batch 240 : 0.012908910401165485
Loss at batch 250 : 0.012301038019359112
Loss at batch 260 : 0.018579598516225815
Loss at batch 270 : 0.016054270789027214
Loss at batch 280 : 0.012370037846267223
Loss at batch 290 : 0.006540151312947273
Loss at batch 300 : 0.015063383616507053
Loss at batch 310 : 0.009669441729784012
Loss at batch 320 : 0.010481326840817928
Loss at batch 330 : 0.013253525830805302
Loss at batch 340 : 0.02310113236308098
Loss at batch 350 : 0.015096682123839855
Loss at batch 360 : 0.020460719242691994
Loss at batch 370 : 0.009088424034416676
epoch167 finished!
Loss at batch 10 : 0.011322321370244026
Loss at batch 20 : 0.00935441441833973
Loss at batch 30 : 0.014724520966410637
Loss at batch 40 : 0.008982643485069275
Loss at batch 50 : 0.00775825884193182
Loss at batch 60 : 0.02092846855521202
Loss at batch 70 : 0.01818211004137993
Loss at batch 80 : 0.012199453078210354
Loss at batch 90 : 0.013236822560429573
Loss at batch 100 : 0.020398538559675217
Loss at batch 110 : 0.012618823908269405
Loss at batch 120 : 0.015002868138253689
Loss at batch 130 : 0.012249027378857136
Loss at batch 140 : 0.020794151350855827
Loss at batch 150 : 0.01581866480410099
Loss at batch 160 : 0.005232291296124458
Loss at batch 170 : 0.014448168687522411
Loss at batch 180 : 0.00808196421712637
Loss at batch 190 : 0.021814728155732155
Loss at batch 200 : 0.015310890041291714
Loss at batch 210 : 0.008545014075934887
Loss at batch 220 : 0.00833798386156559
Loss at batch 230 : 0.013354193419218063
Loss at batch 240 : 0.014301145449280739
Loss at batch 250 : 0.016297154128551483
Loss at batch 260 : 0.01565840095281601
Loss at batch 270 : 0.00949722621589899
Loss at batch 280 : 0.007350357249379158
Loss at batch 290 : 0.0161364134401083
Loss at batch 300 : 0.009484994225203991
Loss at batch 310 : 0.01018794160336256
Loss at batch 320 : 0.011482630856335163
Loss at batch 330 : 0.014164257794618607
Loss at batch 340 : 0.014580568298697472
Loss at batch 350 : 0.010282281786203384
Loss at batch 360 : 0.013445855118334293
Loss at batch 370 : 0.0122012197971344
epoch76 finished!
Loss at batch 10 : 0.010197009891271591
Loss at batch 20 : 0.016997385770082474
Loss at batch 30 : 0.0080857640132308
Loss at batch 40 : 0.010788822546601295
Loss at batch 50 : 0.01795058138668537
Loss at batch 60 : 0.021628791466355324
Loss at batch 70 : 0.01086161658167839
Loss at batch 80 : 0.007594584953039885
Loss at batch 90 : 0.016551636159420013
Loss at batch 100 : 0.01826818846166134
Loss at batch 110 : 0.013995062559843063
Loss at batch 120 : 0.012917054817080498
Loss at batch 130 : 0.013855771161615849
Loss at batch 140 : 0.013735216110944748
Loss at batch 150 : 0.016699254512786865
Loss at batch 160 : 0.011290722526609898
Loss at batch 170 : 0.014531602151691914
Loss at batch 180 : 0.011549700982868671
Loss at batch 190 : 0.009270276874303818
Loss at batch 200 : 0.012565664947032928
Loss at batch 210 : 0.012711744755506516
Loss at batch 220 : 0.023876797407865524
Loss at batch 230 : 0.013525101356208324
Loss at batch 240 : 0.02729176916182041
Loss at batch 250 : 0.010647824965417385
Loss at batch 260 : 0.012237368151545525
Loss at batch 270 : 0.014801360666751862
Loss at batch 280 : 0.01762472838163376
Loss at batch 290 : 0.019707251340150833
Loss at batch 300 : 0.011041148565709591
Loss at batch 310 : 0.01963121071457863
Loss at batch 320 : 0.014322501607239246
Loss at batch 330 : 0.007826266810297966
Loss at batch 340 : 0.021355994045734406
Loss at batch 350 : 0.018128927797079086
Loss at batch 360 : 0.01813962310552597
Loss at batch 370 : 0.02032553218305111
epoch76 finished!
Loss at batch 10 : 0.013526130467653275
Loss at batch 20 : 0.010537181049585342
Loss at batch 30 : 0.008696426637470722
Loss at batch 40 : 0.012023968622088432
Loss at batch 50 : 0.01635436899960041
Loss at batch 60 : 0.016609368845820427
Loss at batch 70 : 0.02557639218866825
Loss at batch 80 : 0.012485348619520664
Loss at batch 90 : 0.01236636657267809
Loss at batch 100 : 0.00937446765601635
Loss at batch 110 : 0.012588546611368656
Loss at batch 120 : 0.01754659041762352
Loss at batch 130 : 0.016857780516147614
Loss at batch 140 : 0.015100663527846336
Loss at batch 150 : 0.00793776661157608
Loss at batch 160 : 0.008138064295053482
Loss at batch 170 : 0.01766986958682537
Loss at batch 180 : 0.012339620850980282
Loss at batch 190 : 0.010500219650566578
Loss at batch 200 : 0.010641261003911495
Loss at batch 210 : 0.012660232372581959
Loss at batch 220 : 0.01189245656132698
Loss at batch 230 : 0.011522220447659492
Loss at batch 240 : 0.015548937022686005
Loss at batch 250 : 0.02268860675394535
Loss at batch 260 : 0.025413542985916138
Loss at batch 270 : 0.018587706610560417
Loss at batch 280 : 0.010014219209551811
Loss at batch 290 : 0.009119742549955845
Loss at batch 300 : 0.00710943853482604
Loss at batch 310 : 0.016573956236243248
Loss at batch 320 : 0.01605946384370327
Loss at batch 330 : 0.007790160831063986
Loss at batch 340 : 0.011619037948548794
Loss at batch 350 : 0.014712797477841377
Loss at batch 360 : 0.011025738902390003
Loss at batch 370 : 0.014290000312030315
epoch168 finished!
Loss at batch 10 : 0.021809294819831848
Loss at batch 20 : 0.008092685602605343
Loss at batch 30 : 0.013094143941998482
Loss at batch 40 : 0.015355994924902916
Loss at batch 50 : 0.009820487350225449
Loss at batch 60 : 0.010176151990890503
Loss at batch 70 : 0.009719094261527061
Loss at batch 80 : 0.016341812908649445
Loss at batch 90 : 0.01255788840353489
Loss at batch 100 : 0.009717383421957493
Loss at batch 110 : 0.01495940238237381
Loss at batch 120 : 0.00783261377364397
Loss at batch 130 : 0.015146213583648205
Loss at batch 140 : 0.010048972442746162
Loss at batch 150 : 0.011722022667527199
Loss at batch 160 : 0.01796364225447178
Loss at batch 170 : 0.016673432663083076
Loss at batch 180 : 0.007881916128098965
Loss at batch 190 : 0.009813359938561916
Loss at batch 200 : 0.013046697713434696
Loss at batch 210 : 0.0117078498005867
Loss at batch 220 : 0.02095060981810093
Loss at batch 230 : 0.015342199243605137
Loss at batch 240 : 0.021927108988165855
Loss at batch 250 : 0.01849224604666233
Loss at batch 260 : 0.02114115096628666
Loss at batch 270 : 0.018546514213085175
Loss at batch 280 : 0.013105100952088833
Loss at batch 290 : 0.009802485816180706
Loss at batch 300 : 0.014888237230479717
Loss at batch 310 : 0.010751097463071346
Loss at batch 320 : 0.024027887731790543
Loss at batch 330 : 0.019961386919021606
Loss at batch 340 : 0.01124314684420824
Loss at batch 350 : 0.013361899182200432
Loss at batch 360 : 0.024685299023985863
Loss at batch 370 : 0.009077809751033783
epoch169 finished!
Loss at batch 10 : 0.009644702076911926
Loss at batch 20 : 0.012227294035255909
Loss at batch 30 : 0.024106107652187347
Loss at batch 40 : 0.02457684837281704
Loss at batch 50 : 0.010300382040441036
Loss at batch 60 : 0.029729051515460014
Loss at batch 70 : 0.010469344444572926
Loss at batch 80 : 0.015581660903990269
Loss at batch 90 : 0.017137672752141953
Loss at batch 100 : 0.015273954719305038
Loss at batch 110 : 0.009344544261693954
Loss at batch 120 : 0.016580112278461456
Loss at batch 130 : 0.017926881089806557
Loss at batch 140 : 0.011385983787477016
Loss at batch 150 : 0.009658976458013058
Loss at batch 160 : 0.014826851896941662
Loss at batch 170 : 0.022752778604626656
Loss at batch 180 : 0.011507146060466766
Loss at batch 190 : 0.010914972051978111
Loss at batch 200 : 0.026205072179436684
Loss at batch 210 : 0.017392544075846672
Loss at batch 220 : 0.011140447109937668
Loss at batch 230 : 0.009033726528286934
Loss at batch 240 : 0.013811838813126087
Loss at batch 250 : 0.007992311380803585
Loss at batch 260 : 0.01560291089117527
Loss at batch 270 : 0.013279321603477001
Loss at batch 280 : 0.02053825370967388
Loss at batch 290 : 0.01371044386178255
Loss at batch 300 : 0.012053197249770164
Loss at batch 310 : 0.022797221317887306
Loss at batch 320 : 0.016079606488347054
Loss at batch 330 : 0.014886043034493923
Loss at batch 340 : 0.009551918134093285
Loss at batch 350 : 0.015822891145944595
Loss at batch 360 : 0.01264915894716978
Loss at batch 370 : 0.029317496344447136
epoch77 finished!
Loss at batch 10 : 0.02124439738690853
Loss at batch 20 : 0.017615340650081635
Loss at batch 30 : 0.01051432453095913
Loss at batch 40 : 0.016773773357272148
Loss at batch 50 : 0.009318518452346325
Loss at batch 60 : 0.018221499398350716
Loss at batch 70 : 0.01623154617846012
Loss at batch 80 : 0.006974013987928629
Loss at batch 90 : 0.013183146715164185
Loss at batch 100 : 0.013993608765304089
Loss at batch 110 : 0.01958872191607952
Loss at batch 120 : 0.013442682102322578
Loss at batch 130 : 0.019109409302473068
Loss at batch 140 : 0.013853581622242928
Loss at batch 150 : 0.018278716132044792
Loss at batch 160 : 0.014024676755070686
Loss at batch 170 : 0.016358114778995514
Loss at batch 180 : 0.01619119755923748
Loss at batch 190 : 0.013525170274078846
Loss at batch 200 : 0.017516620457172394
Loss at batch 210 : 0.01236947625875473
Loss at batch 220 : 0.01562652364373207
Loss at batch 230 : 0.011158376932144165
Loss at batch 240 : 0.008067892864346504
Loss at batch 250 : 0.010573014616966248
Loss at batch 260 : 0.01731102354824543
Loss at batch 270 : 0.012169980444014072
Loss at batch 280 : 0.019410431385040283
Loss at batch 290 : 0.02374097891151905
Loss at batch 300 : 0.011970126070082188
Loss at batch 310 : 0.012511618435382843
Loss at batch 320 : 0.009530836716294289
Loss at batch 330 : 0.012367052026093006
Loss at batch 340 : 0.008714583702385426
Loss at batch 350 : 0.011579702608287334
Loss at batch 360 : 0.013354388996958733
Loss at batch 370 : 0.01606985554099083
epoch77 finished!
Loss at batch 10 : 0.011453744024038315
Loss at batch 20 : 0.015493561513721943
Loss at batch 30 : 0.01185678318142891
Loss at batch 40 : 0.01170158851891756
Loss at batch 50 : 0.020345419645309448
Loss at batch 60 : 0.010138043202459812
Loss at batch 70 : 0.014603878371417522
Loss at batch 80 : 0.015501245856285095
Loss at batch 90 : 0.00775093724951148
Loss at batch 100 : 0.016876868903636932
Loss at batch 110 : 0.013845240697264671
Loss at batch 120 : 0.012409507296979427
Loss at batch 130 : 0.01383406575769186
Loss at batch 140 : 0.014784818515181541
Loss at batch 150 : 0.025158939883112907
Loss at batch 160 : 0.018241820856928825
Loss at batch 170 : 0.017568059265613556
Loss at batch 180 : 0.019461793825030327
Loss at batch 190 : 0.024549713358283043
Loss at batch 200 : 0.016140712425112724
Loss at batch 210 : 0.011579928919672966
Loss at batch 220 : 0.011760194785892963
Loss at batch 230 : 0.022593528032302856
Loss at batch 240 : 0.021853256970643997
Loss at batch 250 : 0.008770482614636421
Loss at batch 260 : 0.011702329851686954
Loss at batch 270 : 0.009055458009243011
Loss at batch 280 : 0.009350275620818138
Loss at batch 290 : 0.012581763789057732
Loss at batch 300 : 0.014215389266610146
Loss at batch 310 : 0.008064736612141132
Loss at batch 320 : 0.01081426627933979
Loss at batch 330 : 0.014106765389442444
Loss at batch 340 : 0.02019537426531315
Loss at batch 350 : 0.008494422771036625
Loss at batch 360 : 0.010451632551848888
Loss at batch 370 : 0.013305705040693283
epoch170 finished!
Loss at batch 10 : 0.019545674324035645
Loss at batch 20 : 0.013665851205587387
Loss at batch 30 : 0.013240699656307697
Loss at batch 40 : 0.013496790081262589
Loss at batch 50 : 0.010647241026163101
Loss at batch 60 : 0.013857778161764145
Loss at batch 70 : 0.01223466545343399
Loss at batch 80 : 0.01721280626952648
Loss at batch 90 : 0.025797836482524872
Loss at batch 100 : 0.01322387345135212
Loss at batch 110 : 0.020066775381565094
Loss at batch 120 : 0.015210215002298355
Loss at batch 130 : 0.016889311373233795
Loss at batch 140 : 0.019236180931329727
Loss at batch 150 : 0.00741848349571228
Loss at batch 160 : 0.009458175860345364
Loss at batch 170 : 0.011394736357033253
Loss at batch 180 : 0.014566775411367416
Loss at batch 190 : 0.016738900914788246
Loss at batch 200 : 0.017433518543839455
Loss at batch 210 : 0.011069298721849918
Loss at batch 220 : 0.012620685622096062
Loss at batch 230 : 0.014544797129929066
Loss at batch 240 : 0.004020150285214186
Loss at batch 250 : 0.011401149444282055
Loss at batch 260 : 0.008169412612915039
Loss at batch 270 : 0.01936914026737213
Loss at batch 280 : 0.010685643181204796
Loss at batch 290 : 0.022584203630685806
Loss at batch 300 : 0.01687674969434738
Loss at batch 310 : 0.015043234452605247
Loss at batch 320 : 0.011316376738250256
Loss at batch 330 : 0.01378888450562954
Loss at batch 340 : 0.009917229413986206
Loss at batch 350 : 0.012725615873932838
Loss at batch 360 : 0.013248189352452755
Loss at batch 370 : 0.01165186706930399
epoch171 finished!
Loss at batch 10 : 0.01118745282292366
Loss at batch 20 : 0.015316770412027836
Loss at batch 30 : 0.014834499917924404
Loss at batch 40 : 0.023225093260407448
Loss at batch 50 : 0.016043255105614662
Loss at batch 60 : 0.010476987808942795
Loss at batch 70 : 0.007505354471504688
Loss at batch 80 : 0.013600494712591171
Loss at batch 90 : 0.010175254195928574
Loss at batch 100 : 0.01623060181736946
Loss at batch 110 : 0.012580309994518757
Loss at batch 120 : 0.01087348721921444
Loss at batch 130 : 0.015856409445405006
Loss at batch 140 : 0.011146767064929008
Loss at batch 150 : 0.012304629199206829
Loss at batch 160 : 0.014512753114104271
Loss at batch 170 : 0.012689639814198017
Loss at batch 180 : 0.015412122942507267
Loss at batch 190 : 0.017974883317947388
Loss at batch 200 : 0.011821219697594643
Loss at batch 210 : 0.011009497568011284
Loss at batch 220 : 0.008871739730238914
Loss at batch 230 : 0.018801486119627953
Loss at batch 240 : 0.018356146290898323
Loss at batch 250 : 0.020284106954932213
Loss at batch 260 : 0.02499985508620739
Loss at batch 270 : 0.010921577922999859
Loss at batch 280 : 0.013779238797724247
Loss at batch 290 : 0.01369672641158104
Loss at batch 300 : 0.017916174605488777
Loss at batch 310 : 0.011339832097291946
Loss at batch 320 : 0.022265659645199776
Loss at batch 330 : 0.01319698803126812
Loss at batch 340 : 0.008805290795862675
Loss at batch 350 : 0.010779161006212234
Loss at batch 360 : 0.021080631762742996
Loss at batch 370 : 0.014469066634774208
epoch78 finished!
Loss at batch 10 : 0.008470878005027771
Loss at batch 20 : 0.022239742800593376
Loss at batch 30 : 0.020429393276572227
Loss at batch 40 : 0.02047722041606903
Loss at batch 50 : 0.015730291604995728
Loss at batch 60 : 0.011561119928956032
Loss at batch 70 : 0.010695543140172958
Loss at batch 80 : 0.011168116703629494
Loss at batch 90 : 0.0071981134824454784
Loss at batch 100 : 0.007187121547758579
Loss at batch 110 : 0.007690625265240669
Loss at batch 120 : 0.012950342148542404
Loss at batch 130 : 0.008220522664487362
Loss at batch 140 : 0.015234837308526039
Loss at batch 150 : 0.022521913051605225
Loss at batch 160 : 0.010650532320141792
Loss at batch 170 : 0.013157472014427185
Loss at batch 180 : 0.023589974269270897
Loss at batch 190 : 0.014991529285907745
Loss at batch 200 : 0.014047544449567795
Loss at batch 210 : 0.01692068576812744
Loss at batch 220 : 0.008825676515698433
Loss at batch 230 : 0.017087046056985855
Loss at batch 240 : 0.02341117151081562
Loss at batch 250 : 0.018651526421308517
Loss at batch 260 : 0.018131788820028305
Loss at batch 270 : 0.011500378139317036
Loss at batch 280 : 0.013879260048270226
Loss at batch 290 : 0.011957943439483643
Loss at batch 300 : 0.018565436825156212
Loss at batch 310 : 0.021469371393322945
Loss at batch 320 : 0.009969042614102364
Loss at batch 330 : 0.0166392270475626
Loss at batch 340 : 0.007463899441063404
Loss at batch 350 : 0.010586336255073547
Loss at batch 360 : 0.005655456800013781
Loss at batch 370 : 0.011667122133076191
epoch78 finished!
Loss at batch 10 : 0.013259010389447212
Loss at batch 20 : 0.017343392595648766
Loss at batch 30 : 0.017742346972227097
Loss at batch 40 : 0.0058662258088588715
Loss at batch 50 : 0.011736974120140076
Loss at batch 60 : 0.01912996731698513
Loss at batch 70 : 0.015110492706298828
Loss at batch 80 : 0.01734982803463936
Loss at batch 90 : 0.01538581121712923
Loss at batch 100 : 0.02122369594871998
Loss at batch 110 : 0.013481288217008114
Loss at batch 120 : 0.021958885714411736
Loss at batch 130 : 0.014665915630757809
Loss at batch 140 : 0.016657941043376923
Loss at batch 150 : 0.013635791838169098
Loss at batch 160 : 0.014018818736076355
Loss at batch 170 : 0.01802930235862732
Loss at batch 180 : 0.009198695421218872
Loss at batch 190 : 0.011242754757404327
Loss at batch 200 : 0.011157640255987644
Loss at batch 210 : 0.016167793422937393
Loss at batch 220 : 0.021403253078460693
Loss at batch 230 : 0.021363552659749985
Loss at batch 240 : 0.007890705950558186
Loss at batch 250 : 0.018087057396769524
Loss at batch 260 : 0.0071844058111310005
Loss at batch 270 : 0.015324209816753864
Loss at batch 280 : 0.014753871597349644
Loss at batch 290 : 0.009004575200378895
Loss at batch 300 : 0.019287945702672005
Loss at batch 310 : 0.012285077944397926
Loss at batch 320 : 0.00684891315177083
Loss at batch 330 : 0.013242109678685665
Loss at batch 340 : 0.015225700102746487
Loss at batch 350 : 0.010676807723939419
Loss at batch 360 : 0.01177323516458273
Loss at batch 370 : 0.02251346781849861
epoch172 finished!
Loss at batch 10 : 0.010569916106760502
Loss at batch 20 : 0.011243565939366817
Loss at batch 30 : 0.016015473753213882
Loss at batch 40 : 0.0211003627628088
Loss at batch 50 : 0.01946636661887169
Loss at batch 60 : 0.012140939943492413
Loss at batch 70 : 0.014675524085760117
Loss at batch 80 : 0.015550779178738594
Loss at batch 90 : 0.013876010663807392
Loss at batch 100 : 0.01587095484137535
Loss at batch 110 : 0.0077550457790493965
Loss at batch 120 : 0.01156754419207573
Loss at batch 130 : 0.01225806400179863
Loss at batch 140 : 0.011707728728652
Loss at batch 150 : 0.009556167759001255
Loss at batch 160 : 0.010697977617383003
Loss at batch 170 : 0.015120971016585827
Loss at batch 180 : 0.022937890142202377
Loss at batch 190 : 0.010220213793218136
Loss at batch 200 : 0.01447480171918869
Loss at batch 210 : 0.009291846305131912
Loss at batch 220 : 0.02053060755133629
Loss at batch 230 : 0.011326540261507034
Loss at batch 240 : 0.012884432449936867
Loss at batch 250 : 0.014387459494173527
Loss at batch 260 : 0.004944304469972849
Loss at batch 270 : 0.007319803815335035
Loss at batch 280 : 0.019570859149098396
Loss at batch 290 : 0.013311087153851986
Loss at batch 300 : 0.013875313103199005
Loss at batch 310 : 0.0219911839812994
Loss at batch 320 : 0.026250941678881645
Loss at batch 330 : 0.008812501095235348
Loss at batch 340 : 0.015849554911255836
Loss at batch 350 : 0.013582290150225163
Loss at batch 360 : 0.015363731421530247
Loss at batch 370 : 0.009051050059497356
epoch173 finished!
Loss at batch 10 : 0.009994217194616795
Loss at batch 20 : 0.010176324285566807
Loss at batch 30 : 0.012742022052407265
Loss at batch 40 : 0.01870238408446312
Loss at batch 50 : 0.014884446747601032
Loss at batch 60 : 0.03223058208823204
Loss at batch 70 : 0.024830864742398262
Loss at batch 80 : 0.01204934436827898
Loss at batch 90 : 0.010256070643663406
Loss at batch 100 : 0.012151967734098434
Loss at batch 110 : 0.012348666787147522
Loss at batch 120 : 0.01354281883686781
Loss at batch 130 : 0.00723695894703269
Loss at batch 140 : 0.009311839006841183
Loss at batch 150 : 0.011503556743264198
Loss at batch 160 : 0.013928313739597797
Loss at batch 170 : 0.02248908020555973
Loss at batch 180 : 0.014145792461931705
Loss at batch 190 : 0.02177383191883564
Loss at batch 200 : 0.010697671212255955
Loss at batch 210 : 0.019622942432761192
Loss at batch 220 : 0.009253332391381264
Loss at batch 230 : 0.01114185806363821
Loss at batch 240 : 0.01588519662618637
Loss at batch 250 : 0.012040349654853344
Loss at batch 260 : 0.01443373691290617
Loss at batch 270 : 0.016329318284988403
Loss at batch 280 : 0.005662155337631702
Loss at batch 290 : 0.017671221867203712
Loss at batch 300 : 0.016474202275276184
Loss at batch 310 : 0.009988195262849331
Loss at batch 320 : 0.020301705226302147
Loss at batch 330 : 0.011546862311661243
Loss at batch 340 : 0.013667365536093712
Loss at batch 350 : 0.013582967221736908
Loss at batch 360 : 0.020067138597369194
Loss at batch 370 : 0.00930571649223566
epoch79 finished!
Loss at batch 10 : 0.017805689945816994
Loss at batch 20 : 0.01323868427425623
Loss at batch 30 : 0.007222409825772047
Loss at batch 40 : 0.007665407378226519
Loss at batch 50 : 0.011691500432789326
Loss at batch 60 : 0.012224349193274975
Loss at batch 70 : 0.01955544203519821
Loss at batch 80 : 0.009731892496347427
Loss at batch 90 : 0.007179704494774342
Loss at batch 100 : 0.012165877036750317
Loss at batch 110 : 0.011818903498351574
Loss at batch 120 : 0.010587762109935284
Loss at batch 130 : 0.019991153851151466
Loss at batch 140 : 0.01810687594115734
Loss at batch 150 : 0.012067598290741444
Loss at batch 160 : 0.018372289836406708
Loss at batch 170 : 0.0103849982842803
Loss at batch 180 : 0.014609110541641712
Loss at batch 190 : 0.008684476837515831
Loss at batch 200 : 0.014614645391702652
Loss at batch 210 : 0.01747109554708004
Loss at batch 220 : 0.014260401949286461
Loss at batch 230 : 0.006880481261759996
Loss at batch 240 : 0.016788456588983536
Loss at batch 250 : 0.025624699890613556
Loss at batch 260 : 0.013451633974909782
Loss at batch 270 : 0.0191243477165699
Loss at batch 280 : 0.018492206931114197
Loss at batch 290 : 0.012935986742377281
Loss at batch 300 : 0.01213170401751995
Loss at batch 310 : 0.01114013884216547
Loss at batch 320 : 0.01161770336329937
Loss at batch 330 : 0.015363945625722408
Loss at batch 340 : 0.01192850898951292
Loss at batch 350 : 0.01895814761519432
Loss at batch 360 : 0.01264628954231739
Loss at batch 370 : 0.020818481221795082
epoch79 finished!
Loss at batch 10 : 0.015529166907072067
Loss at batch 20 : 0.01272570714354515
Loss at batch 30 : 0.01094876416027546
Loss at batch 40 : 0.010179128497838974
Loss at batch 50 : 0.017975877970457077
Loss at batch 60 : 0.01648435927927494
Loss at batch 70 : 0.023755235597491264
Loss at batch 80 : 0.010556197725236416
Loss at batch 90 : 0.014992184937000275
Loss at batch 100 : 0.021701224148273468
Loss at batch 110 : 0.022175874561071396
Loss at batch 120 : 0.00846634991466999
Loss at batch 130 : 0.008231832645833492
Loss at batch 140 : 0.012410908006131649
Loss at batch 150 : 0.007959411479532719
Loss at batch 160 : 0.011023973114788532
Loss at batch 170 : 0.017055470496416092
Loss at batch 180 : 0.011460920795798302
Loss at batch 190 : 0.013574905693531036
Loss at batch 200 : 0.021936001256108284
Loss at batch 210 : 0.01155881304293871
Loss at batch 220 : 0.013555026613175869
Loss at batch 230 : 0.005510894116014242
Loss at batch 240 : 0.019217466935515404
Loss at batch 250 : 0.013571699149906635
Loss at batch 260 : 0.016664128750562668
Loss at batch 270 : 0.010324832051992416
Loss at batch 280 : 0.01369026955217123
Loss at batch 290 : 0.014576708897948265
Loss at batch 300 : 0.014873572625219822
Loss at batch 310 : 0.014257128350436687
Loss at batch 320 : 0.010071790777146816
Loss at batch 330 : 0.018209252506494522
Loss at batch 340 : 0.011874271556735039
Loss at batch 350 : 0.012120808474719524
Loss at batch 360 : 0.022912992164492607
Loss at batch 370 : 0.00825066864490509
epoch174 finished!
Loss at batch 10 : 0.009943769313395023
Loss at batch 20 : 0.009466925635933876
Loss at batch 30 : 0.012144116684794426
Loss at batch 40 : 0.015205621719360352
Loss at batch 50 : 0.0069656395353376865
Loss at batch 60 : 0.02349235676229
Loss at batch 70 : 0.013776815496385098
Loss at batch 80 : 0.009895304217934608
Loss at batch 90 : 0.01613684743642807
Loss at batch 100 : 0.014188703149557114
Loss at batch 110 : 0.014753123745322227
Loss at batch 120 : 0.012129845097661018
Loss at batch 130 : 0.014389822259545326
Loss at batch 140 : 0.014953169040381908
Loss at batch 150 : 0.010479047894477844
Loss at batch 160 : 0.01384566631168127
Loss at batch 170 : 0.023710526525974274
Loss at batch 180 : 0.009175089187920094
Loss at batch 190 : 0.012930058874189854
Loss at batch 200 : 0.01322693470865488
Loss at batch 210 : 0.013743015937507153
Loss at batch 220 : 0.017351359128952026
Loss at batch 230 : 0.00893240887671709
Loss at batch 240 : 0.016484558582305908
Loss at batch 250 : 0.011541763320565224
Loss at batch 260 : 0.0104787303134799
Loss at batch 270 : 0.020982865244150162
Loss at batch 280 : 0.01844199188053608
Loss at batch 290 : 0.024077313020825386
Loss at batch 300 : 0.009104743599891663
Loss at batch 310 : 0.014149419032037258
Loss at batch 320 : 0.007532523479312658
Loss at batch 330 : 0.01711796410381794
Loss at batch 340 : 0.01129111833870411
Loss at batch 350 : 0.02143133245408535
Loss at batch 360 : 0.014746466651558876
Loss at batch 370 : 0.010336711071431637
epoch175 finished!
Loss at batch 10 : 0.022365311160683632
Loss at batch 20 : 0.0215599462389946
Loss at batch 30 : 0.021220725029706955
Loss at batch 40 : 0.011605648323893547
Loss at batch 50 : 0.006598821375519037
Loss at batch 60 : 0.013529242016375065
Loss at batch 70 : 0.015245097689330578
Loss at batch 80 : 0.012031152844429016
Loss at batch 90 : 0.013001352548599243
Loss at batch 100 : 0.010881662368774414
Loss at batch 110 : 0.020148109644651413
Loss at batch 120 : 0.012913977727293968
Loss at batch 130 : 0.011199209839105606
Loss at batch 140 : 0.012831873260438442
Loss at batch 150 : 0.013542693108320236
Loss at batch 160 : 0.0117277717217803
Loss at batch 170 : 0.009220810607075691
Loss at batch 180 : 0.029682185500860214
Loss at batch 190 : 0.012830677442252636
Loss at batch 200 : 0.008159351535141468
Loss at batch 210 : 0.011794086545705795
Loss at batch 220 : 0.017283372581005096
Loss at batch 230 : 0.01920173689723015
Loss at batch 240 : 0.024125399067997932
Loss at batch 250 : 0.01355577353388071
Loss at batch 260 : 0.012100688181817532
Loss at batch 270 : 0.012979007326066494
Loss at batch 280 : 0.010754884220659733
Loss at batch 290 : 0.010789512656629086
Loss at batch 300 : 0.010106063447892666
Loss at batch 310 : 0.015458890236914158
Loss at batch 320 : 0.0119163254275918
Loss at batch 330 : 0.01446004118770361
Loss at batch 340 : 0.01811230555176735
Loss at batch 350 : 0.019067157059907913
Loss at batch 360 : 0.025922026485204697
Loss at batch 370 : 0.01232957560569048
epoch80 finished!
Loss at batch 10 : 0.017620019614696503
Loss at batch 20 : 0.010621397756040096
Loss at batch 30 : 0.010304955765604973
Loss at batch 40 : 0.008775021880865097
Loss at batch 50 : 0.016044482588768005
Loss at batch 60 : 0.014520241878926754
Loss at batch 70 : 0.013908222317695618
Loss at batch 80 : 0.01571989245712757
Loss at batch 90 : 0.012159671634435654
Loss at batch 100 : 0.014066348783671856
Loss at batch 110 : 0.00868750549852848
Loss at batch 120 : 0.01672918163239956
Loss at batch 130 : 0.008825897239148617
Loss at batch 140 : 0.022714538499712944
Loss at batch 150 : 0.014791338704526424
Loss at batch 160 : 0.017201488837599754
Loss at batch 170 : 0.014679137617349625
Loss at batch 180 : 0.015036841854453087
Loss at batch 190 : 0.007273995317518711
Loss at batch 200 : 0.01754792593419552
Loss at batch 210 : 0.01922706514596939
Loss at batch 220 : 0.010727874003350735
Loss at batch 230 : 0.01840747334063053
Loss at batch 240 : 0.008214619942009449
Loss at batch 250 : 0.010180586948990822
Loss at batch 260 : 0.010973961092531681
Loss at batch 270 : 0.016732918098568916
Loss at batch 280 : 0.013865562155842781
Loss at batch 290 : 0.011052259244024754
Loss at batch 300 : 0.013126986101269722
Loss at batch 310 : 0.014059765264391899
Loss at batch 320 : 0.010511290282011032
Loss at batch 330 : 0.016559217125177383
Loss at batch 340 : 0.014468911103904247
Loss at batch 350 : 0.014960503205657005
Loss at batch 360 : 0.00962475873529911
Loss at batch 370 : 0.007635097485035658
epoch80 finished!
Loss at batch 10 : 0.008373752236366272
Loss at batch 20 : 0.013057668693363667
Loss at batch 30 : 0.01799301989376545
Loss at batch 40 : 0.011253722943365574
Loss at batch 50 : 0.022720392793416977
Loss at batch 60 : 0.011490694247186184
Loss at batch 70 : 0.012187776155769825
Loss at batch 80 : 0.018759138882160187
Loss at batch 90 : 0.013616958633065224
Loss at batch 100 : 0.015709763392806053
Loss at batch 110 : 0.014928831718862057
Loss at batch 120 : 0.012870962731540203
Loss at batch 130 : 0.019493862986564636
Loss at batch 140 : 0.008953389711678028
Loss at batch 150 : 0.00983095820993185
Loss at batch 160 : 0.010216424241662025
Loss at batch 170 : 0.013473369181156158
Loss at batch 180 : 0.007704996038228273
Loss at batch 190 : 0.00991284754127264
Loss at batch 200 : 0.007492599077522755
Loss at batch 210 : 0.011391031555831432
Loss at batch 220 : 0.009285354055464268
Loss at batch 230 : 0.01079503446817398
Loss at batch 240 : 0.017306027933955193
Loss at batch 250 : 0.01761900633573532
Loss at batch 260 : 0.01587088592350483
Loss at batch 270 : 0.012757069431245327
Loss at batch 280 : 0.011795123107731342
Loss at batch 290 : 0.0065318625420331955
Loss at batch 300 : 0.010873621329665184
Loss at batch 310 : 0.013104241341352463
Loss at batch 320 : 0.01206024270504713
Loss at batch 330 : 0.012260647490620613
Loss at batch 340 : 0.014149438589811325
Loss at batch 350 : 0.011772379279136658
Loss at batch 360 : 0.010000725276768208
Loss at batch 370 : 0.015182506293058395
epoch176 finished!
Loss at batch 10 : 0.010921315290033817
Loss at batch 20 : 0.015355841256678104
Loss at batch 30 : 0.03306690603494644
Loss at batch 40 : 0.028640786185860634
Loss at batch 50 : 0.018653610721230507
Loss at batch 60 : 0.013534905388951302
Loss at batch 70 : 0.014436607249081135
Loss at batch 80 : 0.015118989162147045
Loss at batch 90 : 0.02011614665389061
Loss at batch 100 : 0.01631108485162258
Loss at batch 110 : 0.01308908686041832
Loss at batch 120 : 0.012898820452392101
Loss at batch 130 : 0.01577567309141159
Loss at batch 140 : 0.022183092311024666
Loss at batch 150 : 0.012306218966841698
Loss at batch 160 : 0.016749057918787003
Loss at batch 170 : 0.013405433855950832
Loss at batch 180 : 0.013227651827037334
Loss at batch 190 : 0.008976243436336517
Loss at batch 200 : 0.022227097302675247
Loss at batch 210 : 0.016150955110788345
Loss at batch 220 : 0.009233199059963226
Loss at batch 230 : 0.011305893771350384
Loss at batch 240 : 0.01253665704280138
Loss at batch 250 : 0.013484109193086624
Loss at batch 260 : 0.019949713721871376
Loss at batch 270 : 0.011823192238807678
Loss at batch 280 : 0.024134868755936623
Loss at batch 290 : 0.01590702496469021
Loss at batch 300 : 0.015402046032249928
Loss at batch 310 : 0.014676976017653942
Loss at batch 320 : 0.018177716061472893
Loss at batch 330 : 0.013174599967896938
Loss at batch 340 : 0.016654904931783676
Loss at batch 350 : 0.020826831459999084
Loss at batch 360 : 0.007652912754565477
Loss at batch 370 : 0.014432529918849468
epoch177 finished!
Loss at batch 10 : 0.01146823912858963
Loss at batch 20 : 0.010319264605641365
Loss at batch 30 : 0.018409479409456253
Loss at batch 40 : 0.02364676259458065
Loss at batch 50 : 0.009837118908762932
Loss at batch 60 : 0.016222449019551277
Loss at batch 70 : 0.02093379572033882
Loss at batch 80 : 0.012307900935411453
Loss at batch 90 : 0.012185209430754185
Loss at batch 100 : 0.010581186041235924
Loss at batch 110 : 0.01406773179769516
Loss at batch 120 : 0.0091372299939394
Loss at batch 130 : 0.016550688073039055
Loss at batch 140 : 0.017589068040251732
Loss at batch 150 : 0.012503140605986118
Loss at batch 160 : 0.01047287043184042
Loss at batch 170 : 0.010889430530369282
Loss at batch 180 : 0.008985140360891819
Loss at batch 190 : 0.014328217133879662
Loss at batch 200 : 0.017063789069652557
Loss at batch 210 : 0.008296502754092216
Loss at batch 220 : 0.012369758449494839
Loss at batch 230 : 0.01414758712053299
Loss at batch 240 : 0.01383751630783081
Loss at batch 250 : 0.01940816454589367
Loss at batch 260 : 0.012820590287446976
Loss at batch 270 : 0.010081306099891663
Loss at batch 280 : 0.010100788436830044
Loss at batch 290 : 0.018401362001895905
Loss at batch 300 : 0.011391039937734604
Loss at batch 310 : 0.02081943489611149
Loss at batch 320 : 0.013928958214819431
Loss at batch 330 : 0.016234584152698517
Loss at batch 340 : 0.011445081792771816
Loss at batch 350 : 0.01857500709593296
Loss at batch 360 : 0.016798358410596848
Loss at batch 370 : 0.02189461886882782
epoch81 finished!
Loss at batch 10 : 0.010065602138638496
Loss at batch 20 : 0.013745850883424282
Loss at batch 30 : 0.015187437646090984
Loss at batch 40 : 0.010163173079490662
Loss at batch 50 : 0.008131165988743305
Loss at batch 60 : 0.01283381599932909
Loss at batch 70 : 0.01739312708377838
Loss at batch 80 : 0.02609981782734394
Loss at batch 90 : 0.018454870209097862
Loss at batch 100 : 0.014551080763339996
Loss at batch 110 : 0.01717718504369259
Loss at batch 120 : 0.015471762046217918
Loss at batch 130 : 0.014207967557013035
Loss at batch 140 : 0.015429064631462097
Loss at batch 150 : 0.009734151884913445
Loss at batch 160 : 0.01086683850735426
Loss at batch 170 : 0.012407414615154266
Loss at batch 180 : 0.014819399453699589
Loss at batch 190 : 0.015928640961647034
Loss at batch 200 : 0.013937254436314106
Loss at batch 210 : 0.014772587455809116
Loss at batch 220 : 0.013199367560446262
Loss at batch 230 : 0.010350530967116356
Loss at batch 240 : 0.015179592184722424
Loss at batch 250 : 0.010128133930265903
Loss at batch 260 : 0.01669301465153694
Loss at batch 270 : 0.010150223039090633
Loss at batch 280 : 0.016320262104272842
Loss at batch 290 : 0.011480670422315598
Loss at batch 300 : 0.015354267321527004
Loss at batch 310 : 0.016296271234750748
Loss at batch 320 : 0.010636033490300179
Loss at batch 330 : 0.01931091398000717
Loss at batch 340 : 0.012598971836268902
Loss at batch 350 : 0.014934001490473747
Loss at batch 360 : 0.01778615079820156
Loss at batch 370 : 0.014927300624549389
epoch81 finished!
Loss at batch 10 : 0.011594165116548538
Loss at batch 20 : 0.009277945384383202
Loss at batch 30 : 0.01051949243992567
Loss at batch 40 : 0.009524806402623653
Loss at batch 50 : 0.012191537767648697
Loss at batch 60 : 0.016292186453938484
Loss at batch 70 : 0.015347199514508247
Loss at batch 80 : 0.019655397161841393
Loss at batch 90 : 0.013326941058039665
Loss at batch 100 : 0.017854511737823486
Loss at batch 110 : 0.013226522132754326
Loss at batch 120 : 0.01056236494332552
Loss at batch 130 : 0.009207585826516151
Loss at batch 140 : 0.026051919907331467
Loss at batch 150 : 0.005650096572935581
Loss at batch 160 : 0.013723730109632015
Loss at batch 170 : 0.010867287404835224
Loss at batch 180 : 0.01861366257071495
Loss at batch 190 : 0.0228639654815197
Loss at batch 200 : 0.009454160928726196
Loss at batch 210 : 0.010437363758683205
Loss at batch 220 : 0.013389435596764088
Loss at batch 230 : 0.010043689049780369
Loss at batch 240 : 0.007489868905395269
Loss at batch 250 : 0.02305050939321518
Loss at batch 260 : 0.014116374775767326
Loss at batch 270 : 0.023788196966052055
Loss at batch 280 : 0.024312786757946014
Loss at batch 290 : 0.008197018876671791
Loss at batch 300 : 0.01818273216485977
Loss at batch 310 : 0.019886083900928497
Loss at batch 320 : 0.015752099454402924
Loss at batch 330 : 0.02296723611652851
Loss at batch 340 : 0.01341032050549984
Loss at batch 350 : 0.02062501758337021
Loss at batch 360 : 0.01139985304325819
Loss at batch 370 : 0.014829549938440323
epoch178 finished!
Loss at batch 10 : 0.017600594088435173
Loss at batch 20 : 0.012843875214457512
Loss at batch 30 : 0.01173690427094698
Loss at batch 40 : 0.013878101482987404
Loss at batch 50 : 0.00614901864901185
Loss at batch 60 : 0.014209801331162453
Loss at batch 70 : 0.013108696788549423
Loss at batch 80 : 0.009759879671037197
Loss at batch 90 : 0.018123198300600052
Loss at batch 100 : 0.014312958344817162
Loss at batch 110 : 0.01289645116776228
Loss at batch 120 : 0.014713887125253677
Loss at batch 130 : 0.014107855968177319
Loss at batch 140 : 0.016442641615867615
Loss at batch 150 : 0.021577829495072365
Loss at batch 160 : 0.011744426563382149
Loss at batch 170 : 0.012926528230309486
Loss at batch 180 : 0.01695152558386326
Loss at batch 190 : 0.013333278708159924
Loss at batch 200 : 0.019324086606502533
Loss at batch 210 : 0.01693011447787285
Loss at batch 220 : 0.009281599894165993
Loss at batch 230 : 0.008861804381012917
Loss at batch 240 : 0.010658396407961845
Loss at batch 250 : 0.016160864382982254
Loss at batch 260 : 0.01119678933173418
Loss at batch 270 : 0.020646892488002777
Loss at batch 280 : 0.012972386553883553
Loss at batch 290 : 0.015961382538080215
Loss at batch 300 : 0.01654406078159809
Loss at batch 310 : 0.017815005034208298
Loss at batch 320 : 0.024989889934659004
Loss at batch 330 : 0.006007207557559013
Loss at batch 340 : 0.008351429365575314
Loss at batch 350 : 0.030705375596880913
Loss at batch 360 : 0.020923035219311714
Loss at batch 370 : 0.014310259371995926
epoch179 finished!
Loss at batch 10 : 0.012599675916135311
Loss at batch 20 : 0.010145110078155994
Loss at batch 30 : 0.02088264562189579
Loss at batch 40 : 0.01327496487647295
Loss at batch 50 : 0.020558224990963936
Loss at batch 60 : 0.015795694664120674
Loss at batch 70 : 0.017207494005560875
Loss at batch 80 : 0.031632713973522186
Loss at batch 90 : 0.010625815950334072
Loss at batch 100 : 0.013239644467830658
Loss at batch 110 : 0.015160744078457355
Loss at batch 120 : 0.025216763839125633
Loss at batch 130 : 0.015580608509480953
Loss at batch 140 : 0.0200345441699028
Loss at batch 150 : 0.0108681945130229
Loss at batch 160 : 0.020208826288580894
Loss at batch 170 : 0.019640158861875534
Loss at batch 180 : 0.012037491425871849
Loss at batch 190 : 0.031155485659837723
Loss at batch 200 : 0.01888156309723854
Loss at batch 210 : 0.018100854009389877
Loss at batch 220 : 0.012635530903935432
Loss at batch 230 : 0.0055939448066055775
Loss at batch 240 : 0.013333646580576897
Loss at batch 250 : 0.015313984826207161
Loss at batch 260 : 0.009507996030151844
Loss at batch 270 : 0.0100288400426507
Loss at batch 280 : 0.02113349549472332
Loss at batch 290 : 0.009450912475585938
Loss at batch 300 : 0.016590073704719543
Loss at batch 310 : 0.0099562406539917
Loss at batch 320 : 0.012616469524800777
Loss at batch 330 : 0.00771068362519145
Loss at batch 340 : 0.015629608184099197
Loss at batch 350 : 0.016711710020899773
Loss at batch 360 : 0.019916726276278496
Loss at batch 370 : 0.029161958023905754
epoch82 finished!
Loss at batch 10 : 0.012237139977514744
Loss at batch 20 : 0.015345007181167603
Loss at batch 30 : 0.015216480009257793
Loss at batch 40 : 0.019112305715680122
Loss at batch 50 : 0.011076792143285275
Loss at batch 60 : 0.010634390637278557
Loss at batch 70 : 0.009807591326534748
Loss at batch 80 : 0.011728375218808651
Loss at batch 90 : 0.011913399212062359
Loss at batch 100 : 0.00952974148094654
Loss at batch 110 : 0.008890525437891483
Loss at batch 120 : 0.009683160111308098
Loss at batch 130 : 0.017702221870422363
Loss at batch 140 : 0.014656963758170605
Loss at batch 150 : 0.016736285760998726
Loss at batch 160 : 0.014065839350223541
Loss at batch 170 : 0.015067463740706444
Loss at batch 180 : 0.013373669236898422
Loss at batch 190 : 0.015184625051915646
Loss at batch 200 : 0.011464294977486134
Loss at batch 210 : 0.010840672999620438
Loss at batch 220 : 0.00973269622772932
Loss at batch 230 : 0.008292097598314285
Loss at batch 240 : 0.01749277673661709
Loss at batch 250 : 0.0099178496748209
Loss at batch 260 : 0.01916598528623581
Loss at batch 270 : 0.025215964764356613
Loss at batch 280 : 0.007936043664813042
Loss at batch 290 : 0.01652579940855503
Loss at batch 300 : 0.01276341825723648
Loss at batch 310 : 0.018527306616306305
Loss at batch 320 : 0.013992322608828545
Loss at batch 330 : 0.007516562473028898
Loss at batch 340 : 0.015586867928504944
Loss at batch 350 : 0.009020994417369366
Loss at batch 360 : 0.010379208251833916
Loss at batch 370 : 0.011430799029767513
epoch82 finished!
Loss at batch 10 : 0.021445145830512047
Loss at batch 20 : 0.010385693982243538
Loss at batch 30 : 0.02548713982105255
Loss at batch 40 : 0.020863499492406845
Loss at batch 50 : 0.020725559443235397
Loss at batch 60 : 0.01781790889799595
Loss at batch 70 : 0.010265118442475796
Loss at batch 80 : 0.009195046499371529
Loss at batch 90 : 0.020733218640089035
Loss at batch 100 : 0.024171216413378716
Loss at batch 110 : 0.015544579364359379
Loss at batch 120 : 0.013490848243236542
Loss at batch 130 : 0.011391038075089455
Loss at batch 140 : 0.019038187339901924
Loss at batch 150 : 0.009118550457060337
Loss at batch 160 : 0.020942682400345802
Loss at batch 170 : 0.013004441745579243
Loss at batch 180 : 0.023577099665999413
Loss at batch 190 : 0.013577564619481564
Loss at batch 200 : 0.018025577068328857
Loss at batch 210 : 0.0128171993419528
Loss at batch 220 : 0.014046190306544304
Loss at batch 230 : 0.016034847125411034
Loss at batch 240 : 0.01100865751504898
Loss at batch 250 : 0.009544527158141136
Loss at batch 260 : 0.014689545147120953
Loss at batch 270 : 0.012711940333247185
Loss at batch 280 : 0.010836204513907433
Loss at batch 290 : 0.012056141160428524
Loss at batch 300 : 0.019533643499016762
Loss at batch 310 : 0.014196570962667465
Loss at batch 320 : 0.00962909683585167
Loss at batch 330 : 0.012709477916359901
Loss at batch 340 : 0.012242598459124565
Loss at batch 350 : 0.013309251517057419
Loss at batch 360 : 0.007076927460730076
Loss at batch 370 : 0.016773898154497147
epoch180 finished!
Loss at batch 10 : 0.011061206459999084
Loss at batch 20 : 0.018486693501472473
Loss at batch 30 : 0.012171425856649876
Loss at batch 40 : 0.014093481935560703
Loss at batch 50 : 0.01018205564469099
Loss at batch 60 : 0.013465385884046555
Loss at batch 70 : 0.013152319006621838
Loss at batch 80 : 0.016191422939300537
Loss at batch 90 : 0.009153394959867
Loss at batch 100 : 0.013172976672649384
Loss at batch 110 : 0.01256386749446392
Loss at batch 120 : 0.008466813713312149
Loss at batch 130 : 0.010957793332636356
Loss at batch 140 : 0.013765896670520306
Loss at batch 150 : 0.013840912841260433
Loss at batch 160 : 0.006788622122257948
Loss at batch 170 : 0.014901489950716496
Loss at batch 180 : 0.009189414791762829
Loss at batch 190 : 0.021369339898228645
Loss at batch 200 : 0.013537261635065079
Loss at batch 210 : 0.012735840864479542
Loss at batch 220 : 0.012980611994862556
Loss at batch 230 : 0.013613426126539707
Loss at batch 240 : 0.013451341539621353
Loss at batch 250 : 0.014812659472227097
Loss at batch 260 : 0.019295724108815193
Loss at batch 270 : 0.0155004458501935
Loss at batch 280 : 0.010231928899884224
Loss at batch 290 : 0.018194641917943954
Loss at batch 300 : 0.016780585050582886
Loss at batch 310 : 0.009153512306511402
Loss at batch 320 : 0.017570730298757553
Loss at batch 330 : 0.012798258103430271
Loss at batch 340 : 0.01237459760159254
Loss at batch 350 : 0.005224890075623989
Loss at batch 360 : 0.011859283782541752
Loss at batch 370 : 0.010921236127614975
epoch181 finished!
Loss at batch 10 : 0.008086607791483402
Loss at batch 20 : 0.021452443674206734
Loss at batch 30 : 0.013690592721104622
Loss at batch 40 : 0.009356897324323654
Loss at batch 50 : 0.01388011034578085
Loss at batch 60 : 0.012371390126645565
Loss at batch 70 : 0.011677145026624203
Loss at batch 80 : 0.018846305087208748
Loss at batch 90 : 0.012214729562401772
Loss at batch 100 : 0.00548288831487298
Loss at batch 110 : 0.00909145176410675
Loss at batch 120 : 0.016637487336993217
Loss at batch 130 : 0.012437221594154835
Loss at batch 140 : 0.01556345634162426
Loss at batch 150 : 0.011308134533464909
Loss at batch 160 : 0.013395044021308422
Loss at batch 170 : 0.011806399561464787
Loss at batch 180 : 0.01082543469965458
Loss at batch 190 : 0.0056480965577065945
Loss at batch 200 : 0.008557600900530815
Loss at batch 210 : 0.014557383954524994
Loss at batch 220 : 0.014801569283008575
Loss at batch 230 : 0.014604810625314713
Loss at batch 240 : 0.011948231607675552
Loss at batch 250 : 0.008912714198231697
Loss at batch 260 : 0.01403985545039177
Loss at batch 270 : 0.008127294480800629
Loss at batch 280 : 0.01896018162369728
Loss at batch 290 : 0.017429230734705925
Loss at batch 300 : 0.02013290487229824
Loss at batch 310 : 0.009930811822414398
Loss at batch 320 : 0.020297178998589516
Loss at batch 330 : 0.007334774360060692
Loss at batch 340 : 0.02170342393219471
Loss at batch 350 : 0.016288096085190773
Loss at batch 360 : 0.011335237883031368
Loss at batch 370 : 0.013512947596609592
epoch182 finished!
Loss at batch 10 : 0.021049262955784798
Loss at batch 20 : 0.0174440648406744
Loss at batch 30 : 0.010057434439659119
Loss at batch 40 : 0.01176237128674984
Loss at batch 50 : 0.014580088667571545
Loss at batch 60 : 0.01825653947889805
Loss at batch 70 : 0.011990115977823734
Loss at batch 80 : 0.02017439529299736
Loss at batch 90 : 0.008592982776463032
Loss at batch 100 : 0.015083955600857735
Loss at batch 110 : 0.008468031883239746
Loss at batch 120 : 0.009661738760769367
Loss at batch 130 : 0.01350280363112688
Loss at batch 140 : 0.01700066216289997
Loss at batch 150 : 0.01571510173380375
Loss at batch 160 : 0.014653103426098824
Loss at batch 170 : 0.02476232871413231
Loss at batch 180 : 0.013819320127367973
Loss at batch 190 : 0.01698676124215126
Loss at batch 200 : 0.00862004142254591
Loss at batch 210 : 0.01979954168200493
Loss at batch 220 : 0.018894590437412262
Loss at batch 230 : 0.019739367067813873
Loss at batch 240 : 0.013230796903371811
Loss at batch 250 : 0.028870536014437675
Loss at batch 260 : 0.016350779682397842
Loss at batch 270 : 0.013172315433621407
Loss at batch 280 : 0.023592131212353706
Loss at batch 290 : 0.01459590531885624
Loss at batch 300 : 0.014903990551829338
Loss at batch 310 : 0.010875936597585678
Loss at batch 320 : 0.011551067233085632
Loss at batch 330 : 0.016541367396712303
Loss at batch 340 : 0.012202820740640163
Loss at batch 350 : 0.00821477547287941
Loss at batch 360 : 0.017123807221651077
Loss at batch 370 : 0.012335475534200668
epoch83 finished!
Loss at batch 10 : 0.028387082740664482
Loss at batch 20 : 0.01006119791418314
Loss at batch 30 : 0.012706583365797997
Loss at batch 40 : 0.013484632596373558
Loss at batch 50 : 0.019577786326408386
Loss at batch 60 : 0.010913098230957985
Loss at batch 70 : 0.011738712899386883
Loss at batch 80 : 0.013127975165843964
Loss at batch 90 : 0.012145116925239563
Loss at batch 100 : 0.01207766868174076
Loss at batch 110 : 0.008779791183769703
Loss at batch 120 : 0.017765101045370102
Loss at batch 130 : 0.014888460747897625
Loss at batch 140 : 0.015989316627383232
Loss at batch 150 : 0.01144617609679699
Loss at batch 160 : 0.015988584607839584
Loss at batch 170 : 0.013716466724872589
Loss at batch 180 : 0.023188218474388123
Loss at batch 190 : 0.013134662061929703
Loss at batch 200 : 0.020723769441246986
Loss at batch 210 : 0.011365729384124279
Loss at batch 220 : 0.008647128008306026
Loss at batch 230 : 0.012336669489741325
Loss at batch 240 : 0.010998968034982681
Loss at batch 250 : 0.01172659732401371
Loss at batch 260 : 0.02025808021426201
Loss at batch 270 : 0.01408436894416809
Loss at batch 280 : 0.02101401425898075
Loss at batch 290 : 0.01422029547393322
Loss at batch 300 : 0.014911380596458912
Loss at batch 310 : 0.019128715619444847
Loss at batch 320 : 0.019798096269369125
Loss at batch 330 : 0.017888791859149933
Loss at batch 340 : 0.009120502509176731
Loss at batch 350 : 0.012989593669772148
Loss at batch 360 : 0.010145600885152817
Loss at batch 370 : 0.013567892834544182
epoch83 finished!
Loss at batch 10 : 0.005813242867588997
Loss at batch 20 : 0.017176654189825058
Loss at batch 30 : 0.013943130150437355
Loss at batch 40 : 0.019628727808594704
Loss at batch 50 : 0.013996999710798264
Loss at batch 60 : 0.010521716438233852
Loss at batch 70 : 0.01371052023023367
Loss at batch 80 : 0.010593830607831478
Loss at batch 90 : 0.014949396252632141
Loss at batch 100 : 0.019229969009757042
Loss at batch 110 : 0.009884586557745934
Loss at batch 120 : 0.012472424656152725
Loss at batch 130 : 0.02098543383181095
Loss at batch 140 : 0.011344190686941147
Loss at batch 150 : 0.011026634834706783
Loss at batch 160 : 0.011485771276056767
Loss at batch 170 : 0.010368388146162033
Loss at batch 180 : 0.013398414477705956
Loss at batch 190 : 0.011931955814361572
Loss at batch 200 : 0.01832985319197178
Loss at batch 210 : 0.014555998146533966
Loss at batch 220 : 0.0068482086062431335
Loss at batch 230 : 0.013783512637019157
Loss at batch 240 : 0.02171381562948227
Loss at batch 250 : 0.013076809234917164
Loss at batch 260 : 0.013515930622816086
Loss at batch 270 : 0.013218244537711143
Loss at batch 280 : 0.018789900466799736
Loss at batch 290 : 0.018636804074048996
Loss at batch 300 : 0.009221772663295269
Loss at batch 310 : 0.01081779319792986
Loss at batch 320 : 0.015151766128838062
Loss at batch 330 : 0.009867868386209011
Loss at batch 340 : 0.023977506905794144
Loss at batch 350 : 0.01755627803504467
Loss at batch 360 : 0.011801999993622303
Loss at batch 370 : 0.016566094011068344
epoch183 finished!
Loss at batch 10 : 0.014586065895855427
Loss at batch 20 : 0.012975309044122696
Loss at batch 30 : 0.018840808421373367
Loss at batch 40 : 0.00930144265294075
Loss at batch 50 : 0.005578670650720596
Loss at batch 60 : 0.012287701480090618
Loss at batch 70 : 0.00830581784248352
Loss at batch 80 : 0.01467827893793583
Loss at batch 90 : 0.013014095835387707
Loss at batch 100 : 0.02117954008281231
Loss at batch 110 : 0.011749581433832645
Loss at batch 120 : 0.014515414834022522
Loss at batch 130 : 0.009157367050647736
Loss at batch 140 : 0.019268345087766647
Loss at batch 150 : 0.0090167336165905
Loss at batch 160 : 0.014016743749380112
Loss at batch 170 : 0.018397165462374687
Loss at batch 180 : 0.00858587957918644
Loss at batch 190 : 0.015512058511376381
Loss at batch 200 : 0.01114106085151434
Loss at batch 210 : 0.012910556979477406
Loss at batch 220 : 0.008965241722762585
Loss at batch 230 : 0.013473138213157654
Loss at batch 240 : 0.020839624106884003
Loss at batch 250 : 0.01421684306114912
Loss at batch 260 : 0.013733018189668655
Loss at batch 270 : 0.025463925674557686
Loss at batch 280 : 0.009655416943132877
Loss at batch 290 : 0.0152748329564929
Loss at batch 300 : 0.018682274967432022
Loss at batch 310 : 0.0167817585170269
Loss at batch 320 : 0.014205816201865673
Loss at batch 330 : 0.017575478181242943
Loss at batch 340 : 0.019741864874958992
Loss at batch 350 : 0.010999172925949097
Loss at batch 360 : 0.018218541517853737
Loss at batch 370 : 0.009503803215920925
epoch184 finished!
Loss at batch 10 : 0.02630288153886795
Loss at batch 20 : 0.01455316599458456
Loss at batch 30 : 0.010500465519726276
Loss at batch 40 : 0.026903590187430382
Loss at batch 50 : 0.026416029781103134
Loss at batch 60 : 0.019046586006879807
Loss at batch 70 : 0.011248915456235409
Loss at batch 80 : 0.008888596668839455
Loss at batch 90 : 0.009739636443555355
Loss at batch 100 : 0.012625398114323616
Loss at batch 110 : 0.016991402953863144
Loss at batch 120 : 0.019364705309271812
Loss at batch 130 : 0.01269187405705452
Loss at batch 140 : 0.010975467041134834
Loss at batch 150 : 0.02381434105336666
Loss at batch 160 : 0.01681653968989849
Loss at batch 170 : 0.020937174558639526
Loss at batch 180 : 0.009305945597589016
Loss at batch 190 : 0.018587063997983932
Loss at batch 200 : 0.02277141436934471
Loss at batch 210 : 0.01877719908952713
Loss at batch 220 : 0.011745472438633442
Loss at batch 230 : 0.009550366550683975
Loss at batch 240 : 0.019281312823295593
Loss at batch 250 : 0.007270645350217819
Loss at batch 260 : 0.028130244463682175
Loss at batch 270 : 0.015998225659132004
Loss at batch 280 : 0.011278212070465088
Loss at batch 290 : 0.012208741158246994
Loss at batch 300 : 0.017554230988025665
Loss at batch 310 : 0.010504630394279957
Loss at batch 320 : 0.016669275239109993
Loss at batch 330 : 0.018328946083784103
Loss at batch 340 : 0.013700803741812706
Loss at batch 350 : 0.008317435160279274
Loss at batch 360 : 0.019596748054027557
Loss at batch 370 : 0.013393367640674114
epoch84 finished!
Loss at batch 10 : 0.008332780562341213
Loss at batch 20 : 0.011590061709284782
Loss at batch 30 : 0.012680931016802788
Loss at batch 40 : 0.014279060997068882
Loss at batch 50 : 0.009064498357474804
Loss at batch 60 : 0.009883465245366096
Loss at batch 70 : 0.011812910437583923
Loss at batch 80 : 0.012559132650494576
Loss at batch 90 : 0.007350871339440346
Loss at batch 100 : 0.009862919338047504
Loss at batch 110 : 0.009235519915819168
Loss at batch 120 : 0.014317866414785385
Loss at batch 130 : 0.01831977069377899
Loss at batch 140 : 0.010802984237670898
Loss at batch 150 : 0.01236636284738779
Loss at batch 160 : 0.023095054551959038
Loss at batch 170 : 0.013012213632464409
Loss at batch 180 : 0.011813164688646793
Loss at batch 190 : 0.015852928161621094
Loss at batch 200 : 0.00942195113748312
Loss at batch 210 : 0.01740197092294693
Loss at batch 220 : 0.02354508265852928
Loss at batch 230 : 0.016138212755322456
Loss at batch 240 : 0.014204838313162327
Loss at batch 250 : 0.015720320865511894
Loss at batch 260 : 0.015047877095639706
Loss at batch 270 : 0.013108729384839535
Loss at batch 280 : 0.009447669610381126
Loss at batch 290 : 0.02247915230691433
Loss at batch 300 : 0.016558751463890076
Loss at batch 310 : 0.021120619028806686
Loss at batch 320 : 0.011258083395659924
Loss at batch 330 : 0.012701204046607018
Loss at batch 340 : 0.012556160800158978
Loss at batch 350 : 0.01674872636795044
Loss at batch 360 : 0.016646916046738625
Loss at batch 370 : 0.01152619905769825
epoch84 finished!
Loss at batch 10 : 0.013334718532860279
Loss at batch 20 : 0.014136187732219696
Loss at batch 30 : 0.015796031802892685
Loss at batch 40 : 0.011487944051623344
Loss at batch 50 : 0.01679414138197899
Loss at batch 60 : 0.019884880632162094
Loss at batch 70 : 0.009072015061974525
Loss at batch 80 : 0.02343914844095707
Loss at batch 90 : 0.01632572151720524
Loss at batch 100 : 0.010334995575249195
Loss at batch 110 : 0.013846144080162048
Loss at batch 120 : 0.015327466651797295
Loss at batch 130 : 0.012523027136921883
Loss at batch 140 : 0.02141045778989792
Loss at batch 150 : 0.017789501696825027
Loss at batch 160 : 0.00684219179674983
Loss at batch 170 : 0.0111795449629426
Loss at batch 180 : 0.006127682514488697
Loss at batch 190 : 0.010106689296662807
Loss at batch 200 : 0.008900659158825874
Loss at batch 210 : 0.011877288110554218
Loss at batch 220 : 0.010251720435917377
Loss at batch 230 : 0.012643036432564259
Loss at batch 240 : 0.013920438475906849
Loss at batch 250 : 0.011253955774009228
Loss at batch 260 : 0.014177371747791767
Loss at batch 270 : 0.021835502237081528
Loss at batch 280 : 0.011185680516064167
Loss at batch 290 : 0.010638349689543247
Loss at batch 300 : 0.017387066036462784
Loss at batch 310 : 0.007635268848389387
Loss at batch 320 : 0.01151476614177227
Loss at batch 330 : 0.010804013349115849
Loss at batch 340 : 0.010003547184169292
Loss at batch 350 : 0.012144479900598526
Loss at batch 360 : 0.019388191401958466
Loss at batch 370 : 0.012787418439984322
epoch185 finished!
Loss at batch 10 : 0.009697659872472286
Loss at batch 20 : 0.0158710777759552
Loss at batch 30 : 0.011601508595049381
Loss at batch 40 : 0.014048134908080101
Loss at batch 50 : 0.015102550387382507
Loss at batch 60 : 0.010567332617938519
Loss at batch 70 : 0.014987482689321041
Loss at batch 80 : 0.011265378445386887
Loss at batch 90 : 0.021648142486810684
Loss at batch 100 : 0.018328189849853516
Loss at batch 110 : 0.012399725615978241
Loss at batch 120 : 0.011940794996917248
Loss at batch 130 : 0.02114776521921158
Loss at batch 140 : 0.02477850578725338
Loss at batch 150 : 0.014331898652017117
Loss at batch 160 : 0.01071132067590952
Loss at batch 170 : 0.00932733342051506
Loss at batch 180 : 0.011534652672708035
Loss at batch 190 : 0.015026212669909
Loss at batch 200 : 0.010338124819099903
Loss at batch 210 : 0.02959720976650715
Loss at batch 220 : 0.010658279992640018
Loss at batch 230 : 0.0073759229853749275
Loss at batch 240 : 0.006931031588464975
Loss at batch 250 : 0.022719528526067734
Loss at batch 260 : 0.022595388814806938
Loss at batch 270 : 0.0058878520503640175
Loss at batch 280 : 0.011843649670481682
Loss at batch 290 : 0.018657999113202095
Loss at batch 300 : 0.020297758281230927
Loss at batch 310 : 0.011095982976257801
Loss at batch 320 : 0.012742195278406143
Loss at batch 330 : 0.010816873051226139
Loss at batch 340 : 0.01040404848754406
Loss at batch 350 : 0.017217885702848434
Loss at batch 360 : 0.015280334278941154
Loss at batch 370 : 0.018853861838579178
epoch186 finished!
Loss at batch 10 : 0.00659379456192255
Loss at batch 20 : 0.012549931183457375
Loss at batch 30 : 0.012865808792412281
Loss at batch 40 : 0.012080008164048195
Loss at batch 50 : 0.01226620003581047
Loss at batch 60 : 0.010809998027980328
Loss at batch 70 : 0.01737469807267189
Loss at batch 80 : 0.016896001994609833
Loss at batch 90 : 0.00790337286889553
Loss at batch 100 : 0.012335277162492275
Loss at batch 110 : 0.025006642565131187
Loss at batch 120 : 0.011785637587308884
Loss at batch 130 : 0.013839900493621826
Loss at batch 140 : 0.008549779653549194
Loss at batch 150 : 0.018811006098985672
Loss at batch 160 : 0.019859297201037407
Loss at batch 170 : 0.023706352338194847
Loss at batch 180 : 0.011491167359054089
Loss at batch 190 : 0.020570896565914154
Loss at batch 200 : 0.013726525940001011
Loss at batch 210 : 0.01411572378128767
Loss at batch 220 : 0.015059293247759342
Loss at batch 230 : 0.013369888998568058
Loss at batch 240 : 0.021289415657520294
Loss at batch 250 : 0.012606418691575527
Loss at batch 260 : 0.02860948070883751
Loss at batch 270 : 0.016456471756100655
Loss at batch 280 : 0.017217855900526047
Loss at batch 290 : 0.02181304432451725
Loss at batch 300 : 0.007845574989914894
Loss at batch 310 : 0.017072055488824844
Loss at batch 320 : 0.012043625116348267
Loss at batch 330 : 0.01739531010389328
Loss at batch 340 : 0.022894520312547684
Loss at batch 350 : 0.006401348393410444
Loss at batch 360 : 0.011478615924715996
Loss at batch 370 : 0.019319286569952965
epoch85 finished!
Loss at batch 10 : 0.017077457159757614
Loss at batch 20 : 0.010349510237574577
Loss at batch 30 : 0.021028824150562286
Loss at batch 40 : 0.007930951192975044
Loss at batch 50 : 0.009736312553286552
Loss at batch 60 : 0.014827459119260311
Loss at batch 70 : 0.012194432318210602
Loss at batch 80 : 0.012251378037035465
Loss at batch 90 : 0.01272746454924345
Loss at batch 100 : 0.007774500176310539
Loss at batch 110 : 0.011727625504136086
Loss at batch 120 : 0.014289485290646553
Loss at batch 130 : 0.013183058239519596
Loss at batch 140 : 0.01150695700198412
Loss at batch 150 : 0.009948419407010078
Loss at batch 160 : 0.018918313086032867
Loss at batch 170 : 0.020786721259355545
Loss at batch 180 : 0.008993132039904594
Loss at batch 190 : 0.02082720957696438
Loss at batch 200 : 0.01120613794773817
Loss at batch 210 : 0.012175669893622398
Loss at batch 220 : 0.007237304002046585
Loss at batch 230 : 0.014659923501312733
Loss at batch 240 : 0.009563243947923183
Loss at batch 250 : 0.012599595822393894
Loss at batch 260 : 0.008247488178312778
Loss at batch 270 : 0.013756477274000645
Loss at batch 280 : 0.01515482272952795
Loss at batch 290 : 0.017888829112052917
Loss at batch 300 : 0.01695207692682743
Loss at batch 310 : 0.008473259396851063
Loss at batch 320 : 0.007551976013928652
Loss at batch 330 : 0.010309885255992413
Loss at batch 340 : 0.014003818854689598
Loss at batch 350 : 0.010697337798774242
Loss at batch 360 : 0.021382229402661324
Loss at batch 370 : 0.018737344071269035
epoch85 finished!
Loss at batch 10 : 0.026957405731081963
Loss at batch 20 : 0.016214553266763687
Loss at batch 30 : 0.007399612106382847
Loss at batch 40 : 0.016631130129098892
Loss at batch 50 : 0.019879743456840515
Loss at batch 60 : 0.013302349485456944
Loss at batch 70 : 0.012520702555775642
Loss at batch 80 : 0.01227961853146553
Loss at batch 90 : 0.011322402395308018
Loss at batch 100 : 0.014579360373318195
Loss at batch 110 : 0.013511762022972107
Loss at batch 120 : 0.020030435174703598
Loss at batch 130 : 0.012209468521177769
Loss at batch 140 : 0.020747575908899307
Loss at batch 150 : 0.011954473331570625
Loss at batch 160 : 0.016440236940979958
Loss at batch 170 : 0.008116395212709904
Loss at batch 180 : 0.009610911831259727
Loss at batch 190 : 0.008511200547218323
Loss at batch 200 : 0.01068619079887867
Loss at batch 210 : 0.008845324628055096
Loss at batch 220 : 0.02724694088101387
Loss at batch 230 : 0.01348552294075489
Loss at batch 240 : 0.015264810062944889
Loss at batch 250 : 0.021940192207694054
Loss at batch 260 : 0.018110478296875954
Loss at batch 270 : 0.008809803053736687
Loss at batch 280 : 0.011641347780823708
Loss at batch 290 : 0.012261323630809784
Loss at batch 300 : 0.011782790534198284
Loss at batch 310 : 0.013470422476530075
Loss at batch 320 : 0.005808148067444563
Loss at batch 330 : 0.01575167290866375
Loss at batch 340 : 0.006558526307344437
Loss at batch 350 : 0.007783559150993824
Loss at batch 360 : 0.013789192773401737
Loss at batch 370 : 0.012819737195968628
epoch187 finished!
Loss at batch 10 : 0.01519765891134739
Loss at batch 20 : 0.012354999780654907
Loss at batch 30 : 0.016811562702059746
Loss at batch 40 : 0.01607685163617134
Loss at batch 50 : 0.01990552619099617
Loss at batch 60 : 0.01281725149601698
Loss at batch 70 : 0.012347670271992683
Loss at batch 80 : 0.011976178735494614
Loss at batch 90 : 0.02221933752298355
Loss at batch 100 : 0.013926158659160137
Loss at batch 110 : 0.008238881826400757
Loss at batch 120 : 0.018206022679805756
Loss at batch 130 : 0.012556114234030247
Loss at batch 140 : 0.008316878229379654
Loss at batch 150 : 0.024009743705391884
Loss at batch 160 : 0.014824948273599148
Loss at batch 170 : 0.016809659078717232
Loss at batch 180 : 0.014344180934131145
Loss at batch 190 : 0.02000073716044426
Loss at batch 200 : 0.009552669711411
Loss at batch 210 : 0.006475595757365227
Loss at batch 220 : 0.02092045731842518
Loss at batch 230 : 0.02273532748222351
Loss at batch 240 : 0.017269408330321312
Loss at batch 250 : 0.01526931393891573
Loss at batch 260 : 0.015101590193808079
Loss at batch 270 : 0.011677778325974941
Loss at batch 280 : 0.014431321993470192
Loss at batch 290 : 0.015543493442237377
Loss at batch 300 : 0.008696641772985458
Loss at batch 310 : 0.02399061806499958
Loss at batch 320 : 0.011365127749741077
Loss at batch 330 : 0.01861114799976349
Loss at batch 340 : 0.01654766872525215
Loss at batch 350 : 0.011820774525403976
Loss at batch 360 : 0.009091903455555439
Loss at batch 370 : 0.01421402208507061
epoch188 finished!
Loss at batch 10 : 0.013471276499330997
Loss at batch 20 : 0.02631084993481636
Loss at batch 30 : 0.016242317855358124
Loss at batch 40 : 0.012589127756655216
Loss at batch 50 : 0.012410509400069714
Loss at batch 60 : 0.011423325166106224
Loss at batch 70 : 0.009200948290526867
Loss at batch 80 : 0.0110778221860528
Loss at batch 90 : 0.026759332045912743
Loss at batch 100 : 0.007696115877479315
Loss at batch 110 : 0.009784425608813763
Loss at batch 120 : 0.013094301335513592
Loss at batch 130 : 0.017743844538927078
Loss at batch 140 : 0.021505363285541534
Loss at batch 150 : 0.008652931079268456
Loss at batch 160 : 0.022066481411457062
Loss at batch 170 : 0.01697276346385479
Loss at batch 180 : 0.014822756871581078
Loss at batch 190 : 0.011743311770260334
Loss at batch 200 : 0.016172189265489578
Loss at batch 210 : 0.010382137261331081
Loss at batch 220 : 0.016036882996559143
Loss at batch 230 : 0.015699420124292374
Loss at batch 240 : 0.01230860035866499
Loss at batch 250 : 0.015954595059156418
Loss at batch 260 : 0.013966003432869911
Loss at batch 270 : 0.013521774671971798
Loss at batch 280 : 0.01604929380118847
Loss at batch 290 : 0.011568259447813034
Loss at batch 300 : 0.017601968720555305
Loss at batch 310 : 0.015861693769693375
Loss at batch 320 : 0.01693764142692089
Loss at batch 330 : 0.011254183948040009
Loss at batch 340 : 0.011967502534389496
Loss at batch 350 : 0.012303940020501614
Loss at batch 360 : 0.01148159708827734
Loss at batch 370 : 0.014315726235508919
epoch86 finished!
Loss at batch 10 : 0.014529671519994736
Loss at batch 20 : 0.01485084556043148
Loss at batch 30 : 0.019778285175561905
Loss at batch 40 : 0.013630188070237637
Loss at batch 50 : 0.006977096199989319
Loss at batch 60 : 0.008223527111113071
Loss at batch 70 : 0.013769405893981457
Loss at batch 80 : 0.009808252565562725
Loss at batch 90 : 0.009063531644642353
Loss at batch 100 : 0.020330306142568588
Loss at batch 110 : 0.02272828482091427
Loss at batch 120 : 0.020910965278744698
Loss at batch 130 : 0.011123919859528542
Loss at batch 140 : 0.01880508102476597
Loss at batch 150 : 0.008982888422906399
Loss at batch 160 : 0.01548332441598177
Loss at batch 170 : 0.01451659481972456
Loss at batch 180 : 0.010276786983013153
Loss at batch 190 : 0.017498064786195755
Loss at batch 200 : 0.0182937104254961
Loss at batch 210 : 0.01372363232076168
Loss at batch 220 : 0.015731966122984886
Loss at batch 230 : 0.018934717401862144
Loss at batch 240 : 0.01690717600286007
Loss at batch 250 : 0.016623038798570633
Loss at batch 260 : 0.015988627448678017
Loss at batch 270 : 0.01001452561467886
Loss at batch 280 : 0.01401749812066555
Loss at batch 290 : 0.015275589190423489
Loss at batch 300 : 0.014961388893425465
Loss at batch 310 : 0.01605028472840786
Loss at batch 320 : 0.013216400519013405
Loss at batch 330 : 0.027348514646291733
Loss at batch 340 : 0.015351571142673492
Loss at batch 350 : 0.009483937174081802
Loss at batch 360 : 0.010741514153778553
Loss at batch 370 : 0.012365739792585373
epoch86 finished!
Loss at batch 10 : 0.007789916824549437
Loss at batch 20 : 0.018321577459573746
Loss at batch 30 : 0.009027858264744282
Loss at batch 40 : 0.014875819906592369
Loss at batch 50 : 0.0091280248016119
Loss at batch 60 : 0.019134147092700005
Loss at batch 70 : 0.019547009840607643
Loss at batch 80 : 0.011045313440263271
Loss at batch 90 : 0.011042317375540733
Loss at batch 100 : 0.007256232667714357
Loss at batch 110 : 0.015714919194579124
Loss at batch 120 : 0.021499916911125183
Loss at batch 130 : 0.012949619442224503
Loss at batch 140 : 0.00806083157658577
Loss at batch 150 : 0.006524038501083851
Loss at batch 160 : 0.013083826750516891
Loss at batch 170 : 0.01676863618195057
Loss at batch 180 : 0.014756337739527225
Loss at batch 190 : 0.01783090829849243
Loss at batch 200 : 0.013192766346037388
Loss at batch 210 : 0.007763681933283806
Loss at batch 220 : 0.023824401199817657
Loss at batch 230 : 0.015983138233423233
Loss at batch 240 : 0.01484599243849516
Loss at batch 250 : 0.012203105725347996
Loss at batch 260 : 0.009521382860839367
Loss at batch 270 : 0.007092037703841925
Loss at batch 280 : 0.01667330041527748
Loss at batch 290 : 0.013935472816228867
Loss at batch 300 : 0.014949348755180836
Loss at batch 310 : 0.015715105459094048
Loss at batch 320 : 0.010054400190711021
Loss at batch 330 : 0.007570372428745031
Loss at batch 340 : 0.022276056930422783
Loss at batch 350 : 0.008214008063077927
Loss at batch 360 : 0.0063452511094510555
Loss at batch 370 : 0.011266588233411312
epoch189 finished!
Loss at batch 10 : 0.01935053989291191
Loss at batch 20 : 0.022647570818662643
Loss at batch 30 : 0.02580568939447403
Loss at batch 40 : 0.009152508340775967
Loss at batch 50 : 0.015312569215893745
Loss at batch 60 : 0.020668432116508484
Loss at batch 70 : 0.011575798504054546
Loss at batch 80 : 0.011586420238018036
Loss at batch 90 : 0.016115175560116768
Loss at batch 100 : 0.012398210354149342
Loss at batch 110 : 0.010133795440196991
Loss at batch 120 : 0.006632209289819002
Loss at batch 130 : 0.01586342416703701
Loss at batch 140 : 0.00781875941902399
Loss at batch 150 : 0.013836589641869068
Loss at batch 160 : 0.02259998396039009
Loss at batch 170 : 0.01896239072084427
Loss at batch 180 : 0.02481044828891754
Loss at batch 190 : 0.009935307316482067
Loss at batch 200 : 0.010934580117464066
Loss at batch 210 : 0.007662807125598192
Loss at batch 220 : 0.016383057460188866
Loss at batch 230 : 0.010214639827609062
Loss at batch 240 : 0.010174715891480446
Loss at batch 250 : 0.014949616976082325
Loss at batch 260 : 0.016962001100182533
Loss at batch 270 : 0.012046078220009804
Loss at batch 280 : 0.009363037534058094
Loss at batch 290 : 0.02103564329445362
Loss at batch 300 : 0.01935930922627449
Loss at batch 310 : 0.013052321970462799
Loss at batch 320 : 0.012728051282465458
Loss at batch 330 : 0.0197867751121521
Loss at batch 340 : 0.014381051063537598
Loss at batch 350 : 0.017131127417087555
Loss at batch 360 : 0.0310729518532753
Loss at batch 370 : 0.008994831703603268
epoch190 finished!
Loss at batch 10 : 0.010327981784939766
Loss at batch 20 : 0.024589328095316887
Loss at batch 30 : 0.009636791422963142
Loss at batch 40 : 0.017980631440877914
Loss at batch 50 : 0.015284629538655281
Loss at batch 60 : 0.010985752567648888
Loss at batch 70 : 0.016280166804790497
Loss at batch 80 : 0.009379206225275993
Loss at batch 90 : 0.020970121026039124
Loss at batch 100 : 0.01261964812874794
Loss at batch 110 : 0.023645231500267982
Loss at batch 120 : 0.025565767660737038
Loss at batch 130 : 0.013835238292813301
Loss at batch 140 : 0.014692489057779312
Loss at batch 150 : 0.01783875748515129
Loss at batch 160 : 0.016276784241199493
Loss at batch 170 : 0.01232948899269104
Loss at batch 180 : 0.012218132615089417
Loss at batch 190 : 0.010617951862514019
Loss at batch 200 : 0.009635290130972862
Loss at batch 210 : 0.013368925079703331
Loss at batch 220 : 0.011484469287097454
Loss at batch 230 : 0.02251371741294861
Loss at batch 240 : 0.02208385057747364
Loss at batch 250 : 0.011737368069589138
Loss at batch 260 : 0.017088979482650757
Loss at batch 270 : 0.01414658036082983
Loss at batch 280 : 0.025960424914956093
Loss at batch 290 : 0.014051240868866444
Loss at batch 300 : 0.012508662417531013
Loss at batch 310 : 0.01401716098189354
Loss at batch 320 : 0.015626607462763786
Loss at batch 330 : 0.0188295841217041
Loss at batch 340 : 0.011875305324792862
Loss at batch 350 : 0.012774833478033543
Loss at batch 360 : 0.018388189375400543
Loss at batch 370 : 0.03214535489678383
epoch87 finished!
Loss at batch 10 : 0.01567918062210083
Loss at batch 20 : 0.008150958456099033
Loss at batch 30 : 0.011783167719841003
Loss at batch 40 : 0.02363300882279873
Loss at batch 50 : 0.01683773286640644
Loss at batch 60 : 0.014508957043290138
Loss at batch 70 : 0.013834292069077492
Loss at batch 80 : 0.011978765949606895
Loss at batch 90 : 0.012562043964862823
Loss at batch 100 : 0.010049727745354176
Loss at batch 110 : 0.014566361904144287
Loss at batch 120 : 0.014620400033891201
Loss at batch 130 : 0.010481711477041245
Loss at batch 140 : 0.010526706464588642
Loss at batch 150 : 0.013569538481533527
Loss at batch 160 : 0.010749515146017075
Loss at batch 170 : 0.016587190330028534
Loss at batch 180 : 0.008385328575968742
Loss at batch 190 : 0.010022900998592377
Loss at batch 200 : 0.01003003679215908
Loss at batch 210 : 0.020007139071822166
Loss at batch 220 : 0.008095687255263329
Loss at batch 230 : 0.00966104306280613
Loss at batch 240 : 0.015649858862161636
Loss at batch 250 : 0.034353528171777725
Loss at batch 260 : 0.009178262203931808
Loss at batch 270 : 0.01545330323278904
Loss at batch 280 : 0.019067464396357536
Loss at batch 290 : 0.019474316388368607
Loss at batch 300 : 0.014114044606685638
Loss at batch 310 : 0.023575471714138985
Loss at batch 320 : 0.013808287680149078
Loss at batch 330 : 0.007250296883285046
Loss at batch 340 : 0.015260614454746246
Loss at batch 350 : 0.01382224541157484
Loss at batch 360 : 0.011708120815455914
Loss at batch 370 : 0.01496894657611847
epoch87 finished!
Loss at batch 10 : 0.014455132186412811
Loss at batch 20 : 0.01887362264096737
Loss at batch 30 : 0.011230864562094212
Loss at batch 40 : 0.011449780315160751
Loss at batch 50 : 0.010276148095726967
Loss at batch 60 : 0.010144139640033245
Loss at batch 70 : 0.007067147642374039
Loss at batch 80 : 0.009814399294555187
Loss at batch 90 : 0.020206982269883156
Loss at batch 100 : 0.008495009504258633
Loss at batch 110 : 0.009395275264978409
Loss at batch 120 : 0.009747227653861046
Loss at batch 130 : 0.017187103629112244
Loss at batch 140 : 0.01885225623846054
Loss at batch 150 : 0.01456620916724205
Loss at batch 160 : 0.014655613340437412
Loss at batch 170 : 0.010716810822486877
Loss at batch 180 : 0.012073877267539501
Loss at batch 190 : 0.021787356585264206
Loss at batch 200 : 0.015661563724279404
Loss at batch 210 : 0.00970345176756382
Loss at batch 220 : 0.015099161304533482
Loss at batch 230 : 0.009558799676597118
Loss at batch 240 : 0.012976299040019512
Loss at batch 250 : 0.012323540635406971
Loss at batch 260 : 0.01217490341514349
Loss at batch 270 : 0.016997646540403366
Loss at batch 280 : 0.009208833798766136
Loss at batch 290 : 0.014275584369897842
Loss at batch 300 : 0.01322582084685564
Loss at batch 310 : 0.014276825822889805
Loss at batch 320 : 0.013517124578356743
Loss at batch 330 : 0.00937528908252716
Loss at batch 340 : 0.014731340110301971
Loss at batch 350 : 0.010690686292946339
Loss at batch 360 : 0.016846461221575737
Loss at batch 370 : 0.01912551559507847
epoch191 finished!
Loss at batch 10 : 0.011933956295251846
Loss at batch 20 : 0.013100828044116497
Loss at batch 30 : 0.01223864033818245
Loss at batch 40 : 0.012836005538702011
Loss at batch 50 : 0.010176895186305046
Loss at batch 60 : 0.006247933022677898
Loss at batch 70 : 0.01618071272969246
Loss at batch 80 : 0.021355491131544113
Loss at batch 90 : 0.013658871874213219
Loss at batch 100 : 0.022045288234949112
Loss at batch 110 : 0.015520685352385044
Loss at batch 120 : 0.016616789624094963
Loss at batch 130 : 0.0352657288312912
Loss at batch 140 : 0.01944141276180744
Loss at batch 150 : 0.018903804942965508
Loss at batch 160 : 0.007292500231415033
Loss at batch 170 : 0.01740516722202301
Loss at batch 180 : 0.013876250013709068
Loss at batch 190 : 0.009909449145197868
Loss at batch 200 : 0.017360808327794075
Loss at batch 210 : 0.006459468510001898
Loss at batch 220 : 0.01537159364670515
Loss at batch 230 : 0.010958729311823845
Loss at batch 240 : 0.010329351760447025
Loss at batch 250 : 0.010091069154441357
Loss at batch 260 : 0.010733697563409805
Loss at batch 270 : 0.013713900931179523
Loss at batch 280 : 0.01557718962430954
Loss at batch 290 : 0.018428273499011993
Loss at batch 300 : 0.010654288344085217
Loss at batch 310 : 0.010199935175478458
Loss at batch 320 : 0.015115119516849518
Loss at batch 330 : 0.015098010189831257
Loss at batch 340 : 0.013885419815778732
Loss at batch 350 : 0.014909302815794945
Loss at batch 360 : 0.011868716217577457
Loss at batch 370 : 0.006998218595981598
epoch192 finished!
Loss at batch 10 : 0.01598287746310234
Loss at batch 20 : 0.011574163101613522
Loss at batch 30 : 0.030327940359711647
Loss at batch 40 : 0.011720733717083931
Loss at batch 50 : 0.0225151889026165
Loss at batch 60 : 0.008106735534965992
Loss at batch 70 : 0.01340754609555006
Loss at batch 80 : 0.009278882294893265
Loss at batch 90 : 0.018335504457354546
Loss at batch 100 : 0.008579396642744541
Loss at batch 110 : 0.017630737274885178
Loss at batch 120 : 0.013954969123005867
Loss at batch 130 : 0.011627871543169022
Loss at batch 140 : 0.01808258332312107
Loss at batch 150 : 0.01420739758759737
Loss at batch 160 : 0.01477857306599617
Loss at batch 170 : 0.008856458589434624
Loss at batch 180 : 0.014965892769396305
Loss at batch 190 : 0.031758587807416916
Loss at batch 200 : 0.020397096872329712
Loss at batch 210 : 0.014027915894985199
Loss at batch 220 : 0.011040177196264267
Loss at batch 230 : 0.015337159857153893
Loss at batch 240 : 0.01223353948444128
Loss at batch 250 : 0.018006538972258568
Loss at batch 260 : 0.01005912572145462
Loss at batch 270 : 0.018430070951581
Loss at batch 280 : 0.0118908965960145
Loss at batch 290 : 0.012105782516300678
Loss at batch 300 : 0.009312317706644535
Loss at batch 310 : 0.017557060346007347
Loss at batch 320 : 0.008828635327517986
Loss at batch 330 : 0.012267481535673141
Loss at batch 340 : 0.0126970699056983
Loss at batch 350 : 0.019995544105768204
Loss at batch 360 : 0.016157716512680054
Loss at batch 370 : 0.011332862079143524
epoch88 finished!
Loss at batch 10 : 0.01967228390276432
Loss at batch 20 : 0.019048821181058884
Loss at batch 30 : 0.025300171226263046
Loss at batch 40 : 0.0151605736464262
Loss at batch 50 : 0.012949172407388687
Loss at batch 60 : 0.026917079463601112
Loss at batch 70 : 0.023012729361653328
Loss at batch 80 : 0.01291434932500124
Loss at batch 90 : 0.025550898164510727
Loss at batch 100 : 0.01812645047903061
Loss at batch 110 : 0.020572880282998085
Loss at batch 120 : 0.010700982995331287
Loss at batch 130 : 0.006613084115087986
Loss at batch 140 : 0.00930831115692854
Loss at batch 150 : 0.015736084431409836
Loss at batch 160 : 0.016551125794649124
Loss at batch 170 : 0.010019302368164062
Loss at batch 180 : 0.017648130655288696
Loss at batch 190 : 0.015196684747934341
Loss at batch 200 : 0.014664107002317905
Loss at batch 210 : 0.019135041162371635
Loss at batch 220 : 0.015934789553284645
Loss at batch 230 : 0.009441005066037178
Loss at batch 240 : 0.008989016525447369
Loss at batch 250 : 0.017248239368200302
Loss at batch 260 : 0.021045740693807602
Loss at batch 270 : 0.014667647890746593
Loss at batch 280 : 0.008328067138791084
Loss at batch 290 : 0.008855339139699936
Loss at batch 300 : 0.009542140178382397
Loss at batch 310 : 0.00821700319647789
Loss at batch 320 : 0.0058105941861867905
Loss at batch 330 : 0.013562147505581379
Loss at batch 340 : 0.017918024212121964
Loss at batch 350 : 0.014200707897543907
Loss at batch 360 : 0.017834778875112534
Loss at batch 370 : 0.00946918223053217
epoch88 finished!
Loss at batch 10 : 0.010692342184484005
Loss at batch 20 : 0.012662663124501705
Loss at batch 30 : 0.010621858760714531
Loss at batch 40 : 0.011526498012244701
Loss at batch 50 : 0.01166497077792883
Loss at batch 60 : 0.00782163068652153
Loss at batch 70 : 0.009780652821063995
Loss at batch 80 : 0.017062218859791756
Loss at batch 90 : 0.006450684275478125
Loss at batch 100 : 0.01018600258976221
Loss at batch 110 : 0.023114999756217003
Loss at batch 120 : 0.01406172662973404
Loss at batch 130 : 0.021829187870025635
Loss at batch 140 : 0.013470561243593693
Loss at batch 150 : 0.015114568173885345
Loss at batch 160 : 0.01586243137717247
Loss at batch 170 : 0.012827317230403423
Loss at batch 180 : 0.011148937977850437
Loss at batch 190 : 0.012307276949286461
Loss at batch 200 : 0.012114531360566616
Loss at batch 210 : 0.01396512147039175
Loss at batch 220 : 0.022136345505714417
Loss at batch 230 : 0.010362165048718452
Loss at batch 240 : 0.009866702370345592
Loss at batch 250 : 0.022569430992007256
Loss at batch 260 : 0.016213124617934227
Loss at batch 270 : 0.009985134936869144
Loss at batch 280 : 0.01208504382520914
Loss at batch 290 : 0.014198469929397106
Loss at batch 300 : 0.013660633005201817
Loss at batch 310 : 0.00791591964662075
Loss at batch 320 : 0.01037633791565895
Loss at batch 330 : 0.014827259816229343
Loss at batch 340 : 0.021177586168050766
Loss at batch 350 : 0.020826760679483414
Loss at batch 360 : 0.023167351260781288
Loss at batch 370 : 0.011386600323021412
epoch193 finished!
Loss at batch 10 : 0.007623941171914339
Loss at batch 20 : 0.0210111066699028
Loss at batch 30 : 0.016255084425210953
Loss at batch 40 : 0.01636814884841442
Loss at batch 50 : 0.014280661940574646
Loss at batch 60 : 0.011252677999436855
Loss at batch 70 : 0.01644960604608059
Loss at batch 80 : 0.015455922111868858
Loss at batch 90 : 0.013109749183058739
Loss at batch 100 : 0.007589306682348251
Loss at batch 110 : 0.014327817596495152
Loss at batch 120 : 0.015236422419548035
Loss at batch 130 : 0.010374852456152439
Loss at batch 140 : 0.016249001026153564
Loss at batch 150 : 0.018969621509313583
Loss at batch 160 : 0.011554940603673458
Loss at batch 170 : 0.014091120101511478
Loss at batch 180 : 0.014902481809258461
Loss at batch 190 : 0.014859197661280632
Loss at batch 200 : 0.01474824734032154
Loss at batch 210 : 0.02469274401664734
Loss at batch 220 : 0.016185715794563293
Loss at batch 230 : 0.009628307074308395
Loss at batch 240 : 0.02148928865790367
Loss at batch 250 : 0.02523987740278244
Loss at batch 260 : 0.014261502772569656
Loss at batch 270 : 0.013259273022413254
Loss at batch 280 : 0.017433617264032364
Loss at batch 290 : 0.03496754541993141
Loss at batch 300 : 0.014228494837880135
Loss at batch 310 : 0.013371041975915432
Loss at batch 320 : 0.01622893288731575
Loss at batch 330 : 0.01479782909154892
Loss at batch 340 : 0.014373461715877056
Loss at batch 350 : 0.011217983439564705
Loss at batch 360 : 0.02412472665309906
Loss at batch 370 : 0.014324717223644257
epoch194 finished!
Loss at batch 10 : 0.01560290902853012
Loss at batch 20 : 0.008942772634327412
Loss at batch 30 : 0.010163677856326103
Loss at batch 40 : 0.015463101677596569
Loss at batch 50 : 0.021753527224063873
Loss at batch 60 : 0.021125417202711105
Loss at batch 70 : 0.0111599862575531
Loss at batch 80 : 0.012753232382237911
Loss at batch 90 : 0.012783762998878956
Loss at batch 100 : 0.013902577571570873
Loss at batch 110 : 0.011335723102092743
Loss at batch 120 : 0.009733485989272594
Loss at batch 130 : 0.02276882715523243
Loss at batch 140 : 0.011125151999294758
Loss at batch 150 : 0.02219865657389164
Loss at batch 160 : 0.017079506069421768
Loss at batch 170 : 0.012573258019983768
Loss at batch 180 : 0.024243267253041267
Loss at batch 190 : 0.013086936436593533
Loss at batch 200 : 0.01579318381845951
Loss at batch 210 : 0.024060409516096115
Loss at batch 220 : 0.009651976637542248
Loss at batch 230 : 0.01887914538383484
Loss at batch 240 : 0.0076470389030873775
Loss at batch 250 : 0.011027565225958824
Loss at batch 260 : 0.012127499096095562
Loss at batch 270 : 0.006285103969275951
Loss at batch 280 : 0.014278064481914043
Loss at batch 290 : 0.013883113861083984
Loss at batch 300 : 0.013696443289518356
Loss at batch 310 : 0.014673036523163319
Loss at batch 320 : 0.012374001555144787
Loss at batch 330 : 0.008938325569033623
Loss at batch 340 : 0.01627304032444954
Loss at batch 350 : 0.009916401468217373
Loss at batch 360 : 0.013814644888043404
Loss at batch 370 : 0.012788504362106323
epoch89 finished!
Loss at batch 10 : 0.014249742962419987
Loss at batch 20 : 0.012901857495307922
Loss at batch 30 : 0.019686222076416016
Loss at batch 40 : 0.022327877581119537
Loss at batch 50 : 0.012526950798928738
Loss at batch 60 : 0.02343764528632164
Loss at batch 70 : 0.01595035009086132
Loss at batch 80 : 0.02330116741359234
Loss at batch 90 : 0.014857256785035133
Loss at batch 100 : 0.010694730095565319
Loss at batch 110 : 0.018691079691052437
Loss at batch 120 : 0.015188934281468391
Loss at batch 130 : 0.013065668754279613
Loss at batch 140 : 0.01408362202346325
Loss at batch 150 : 0.011347582563757896
Loss at batch 160 : 0.009216283448040485
Loss at batch 170 : 0.009389134123921394
Loss at batch 180 : 0.011580576188862324
Loss at batch 190 : 0.0117076700553298
Loss at batch 200 : 0.01648963801562786
Loss at batch 210 : 0.03205028548836708
Loss at batch 220 : 0.01396599318832159
Loss at batch 230 : 0.01305101066827774
Loss at batch 240 : 0.011824894696474075
Loss at batch 250 : 0.009602180682122707
Loss at batch 260 : 0.011121613904833794
Loss at batch 270 : 0.012136440724134445
Loss at batch 280 : 0.015814637765288353
Loss at batch 290 : 0.0127012450248003
Loss at batch 300 : 0.014918581582605839
Loss at batch 310 : 0.009197351522743702
Loss at batch 320 : 0.0080408975481987
Loss at batch 330 : 0.013903997838497162
Loss at batch 340 : 0.010112544521689415
Loss at batch 350 : 0.00927099958062172
Loss at batch 360 : 0.01110121887177229
Loss at batch 370 : 0.012642057612538338
epoch195 finished!
Loss at batch 10 : 0.021041667088866234
Loss at batch 20 : 0.015166688710451126
Loss at batch 30 : 0.012795418500900269
Loss at batch 40 : 0.016221247613430023
Loss at batch 50 : 0.0076538631692528725
Loss at batch 60 : 0.012279544025659561
Loss at batch 70 : 0.01576717011630535
Loss at batch 80 : 0.01727874018251896
Loss at batch 90 : 0.01670393906533718
Loss at batch 100 : 0.010601089335978031
Loss at batch 110 : 0.01130388118326664
Loss at batch 120 : 0.015402722172439098
Loss at batch 130 : 0.009844235144555569
Loss at batch 140 : 0.00995271559804678
Loss at batch 150 : 0.02530585788190365
Loss at batch 160 : 0.014302262105047703
Loss at batch 170 : 0.02137678489089012
Loss at batch 180 : 0.017667924985289574
Loss at batch 190 : 0.023387914523482323
Loss at batch 200 : 0.015892939642071724
Loss at batch 210 : 0.012873994186520576
Loss at batch 220 : 0.007861881516873837
Loss at batch 230 : 0.022969966754317284
Loss at batch 240 : 0.027333976700901985
Loss at batch 250 : 0.017041029408574104
Loss at batch 260 : 0.01159397792071104
Loss at batch 270 : 0.014114776626229286
Loss at batch 280 : 0.01022548507899046
Loss at batch 290 : 0.02048921398818493
Loss at batch 300 : 0.02204344980418682
Loss at batch 310 : 0.018787646666169167
Loss at batch 320 : 0.03336266055703163
Loss at batch 330 : 0.012937529943883419
Loss at batch 340 : 0.015101790428161621
Loss at batch 350 : 0.012149285525083542
Loss at batch 360 : 0.009410848841071129
Loss at batch 370 : 0.01301567256450653
epoch89 finished!
Loss at batch 10 : 0.008116739802062511
Loss at batch 20 : 0.007302052341401577
Loss at batch 30 : 0.01719675213098526
Loss at batch 40 : 0.024650489911437035
Loss at batch 50 : 0.010052518919110298
Loss at batch 60 : 0.01330603938549757
Loss at batch 70 : 0.015344111248850822
Loss at batch 80 : 0.01731734350323677
Loss at batch 90 : 0.007115858141332865
Loss at batch 100 : 0.013235646300017834
Loss at batch 110 : 0.012500601820647717
Loss at batch 120 : 0.0116990702226758
Loss at batch 130 : 0.013835329562425613
Loss at batch 140 : 0.01600274071097374
Loss at batch 150 : 0.012728722766041756
Loss at batch 160 : 0.012781704775989056
Loss at batch 170 : 0.01983543112874031
Loss at batch 180 : 0.013492691330611706
Loss at batch 190 : 0.021381141617894173
Loss at batch 200 : 0.023540202528238297
Loss at batch 210 : 0.014079895801842213
Loss at batch 220 : 0.018286997452378273
Loss at batch 230 : 0.01779451221227646
Loss at batch 240 : 0.03240752965211868
Loss at batch 250 : 0.017959363758563995
Loss at batch 260 : 0.014001265168190002
Loss at batch 270 : 0.011798863299190998
Loss at batch 280 : 0.010796947404742241
Loss at batch 290 : 0.006168398540467024
Loss at batch 300 : 0.008885265327990055
Loss at batch 310 : 0.020582016557455063
Loss at batch 320 : 0.010067017748951912
Loss at batch 330 : 0.017369892448186874
Loss at batch 340 : 0.017466450110077858
Loss at batch 350 : 0.012425804510712624
Loss at batch 360 : 0.015655426308512688
Loss at batch 370 : 0.012487515807151794
epoch196 finished!
Loss at batch 10 : 0.010719210840761662
Loss at batch 20 : 0.015619177371263504
Loss at batch 30 : 0.009497301653027534
Loss at batch 40 : 0.022129766643047333
Loss at batch 50 : 0.013025841675698757
Loss at batch 60 : 0.013866700232028961
Loss at batch 70 : 0.01623956859111786
Loss at batch 80 : 0.02013421803712845
Loss at batch 90 : 0.015458060428500175
Loss at batch 100 : 0.009931094944477081
Loss at batch 110 : 0.014514679089188576
Loss at batch 120 : 0.014086998999118805
Loss at batch 130 : 0.013430613093078136
Loss at batch 140 : 0.00906290952116251
Loss at batch 150 : 0.014986295253038406
Loss at batch 160 : 0.018615102395415306
Loss at batch 170 : 0.012377150356769562
Loss at batch 180 : 0.015249445103108883
Loss at batch 190 : 0.014527956023812294
Loss at batch 200 : 0.011818069033324718
Loss at batch 210 : 0.011025267653167248
Loss at batch 220 : 0.015593832358717918
Loss at batch 230 : 0.011494077742099762
Loss at batch 240 : 0.0100023802369833
Loss at batch 250 : 0.01154499314725399
Loss at batch 260 : 0.008222932927310467
Loss at batch 270 : 0.007521291263401508
Loss at batch 280 : 0.012057020328938961
Loss at batch 290 : 0.00582899060100317
Loss at batch 300 : 0.015146738849580288
Loss at batch 310 : 0.008442390710115433
Loss at batch 320 : 0.0148408692330122
Loss at batch 330 : 0.01933523267507553
Loss at batch 340 : 0.014776993542909622
Loss at batch 350 : 0.013538053259253502
Loss at batch 360 : 0.021122600883245468
Loss at batch 370 : 0.009329447522759438
epoch197 finished!
Loss at batch 10 : 0.01796027272939682
Loss at batch 20 : 0.007692570798099041
Loss at batch 30 : 0.016483506187796593
Loss at batch 40 : 0.008999943733215332
Loss at batch 50 : 0.014574186876416206
Loss at batch 60 : 0.010253130458295345
Loss at batch 70 : 0.009803121909499168
Loss at batch 80 : 0.025156386196613312
Loss at batch 90 : 0.015487121418118477
Loss at batch 100 : 0.01643386483192444
Loss at batch 110 : 0.01374735590070486
Loss at batch 120 : 0.012543905526399612
Loss at batch 130 : 0.016760850325226784
Loss at batch 140 : 0.017850369215011597
Loss at batch 150 : 0.02903420850634575
Loss at batch 160 : 0.009767894633114338
Loss at batch 170 : 0.020300908014178276
Loss at batch 180 : 0.013636786490678787
Loss at batch 190 : 0.02575189806520939
Loss at batch 200 : 0.01283138059079647
Loss at batch 210 : 0.030558370053768158
Loss at batch 220 : 0.01699749380350113
Loss at batch 230 : 0.021063435822725296
Loss at batch 240 : 0.015203543938696384
Loss at batch 250 : 0.017297280952334404
Loss at batch 260 : 0.012663946487009525
Loss at batch 270 : 0.009543978609144688
Loss at batch 280 : 0.018025148659944534
Loss at batch 290 : 0.02440533973276615
Loss at batch 300 : 0.010296815074980259
Loss at batch 310 : 0.017060663551092148
Loss at batch 320 : 0.011561065912246704
Loss at batch 330 : 0.01980856992304325
Loss at batch 340 : 0.020325208082795143
Loss at batch 350 : 0.012823865748941898
Loss at batch 360 : 0.01033482514321804
Loss at batch 370 : 0.021001014858484268
epoch90 finished!
Loss at batch 10 : 0.010080496780574322
Loss at batch 20 : 0.014339172281324863
Loss at batch 30 : 0.015436043962836266
Loss at batch 40 : 0.008634703233838081
Loss at batch 50 : 0.018541783094406128
Loss at batch 60 : 0.019030969589948654
Loss at batch 70 : 0.010841457173228264
Loss at batch 80 : 0.023044176399707794
Loss at batch 90 : 0.00985381007194519
Loss at batch 100 : 0.021858762949705124
Loss at batch 110 : 0.018416035920381546
Loss at batch 120 : 0.009206168353557587
Loss at batch 130 : 0.014159207232296467
Loss at batch 140 : 0.014267757534980774
Loss at batch 150 : 0.025173023343086243
Loss at batch 160 : 0.01889606937766075
Loss at batch 170 : 0.016348782926797867
Loss at batch 180 : 0.007132881321012974
Loss at batch 190 : 0.007946250960230827
Loss at batch 200 : 0.009360205382108688
Loss at batch 210 : 0.009527641348540783
Loss at batch 220 : 0.009790734387934208
Loss at batch 230 : 0.008412336930632591
Loss at batch 240 : 0.010298951528966427
Loss at batch 250 : 0.007938666269183159
Loss at batch 260 : 0.02635444886982441
Loss at batch 270 : 0.011493759229779243
Loss at batch 280 : 0.013178816065192223
Loss at batch 290 : 0.014671224169433117
Loss at batch 300 : 0.007746928837150335
Loss at batch 310 : 0.013437256217002869
Loss at batch 320 : 0.021063080057501793
Loss at batch 330 : 0.013575012795627117
Loss at batch 340 : 0.013277418911457062
Loss at batch 350 : 0.017665622755885124
Loss at batch 360 : 0.012472061440348625
Loss at batch 370 : 0.008923967368900776
epoch90 finished!
Loss at batch 10 : 0.020715799182653427
Loss at batch 20 : 0.01310914009809494
Loss at batch 30 : 0.02165498025715351
Loss at batch 40 : 0.013624989427626133
Loss at batch 50 : 0.023494726046919823
Loss at batch 60 : 0.013139873743057251
Loss at batch 70 : 0.019365688785910606
Loss at batch 80 : 0.01903502643108368
Loss at batch 90 : 0.013431633822619915
Loss at batch 100 : 0.01950215734541416
Loss at batch 110 : 0.012073949910700321
Loss at batch 120 : 0.009641198441386223
Loss at batch 130 : 0.01107931137084961
Loss at batch 140 : 0.010170970112085342
Loss at batch 150 : 0.017079388722777367
Loss at batch 160 : 0.012810461223125458
Loss at batch 170 : 0.008786281570792198
Loss at batch 180 : 0.015463958494365215
Loss at batch 190 : 0.009049237705767155
Loss at batch 200 : 0.009451261721551418
Loss at batch 210 : 0.011218993924558163
Loss at batch 220 : 0.013327947817742825
Loss at batch 230 : 0.01214631088078022
Loss at batch 240 : 0.011706736870110035
Loss at batch 250 : 0.013443841598927975
Loss at batch 260 : 0.009563473984599113
Loss at batch 270 : 0.011581902392208576
Loss at batch 280 : 0.019780965521931648
Loss at batch 290 : 0.012479359284043312
Loss at batch 300 : 0.010968820191919804
Loss at batch 310 : 0.012150313705205917
Loss at batch 320 : 0.023073265329003334
Loss at batch 330 : 0.009560341946780682
Loss at batch 340 : 0.013107182458043098
Loss at batch 350 : 0.009910841472446918
Loss at batch 360 : 0.014488521963357925
Loss at batch 370 : 0.007843743078410625
epoch198 finished!
Loss at batch 10 : 0.01415193360298872
Loss at batch 20 : 0.01566438004374504
Loss at batch 30 : 0.018635688349604607
Loss at batch 40 : 0.010317401960492134
Loss at batch 50 : 0.008046569302678108
Loss at batch 60 : 0.014303328469395638
Loss at batch 70 : 0.011834325268864632
Loss at batch 80 : 0.015768511220812798
Loss at batch 90 : 0.012808325700461864
Loss at batch 100 : 0.033153217285871506
Loss at batch 110 : 0.015413708984851837
Loss at batch 120 : 0.008583608083426952
Loss at batch 130 : 0.015082325786352158
Loss at batch 140 : 0.010555252432823181
Loss at batch 150 : 0.011849846690893173
Loss at batch 160 : 0.01661316677927971
Loss at batch 170 : 0.013878566212952137
Loss at batch 180 : 0.009733733721077442
Loss at batch 190 : 0.017622292041778564
Loss at batch 200 : 0.01179057639092207
Loss at batch 210 : 0.011819252744317055
Loss at batch 220 : 0.00992471445351839
Loss at batch 230 : 0.013887508772313595
Loss at batch 240 : 0.018967917189002037
Loss at batch 250 : 0.009883387014269829
Loss at batch 260 : 0.012181608006358147
Loss at batch 270 : 0.017767231911420822
Loss at batch 280 : 0.019267765805125237
Loss at batch 290 : 0.02350783534348011
Loss at batch 300 : 0.015948442742228508
Loss at batch 310 : 0.009992927312850952
Loss at batch 320 : 0.020417841151356697
Loss at batch 330 : 0.01463265810161829
Loss at batch 340 : 0.017818260937929153
Loss at batch 350 : 0.020456401631236076
Loss at batch 360 : 0.013207423500716686
Loss at batch 370 : 0.015849368646740913
epoch199 finished!
Loss at batch 10 : 0.014219021424651146
Loss at batch 20 : 0.01923205889761448
Loss at batch 30 : 0.015304053202271461
Loss at batch 40 : 0.019882019609212875
Loss at batch 50 : 0.00596322026103735
Loss at batch 60 : 0.01579548604786396
Loss at batch 70 : 0.022241469472646713
Loss at batch 80 : 0.014405622147023678
Loss at batch 90 : 0.011851039715111256
Loss at batch 100 : 0.01813119277358055
Loss at batch 110 : 0.008342760615050793
Loss at batch 120 : 0.01815803349018097
Loss at batch 130 : 0.012931213714182377
Loss at batch 140 : 0.010090366005897522
Loss at batch 150 : 0.012770933099091053
Loss at batch 160 : 0.014809465035796165
Loss at batch 170 : 0.013609962537884712
Loss at batch 180 : 0.03380948305130005
Loss at batch 190 : 0.022753814235329628
Loss at batch 200 : 0.012511128559708595
Loss at batch 210 : 0.014002126641571522
Loss at batch 220 : 0.011007155291736126
Loss at batch 230 : 0.03062277100980282
Loss at batch 240 : 0.016372550278902054
Loss at batch 250 : 0.010187199339270592
Loss at batch 260 : 0.009735073894262314
Loss at batch 270 : 0.015375684015452862
Loss at batch 280 : 0.023213637992739677
Loss at batch 290 : 0.014605870470404625
Loss at batch 300 : 0.013744876720011234
Loss at batch 310 : 0.014739032834768295
Loss at batch 320 : 0.01496592815965414
Loss at batch 330 : 0.02614511176943779
Loss at batch 340 : 0.010758758522570133
Loss at batch 350 : 0.025731990113854408
Loss at batch 360 : 0.008174123242497444
Loss at batch 370 : 0.0093494588509202
epoch91 finished!
Loss at batch 10 : 0.008917615748941898
Loss at batch 20 : 0.01908181607723236
Loss at batch 30 : 0.012383917346596718
Loss at batch 40 : 0.010925544425845146
Loss at batch 50 : 0.025425594300031662
Loss at batch 60 : 0.014290332794189453
Loss at batch 70 : 0.011292953975498676
Loss at batch 80 : 0.007677561603486538
Loss at batch 90 : 0.01059271302074194
Loss at batch 100 : 0.010315248742699623
Loss at batch 110 : 0.02327333763241768
Loss at batch 120 : 0.011549055576324463
Loss at batch 130 : 0.018991699442267418
Loss at batch 140 : 0.011215046979486942
Loss at batch 150 : 0.00932906474918127
Loss at batch 160 : 0.014651890844106674
Loss at batch 170 : 0.014264581725001335
Loss at batch 180 : 0.018432844430208206
Loss at batch 190 : 0.013684868812561035
Loss at batch 200 : 0.011239495128393173
Loss at batch 210 : 0.013953822664916515
Loss at batch 220 : 0.011665874160826206
Loss at batch 230 : 0.01838071644306183
Loss at batch 240 : 0.02116381749510765
Loss at batch 250 : 0.01880819909274578
Loss at batch 260 : 0.024765050038695335
Loss at batch 270 : 0.014271157793700695
Loss at batch 280 : 0.022063102573156357
Loss at batch 290 : 0.009736253879964352
Loss at batch 300 : 0.00885405670851469
Loss at batch 310 : 0.010879535228013992
Loss at batch 320 : 0.00986244436353445
Loss at batch 330 : 0.010463004931807518
Loss at batch 340 : 0.012770458124577999
Loss at batch 350 : 0.024877360090613365
Loss at batch 360 : 0.01207766029983759
Loss at batch 370 : 0.009463634341955185
epoch91 finished!
Loss at batch 10 : 0.012244138866662979
Loss at batch 20 : 0.014852181077003479
Loss at batch 30 : 0.01075782347470522
Loss at batch 40 : 0.013798359781503677
Loss at batch 50 : 0.012612389400601387
Loss at batch 60 : 0.0130829568952322
Loss at batch 70 : 0.012244557961821556
Loss at batch 80 : 0.013129916973412037
Loss at batch 90 : 0.020802929997444153
Loss at batch 100 : 0.015599007718265057
Loss at batch 110 : 0.0073865922167897224
Loss at batch 120 : 0.01643264666199684
Loss at batch 130 : 0.02695782110095024
Loss at batch 140 : 0.02983076311647892
Loss at batch 150 : 0.01790783740580082
Loss at batch 160 : 0.015042356215417385
Loss at batch 170 : 0.012521966360509396
Loss at batch 180 : 0.012025920674204826
Loss at batch 190 : 0.008544517681002617
Loss at batch 200 : 0.02064593695104122
Loss at batch 210 : 0.01198484841734171
Loss at batch 220 : 0.018358947709202766
Loss at batch 230 : 0.012364060617983341
Loss at batch 240 : 0.017206517979502678
Loss at batch 250 : 0.01928570307791233
Loss at batch 260 : 0.025664884597063065
Loss at batch 270 : 0.009186206385493279
Loss at batch 280 : 0.0157314520329237
Loss at batch 290 : 0.021446656435728073
Loss at batch 300 : 0.012951169162988663
Loss at batch 310 : 0.020748313516378403
Loss at batch 320 : 0.01242678239941597
Loss at batch 330 : 0.017953157424926758
Loss at batch 340 : 0.013027198612689972
Loss at batch 350 : 0.011938466690480709
Loss at batch 360 : 0.01603851281106472
Loss at batch 370 : 0.012099841609597206
epoch92 finished!
Loss at batch 10 : 0.010246453806757927
Loss at batch 20 : 0.020174279808998108
Loss at batch 30 : 0.01492376159876585
Loss at batch 40 : 0.020261310040950775
Loss at batch 50 : 0.01679185777902603
Loss at batch 60 : 0.011624136939644814
Loss at batch 70 : 0.012076225131750107
Loss at batch 80 : 0.02168595977127552
Loss at batch 90 : 0.021909184753894806
Loss at batch 100 : 0.010520311072468758
Loss at batch 110 : 0.006687338463962078
Loss at batch 120 : 0.023108866065740585
Loss at batch 130 : 0.009889557957649231
Loss at batch 140 : 0.0090929064899683
Loss at batch 150 : 0.007900077849626541
Loss at batch 160 : 0.015664929524064064
Loss at batch 170 : 0.02126992680132389
Loss at batch 180 : 0.02023305743932724
Loss at batch 190 : 0.011718880385160446
Loss at batch 200 : 0.016675187274813652
Loss at batch 210 : 0.0108563881367445
Loss at batch 220 : 0.008771847933530807
Loss at batch 230 : 0.01814192160964012
Loss at batch 240 : 0.011758732609450817
Loss at batch 250 : 0.022341705858707428
Loss at batch 260 : 0.011641434393823147
Loss at batch 270 : 0.012724429368972778
Loss at batch 280 : 0.016031794250011444
Loss at batch 290 : 0.012048925273120403
Loss at batch 300 : 0.015650829300284386
Loss at batch 310 : 0.014176213182508945
Loss at batch 320 : 0.023370271548628807
Loss at batch 330 : 0.019655300304293633
Loss at batch 340 : 0.0124622518196702
Loss at batch 350 : 0.014614802785217762
Loss at batch 360 : 0.010149518959224224
Loss at batch 370 : 0.009079202078282833
epoch92 finished!
Loss at batch 20 : 0.015620003454387188
Loss at batch 30 : 0.018207432702183723
Loss at batch 40 : 0.008275743573904037
Loss at batch 50 : 0.01414200197905302
Loss at batch 60 : 0.01598343253135681
Loss at batch 70 : 0.013470595702528954
Loss at batch 80 : 0.011145777069032192
Loss at batch 90 : 0.012949801981449127
Loss at batch 100 : 0.01192380953580141
Loss at batch 110 : 0.014848703518509865
Loss at batch 120 : 0.013248112052679062
Loss at batch 130 : 0.01139289140701294
Loss at batch 140 : 0.009575964882969856
Loss at batch 150 : 0.011787707917392254
Loss at batch 160 : 0.0065393573604524136
Loss at batch 170 : 0.007444362156093121
Loss at batch 180 : 0.009495451115071774
Loss at batch 190 : 0.010310104116797447
Loss at batch 200 : 0.009866021573543549
Loss at batch 210 : 0.012162972241640091
Loss at batch 220 : 0.015200241468846798
Loss at batch 230 : 0.009354379959404469
Loss at batch 240 : 0.01497160829603672
Loss at batch 250 : 0.01700863428413868
Loss at batch 260 : 0.007882297039031982
Loss at batch 270 : 0.018034489825367928
Loss at batch 280 : 0.0213598795235157
Loss at batch 290 : 0.01057645957916975
Loss at batch 300 : 0.015785813331604004
Loss at batch 310 : 0.015622665174305439
Loss at batch 320 : 0.010718570090830326
Loss at batch 330 : 0.014914445579051971
Loss at batch 340 : 0.020846964791417122
Loss at batch 350 : 0.014101636596024036
Loss at batch 360 : 0.02090529538691044
Loss at batch 370 : 0.015098392963409424
epoch93 finished!
Loss at batch 10 : 0.014765776693820953
Loss at batch 20 : 0.0069944835267961025
Loss at batch 30 : 0.014471185393631458
Loss at batch 40 : 0.033428411930799484
Loss at batch 50 : 0.015050094574689865
Loss at batch 60 : 0.01150721125304699
Loss at batch 70 : 0.01743042655289173
Loss at batch 80 : 0.009498494677245617
Loss at batch 90 : 0.010892130434513092
Loss at batch 100 : 0.015392547473311424
Loss at batch 110 : 0.021014120429754257
Loss at batch 120 : 0.023074256256222725
Loss at batch 130 : 0.009573845192790031
Loss at batch 140 : 0.016306687146425247
Loss at batch 150 : 0.008763548918068409
Loss at batch 160 : 0.020392050966620445
Loss at batch 170 : 0.015544694848358631
Loss at batch 180 : 0.011229046620428562
Loss at batch 190 : 0.014141127467155457
Loss at batch 200 : 0.011608703061938286
Loss at batch 210 : 0.011231871321797371
Loss at batch 220 : 0.014071954414248466
Loss at batch 230 : 0.01079196110367775
Loss at batch 240 : 0.008852316997945309
Loss at batch 250 : 0.02108837105333805
Loss at batch 260 : 0.01800594851374626
Loss at batch 270 : 0.009302794001996517
Loss at batch 280 : 0.014594287611544132
Loss at batch 290 : 0.013497897423803806
Loss at batch 300 : 0.014183614403009415
Loss at batch 310 : 0.010782522149384022
Loss at batch 320 : 0.011847917921841145
Loss at batch 330 : 0.020465053617954254
Loss at batch 340 : 0.012337489984929562
Loss at batch 350 : 0.011270682327449322
Loss at batch 360 : 0.017829785123467445
Loss at batch 370 : 0.02535131387412548
epoch93 finished!
Loss at batch 10 : 0.020589277148246765
Loss at batch 20 : 0.01491866260766983
Loss at batch 30 : 0.01486299093812704
Loss at batch 40 : 0.01248206663876772
Loss at batch 50 : 0.017255939543247223
Loss at batch 60 : 0.006848486606031656
Loss at batch 70 : 0.010536465793848038
Loss at batch 80 : 0.022985365241765976
Loss at batch 90 : 0.01197947096079588
Loss at batch 100 : 0.014887896366417408
Loss at batch 110 : 0.011544481851160526
Loss at batch 120 : 0.015555216930806637
Loss at batch 130 : 0.0102991359308362
Loss at batch 140 : 0.011919833719730377
Loss at batch 150 : 0.010364155285060406
Loss at batch 160 : 0.015247690491378307
Loss at batch 170 : 0.013598700985312462
Loss at batch 180 : 0.012974536046385765
Loss at batch 190 : 0.012954610399901867
Loss at batch 200 : 0.011262938380241394
Loss at batch 210 : 0.007828108966350555
Loss at batch 220 : 0.008832808583974838
Loss at batch 230 : 0.017521074041724205
Loss at batch 240 : 0.010351978242397308
Loss at batch 250 : 0.009529434144496918
Loss at batch 260 : 0.023961815983057022
Loss at batch 270 : 0.009541991166770458
Loss at batch 280 : 0.012104748748242855
Loss at batch 290 : 0.018666962161660194
Loss at batch 300 : 0.007665339857339859
Loss at batch 310 : 0.013368288055062294
Loss at batch 320 : 0.010860693641006947
Loss at batch 330 : 0.017838049679994583
Loss at batch 340 : 0.01474667713046074
Loss at batch 350 : 0.010403855703771114
Loss at batch 360 : 0.018289625644683838
Loss at batch 370 : 0.016587700694799423
epoch94 finished!
Loss at batch 10 : 0.01525228749960661
Loss at batch 20 : 0.010672793723642826
Loss at batch 30 : 0.01655891165137291
Loss at batch 40 : 0.010568754747509956
Loss at batch 50 : 0.007878681644797325
Loss at batch 60 : 0.012233852408826351
Loss at batch 70 : 0.01204744167625904
Loss at batch 80 : 0.008960917592048645
Loss at batch 90 : 0.0122600756585598
Loss at batch 100 : 0.010783430188894272
Loss at batch 110 : 0.012207729741930962
Loss at batch 120 : 0.00947391428053379
Loss at batch 130 : 0.01928841881453991
Loss at batch 140 : 0.01080891489982605
Loss at batch 150 : 0.013845179229974747
Loss at batch 160 : 0.013846676796674728
Loss at batch 170 : 0.010764000006020069
Loss at batch 180 : 0.00823201797902584
Loss at batch 190 : 0.006940967869013548
Loss at batch 200 : 0.010686885565519333
Loss at batch 210 : 0.013269432820379734
Loss at batch 220 : 0.013407472521066666
Loss at batch 230 : 0.023292727768421173
Loss at batch 240 : 0.01170880813151598
Loss at batch 250 : 0.011948628351092339
Loss at batch 260 : 0.023217007517814636
Loss at batch 270 : 0.01777983270585537
Loss at batch 280 : 0.01817850023508072
Loss at batch 290 : 0.019598713144659996
Loss at batch 300 : 0.010522332042455673
Loss at batch 310 : 0.0139128677546978
Loss at batch 320 : 0.0143425352871418
Loss at batch 330 : 0.013615367002785206
Loss at batch 340 : 0.013586788438260555
Loss at batch 350 : 0.014743980951607227
Loss at batch 360 : 0.008799188770353794
Loss at batch 370 : 0.020721957087516785
epoch94 finished!
Loss at batch 10 : 0.01727054826915264
Loss at batch 20 : 0.012376618571579456
Loss at batch 30 : 0.010191903449594975
Loss at batch 40 : 0.013607904314994812
Loss at batch 50 : 0.018893180415034294
Loss at batch 60 : 0.014026425778865814
Loss at batch 70 : 0.014804505743086338
Loss at batch 80 : 0.011402103118598461
Loss at batch 90 : 0.01934400387108326
Loss at batch 100 : 0.013114873319864273
Loss at batch 110 : 0.012696762569248676
Loss at batch 120 : 0.016522584483027458
Loss at batch 130 : 0.010301731526851654
Loss at batch 140 : 0.011508745141327381
Loss at batch 150 : 0.013474087230861187
Loss at batch 160 : 0.023710303008556366
Loss at batch 170 : 0.010480043478310108
Loss at batch 180 : 0.014873814769089222
Loss at batch 190 : 0.021700246259570122
Loss at batch 200 : 0.03182348236441612
Loss at batch 210 : 0.012030242942273617
Loss at batch 220 : 0.012796986848115921
Loss at batch 230 : 0.01458819955587387
Loss at batch 240 : 0.013380523771047592
Loss at batch 250 : 0.012580289505422115
Loss at batch 260 : 0.019638201221823692
Loss at batch 270 : 0.013802029192447662
Loss at batch 280 : 0.022148780524730682
Loss at batch 290 : 0.018122030422091484
Loss at batch 300 : 0.008998856879770756
Loss at batch 310 : 0.008935625664889812
Loss at batch 320 : 0.008685402572154999
Loss at batch 330 : 0.012569794431328773
Loss at batch 340 : 0.01585492677986622
Loss at batch 350 : 0.015428779646754265
Loss at batch 360 : 0.01736406423151493
Loss at batch 370 : 0.016697818413376808
epoch95 finished!
Loss at batch 10 : 0.015836000442504883
Loss at batch 20 : 0.009741690009832382
Loss at batch 30 : 0.01605450175702572
Loss at batch 40 : 0.014069591648876667
Loss at batch 50 : 0.010518980212509632
Loss at batch 60 : 0.0063684675842523575
Loss at batch 70 : 0.015904666855931282
Loss at batch 80 : 0.017042361199855804
Loss at batch 90 : 0.014408181421458721
Loss at batch 100 : 0.020448895171284676
Loss at batch 110 : 0.022554026916623116
Loss at batch 120 : 0.013515752740204334
Loss at batch 130 : 0.009748117998242378
Loss at batch 140 : 0.012434832751750946
Loss at batch 150 : 0.006824529729783535
Loss at batch 160 : 0.016168583184480667
Loss at batch 170 : 0.01816609874367714
Loss at batch 180 : 0.014609124511480331
Loss at batch 190 : 0.009870033711194992
Loss at batch 200 : 0.012626082636415958
Loss at batch 210 : 0.011263773776590824
Loss at batch 220 : 0.008958792313933372
Loss at batch 230 : 0.013267898932099342
Loss at batch 240 : 0.0074240295216441154
Loss at batch 250 : 0.009180284105241299
Loss at batch 260 : 0.01613047905266285
Loss at batch 270 : 0.009755603969097137
Loss at batch 280 : 0.01575363054871559
Loss at batch 290 : 0.017887528985738754
Loss at batch 300 : 0.013576730154454708
Loss at batch 310 : 0.018407635390758514
Loss at batch 320 : 0.010097809135913849
Loss at batch 330 : 0.03246080502867699
Loss at batch 340 : 0.017770765349268913
Loss at batch 350 : 0.014454550109803677
Loss at batch 360 : 0.012179536744952202
Loss at batch 370 : 0.01624179445207119
epoch95 finished!
Loss at batch 10 : 0.01199774257838726
Loss at batch 20 : 0.013253744691610336
Loss at batch 30 : 0.01950979046523571
Loss at batch 40 : 0.016216447576880455
Loss at batch 50 : 0.010738076642155647
Loss at batch 60 : 0.014173765666782856
Loss at batch 70 : 0.015229352749884129
Loss at batch 80 : 0.01222827099263668
Loss at batch 90 : 0.015428276732563972
Loss at batch 100 : 0.01754234917461872
Loss at batch 110 : 0.011529154144227505
Loss at batch 120 : 0.009113673120737076
Loss at batch 130 : 0.01839989610016346
Loss at batch 140 : 0.021839112043380737
Loss at batch 150 : 0.01572316512465477
Loss at batch 160 : 0.014202267862856388
Loss at batch 170 : 0.017090285196900368
Loss at batch 180 : 0.010936876758933067
Loss at batch 190 : 0.010567547753453255
Loss at batch 200 : 0.018778814002871513
Loss at batch 210 : 0.01421465165913105
Loss at batch 220 : 0.009530124254524708
Loss at batch 230 : 0.008833406493067741
Loss at batch 240 : 0.016319191083312035
Loss at batch 250 : 0.014059536159038544
Loss at batch 260 : 0.019486116245388985
Loss at batch 270 : 0.013584459200501442
Loss at batch 280 : 0.00962495431303978
Loss at batch 290 : 0.01324668899178505
Loss at batch 300 : 0.015770450234413147
Loss at batch 310 : 0.01944582909345627
Loss at batch 320 : 0.014077490195631981
Loss at batch 330 : 0.008800588548183441
Loss at batch 340 : 0.017379144206643105
Loss at batch 350 : 0.013807057403028011
Loss at batch 360 : 0.01921020820736885
Loss at batch 370 : 0.01761145330965519
epoch96 finished!
Loss at batch 10 : 0.008942220360040665
Loss at batch 20 : 0.016107425093650818
Loss at batch 30 : 0.015778379514813423
Loss at batch 40 : 0.012907475233078003
Loss at batch 50 : 0.017062511295080185
Loss at batch 60 : 0.01703684963285923
Loss at batch 70 : 0.01567733846604824
Loss at batch 80 : 0.01744159683585167
Loss at batch 90 : 0.012693031691014767
Loss at batch 100 : 0.009867722168564796
Loss at batch 110 : 0.018852420151233673
Loss at batch 120 : 0.03331194818019867
Loss at batch 130 : 0.019695261493325233
Loss at batch 140 : 0.014456968754529953
Loss at batch 150 : 0.005386325530707836
Loss at batch 160 : 0.006072199437767267
Loss at batch 170 : 0.014300607144832611
Loss at batch 180 : 0.009401625022292137
Loss at batch 190 : 0.018441980704665184
Loss at batch 200 : 0.022688021883368492
Loss at batch 210 : 0.011804001405835152
Loss at batch 220 : 0.012815429829061031
Loss at batch 230 : 0.013725204393267632
Loss at batch 240 : 0.011899982579052448
Loss at batch 250 : 0.014284190721809864
Loss at batch 260 : 0.020993676036596298
Loss at batch 270 : 0.021359199658036232
Loss at batch 280 : 0.008162397891283035
Loss at batch 290 : 0.00991002656519413
Loss at batch 300 : 0.007470056414604187
Loss at batch 310 : 0.01194231677800417
Loss at batch 320 : 0.010633189231157303
Loss at batch 330 : 0.020883778110146523
Loss at batch 340 : 0.01217662449926138
Loss at batch 350 : 0.01100891549140215
Loss at batch 360 : 0.007284501101821661
Loss at batch 370 : 0.014055892825126648
epoch96 finished!
Loss at batch 10 : 0.014465169049799442
Loss at batch 20 : 0.013986045494675636
Loss at batch 30 : 0.008431628346443176
Loss at batch 40 : 0.012494786642491817
Loss at batch 50 : 0.01305152103304863
Loss at batch 60 : 0.009986594319343567
Loss at batch 70 : 0.010411453433334827
Loss at batch 80 : 0.02043168619275093
Loss at batch 90 : 0.01761701889336109
Loss at batch 100 : 0.010654681362211704
Loss at batch 110 : 0.02385331504046917
Loss at batch 120 : 0.01215981226414442
Loss at batch 130 : 0.018048608675599098
Loss at batch 140 : 0.009472121484577656
Loss at batch 150 : 0.0093607809394598
Loss at batch 160 : 0.031166264787316322
Loss at batch 170 : 0.009956186637282372
Loss at batch 180 : 0.016362277790904045
Loss at batch 190 : 0.009718069806694984
Loss at batch 200 : 0.009548806585371494
Loss at batch 210 : 0.02095617726445198
Loss at batch 220 : 0.008350835181772709
Loss at batch 230 : 0.015343435108661652
Loss at batch 240 : 0.021600965410470963
Loss at batch 250 : 0.011914089322090149
Loss at batch 260 : 0.020310919731855392
Loss at batch 270 : 0.01183023676276207
Loss at batch 280 : 0.01895911805331707
Loss at batch 290 : 0.014691414311528206
Loss at batch 300 : 0.006312624551355839
Loss at batch 310 : 0.009176136925816536
Loss at batch 320 : 0.021742451936006546
Loss at batch 330 : 0.021338216960430145
Loss at batch 340 : 0.013529455289244652
Loss at batch 350 : 0.007695791777223349
Loss at batch 360 : 0.027157066389918327
Loss at batch 370 : 0.011113649234175682
epoch97 finished!
Loss at batch 10 : 0.010517110116779804
Loss at batch 20 : 0.01242617517709732
Loss at batch 30 : 0.01620589569211006
Loss at batch 40 : 0.01242066640406847
Loss at batch 50 : 0.01235599908977747
Loss at batch 60 : 0.006786664482206106
Loss at batch 70 : 0.019120197743177414
Loss at batch 80 : 0.007998974993824959
Loss at batch 90 : 0.010524425655603409
Loss at batch 100 : 0.01417009998112917
Loss at batch 110 : 0.01924753375351429
Loss at batch 120 : 0.009719878435134888
Loss at batch 130 : 0.009228850714862347
Loss at batch 140 : 0.021478496491909027
Loss at batch 150 : 0.015718484297394753
Loss at batch 160 : 0.011974488385021687
Loss at batch 170 : 0.018307307735085487
Loss at batch 180 : 0.009210520423948765
Loss at batch 190 : 0.010604879818856716
Loss at batch 200 : 0.008937126025557518
Loss at batch 210 : 0.010958912782371044
Loss at batch 220 : 0.013802152127027512
Loss at batch 230 : 0.03140680491924286
Loss at batch 240 : 0.017713651061058044
Loss at batch 250 : 0.013666803017258644
Loss at batch 260 : 0.01850144751369953
Loss at batch 270 : 0.009844668209552765
Loss at batch 280 : 0.01071204338222742
Loss at batch 290 : 0.008857233449816704
Loss at batch 300 : 0.021887436509132385
Loss at batch 310 : 0.014558522962033749
Loss at batch 320 : 0.01196335069835186
Loss at batch 330 : 0.01017236988991499
Loss at batch 340 : 0.012602156028151512
Loss at batch 350 : 0.01251371018588543
Loss at batch 360 : 0.012677423655986786
Loss at batch 370 : 0.012590762227773666
epoch97 finished!
Loss at batch 10 : 0.009832323528826237
Loss at batch 20 : 0.009455464780330658
Loss at batch 30 : 0.012581647373735905
Loss at batch 40 : 0.01639442890882492
Loss at batch 50 : 0.015402396209537983
Loss at batch 60 : 0.01531087514013052
Loss at batch 70 : 0.013168484903872013
Loss at batch 80 : 0.020159827545285225
Loss at batch 90 : 0.012839633040130138
Loss at batch 100 : 0.007675116881728172
Loss at batch 110 : 0.014842076227068901
Loss at batch 120 : 0.008439610712230206
Loss at batch 130 : 0.00891698244959116
Loss at batch 140 : 0.014007171615958214
Loss at batch 150 : 0.009755822829902172
Loss at batch 160 : 0.04779493808746338
Loss at batch 170 : 0.01359648909419775
Loss at batch 180 : 0.016645072028040886
Loss at batch 190 : 0.015641577541828156
Loss at batch 200 : 0.015283062122762203
Loss at batch 210 : 0.014350229874253273
Loss at batch 220 : 0.011651396751403809
Loss at batch 230 : 0.02826947160065174
Loss at batch 240 : 0.008839957416057587
Loss at batch 250 : 0.011758155189454556
Loss at batch 260 : 0.009810183197259903
Loss at batch 270 : 0.014064579270780087
Loss at batch 280 : 0.01920948550105095
Loss at batch 290 : 0.006070729810744524
Loss at batch 300 : 0.01064175646752119
Loss at batch 310 : 0.015518782660365105
Loss at batch 320 : 0.011615817435085773
Loss at batch 330 : 0.02038165181875229
Loss at batch 340 : 0.0184263214468956
Loss at batch 350 : 0.023719215765595436
Loss at batch 360 : 0.013692963868379593
Loss at batch 370 : 0.01168521586805582
epoch98 finished!
Loss at batch 10 : 0.013803517445921898
Loss at batch 20 : 0.01398721057921648
Loss at batch 30 : 0.019237585365772247
Loss at batch 40 : 0.005377534311264753
Loss at batch 50 : 0.012280617840588093
Loss at batch 60 : 0.00949348695576191
Loss at batch 70 : 0.020189650356769562
Loss at batch 80 : 0.010137288831174374
Loss at batch 90 : 0.013855824247002602
Loss at batch 100 : 0.01939203031361103
Loss at batch 110 : 0.00916016660630703
Loss at batch 120 : 0.014168175868690014
Loss at batch 130 : 0.014789014123380184
Loss at batch 140 : 0.012652757577598095
Loss at batch 150 : 0.01866307109594345
Loss at batch 160 : 0.009515175595879555
Loss at batch 170 : 0.013964562676846981
Loss at batch 180 : 0.01393128465861082
Loss at batch 190 : 0.01022957544773817
Loss at batch 200 : 0.01566215045750141
Loss at batch 210 : 0.01077763270586729
Loss at batch 220 : 0.00957463402301073
Loss at batch 230 : 0.024806741625070572
Loss at batch 240 : 0.009822064079344273
Loss at batch 250 : 0.015544118359684944
Loss at batch 260 : 0.013038079254329205
Loss at batch 270 : 0.0077219558879733086
Loss at batch 280 : 0.00844545941799879
Loss at batch 290 : 0.015984266996383667
Loss at batch 300 : 0.010354778729379177
Loss at batch 310 : 0.015344283543527126
Loss at batch 320 : 0.010106420144438744
Loss at batch 330 : 0.014420329593122005
Loss at batch 340 : 0.010245607234537601
Loss at batch 350 : 0.012480325065553188
Loss at batch 360 : 0.025166388601064682
Loss at batch 370 : 0.013796032406389713
epoch98 finished!
Loss at batch 10 : 0.007697329856455326
Loss at batch 20 : 0.011246834881603718
Loss at batch 30 : 0.01383153535425663
Loss at batch 40 : 0.010501016862690449
Loss at batch 50 : 0.01620057038962841
Loss at batch 60 : 0.008865413255989552
Loss at batch 70 : 0.02089245803654194
Loss at batch 80 : 0.011637041345238686
Loss at batch 90 : 0.024378878995776176
Loss at batch 100 : 0.008423125371336937
Loss at batch 110 : 0.014614208601415157
Loss at batch 120 : 0.014469326473772526
Loss at batch 130 : 0.009679565206170082
Loss at batch 140 : 0.016530806198716164
Loss at batch 150 : 0.011358272284269333
Loss at batch 160 : 0.01748211495578289
Loss at batch 170 : 0.00953369028866291
Loss at batch 180 : 0.018224867060780525
Loss at batch 190 : 0.012041906826198101
Loss at batch 200 : 0.012628532014787197
Loss at batch 210 : 0.01704535447061062
Loss at batch 220 : 0.019198382273316383
Loss at batch 230 : 0.008230986073613167
Loss at batch 240 : 0.017510002478957176
Loss at batch 250 : 0.014790908433496952
Loss at batch 260 : 0.02170080877840519
Loss at batch 270 : 0.009694460779428482
Loss at batch 280 : 0.02044987678527832
Loss at batch 290 : 0.00777349853888154
Loss at batch 300 : 0.013442549854516983
Loss at batch 310 : 0.009913329966366291
Loss at batch 320 : 0.01241903193295002
Loss at batch 330 : 0.021222786977887154
Loss at batch 340 : 0.01874762400984764
Loss at batch 350 : 0.018194474279880524
Loss at batch 360 : 0.011469123885035515
Loss at batch 370 : 0.021299075335264206
epoch99 finished!
Loss at batch 10 : 0.022694753482937813
Loss at batch 20 : 0.017404334619641304
Loss at batch 30 : 0.026733320206403732
Loss at batch 40 : 0.009257391095161438
Loss at batch 50 : 0.02159343846142292
Loss at batch 60 : 0.012318780645728111
Loss at batch 70 : 0.02104789763689041
Loss at batch 80 : 0.01326620765030384
Loss at batch 90 : 0.020196860656142235
Loss at batch 100 : 0.015213492326438427
Loss at batch 110 : 0.018627073615789413
Loss at batch 120 : 0.015422666445374489
Loss at batch 130 : 0.020711658522486687
Loss at batch 140 : 0.01426546461880207
Loss at batch 150 : 0.018605079501867294
Loss at batch 160 : 0.014713798649609089
Loss at batch 170 : 0.016361942514777184
Loss at batch 180 : 0.020672431215643883
Loss at batch 190 : 0.011080735363066196
Loss at batch 200 : 0.011695092543959618
Loss at batch 210 : 0.014740284532308578
Loss at batch 220 : 0.01676655374467373
Loss at batch 230 : 0.011428277008235455
Loss at batch 240 : 0.01902608759701252
Loss at batch 250 : 0.008529233746230602
Loss at batch 260 : 0.00869731791317463
Loss at batch 270 : 0.018257616087794304
Loss at batch 280 : 0.010690002702176571
Loss at batch 290 : 0.012194601818919182
Loss at batch 300 : 0.02426491305232048
Loss at batch 310 : 0.014585026539862156
Loss at batch 320 : 0.015394323505461216
Loss at batch 330 : 0.014604914002120495
Loss at batch 340 : 0.014233928173780441
Loss at batch 350 : 0.014068794436752796
Loss at batch 360 : 0.01740949973464012
Loss at batch 370 : 0.008017155341804028
epoch99 finished!
Loss at batch 10 : 0.01307119894772768
Loss at batch 20 : 0.016154911369085312
Loss at batch 30 : 0.012568158097565174
Loss at batch 40 : 0.012109228409826756
Loss at batch 50 : 0.016285452991724014
Loss at batch 60 : 0.014156464487314224
Loss at batch 70 : 0.011417879723012447
Loss at batch 80 : 0.010734036564826965
Loss at batch 90 : 0.013171679340302944
Loss at batch 100 : 0.013900543563067913
Loss at batch 110 : 0.015712115913629532
Loss at batch 120 : 0.00980137288570404
Loss at batch 130 : 0.016783978790044785
Loss at batch 140 : 0.02392243780195713
Loss at batch 150 : 0.01751694642007351
Loss at batch 160 : 0.01597990281879902
Loss at batch 170 : 0.017777852714061737
Loss at batch 180 : 0.01501424890011549
Loss at batch 190 : 0.01386550534516573
Loss at batch 200 : 0.008866405114531517
Loss at batch 210 : 0.02423173189163208
Loss at batch 220 : 0.010276385582983494
Loss at batch 230 : 0.030193831771612167
Loss at batch 240 : 0.00839914008975029
Loss at batch 250 : 0.0279304888099432
Loss at batch 260 : 0.014623823575675488
Loss at batch 270 : 0.011340080760419369
Loss at batch 280 : 0.010753137059509754
Loss at batch 290 : 0.022851187735795975
Loss at batch 300 : 0.0300140343606472
Loss at batch 310 : 0.01608642004430294
Loss at batch 320 : 0.018518440425395966
Loss at batch 330 : 0.010677427053451538
Loss at batch 340 : 0.014676491729915142
Loss at batch 350 : 0.0153458621352911
Loss at batch 360 : 0.014200243167579174
Loss at batch 370 : 0.011639779433608055
epoch100 finished!
Loss at batch 10 : 0.012284643948078156
Loss at batch 20 : 0.012701391242444515
Loss at batch 30 : 0.014255944639444351
Loss at batch 40 : 0.009013599716126919
Loss at batch 50 : 0.014908374287188053
Loss at batch 60 : 0.005521074868738651
Loss at batch 70 : 0.014021462760865688
Loss at batch 80 : 0.009539278224110603
Loss at batch 90 : 0.015400352887809277
Loss at batch 100 : 0.011039613746106625
Loss at batch 110 : 0.0147374477237463
Loss at batch 120 : 0.011406236328184605
Loss at batch 130 : 0.021975655108690262
Loss at batch 140 : 0.01300868671387434
Loss at batch 150 : 0.012273379601538181
Loss at batch 160 : 0.010023100301623344
Loss at batch 170 : 0.014352688565850258
Loss at batch 180 : 0.015281487256288528
Loss at batch 190 : 0.011377125978469849
Loss at batch 200 : 0.01725023239850998
Loss at batch 210 : 0.009263621643185616
Loss at batch 220 : 0.012637036852538586
Loss at batch 230 : 0.01610017567873001
Loss at batch 240 : 0.01354147493839264
Loss at batch 250 : 0.023085808381438255
Loss at batch 260 : 0.010902532376348972
Loss at batch 270 : 0.011133122257888317
Loss at batch 280 : 0.017615893855690956
Loss at batch 290 : 0.02219366282224655
Loss at batch 300 : 0.013679138384759426
Loss at batch 310 : 0.018484296277165413
Loss at batch 320 : 0.011922447010874748
Loss at batch 330 : 0.01334044523537159
Loss at batch 340 : 0.01653127558529377
Loss at batch 350 : 0.020357467234134674
Loss at batch 360 : 0.013636186718940735
Loss at batch 370 : 0.013962684199213982
epoch100 finished!
Loss at batch 10 : 0.02677411399781704
Loss at batch 20 : 0.014342534355819225
Loss at batch 30 : 0.014844528399407864
Loss at batch 40 : 0.008394179865717888
Loss at batch 50 : 0.008880422450602055
Loss at batch 60 : 0.018393224105238914
Loss at batch 70 : 0.01528221182525158
Loss at batch 80 : 0.01237567700445652
Loss at batch 90 : 0.008274326100945473
Loss at batch 100 : 0.01476264651864767
Loss at batch 110 : 0.014531430788338184
Loss at batch 120 : 0.011846625246107578
Loss at batch 130 : 0.019179822877049446
Loss at batch 140 : 0.020013559609651566
Loss at batch 150 : 0.012146678753197193
Loss at batch 160 : 0.016570676118135452
Loss at batch 170 : 0.008217762224376202
Loss at batch 180 : 0.008620905689895153
Loss at batch 190 : 0.01739775389432907
Loss at batch 200 : 0.015582872554659843
Loss at batch 210 : 0.014288653619587421
Loss at batch 220 : 0.011508455500006676
Loss at batch 230 : 0.012363849207758904
Loss at batch 240 : 0.014905857853591442
Loss at batch 250 : 0.02878471091389656
Loss at batch 260 : 0.023340800777077675
Loss at batch 270 : 0.015808474272489548
Loss at batch 280 : 0.014751298353075981
Loss at batch 290 : 0.011851944029331207
Loss at batch 300 : 0.01912115141749382
Loss at batch 310 : 0.02978970855474472
Loss at batch 320 : 0.020343419164419174
Loss at batch 330 : 0.01445819903165102
Loss at batch 340 : 0.014522846788167953
Loss at batch 350 : 0.011899568140506744
Loss at batch 360 : 0.009516511112451553
Loss at batch 370 : 0.012802093289792538
epoch101 finished!
Loss at batch 10 : 0.011794952675700188
Loss at batch 20 : 0.00924665853381157
Loss at batch 30 : 0.020787836983799934
Loss at batch 40 : 0.013726955279707909
Loss at batch 50 : 0.008523778058588505
Loss at batch 60 : 0.014218268916010857
Loss at batch 70 : 0.014052025973796844
Loss at batch 80 : 0.021804960444569588
Loss at batch 90 : 0.0174088254570961
Loss at batch 100 : 0.011087335646152496
Loss at batch 110 : 0.008056473918259144
Loss at batch 120 : 0.01751558482646942
Loss at batch 130 : 0.011201245710253716
Loss at batch 140 : 0.013261545449495316
Loss at batch 150 : 0.01920853555202484
Loss at batch 160 : 0.01399520505219698
Loss at batch 170 : 0.015430107712745667
Loss at batch 180 : 0.012609081342816353
Loss at batch 190 : 0.008060925640165806
Loss at batch 200 : 0.01434546522796154
Loss at batch 210 : 0.017636405304074287
Loss at batch 220 : 0.011503617279231548
Loss at batch 230 : 0.013407966122031212
Loss at batch 240 : 0.016166506335139275
Loss at batch 250 : 0.022069545462727547
Loss at batch 260 : 0.013202793896198273
Loss at batch 270 : 0.01224575750529766
Loss at batch 280 : 0.012563485652208328
Loss at batch 290 : 0.010610580444335938
Loss at batch 300 : 0.021547911688685417
Loss at batch 310 : 0.01396314986050129
Loss at batch 320 : 0.013279587030410767
Loss at batch 330 : 0.013389547355473042
Loss at batch 340 : 0.009236241690814495
Loss at batch 350 : 0.014300979673862457
Loss at batch 360 : 0.01052092108875513
Loss at batch 370 : 0.009984469041228294
epoch101 finished!
Loss at batch 10 : 0.016578108072280884
Loss at batch 20 : 0.013739904388785362
Loss at batch 30 : 0.010069642215967178
Loss at batch 40 : 0.01639902964234352
Loss at batch 50 : 0.011670513078570366
Loss at batch 60 : 0.0157767366617918
Loss at batch 70 : 0.009635649621486664
Loss at batch 80 : 0.015001952648162842
Loss at batch 90 : 0.007685082033276558
Loss at batch 100 : 0.010143729858100414
Loss at batch 110 : 0.014785355888307095
Loss at batch 120 : 0.020309126004576683
Loss at batch 130 : 0.015545891597867012
Loss at batch 140 : 0.02415679395198822
Loss at batch 150 : 0.016553951427340508
Loss at batch 160 : 0.01785198599100113
Loss at batch 170 : 0.03033905103802681
Loss at batch 180 : 0.011957813054323196
Loss at batch 190 : 0.01221053022891283
Loss at batch 200 : 0.016482792794704437
Loss at batch 210 : 0.01591304875910282
Loss at batch 220 : 0.00912809744477272
Loss at batch 230 : 0.017001153901219368
Loss at batch 240 : 0.020480748265981674
Loss at batch 250 : 0.012393725104629993
Loss at batch 260 : 0.013045331463217735
Loss at batch 270 : 0.009692485444247723
Loss at batch 280 : 0.012649506330490112
Loss at batch 290 : 0.026473958045244217
Loss at batch 300 : 0.00932733528316021
Loss at batch 310 : 0.0114967729896307
Loss at batch 320 : 0.0118825389072299
Loss at batch 330 : 0.0094218160957098
Loss at batch 340 : 0.021860593929886818
Loss at batch 350 : 0.013451887294650078
Loss at batch 360 : 0.015568799339234829
Loss at batch 370 : 0.01277075707912445
epoch102 finished!
Loss at batch 10 : 0.008410267531871796
Loss at batch 20 : 0.011253434233367443
Loss at batch 30 : 0.014146008528769016
Loss at batch 40 : 0.017925579100847244
Loss at batch 50 : 0.026114311069250107
Loss at batch 60 : 0.020533928647637367
Loss at batch 70 : 0.013110105879604816
Loss at batch 80 : 0.021016791462898254
Loss at batch 90 : 0.008051716722548008
Loss at batch 100 : 0.01746082864701748
Loss at batch 110 : 0.020039783790707588
Loss at batch 120 : 0.01551228016614914
Loss at batch 130 : 0.014016969129443169
Loss at batch 140 : 0.008573666214942932
Loss at batch 150 : 0.008944632485508919
Loss at batch 160 : 0.00937170535326004
Loss at batch 170 : 0.01693969964981079
Loss at batch 180 : 0.017939969897270203
Loss at batch 190 : 0.013079811818897724
Loss at batch 200 : 0.01763894595205784
Loss at batch 210 : 0.02851378172636032
Loss at batch 220 : 0.011752760037779808
Loss at batch 230 : 0.018800269812345505
Loss at batch 240 : 0.004997112788259983
Loss at batch 250 : 0.01315457932651043
Loss at batch 260 : 0.011937194503843784
Loss at batch 270 : 0.010478346608579159
Loss at batch 280 : 0.014545976184308529
Loss at batch 290 : 0.011241008527576923
Loss at batch 300 : 0.013268369249999523
Loss at batch 310 : 0.017421744763851166
Loss at batch 320 : 0.019152477383613586
Loss at batch 330 : 0.011668175458908081
Loss at batch 340 : 0.009748308919370174
Loss at batch 350 : 0.012456286698579788
Loss at batch 360 : 0.013253663666546345
Loss at batch 370 : 0.013934500515460968
epoch102 finished!
Loss at batch 10 : 0.012846080586314201
Loss at batch 20 : 0.012196466326713562
Loss at batch 30 : 0.010767770931124687
Loss at batch 40 : 0.010595974512398243
Loss at batch 50 : 0.014444058761000633
Loss at batch 60 : 0.01371246762573719
Loss at batch 70 : 0.032972607761621475
Loss at batch 80 : 0.0146147096529603
Loss at batch 90 : 0.020204583182930946
Loss at batch 100 : 0.012110046111047268
Loss at batch 110 : 0.010777541436254978
Loss at batch 120 : 0.007429930381476879
Loss at batch 130 : 0.006866977084428072
Loss at batch 140 : 0.007430305704474449
Loss at batch 150 : 0.01024695299565792
Loss at batch 160 : 0.013240588828921318
Loss at batch 170 : 0.019170207902789116
Loss at batch 180 : 0.011406905017793179
Loss at batch 190 : 0.01821957528591156
Loss at batch 200 : 0.016977151855826378
Loss at batch 210 : 0.013313012197613716
Loss at batch 220 : 0.01222316361963749
Loss at batch 230 : 0.010385735891759396
Loss at batch 240 : 0.024696851149201393
Loss at batch 250 : 0.012126083485782146
Loss at batch 260 : 0.011407197453081608
Loss at batch 270 : 0.01203407533466816
Loss at batch 280 : 0.01265847310423851
Loss at batch 290 : 0.007861565798521042
Loss at batch 300 : 0.00855964608490467
Loss at batch 310 : 0.009097468107938766
Loss at batch 320 : 0.021831242367625237
Loss at batch 330 : 0.01157630980014801
Loss at batch 340 : 0.011213568970561028
Loss at batch 350 : 0.0154560636729002
Loss at batch 360 : 0.01103741955012083
Loss at batch 370 : 0.02082257717847824
epoch103 finished!
Loss at batch 10 : 0.009793257340788841
Loss at batch 20 : 0.007420775946229696
Loss at batch 30 : 0.008668706752359867
Loss at batch 40 : 0.012513864785432816
Loss at batch 50 : 0.01563025265932083
Loss at batch 60 : 0.011246878653764725
Loss at batch 70 : 0.013701794669032097
Loss at batch 80 : 0.01781684160232544
Loss at batch 90 : 0.010970264673233032
Loss at batch 100 : 0.010855074971914291
Loss at batch 110 : 0.01988835260272026
Loss at batch 120 : 0.011978001333773136
Loss at batch 130 : 0.014203241094946861
Loss at batch 140 : 0.010740216821432114
Loss at batch 150 : 0.010593967512249947
Loss at batch 160 : 0.010968643240630627
Loss at batch 170 : 0.007050063461065292
Loss at batch 180 : 0.01578245870769024
Loss at batch 190 : 0.014191458001732826
Loss at batch 200 : 0.027286572381854057
Loss at batch 210 : 0.013362492434680462
Loss at batch 220 : 0.017464537173509598
Loss at batch 230 : 0.01070052944123745
Loss at batch 240 : 0.014835300855338573
Loss at batch 250 : 0.023798488080501556
Loss at batch 260 : 0.013526098802685738
Loss at batch 270 : 0.0101134292781353
Loss at batch 280 : 0.013612942770123482
Loss at batch 290 : 0.021620437502861023
Loss at batch 300 : 0.006841353606432676
Loss at batch 310 : 0.017807690426707268
Loss at batch 320 : 0.015735765919089317
Loss at batch 330 : 0.010223448276519775
Loss at batch 340 : 0.006317338440567255
Loss at batch 350 : 0.0103815458714962
Loss at batch 360 : 0.012029979377985
Loss at batch 370 : 0.016683228313922882
epoch103 finished!
Loss at batch 10 : 0.02407550811767578
Loss at batch 20 : 0.014822157099843025
Loss at batch 30 : 0.020572107285261154
Loss at batch 40 : 0.012670866213738918
Loss at batch 50 : 0.016734296455979347
Loss at batch 60 : 0.011656023561954498
Loss at batch 70 : 0.009964482858777046
Loss at batch 80 : 0.012768865562975407
Loss at batch 90 : 0.018961066380143166
Loss at batch 100 : 0.01722484827041626
Loss at batch 110 : 0.014065456576645374
Loss at batch 120 : 0.009712409228086472
Loss at batch 130 : 0.01991966739296913
Loss at batch 140 : 0.011569483205676079
Loss at batch 150 : 0.012364435940980911
Loss at batch 160 : 0.02021198160946369
Loss at batch 170 : 0.01628098450601101
Loss at batch 180 : 0.011182147078216076
Loss at batch 190 : 0.006784722208976746
Loss at batch 200 : 0.019195396453142166
Loss at batch 210 : 0.010565289296209812
Loss at batch 220 : 0.019490445032715797
Loss at batch 230 : 0.01728183589875698
Loss at batch 240 : 0.017587268725037575
Loss at batch 250 : 0.025350473821163177
Loss at batch 260 : 0.006832160521298647
Loss at batch 270 : 0.011089452542364597
Loss at batch 280 : 0.016182508319616318
Loss at batch 290 : 0.010386837646365166
Loss at batch 300 : 0.01708468608558178
Loss at batch 310 : 0.01751299388706684
Loss at batch 320 : 0.020243629813194275
Loss at batch 330 : 0.014956049621105194
Loss at batch 340 : 0.01095365546643734
Loss at batch 350 : 0.011485187336802483
Loss at batch 360 : 0.019073087722063065
Loss at batch 370 : 0.010744612663984299
epoch104 finished!
Loss at batch 10 : 0.013915975578129292
Loss at batch 20 : 0.013935708440840244
Loss at batch 30 : 0.014891183003783226
Loss at batch 40 : 0.006761088501662016
Loss at batch 50 : 0.010601520538330078
Loss at batch 60 : 0.012509464286267757
Loss at batch 70 : 0.010794853791594505
Loss at batch 80 : 0.010462846606969833
Loss at batch 90 : 0.010381652973592281
Loss at batch 100 : 0.014295097440481186
Loss at batch 110 : 0.006367785856127739
Loss at batch 120 : 0.007207500748336315
Loss at batch 130 : 0.01773897558450699
Loss at batch 140 : 0.016444791108369827
Loss at batch 150 : 0.014006189070641994
Loss at batch 160 : 0.013403818942606449
Loss at batch 170 : 0.013292834162712097
Loss at batch 180 : 0.015199782326817513
Loss at batch 190 : 0.016836006194353104
Loss at batch 200 : 0.02275770530104637
Loss at batch 210 : 0.016514601185917854
Loss at batch 220 : 0.013400182127952576
Loss at batch 230 : 0.015614068135619164
Loss at batch 240 : 0.00932424608618021
Loss at batch 250 : 0.016049476340413094
Loss at batch 260 : 0.007214002311229706
Loss at batch 270 : 0.00710049644112587
Loss at batch 280 : 0.016829529777169228
Loss at batch 290 : 0.006153866648674011
Loss at batch 300 : 0.016174376010894775
Loss at batch 310 : 0.01072295755147934
Loss at batch 320 : 0.011897692456841469
Loss at batch 330 : 0.010382051579654217
Loss at batch 340 : 0.016952287405729294
Loss at batch 350 : 0.011625154875218868
Loss at batch 360 : 0.024112273007631302
Loss at batch 370 : 0.01665623113512993
epoch104 finished!
Loss at batch 10 : 0.022688422352075577
Loss at batch 20 : 0.009370180778205395
Loss at batch 30 : 0.011507009156048298
Loss at batch 40 : 0.008363844826817513
Loss at batch 50 : 0.019358323886990547
Loss at batch 60 : 0.009392007254064083
Loss at batch 70 : 0.011726686730980873
Loss at batch 80 : 0.019595075398683548
Loss at batch 90 : 0.02480541728436947
Loss at batch 100 : 0.01235999632626772
Loss at batch 110 : 0.017660049721598625
Loss at batch 120 : 0.012270289473235607
Loss at batch 130 : 0.02383686602115631
Loss at batch 140 : 0.01757018268108368
Loss at batch 150 : 0.018525633960962296
Loss at batch 160 : 0.015498684719204903
Loss at batch 170 : 0.015157070942223072
Loss at batch 180 : 0.020539939403533936
Loss at batch 190 : 0.012804619036614895
Loss at batch 200 : 0.015606014057993889
Loss at batch 210 : 0.009453612379729748
Loss at batch 220 : 0.016001351177692413
Loss at batch 230 : 0.013455985113978386
Loss at batch 240 : 0.015422097407281399
Loss at batch 250 : 0.008192223496735096
Loss at batch 260 : 0.0211525559425354
Loss at batch 270 : 0.016192616894841194
Loss at batch 280 : 0.016347911208868027
Loss at batch 290 : 0.0168383177369833
Loss at batch 300 : 0.012933112680912018
Loss at batch 310 : 0.020628292113542557
Loss at batch 320 : 0.016432596370577812
Loss at batch 330 : 0.020373396575450897
Loss at batch 340 : 0.008513599634170532
Loss at batch 350 : 0.009059893898665905
Loss at batch 360 : 0.01982801780104637
Loss at batch 370 : 0.02205188199877739
epoch105 finished!
Loss at batch 10 : 0.016187986359000206
Loss at batch 20 : 0.017283570021390915
Loss at batch 30 : 0.013024243526160717
Loss at batch 40 : 0.006772344466298819
Loss at batch 50 : 0.021113362163305283
Loss at batch 60 : 0.012142406776547432
Loss at batch 70 : 0.011812729761004448
Loss at batch 80 : 0.008642079308629036
Loss at batch 90 : 0.02646416798233986
Loss at batch 100 : 0.009279092773795128
Loss at batch 110 : 0.016951456665992737
Loss at batch 120 : 0.02388213761150837
Loss at batch 130 : 0.01656029187142849
Loss at batch 140 : 0.009742341004312038
Loss at batch 150 : 0.010645018890500069
Loss at batch 160 : 0.015024874359369278
Loss at batch 170 : 0.016255369409918785
Loss at batch 180 : 0.006882477086037397
Loss at batch 190 : 0.009836473502218723
Loss at batch 200 : 0.008453451097011566
Loss at batch 210 : 0.008624314330518246
Loss at batch 220 : 0.01487111859023571
Loss at batch 230 : 0.016728125512599945
Loss at batch 240 : 0.020319057628512383
Loss at batch 250 : 0.01702360436320305
Loss at batch 260 : 0.012577265501022339
Loss at batch 270 : 0.010650747455656528
Loss at batch 280 : 0.012426411733031273
Loss at batch 290 : 0.016654828563332558
Loss at batch 300 : 0.012848925776779652
Loss at batch 310 : 0.012072231620550156
Loss at batch 320 : 0.008915475569665432
Loss at batch 330 : 0.01011689379811287
Loss at batch 340 : 0.019923189654946327
Loss at batch 350 : 0.019131986424326897
Loss at batch 360 : 0.013211787678301334
Loss at batch 370 : 0.014015385881066322
epoch105 finished!
Loss at batch 10 : 0.008702431805431843
Loss at batch 20 : 0.014698374085128307
Loss at batch 30 : 0.014049637131392956
Loss at batch 40 : 0.01534619927406311
Loss at batch 50 : 0.010252292267978191
Loss at batch 60 : 0.007708671968430281
Loss at batch 70 : 0.009288152679800987
Loss at batch 80 : 0.009479599073529243
Loss at batch 90 : 0.013243121095001698
Loss at batch 100 : 0.015996435657143593
Loss at batch 110 : 0.01741103082895279
Loss at batch 120 : 0.010814309120178223
Loss at batch 130 : 0.007121983915567398
Loss at batch 140 : 0.020358065143227577
Loss at batch 150 : 0.012532060034573078
Loss at batch 160 : 0.011266352608799934
Loss at batch 170 : 0.026570690795779228
Loss at batch 180 : 0.017363838851451874
Loss at batch 190 : 0.011441325768828392
Loss at batch 200 : 0.00822577066719532
Loss at batch 210 : 0.0179594773799181
Loss at batch 220 : 0.01742510125041008
Loss at batch 230 : 0.013559111393988132
Loss at batch 240 : 0.00993417575955391
Loss at batch 250 : 0.017272572964429855
Loss at batch 260 : 0.025719493627548218
Loss at batch 270 : 0.010804387740790844
Loss at batch 280 : 0.016474422067403793
Loss at batch 290 : 0.014831687323749065
Loss at batch 300 : 0.014102126471698284
Loss at batch 310 : 0.013132491149008274
Loss at batch 320 : 0.025596531108021736
Loss at batch 330 : 0.013720936141908169
Loss at batch 340 : 0.008130052126944065
Loss at batch 350 : 0.014282863587141037
Loss at batch 360 : 0.014542949385941029
Loss at batch 370 : 0.009963334538042545
epoch106 finished!
Loss at batch 10 : 0.012736809439957142
Loss at batch 20 : 0.012777585536241531
Loss at batch 30 : 0.013458887115120888
Loss at batch 40 : 0.018140876665711403
Loss at batch 50 : 0.012932141311466694
Loss at batch 60 : 0.010342149063944817
Loss at batch 70 : 0.013225043192505836
Loss at batch 80 : 0.01088318508118391
Loss at batch 90 : 0.02080564573407173
Loss at batch 100 : 0.02104499191045761
Loss at batch 110 : 0.012371036224067211
Loss at batch 120 : 0.00854257307946682
Loss at batch 130 : 0.010244439356029034
Loss at batch 140 : 0.01195663120597601
Loss at batch 150 : 0.019143592566251755
Loss at batch 160 : 0.014114085584878922
Loss at batch 170 : 0.013050000183284283
Loss at batch 180 : 0.013254537247121334
Loss at batch 190 : 0.011447235941886902
Loss at batch 200 : 0.010507906787097454
Loss at batch 210 : 0.008636902086436749
Loss at batch 220 : 0.01968325860798359
Loss at batch 230 : 0.013090399093925953
Loss at batch 240 : 0.008841577917337418
Loss at batch 250 : 0.008898246102035046
Loss at batch 260 : 0.013218295760452747
Loss at batch 270 : 0.00814179889857769
Loss at batch 280 : 0.016143249347805977
Loss at batch 290 : 0.012672253884375095
Loss at batch 300 : 0.009810568764805794
Loss at batch 310 : 0.009268708527088165
Loss at batch 320 : 0.01081929262727499
Loss at batch 330 : 0.024395085871219635
Loss at batch 340 : 0.011623013764619827
Loss at batch 350 : 0.016780028119683266
Loss at batch 360 : 0.017176903784275055
Loss at batch 370 : 0.009953704662621021
epoch106 finished!
Loss at batch 10 : 0.010754596441984177
Loss at batch 20 : 0.018727773800492287
Loss at batch 30 : 0.015169304795563221
Loss at batch 40 : 0.008563840761780739
Loss at batch 50 : 0.011289807967841625
Loss at batch 60 : 0.01919233426451683
Loss at batch 70 : 0.012587442994117737
Loss at batch 80 : 0.0149830998852849
Loss at batch 90 : 0.014589954167604446
Loss at batch 100 : 0.013721907511353493
Loss at batch 110 : 0.019918348640203476
Loss at batch 120 : 0.012699456885457039
Loss at batch 130 : 0.015309725888073444
Loss at batch 140 : 0.019206950441002846
Loss at batch 150 : 0.009730827063322067
Loss at batch 160 : 0.015241100452840328
Loss at batch 170 : 0.010439927689731121
Loss at batch 180 : 0.011537732556462288
Loss at batch 190 : 0.01464787032455206
Loss at batch 200 : 0.011822016909718513
Loss at batch 210 : 0.022878974676132202
Loss at batch 220 : 0.012808880768716335
Loss at batch 230 : 0.021141398698091507
Loss at batch 240 : 0.01038705836981535
Loss at batch 250 : 0.018070818856358528
Loss at batch 260 : 0.020574301481246948
Loss at batch 270 : 0.01980070397257805
Loss at batch 280 : 0.015713689848780632
Loss at batch 290 : 0.0071370950900018215
Loss at batch 300 : 0.014385665766894817
Loss at batch 310 : 0.022288374602794647
Loss at batch 320 : 0.012990646995604038
Loss at batch 330 : 0.013760359026491642
Loss at batch 340 : 0.014508162625133991
Loss at batch 350 : 0.008179964497685432
Loss at batch 360 : 0.009472770616412163
Loss at batch 370 : 0.01098325289785862
epoch107 finished!
Loss at batch 10 : 0.011022425256669521
Loss at batch 20 : 0.010112826712429523
Loss at batch 30 : 0.01580752246081829
Loss at batch 40 : 0.014873630367219448
Loss at batch 50 : 0.007943814620375633
Loss at batch 60 : 0.014393961057066917
Loss at batch 70 : 0.01799829490482807
Loss at batch 80 : 0.011781446635723114
Loss at batch 90 : 0.010667434893548489
Loss at batch 100 : 0.01493156235665083
Loss at batch 110 : 0.017289139330387115
Loss at batch 120 : 0.010037388652563095
Loss at batch 130 : 0.016009991988539696
Loss at batch 140 : 0.011502501554787159
Loss at batch 150 : 0.01094287820160389
Loss at batch 160 : 0.01788514479994774
Loss at batch 170 : 0.01001716498285532
Loss at batch 180 : 0.00896102748811245
Loss at batch 190 : 0.021350953727960587
Loss at batch 200 : 0.011163603514432907
Loss at batch 210 : 0.01067204400897026
Loss at batch 220 : 0.012406460009515285
Loss at batch 230 : 0.01771184802055359
Loss at batch 240 : 0.012004571035504341
Loss at batch 250 : 0.018241895362734795
Loss at batch 260 : 0.014139270409941673
Loss at batch 270 : 0.0188519898802042
Loss at batch 280 : 0.011392916552722454
Loss at batch 290 : 0.010110083036124706
Loss at batch 300 : 0.013665585778653622
Loss at batch 310 : 0.013009059242904186
Loss at batch 320 : 0.016058601438999176
Loss at batch 330 : 0.008333154022693634
Loss at batch 340 : 0.010562156327068806
Loss at batch 350 : 0.007204970344901085
Loss at batch 360 : 0.009015305899083614
Loss at batch 370 : 0.012750293128192425
epoch107 finished!
Loss at batch 10 : 0.017209090292453766
Loss at batch 20 : 0.016463803127408028
Loss at batch 30 : 0.009104394353926182
Loss at batch 40 : 0.009185302071273327
Loss at batch 50 : 0.019440799951553345
Loss at batch 60 : 0.01277713943272829
Loss at batch 70 : 0.016161995008587837
Loss at batch 80 : 0.011120200157165527
Loss at batch 90 : 0.015982747077941895
Loss at batch 100 : 0.014216534793376923
Loss at batch 110 : 0.019576454535126686
Loss at batch 120 : 0.0099868755787611
Loss at batch 130 : 0.010134841315448284
Loss at batch 140 : 0.01041500549763441
Loss at batch 150 : 0.013339623808860779
Loss at batch 160 : 0.02907561883330345
Loss at batch 170 : 0.016855984926223755
Loss at batch 180 : 0.008742456324398518
Loss at batch 190 : 0.01703837513923645
Loss at batch 200 : 0.014851684682071209
Loss at batch 210 : 0.013836958445608616
Loss at batch 220 : 0.01035931333899498
Loss at batch 230 : 0.01874714531004429
Loss at batch 240 : 0.016998106613755226
Loss at batch 250 : 0.014768986962735653
Loss at batch 260 : 0.014131927862763405
Loss at batch 270 : 0.015833742916584015
Loss at batch 280 : 0.02324634976685047
Loss at batch 290 : 0.013872816227376461
Loss at batch 300 : 0.016284234821796417
Loss at batch 310 : 0.010452407412230968
Loss at batch 320 : 0.007492139935493469
Loss at batch 330 : 0.0190302561968565
Loss at batch 340 : 0.014141433872282505
Loss at batch 350 : 0.01895330287516117
Loss at batch 360 : 0.015864413231611252
Loss at batch 370 : 0.012982580810785294
epoch108 finished!
Loss at batch 10 : 0.022529905661940575
Loss at batch 20 : 0.014830977655947208
Loss at batch 30 : 0.01056687906384468
Loss at batch 40 : 0.016070889309048653
Loss at batch 50 : 0.020146600902080536
Loss at batch 60 : 0.010841751471161842
Loss at batch 70 : 0.02598084695637226
Loss at batch 80 : 0.008346176706254482
Loss at batch 90 : 0.008154003880918026
Loss at batch 100 : 0.020736485719680786
Loss at batch 110 : 0.013498259708285332
Loss at batch 120 : 0.019519586116075516
Loss at batch 130 : 0.012295057997107506
Loss at batch 140 : 0.008535358123481274
Loss at batch 150 : 0.010539242066442966
Loss at batch 160 : 0.021758750081062317
Loss at batch 170 : 0.012711696326732635
Loss at batch 180 : 0.0095827616751194
Loss at batch 190 : 0.009749109856784344
Loss at batch 200 : 0.014650505036115646
Loss at batch 210 : 0.02431494928896427
Loss at batch 220 : 0.012856299057602882
Loss at batch 230 : 0.01704239845275879
Loss at batch 240 : 0.013667210005223751
Loss at batch 250 : 0.01234385371208191
Loss at batch 260 : 0.010324627161026001
Loss at batch 270 : 0.010688266716897488
Loss at batch 280 : 0.019914450123906136
Loss at batch 290 : 0.017479868605732918
Loss at batch 300 : 0.013249031268060207
Loss at batch 310 : 0.013236328028142452
Loss at batch 320 : 0.007369802333414555
Loss at batch 330 : 0.014826389029622078
Loss at batch 340 : 0.00759779941290617
Loss at batch 350 : 0.007815743796527386
Loss at batch 360 : 0.01742428168654442
Loss at batch 370 : 0.012187108397483826
epoch108 finished!
Loss at batch 10 : 0.014716490171849728
Loss at batch 20 : 0.010492854751646519
Loss at batch 30 : 0.014929809607565403
Loss at batch 40 : 0.015682831406593323
Loss at batch 50 : 0.02033400908112526
Loss at batch 60 : 0.016877278685569763
Loss at batch 70 : 0.021833794191479683
Loss at batch 80 : 0.011057935655117035
Loss at batch 90 : 0.012661210261285305
Loss at batch 100 : 0.010264059528708458
Loss at batch 110 : 0.0191817507147789
Loss at batch 120 : 0.014670263975858688
Loss at batch 130 : 0.007148063741624355
Loss at batch 140 : 0.012539043091237545
Loss at batch 150 : 0.014491118490695953
Loss at batch 160 : 0.014955377206206322
Loss at batch 170 : 0.009714970365166664
Loss at batch 180 : 0.009327772073447704
Loss at batch 190 : 0.010556536726653576
Loss at batch 200 : 0.011331412009894848
Loss at batch 210 : 0.019460249692201614
Loss at batch 220 : 0.009538053534924984
Loss at batch 230 : 0.01183280535042286
Loss at batch 240 : 0.01663048192858696
Loss at batch 250 : 0.009886634536087513
Loss at batch 260 : 0.010219385847449303
Loss at batch 270 : 0.007050267420709133
Loss at batch 280 : 0.0075335148721933365
Loss at batch 290 : 0.015431582927703857
Loss at batch 300 : 0.012659932486712933
Loss at batch 310 : 0.01648668199777603
Loss at batch 320 : 0.007285426836460829
Loss at batch 330 : 0.016845878213644028
Loss at batch 340 : 0.0196236502379179
Loss at batch 350 : 0.017654666677117348
Loss at batch 360 : 0.015195351094007492
Loss at batch 370 : 0.02706732414662838
epoch109 finished!
Loss at batch 10 : 0.012600313872098923
Loss at batch 20 : 0.01341470517218113
Loss at batch 30 : 0.011468196287751198
Loss at batch 40 : 0.015085111372172832
Loss at batch 50 : 0.011119110509753227
Loss at batch 60 : 0.011404218152165413
Loss at batch 70 : 0.016329815611243248
Loss at batch 80 : 0.016753777861595154
Loss at batch 90 : 0.010438346303999424
Loss at batch 100 : 0.02203173004090786
Loss at batch 110 : 0.015425508841872215
Loss at batch 120 : 0.007015917915850878
Loss at batch 130 : 0.012118191458284855
Loss at batch 140 : 0.012476040981709957
Loss at batch 150 : 0.013337123207747936
Loss at batch 160 : 0.03038448840379715
Loss at batch 170 : 0.016450442373752594
Loss at batch 180 : 0.02013837732374668
Loss at batch 190 : 0.01850300468504429
Loss at batch 200 : 0.0144923385232687
Loss at batch 210 : 0.01873583160340786
Loss at batch 220 : 0.015598832629621029
Loss at batch 230 : 0.0118545638397336
Loss at batch 240 : 0.013399352319538593
Loss at batch 250 : 0.011750408448278904
Loss at batch 260 : 0.011956212110817432
Loss at batch 270 : 0.011387210339307785
Loss at batch 280 : 0.010679783299565315
Loss at batch 290 : 0.009232752956449986
Loss at batch 300 : 0.024801360443234444
Loss at batch 310 : 0.011403899639844894
Loss at batch 320 : 0.012161186896264553
Loss at batch 330 : 0.006869935430586338
Loss at batch 340 : 0.013292709365487099
Loss at batch 350 : 0.0068425377830863
Loss at batch 360 : 0.01956971175968647
Loss at batch 370 : 0.010341404937207699
epoch109 finished!
Loss at batch 10 : 0.0158084686845541
Loss at batch 20 : 0.009427706710994244
Loss at batch 30 : 0.026224926114082336
Loss at batch 40 : 0.011543193832039833
Loss at batch 50 : 0.007045962382107973
Loss at batch 60 : 0.01852164790034294
Loss at batch 70 : 0.012626675888895988
Loss at batch 80 : 0.014175178483128548
Loss at batch 90 : 0.013402796350419521
Loss at batch 100 : 0.008681144565343857
Loss at batch 110 : 0.017612837255001068
Loss at batch 120 : 0.01704287715256214
Loss at batch 130 : 0.015526133589446545
Loss at batch 140 : 0.017088595777750015
Loss at batch 150 : 0.01026704628020525
Loss at batch 160 : 0.0076620569452643394
Loss at batch 170 : 0.015155290253460407
Loss at batch 180 : 0.01412963680922985
Loss at batch 190 : 0.012837329879403114
Loss at batch 200 : 0.011881809681653976
Loss at batch 210 : 0.018425505608320236
Loss at batch 220 : 0.014031874015927315
Loss at batch 230 : 0.016680171713232994
Loss at batch 240 : 0.014620441943407059
Loss at batch 250 : 0.02337149903178215
Loss at batch 260 : 0.016978897154331207
Loss at batch 270 : 0.007190584670752287
Loss at batch 280 : 0.013057953678071499
Loss at batch 290 : 0.016642292961478233
Loss at batch 300 : 0.017064368352293968
Loss at batch 310 : 0.009680504910647869
Loss at batch 320 : 0.013363501988351345
Loss at batch 330 : 0.013047103770077229
Loss at batch 340 : 0.032537128776311874
Loss at batch 350 : 0.012957919389009476
Loss at batch 360 : 0.014710388146340847
Loss at batch 370 : 0.00820736400783062
epoch110 finished!
Loss at batch 10 : 0.015447468496859074
Loss at batch 20 : 0.01154140755534172
Loss at batch 30 : 0.02054547891020775
Loss at batch 40 : 0.00873507559299469
Loss at batch 50 : 0.022084873169660568
Loss at batch 60 : 0.013951140455901623
Loss at batch 70 : 0.010817354544997215
Loss at batch 80 : 0.01817432790994644
Loss at batch 90 : 0.024034544825553894
Loss at batch 100 : 0.022603819146752357
Loss at batch 110 : 0.012474472634494305
Loss at batch 120 : 0.009435773827135563
Loss at batch 130 : 0.021530885249376297
Loss at batch 140 : 0.025085212662816048
Loss at batch 150 : 0.01196237001568079
Loss at batch 160 : 0.007979247719049454
Loss at batch 170 : 0.009872011840343475
Loss at batch 180 : 0.017132041975855827
Loss at batch 190 : 0.015440509654581547
Loss at batch 200 : 0.025051716715097427
Loss at batch 210 : 0.007318483665585518
Loss at batch 220 : 0.019138745963573456
Loss at batch 230 : 0.01617027074098587
Loss at batch 240 : 0.021155260503292084
Loss at batch 250 : 0.013538888655602932
Loss at batch 260 : 0.005713717080652714
Loss at batch 270 : 0.009013308212161064
Loss at batch 280 : 0.009370260871946812
Loss at batch 290 : 0.025187646970152855
Loss at batch 300 : 0.014967422001063824
Loss at batch 310 : 0.016190599650144577
Loss at batch 320 : 0.015006299130618572
Loss at batch 330 : 0.008118578232824802
Loss at batch 340 : 0.011804836802184582
Loss at batch 350 : 0.015684617683291435
Loss at batch 360 : 0.014867051504552364
Loss at batch 370 : 0.00829149130731821
epoch110 finished!
Loss at batch 10 : 0.024251829832792282
Loss at batch 20 : 0.01390218734741211
Loss at batch 30 : 0.011766278184950352
Loss at batch 40 : 0.0143034802749753
Loss at batch 50 : 0.018023254349827766
Loss at batch 60 : 0.022324278950691223
Loss at batch 70 : 0.010821673087775707
Loss at batch 80 : 0.023309830576181412
Loss at batch 90 : 0.011267776601016521
Loss at batch 100 : 0.01142959576100111
Loss at batch 110 : 0.008191335946321487
Loss at batch 120 : 0.025913938879966736
Loss at batch 130 : 0.010929391719400883
Loss at batch 140 : 0.010529172606766224
Loss at batch 150 : 0.027366645634174347
Loss at batch 160 : 0.022136636078357697
Loss at batch 170 : 0.02433374710381031
Loss at batch 180 : 0.014737614430487156
Loss at batch 190 : 0.013593764975667
Loss at batch 200 : 0.011542487889528275
Loss at batch 210 : 0.014210402965545654
Loss at batch 220 : 0.017965758219361305
Loss at batch 230 : 0.006536436267197132
Loss at batch 240 : 0.016994955018162727
Loss at batch 250 : 0.018073298037052155
Loss at batch 260 : 0.006198137532919645
Loss at batch 270 : 0.0163169726729393
Loss at batch 280 : 0.02087351121008396
Loss at batch 290 : 0.008234783075749874
Loss at batch 300 : 0.012526601552963257
Loss at batch 310 : 0.009972434490919113
Loss at batch 320 : 0.012232229113578796
Loss at batch 330 : 0.015161856077611446
Loss at batch 340 : 0.017094753682613373
Loss at batch 350 : 0.012598546221852303
Loss at batch 360 : 0.014596318826079369
Loss at batch 370 : 0.009787364862859249
epoch111 finished!
Loss at batch 10 : 0.014594758860766888
Loss at batch 20 : 0.015393522568047047
Loss at batch 30 : 0.02492355741560459
Loss at batch 40 : 0.014894712716341019
Loss at batch 50 : 0.017456436529755592
Loss at batch 60 : 0.019151128828525543
Loss at batch 70 : 0.010395852848887444
Loss at batch 80 : 0.007251434493809938
Loss at batch 90 : 0.016782129183411598
Loss at batch 100 : 0.00845192838460207
Loss at batch 110 : 0.01660403423011303
Loss at batch 120 : 0.017588265240192413
Loss at batch 130 : 0.006055518053472042
Loss at batch 140 : 0.011428512632846832
Loss at batch 150 : 0.01012980192899704
Loss at batch 160 : 0.011728002689778805
Loss at batch 170 : 0.0128622492775321
Loss at batch 180 : 0.018302688375115395
Loss at batch 190 : 0.010452931746840477
Loss at batch 200 : 0.00893191434442997
Loss at batch 210 : 0.01368306390941143
Loss at batch 220 : 0.01730700023472309
Loss at batch 230 : 0.015237965621054173
Loss at batch 240 : 0.009306914173066616
Loss at batch 250 : 0.022688904777169228
Loss at batch 260 : 0.010517651215195656
Loss at batch 270 : 0.02017037384212017
Loss at batch 280 : 0.014977652579545975
Loss at batch 290 : 0.009556170552968979
Loss at batch 300 : 0.026295576244592667
Loss at batch 310 : 0.01687602698802948
Loss at batch 320 : 0.013506616465747356
Loss at batch 330 : 0.016657013446092606
Loss at batch 340 : 0.013223112560808659
Loss at batch 350 : 0.011452063918113708
Loss at batch 360 : 0.021427785977721214
Loss at batch 370 : 0.011785708367824554
epoch111 finished!
Loss at batch 10 : 0.017252784222364426
Loss at batch 20 : 0.016249310225248337
Loss at batch 30 : 0.010837788693606853
Loss at batch 40 : 0.01418424304574728
Loss at batch 50 : 0.011761218309402466
Loss at batch 60 : 0.01574702002108097
Loss at batch 70 : 0.006790751591324806
Loss at batch 80 : 0.014496814459562302
Loss at batch 90 : 0.01103966310620308
Loss at batch 100 : 0.010945074260234833
Loss at batch 110 : 0.01481572911143303
Loss at batch 120 : 0.016888875514268875
Loss at batch 130 : 0.019855299964547157
Loss at batch 140 : 0.01112743653357029
Loss at batch 150 : 0.007920543663203716
Loss at batch 160 : 0.009496258571743965
Loss at batch 170 : 0.009490299038589
Loss at batch 180 : 0.016206588596105576
Loss at batch 190 : 0.01876862905919552
Loss at batch 200 : 0.013000564649701118
Loss at batch 210 : 0.013236652128398418
Loss at batch 220 : 0.012257029302418232
Loss at batch 230 : 0.018501494079828262
Loss at batch 240 : 0.021142203360795975
Loss at batch 250 : 0.010899131186306477
Loss at batch 260 : 0.011298795230686665
Loss at batch 270 : 0.011798720806837082
Loss at batch 280 : 0.01288710068911314
Loss at batch 290 : 0.015515509992837906
Loss at batch 300 : 0.024301551282405853
Loss at batch 310 : 0.007366700563579798
Loss at batch 320 : 0.017726488411426544
Loss at batch 330 : 0.0128872599452734
Loss at batch 340 : 0.030827833339571953
Loss at batch 350 : 0.013232920318841934
Loss at batch 360 : 0.025143146514892578
Loss at batch 370 : 0.014281783252954483
epoch112 finished!
Loss at batch 10 : 0.012027484364807606
Loss at batch 20 : 0.010780018754303455
Loss at batch 30 : 0.01926705427467823
Loss at batch 40 : 0.015777183696627617
Loss at batch 50 : 0.011615660041570663
Loss at batch 60 : 0.021930299699306488
Loss at batch 70 : 0.013464326038956642
Loss at batch 80 : 0.012845872901380062
Loss at batch 90 : 0.013427576050162315
Loss at batch 100 : 0.010454820469021797
Loss at batch 110 : 0.01093350350856781
Loss at batch 120 : 0.00837179459631443
Loss at batch 130 : 0.01087091863155365
Loss at batch 140 : 0.017554927617311478
Loss at batch 150 : 0.02571142464876175
Loss at batch 160 : 0.01496728602796793
Loss at batch 170 : 0.01156788319349289
Loss at batch 180 : 0.015982484444975853
Loss at batch 190 : 0.010623900219798088
Loss at batch 200 : 0.010995077900588512
Loss at batch 210 : 0.014898397959768772
Loss at batch 220 : 0.00994107499718666
Loss at batch 230 : 0.00996617041528225
Loss at batch 240 : 0.012448934838175774
Loss at batch 250 : 0.013405198231339455
Loss at batch 260 : 0.01386820524930954
Loss at batch 270 : 0.01016728114336729
Loss at batch 280 : 0.017454372718930244
Loss at batch 290 : 0.013415788300335407
Loss at batch 300 : 0.018055615946650505
Loss at batch 310 : 0.010191611014306545
Loss at batch 320 : 0.01427240390330553
Loss at batch 330 : 0.014701414853334427
Loss at batch 340 : 0.01465755607932806
Loss at batch 350 : 0.021717097610235214
Loss at batch 360 : 0.014751947484910488
Loss at batch 370 : 0.018091771751642227
epoch112 finished!
Loss at batch 10 : 0.011517263948917389
Loss at batch 20 : 0.016121583059430122
Loss at batch 30 : 0.0126569839194417
Loss at batch 40 : 0.017262285575270653
Loss at batch 50 : 0.009247942827641964
Loss at batch 60 : 0.016822509467601776
Loss at batch 70 : 0.01032531913369894
Loss at batch 80 : 0.015055999159812927
Loss at batch 90 : 0.023041212931275368
Loss at batch 100 : 0.011870482936501503
Loss at batch 110 : 0.02350158803164959
Loss at batch 120 : 0.019600892439484596
Loss at batch 130 : 0.016213878989219666
Loss at batch 140 : 0.012586871162056923
Loss at batch 150 : 0.009211831726133823
Loss at batch 160 : 0.016620200127363205
Loss at batch 170 : 0.007198045030236244
Loss at batch 180 : 0.007757273968309164
Loss at batch 190 : 0.01160203106701374
Loss at batch 200 : 0.0184929221868515
Loss at batch 210 : 0.013024461455643177
Loss at batch 220 : 0.014434782788157463
Loss at batch 230 : 0.01003813836723566
Loss at batch 240 : 0.01536934170871973
Loss at batch 250 : 0.013557739555835724
Loss at batch 260 : 0.012341137044131756
Loss at batch 270 : 0.02661450393497944
Loss at batch 280 : 0.01618993654847145
Loss at batch 290 : 0.01364822406321764
Loss at batch 300 : 0.016687843948602676
Loss at batch 310 : 0.01762813702225685
Loss at batch 320 : 0.01483655534684658
Loss at batch 330 : 0.01378702837973833
Loss at batch 340 : 0.010875442996621132
Loss at batch 350 : 0.011315938085317612
Loss at batch 360 : 0.012407275848090649
Loss at batch 370 : 0.011938018724322319
epoch113 finished!
Loss at batch 10 : 0.00864972360432148
Loss at batch 20 : 0.022798839956521988
Loss at batch 30 : 0.009095550514757633
Loss at batch 40 : 0.016057999804615974
Loss at batch 50 : 0.016016583889722824
Loss at batch 60 : 0.008542372845113277
Loss at batch 70 : 0.019612468779087067
Loss at batch 80 : 0.017676403746008873
Loss at batch 90 : 0.01426058728247881
Loss at batch 100 : 0.018335789442062378
Loss at batch 110 : 0.00905372854322195
Loss at batch 120 : 0.020055627450346947
Loss at batch 130 : 0.02173033356666565
Loss at batch 140 : 0.022708412259817123
Loss at batch 150 : 0.00816544983536005
Loss at batch 160 : 0.010664490982890129
Loss at batch 170 : 0.01156369224190712
Loss at batch 180 : 0.014539909549057484
Loss at batch 190 : 0.012829208746552467
Loss at batch 200 : 0.00915341917425394
Loss at batch 210 : 0.010776820592582226
Loss at batch 220 : 0.010514594614505768
Loss at batch 230 : 0.006809924263507128
Loss at batch 240 : 0.012092665769159794
Loss at batch 250 : 0.015866467729210854
Loss at batch 260 : 0.02345760352909565
Loss at batch 270 : 0.02011333964765072
Loss at batch 280 : 0.010773233138024807
Loss at batch 290 : 0.009974492713809013
Loss at batch 300 : 0.014287233352661133
Loss at batch 310 : 0.01967109553515911
Loss at batch 320 : 0.013082358986139297
Loss at batch 330 : 0.012554938904941082
Loss at batch 340 : 0.022027764469385147
Loss at batch 350 : 0.02746938355267048
Loss at batch 360 : 0.009162645787000656
Loss at batch 370 : 0.018794985488057137
epoch113 finished!
Loss at batch 10 : 0.0081959068775177
Loss at batch 20 : 0.014795693568885326
Loss at batch 30 : 0.015445506200194359
Loss at batch 40 : 0.015129592269659042
Loss at batch 50 : 0.011987883597612381
Loss at batch 60 : 0.014860040508210659
Loss at batch 70 : 0.020043518394231796
Loss at batch 80 : 0.008823373354971409
Loss at batch 90 : 0.023122236132621765
Loss at batch 100 : 0.020536931231617928
Loss at batch 110 : 0.00815870426595211
Loss at batch 120 : 0.02025708742439747
Loss at batch 130 : 0.00917811319231987
Loss at batch 140 : 0.018436115235090256
Loss at batch 150 : 0.011725428514182568
Loss at batch 160 : 0.00851423665881157
Loss at batch 170 : 0.011699051596224308
Loss at batch 180 : 0.0322219617664814
Loss at batch 190 : 0.01068711094558239
Loss at batch 200 : 0.014450518414378166
Loss at batch 210 : 0.022054878994822502
Loss at batch 220 : 0.01698184385895729
Loss at batch 230 : 0.015304799191653728
Loss at batch 240 : 0.009920481592416763
Loss at batch 250 : 0.010543662123382092
Loss at batch 260 : 0.016650723293423653
Loss at batch 270 : 0.014129077084362507
Loss at batch 280 : 0.01543483417481184
Loss at batch 290 : 0.009125587530434132
Loss at batch 300 : 0.020883509889245033
Loss at batch 310 : 0.014065316878259182
Loss at batch 320 : 0.010882860980927944
Loss at batch 330 : 0.016517672687768936
Loss at batch 340 : 0.015042077749967575
Loss at batch 350 : 0.0110446996986866
Loss at batch 360 : 0.012020721100270748
Loss at batch 370 : 0.013655055314302444
epoch114 finished!
Loss at batch 10 : 0.014199754223227501
Loss at batch 20 : 0.01595691591501236
Loss at batch 30 : 0.011942199431359768
Loss at batch 40 : 0.01564600318670273
Loss at batch 50 : 0.013422383926808834
Loss at batch 60 : 0.011014939285814762
Loss at batch 70 : 0.009820365346968174
Loss at batch 80 : 0.011929127387702465
Loss at batch 90 : 0.014050513505935669
Loss at batch 100 : 0.010171057656407356
Loss at batch 110 : 0.009609079919755459
Loss at batch 120 : 0.025255722925066948
Loss at batch 130 : 0.01908131130039692
Loss at batch 140 : 0.019344285130500793
Loss at batch 150 : 0.010102222673594952
Loss at batch 160 : 0.01766400784254074
Loss at batch 170 : 0.019459601491689682
Loss at batch 180 : 0.009785658679902554
Loss at batch 190 : 0.007858592085540295
Loss at batch 200 : 0.008469863794744015
Loss at batch 210 : 0.025391554459929466
Loss at batch 220 : 0.012511149980127811
Loss at batch 230 : 0.019798999652266502
Loss at batch 240 : 0.01253562979400158
Loss at batch 250 : 0.008412564173340797
Loss at batch 260 : 0.01548987627029419
Loss at batch 270 : 0.018899589776992798
Loss at batch 280 : 0.012413875199854374
Loss at batch 290 : 0.018092095851898193
Loss at batch 300 : 0.01135439146310091
Loss at batch 310 : 0.009473791345953941
Loss at batch 320 : 0.017719971016049385
Loss at batch 330 : 0.01433759368956089
Loss at batch 340 : 0.011172718368470669
Loss at batch 350 : 0.010192301124334335
Loss at batch 360 : 0.01299368403851986
Loss at batch 370 : 0.020596230402588844
epoch114 finished!
Loss at batch 10 : 0.01381772756576538
Loss at batch 20 : 0.007871696725487709
Loss at batch 30 : 0.011853523552417755
Loss at batch 40 : 0.015780026093125343
Loss at batch 50 : 0.009515520185232162
Loss at batch 60 : 0.012490983121097088
Loss at batch 70 : 0.013530985452234745
Loss at batch 80 : 0.02055174484848976
Loss at batch 90 : 0.008804412558674812
Loss at batch 100 : 0.01610901579260826
Loss at batch 110 : 0.01518633309751749
Loss at batch 120 : 0.02357839047908783
Loss at batch 130 : 0.010344893671572208
Loss at batch 140 : 0.010180581361055374
Loss at batch 150 : 0.013297137804329395
Loss at batch 160 : 0.016173535957932472
Loss at batch 170 : 0.00997436698526144
Loss at batch 180 : 0.011105842888355255
Loss at batch 190 : 0.01162048988044262
Loss at batch 200 : 0.014730122871696949
Loss at batch 210 : 0.011872983537614346
Loss at batch 220 : 0.021063318476080894
Loss at batch 230 : 0.012083379551768303
Loss at batch 240 : 0.01161521952599287
Loss at batch 250 : 0.010885580442845821
Loss at batch 260 : 0.014600374735891819
Loss at batch 270 : 0.01375457551330328
Loss at batch 280 : 0.01276052463799715
Loss at batch 290 : 0.008216843008995056
Loss at batch 300 : 0.016124418005347252
Loss at batch 310 : 0.012961591593921185
Loss at batch 320 : 0.019208302721381187
Loss at batch 330 : 0.017747467383742332
Loss at batch 340 : 0.013655688613653183
Loss at batch 350 : 0.02278999425470829
Loss at batch 360 : 0.007109100930392742
Loss at batch 370 : 0.012661164626479149
epoch115 finished!
Loss at batch 10 : 0.01670701615512371
Loss at batch 20 : 0.015106067061424255
Loss at batch 30 : 0.01898300088942051
Loss at batch 40 : 0.015308295376598835
Loss at batch 50 : 0.022531885653734207
Loss at batch 60 : 0.00913634616881609
Loss at batch 70 : 0.012484394013881683
Loss at batch 80 : 0.012998760677874088
Loss at batch 90 : 0.016888370737433434
Loss at batch 100 : 0.01505324523895979
Loss at batch 110 : 0.015676157549023628
Loss at batch 120 : 0.009726405143737793
Loss at batch 130 : 0.010123390704393387
Loss at batch 140 : 0.011231551878154278
Loss at batch 150 : 0.030610892921686172
Loss at batch 160 : 0.01727505773305893
Loss at batch 170 : 0.013944299891591072
Loss at batch 180 : 0.02108730562031269
Loss at batch 190 : 0.022403404116630554
Loss at batch 200 : 0.009501977823674679
Loss at batch 210 : 0.012042013928294182
Loss at batch 220 : 0.020470740273594856
Loss at batch 230 : 0.011008867993950844
Loss at batch 240 : 0.016899826005101204
Loss at batch 250 : 0.01850903406739235
Loss at batch 260 : 0.01349664106965065
Loss at batch 270 : 0.010217077098786831
Loss at batch 280 : 0.02037009783089161
Loss at batch 290 : 0.013836875557899475
Loss at batch 300 : 0.011977090500295162
Loss at batch 310 : 0.014130422845482826
Loss at batch 320 : 0.017508938908576965
Loss at batch 330 : 0.01626814343035221
Loss at batch 340 : 0.008672809228301048
Loss at batch 350 : 0.007103023584932089
Loss at batch 360 : 0.01454149466007948
Loss at batch 370 : 0.008267118595540524
epoch115 finished!
Loss at batch 10 : 0.010085941292345524
Loss at batch 20 : 0.010634288191795349
Loss at batch 30 : 0.007444566581398249
Loss at batch 40 : 0.010797228664159775
Loss at batch 50 : 0.014161219820380211
Loss at batch 60 : 0.012808318249881268
Loss at batch 70 : 0.0189663115888834
Loss at batch 80 : 0.016708487644791603
Loss at batch 90 : 0.009542007930576801
Loss at batch 100 : 0.010527853854000568
Loss at batch 110 : 0.011729813180863857
Loss at batch 120 : 0.015851953998208046
Loss at batch 130 : 0.007334178779274225
Loss at batch 140 : 0.017554959282279015
Loss at batch 150 : 0.019876880571246147
Loss at batch 160 : 0.015144344419240952
Loss at batch 170 : 0.011821962893009186
Loss at batch 180 : 0.024862797930836678
Loss at batch 190 : 0.014253176748752594
Loss at batch 200 : 0.013438931666314602
Loss at batch 210 : 0.022537657991051674
Loss at batch 220 : 0.00801908690482378
Loss at batch 230 : 0.004858298227190971
Loss at batch 240 : 0.017831353470683098
Loss at batch 250 : 0.014774358831346035
Loss at batch 260 : 0.018956417217850685
Loss at batch 270 : 0.014968044124543667
Loss at batch 280 : 0.013519644737243652
Loss at batch 290 : 0.018081529065966606
Loss at batch 300 : 0.011973796412348747
Loss at batch 310 : 0.01809077337384224
Loss at batch 320 : 0.012013528496026993
Loss at batch 330 : 0.01036263071000576
Loss at batch 340 : 0.011690869927406311
Loss at batch 350 : 0.013546185567975044
Loss at batch 360 : 0.01721811480820179
Loss at batch 370 : 0.011466681025922298
epoch116 finished!
Loss at batch 10 : 0.00870408583432436
Loss at batch 20 : 0.013617168180644512
Loss at batch 30 : 0.02480573020875454
Loss at batch 40 : 0.01392887532711029
Loss at batch 50 : 0.005722563248127699
Loss at batch 60 : 0.016109829768538475
Loss at batch 70 : 0.01838645525276661
Loss at batch 80 : 0.009043339639902115
Loss at batch 90 : 0.01485320832580328
Loss at batch 100 : 0.022063005715608597
Loss at batch 110 : 0.016040150076150894
Loss at batch 120 : 0.017772063612937927
Loss at batch 130 : 0.012060784734785557
Loss at batch 140 : 0.020768672227859497
Loss at batch 150 : 0.006575779058039188
Loss at batch 160 : 0.012849437072873116
Loss at batch 170 : 0.013389257714152336
Loss at batch 180 : 0.018517643213272095
Loss at batch 190 : 0.015499770641326904
Loss at batch 200 : 0.014119651168584824
Loss at batch 210 : 0.014661219902336597
Loss at batch 220 : 0.014199680648744106
Loss at batch 230 : 0.014093492180109024
Loss at batch 240 : 0.014444972388446331
Loss at batch 250 : 0.011672904714941978
Loss at batch 260 : 0.010749931447207928
Loss at batch 270 : 0.008967220783233643
Loss at batch 280 : 0.018084298819303513
Loss at batch 290 : 0.016731223091483116
Loss at batch 300 : 0.0078047956340014935
Loss at batch 310 : 0.0148234311491251
Loss at batch 320 : 0.017894428223371506
Loss at batch 330 : 0.011317442171275616
Loss at batch 340 : 0.020838381722569466
Loss at batch 350 : 0.01630743220448494
Loss at batch 360 : 0.01183479093015194
Loss at batch 370 : 0.01795184426009655
epoch116 finished!
Loss at batch 10 : 0.018471743911504745
Loss at batch 20 : 0.011197978630661964
Loss at batch 30 : 0.023354550823569298
Loss at batch 40 : 0.007957624271512032
Loss at batch 50 : 0.01409161277115345
Loss at batch 60 : 0.015474953688681126
Loss at batch 70 : 0.016620023176074028
Loss at batch 80 : 0.011544800363481045
Loss at batch 90 : 0.006955633405596018
Loss at batch 100 : 0.01067774835973978
Loss at batch 110 : 0.011834617704153061
Loss at batch 120 : 0.006438619922846556
Loss at batch 130 : 0.008371123112738132
Loss at batch 140 : 0.015079604461789131
Loss at batch 150 : 0.014198344200849533
Loss at batch 160 : 0.013766694813966751
Loss at batch 170 : 0.0072738733142614365
Loss at batch 180 : 0.007516069803386927
Loss at batch 190 : 0.00926998257637024
Loss at batch 200 : 0.009246462024748325
Loss at batch 210 : 0.02652904950082302
Loss at batch 220 : 0.008595223538577557
Loss at batch 230 : 0.017493238672614098
Loss at batch 240 : 0.011752329766750336
Loss at batch 250 : 0.014150748029351234
Loss at batch 260 : 0.01662093587219715
Loss at batch 270 : 0.02720576710999012
Loss at batch 280 : 0.015661414712667465
Loss at batch 290 : 0.021759679540991783
Loss at batch 300 : 0.008875702507793903
Loss at batch 310 : 0.019473306834697723
Loss at batch 320 : 0.023223796859383583
Loss at batch 330 : 0.01299939677119255
Loss at batch 340 : 0.01407795213162899
Loss at batch 350 : 0.015556647442281246
Loss at batch 360 : 0.016361629590392113
Loss at batch 370 : 0.014682278037071228
epoch117 finished!
Loss at batch 10 : 0.009893870912492275
Loss at batch 20 : 0.013648093678057194
Loss at batch 30 : 0.007447352167218924
Loss at batch 40 : 0.011867767199873924
Loss at batch 50 : 0.013362949714064598
Loss at batch 60 : 0.015183726325631142
Loss at batch 70 : 0.021279655396938324
Loss at batch 80 : 0.01682019792497158
Loss at batch 90 : 0.015726905316114426
Loss at batch 100 : 0.012142753228545189
Loss at batch 110 : 0.008920692838728428
Loss at batch 120 : 0.012027740478515625
Loss at batch 130 : 0.016434669494628906
Loss at batch 140 : 0.012254348024725914
Loss at batch 150 : 0.016481535509228706
Loss at batch 160 : 0.009621873497962952
Loss at batch 170 : 0.014984168112277985
Loss at batch 180 : 0.010721404105424881
Loss at batch 190 : 0.018215226009488106
Loss at batch 200 : 0.017775284126400948
Loss at batch 210 : 0.0123029425740242
Loss at batch 220 : 0.014885354787111282
Loss at batch 230 : 0.01552526280283928
Loss at batch 240 : 0.012216332368552685
Loss at batch 250 : 0.013455106876790524
Loss at batch 260 : 0.026489270851016045
Loss at batch 270 : 0.014655007980763912
Loss at batch 280 : 0.011984670534729958
Loss at batch 290 : 0.013876528479158878
Loss at batch 300 : 0.012800032272934914
Loss at batch 310 : 0.010224302299320698
Loss at batch 320 : 0.015286003239452839
Loss at batch 330 : 0.021538658067584038
Loss at batch 340 : 0.020836297422647476
Loss at batch 350 : 0.011285065673291683
Loss at batch 360 : 0.009213327430188656
Loss at batch 370 : 0.011723370291292667
epoch117 finished!
Loss at batch 10 : 0.020173916593194008
Loss at batch 20 : 0.017172951251268387
Loss at batch 30 : 0.012228194624185562
Loss at batch 40 : 0.008355459198355675
Loss at batch 50 : 0.00783004891127348
Loss at batch 60 : 0.015308785252273083
Loss at batch 70 : 0.012968864291906357
Loss at batch 80 : 0.023512989282608032
Loss at batch 90 : 0.013622373342514038
Loss at batch 100 : 0.013578087091445923
Loss at batch 110 : 0.018969446420669556
Loss at batch 120 : 0.013593774288892746
Loss at batch 130 : 0.010969706811010838
Loss at batch 140 : 0.016695218160748482
Loss at batch 150 : 0.008846276439726353
Loss at batch 160 : 0.014269474893808365
Loss at batch 170 : 0.01742279715836048
Loss at batch 180 : 0.009921861812472343
Loss at batch 190 : 0.010314378887414932
Loss at batch 200 : 0.017724908888339996
Loss at batch 210 : 0.021636512130498886
Loss at batch 220 : 0.015581534244120121
Loss at batch 230 : 0.006722503807395697
Loss at batch 240 : 0.01288342010229826
Loss at batch 250 : 0.013303718529641628
Loss at batch 260 : 0.014866767451167107
Loss at batch 270 : 0.01400933787226677
Loss at batch 280 : 0.012146045453846455
Loss at batch 290 : 0.0053689004853367805
Loss at batch 300 : 0.015147245489060879
Loss at batch 310 : 0.008044577203691006
Loss at batch 320 : 0.011608641594648361
Loss at batch 330 : 0.014700395055115223
Loss at batch 340 : 0.017756128683686256
Loss at batch 350 : 0.00821832474321127
Loss at batch 360 : 0.00801216159015894
Loss at batch 370 : 0.007909786887466908
epoch118 finished!
Loss at batch 10 : 0.019910676404833794
Loss at batch 20 : 0.018100734800100327
Loss at batch 30 : 0.007311454974114895
Loss at batch 40 : 0.011452977545559406
Loss at batch 50 : 0.006928892340511084
Loss at batch 60 : 0.01287319976836443
Loss at batch 70 : 0.016793306916952133
Loss at batch 80 : 0.011456804350018501
Loss at batch 90 : 0.01434649620205164
Loss at batch 100 : 0.020554563030600548
Loss at batch 110 : 0.017794180661439896
Loss at batch 120 : 0.010473594069480896
Loss at batch 130 : 0.011464901268482208
Loss at batch 140 : 0.018435582518577576
Loss at batch 150 : 0.01243648212403059
Loss at batch 160 : 0.010689405724406242
Loss at batch 170 : 0.009951549582183361
Loss at batch 180 : 0.024425406008958817
Loss at batch 190 : 0.022867169231176376
Loss at batch 200 : 0.011248188093304634
Loss at batch 210 : 0.015811584889888763
Loss at batch 220 : 0.02012939751148224
Loss at batch 230 : 0.011473621241748333
Loss at batch 240 : 0.012862421572208405
Loss at batch 250 : 0.018655434250831604
Loss at batch 260 : 0.010324317961931229
Loss at batch 270 : 0.01719321496784687
Loss at batch 280 : 0.011302067898213863
Loss at batch 290 : 0.02147955633699894
Loss at batch 300 : 0.009773616679012775
Loss at batch 310 : 0.013052704744040966
Loss at batch 320 : 0.009175014682114124
Loss at batch 330 : 0.010895789600908756
Loss at batch 340 : 0.021158404648303986
Loss at batch 350 : 0.01485748216509819
Loss at batch 360 : 0.01816229522228241
Loss at batch 370 : 0.011364445090293884
epoch118 finished!
Loss at batch 10 : 0.015476252883672714
Loss at batch 20 : 0.012613683938980103
Loss at batch 30 : 0.019418912008404732
Loss at batch 40 : 0.0146462582051754
Loss at batch 50 : 0.011449496261775494
Loss at batch 60 : 0.018348198384046555
Loss at batch 70 : 0.01800454966723919
Loss at batch 80 : 0.008269080892205238
Loss at batch 90 : 0.010506106540560722
Loss at batch 100 : 0.018561838194727898
Loss at batch 110 : 0.014691297896206379
Loss at batch 120 : 0.015075582079589367
Loss at batch 130 : 0.020103611052036285
Loss at batch 140 : 0.02614710107445717
Loss at batch 150 : 0.014779706485569477
Loss at batch 160 : 0.01626640185713768
Loss at batch 170 : 0.01144740916788578
Loss at batch 180 : 0.015261533670127392
Loss at batch 190 : 0.015545627102255821
Loss at batch 200 : 0.011873798444867134
Loss at batch 210 : 0.011005711741745472
Loss at batch 220 : 0.011718248948454857
Loss at batch 230 : 0.019941110163927078
Loss at batch 240 : 0.014509587548673153
Loss at batch 250 : 0.006479119881987572
Loss at batch 260 : 0.01595268025994301
Loss at batch 270 : 0.016428625211119652
Loss at batch 280 : 0.029134482145309448
Loss at batch 290 : 0.014229935593903065
Loss at batch 300 : 0.015107746236026287
Loss at batch 310 : 0.009713368490338326
Loss at batch 320 : 0.007605032064020634
Loss at batch 330 : 0.008128372952342033
Loss at batch 340 : 0.014438832178711891
Loss at batch 350 : 0.018372127786278725
Loss at batch 360 : 0.014425267465412617
Loss at batch 370 : 0.0169196929782629
epoch119 finished!
Loss at batch 10 : 0.011800426058471203
Loss at batch 20 : 0.01461791805922985
Loss at batch 30 : 0.010846108198165894
Loss at batch 40 : 0.01556702796369791
Loss at batch 50 : 0.02099662460386753
Loss at batch 60 : 0.017643257975578308
Loss at batch 70 : 0.013583339750766754
Loss at batch 80 : 0.019093137234449387
Loss at batch 90 : 0.01374051719903946
Loss at batch 100 : 0.011903822422027588
Loss at batch 110 : 0.011963378638029099
Loss at batch 120 : 0.018795328214764595
Loss at batch 130 : 0.014687943272292614
Loss at batch 140 : 0.016425851732492447
Loss at batch 150 : 0.011010081507265568
Loss at batch 160 : 0.017319494858384132
Loss at batch 170 : 0.0208626389503479
Loss at batch 180 : 0.008058913983404636
Loss at batch 190 : 0.018206218257546425
Loss at batch 200 : 0.013985437341034412
Loss at batch 210 : 0.013396515510976315
Loss at batch 220 : 0.010176455602049828
Loss at batch 230 : 0.022527135908603668
Loss at batch 240 : 0.015580958686769009
Loss at batch 250 : 0.01515866443514824
Loss at batch 260 : 0.01846192218363285
Loss at batch 270 : 0.016019999980926514
Loss at batch 280 : 0.022705649957060814
Loss at batch 290 : 0.00917041301727295
Loss at batch 300 : 0.013784285634756088
Loss at batch 310 : 0.01360032893717289
Loss at batch 320 : 0.008167918771505356
Loss at batch 330 : 0.012283653020858765
Loss at batch 340 : 0.024269629269838333
Loss at batch 350 : 0.008081750944256783
Loss at batch 360 : 0.008369285613298416
Loss at batch 370 : 0.015227398835122585
epoch119 finished!
Loss at batch 10 : 0.007782853674143553
Loss at batch 20 : 0.009998396039009094
Loss at batch 30 : 0.01235599908977747
Loss at batch 40 : 0.010554741136729717
Loss at batch 50 : 0.011841543018817902
Loss at batch 60 : 0.013612592592835426
Loss at batch 70 : 0.012369190342724323
Loss at batch 80 : 0.013346142135560513
Loss at batch 90 : 0.029456688091158867
Loss at batch 100 : 0.024518342688679695
Loss at batch 110 : 0.013841711916029453
Loss at batch 120 : 0.009725806303322315
Loss at batch 130 : 0.011729017831385136
Loss at batch 140 : 0.007070738822221756
Loss at batch 150 : 0.016376296058297157
Loss at batch 160 : 0.022071778774261475
Loss at batch 170 : 0.010315465740859509
Loss at batch 180 : 0.012807196006178856
Loss at batch 190 : 0.019463984295725822
Loss at batch 200 : 0.011782943271100521
Loss at batch 210 : 0.013971715234220028
Loss at batch 220 : 0.026822734624147415
Loss at batch 230 : 0.0132963377982378
Loss at batch 240 : 0.018582547083497047
Loss at batch 250 : 0.01675235852599144
Loss at batch 260 : 0.013960846699774265
Loss at batch 270 : 0.01670786738395691
Loss at batch 280 : 0.013777332380414009
Loss at batch 290 : 0.00503874896094203
Loss at batch 300 : 0.021438727155327797
Loss at batch 310 : 0.017617080360651016
Loss at batch 320 : 0.00913993176072836
Loss at batch 330 : 0.010404934175312519
Loss at batch 340 : 0.009096410125494003
Loss at batch 350 : 0.010427170433104038
Loss at batch 360 : 0.014282027259469032
Loss at batch 370 : 0.011253096163272858
epoch120 finished!
Loss at batch 10 : 0.01923610083758831
Loss at batch 20 : 0.015410948544740677
Loss at batch 30 : 0.008032567799091339
Loss at batch 40 : 0.017421700060367584
Loss at batch 50 : 0.009161077439785004
Loss at batch 60 : 0.009546437300741673
Loss at batch 70 : 0.01259398553520441
Loss at batch 80 : 0.014884240925312042
Loss at batch 90 : 0.009974123910069466
Loss at batch 100 : 0.017824042588472366
Loss at batch 110 : 0.012572850100696087
Loss at batch 120 : 0.013043751940131187
Loss at batch 130 : 0.018290964886546135
Loss at batch 140 : 0.01904282160103321
Loss at batch 150 : 0.012696824036538601
Loss at batch 160 : 0.014725230634212494
Loss at batch 170 : 0.02040325291454792
Loss at batch 180 : 0.016545897349715233
Loss at batch 190 : 0.01202939823269844
Loss at batch 200 : 0.012100343592464924
Loss at batch 210 : 0.012364291585981846
Loss at batch 220 : 0.016523871570825577
Loss at batch 230 : 0.013558898121118546
Loss at batch 240 : 0.011909537017345428
Loss at batch 250 : 0.014194437302649021
Loss at batch 260 : 0.025909708812832832
Loss at batch 270 : 0.023508796468377113
Loss at batch 280 : 0.011919586919248104
Loss at batch 290 : 0.009414376690983772
Loss at batch 300 : 0.017175855115056038
Loss at batch 310 : 0.012663131579756737
Loss at batch 320 : 0.020180141553282738
Loss at batch 330 : 0.022722452878952026
Loss at batch 340 : 0.007717381231486797
Loss at batch 350 : 0.025983361527323723
Loss at batch 360 : 0.01711621694266796
Loss at batch 370 : 0.018358534201979637
epoch120 finished!
Loss at batch 10 : 0.007663209922611713
Loss at batch 20 : 0.0199129581451416
Loss at batch 30 : 0.0077875410206615925
Loss at batch 40 : 0.028835473582148552
Loss at batch 50 : 0.011553948745131493
Loss at batch 60 : 0.02287103980779648
Loss at batch 70 : 0.013826053589582443
Loss at batch 80 : 0.014365616254508495
Loss at batch 90 : 0.020047836005687714
Loss at batch 100 : 0.017925750464200974
Loss at batch 110 : 0.020200248807668686
Loss at batch 120 : 0.013697577640414238
Loss at batch 130 : 0.012382696382701397
Loss at batch 140 : 0.010903071612119675
Loss at batch 150 : 0.013883582316339016
Loss at batch 160 : 0.012056864798069
Loss at batch 170 : 0.010792381130158901
Loss at batch 180 : 0.01286507397890091
Loss at batch 190 : 0.021855007857084274
Loss at batch 200 : 0.011641432531177998
Loss at batch 210 : 0.013700558803975582
Loss at batch 220 : 0.014094741083681583
Loss at batch 230 : 0.011061965487897396
Loss at batch 240 : 0.005770190618932247
Loss at batch 250 : 0.017910901457071304
Loss at batch 260 : 0.03226806968450546
Loss at batch 270 : 0.01733808033168316
Loss at batch 280 : 0.017359737306833267
Loss at batch 290 : 0.014550480991601944
Loss at batch 300 : 0.008823467418551445
Loss at batch 310 : 0.017689237371087074
Loss at batch 320 : 0.010013848543167114
Loss at batch 330 : 0.01378032099455595
Loss at batch 340 : 0.007659307215362787
Loss at batch 350 : 0.0098552405834198
Loss at batch 360 : 0.02723545953631401
Loss at batch 370 : 0.013455379754304886
epoch121 finished!
Loss at batch 10 : 0.011076323688030243
Loss at batch 20 : 0.027749808505177498
Loss at batch 30 : 0.01319278497248888
Loss at batch 40 : 0.0071947528049349785
Loss at batch 50 : 0.015182743780314922
Loss at batch 60 : 0.01308516226708889
Loss at batch 70 : 0.0173705592751503
Loss at batch 80 : 0.013002336956560612
Loss at batch 90 : 0.019958293065428734
Loss at batch 100 : 0.011535285972058773
Loss at batch 110 : 0.02025461383163929
Loss at batch 120 : 0.010965235531330109
Loss at batch 130 : 0.013800963759422302
Loss at batch 140 : 0.020766686648130417
Loss at batch 150 : 0.014162968844175339
Loss at batch 160 : 0.006401456892490387
Loss at batch 170 : 0.012389001436531544
Loss at batch 180 : 0.014180739410221577
Loss at batch 190 : 0.014726667664945126
Loss at batch 200 : 0.020305844023823738
Loss at batch 210 : 0.011638416908681393
Loss at batch 220 : 0.0096006840467453
Loss at batch 230 : 0.014126051217317581
Loss at batch 240 : 0.013887155801057816
Loss at batch 250 : 0.008576072752475739
Loss at batch 260 : 0.012862062081694603
Loss at batch 270 : 0.02007211185991764
Loss at batch 280 : 0.011025667190551758
Loss at batch 290 : 0.00985411461442709
Loss at batch 300 : 0.02676706574857235
Loss at batch 310 : 0.008884206414222717
Loss at batch 320 : 0.009155023843050003
Loss at batch 330 : 0.014219122938811779
Loss at batch 340 : 0.016858527436852455
Loss at batch 350 : 0.022653372958302498
Loss at batch 360 : 0.018282759934663773
Loss at batch 370 : 0.013128574937582016
epoch121 finished!
Loss at batch 10 : 0.008454378694295883
Loss at batch 20 : 0.021400948986411095
Loss at batch 30 : 0.014892451465129852
Loss at batch 40 : 0.011362588033080101
Loss at batch 50 : 0.011477500200271606
Loss at batch 60 : 0.018545689061284065
Loss at batch 70 : 0.010315729305148125
Loss at batch 80 : 0.01009890902787447
Loss at batch 90 : 0.01542087271809578
Loss at batch 100 : 0.013945800252258778
Loss at batch 110 : 0.012219018302857876
Loss at batch 120 : 0.012326638214290142
Loss at batch 130 : 0.010704120621085167
Loss at batch 140 : 0.015337707474827766
Loss at batch 150 : 0.026073481887578964
Loss at batch 160 : 0.009248279966413975
Loss at batch 170 : 0.012813941575586796
Loss at batch 180 : 0.0163970235735178
Loss at batch 190 : 0.01354715134948492
Loss at batch 200 : 0.012724853120744228
Loss at batch 210 : 0.024289699271321297
Loss at batch 220 : 0.006964379921555519
Loss at batch 230 : 0.012120538391172886
Loss at batch 240 : 0.016102077439427376
Loss at batch 250 : 0.008028348907828331
Loss at batch 260 : 0.016139887273311615
Loss at batch 270 : 0.01832878775894642
Loss at batch 280 : 0.009541249834001064
Loss at batch 290 : 0.02165757492184639
Loss at batch 300 : 0.010832379572093487
Loss at batch 310 : 0.024055566638708115
Loss at batch 320 : 0.00984308309853077
Loss at batch 330 : 0.010229718871414661
Loss at batch 340 : 0.017648352310061455
Loss at batch 350 : 0.011505039408802986
Loss at batch 360 : 0.017621731385588646
Loss at batch 370 : 0.011884598061442375
epoch122 finished!
Loss at batch 10 : 0.016642464324831963
Loss at batch 20 : 0.02264825813472271
Loss at batch 30 : 0.007906513288617134
Loss at batch 40 : 0.014725025743246078
Loss at batch 50 : 0.01353787537664175
Loss at batch 60 : 0.013901475816965103
Loss at batch 70 : 0.014955801889300346
Loss at batch 80 : 0.016642587259411812
Loss at batch 90 : 0.014034966938197613
Loss at batch 100 : 0.0157843716442585
Loss at batch 110 : 0.011669893749058247
Loss at batch 120 : 0.01418287307024002
Loss at batch 130 : 0.014118656516075134
Loss at batch 140 : 0.009638717398047447
Loss at batch 150 : 0.010129316709935665
Loss at batch 160 : 0.008157565258443356
Loss at batch 170 : 0.016250580549240112
Loss at batch 180 : 0.011877943761646748
Loss at batch 190 : 0.009950367733836174
Loss at batch 200 : 0.01898711360991001
Loss at batch 210 : 0.011082690209150314
Loss at batch 220 : 0.013676685281097889
Loss at batch 230 : 0.013461262919008732
Loss at batch 240 : 0.022526519373059273
Loss at batch 250 : 0.02077903412282467
Loss at batch 260 : 0.01745487004518509
Loss at batch 270 : 0.01073501631617546
Loss at batch 280 : 0.008821550756692886
Loss at batch 290 : 0.017953140661120415
Loss at batch 300 : 0.006804735865443945
Loss at batch 310 : 0.016971919685602188
Loss at batch 320 : 0.009391291067004204
Loss at batch 330 : 0.010128623805940151
Loss at batch 340 : 0.011107790283858776
Loss at batch 350 : 0.012822974473237991
Loss at batch 360 : 0.0079922154545784
Loss at batch 370 : 0.015343962237238884
epoch122 finished!
Loss at batch 10 : 0.022761305794119835
Loss at batch 20 : 0.019251957535743713
Loss at batch 30 : 0.015581073239445686
Loss at batch 40 : 0.01728728599846363
Loss at batch 50 : 0.011879809200763702
Loss at batch 60 : 0.011883886530995369
Loss at batch 70 : 0.020705344155430794
Loss at batch 80 : 0.015537931583821774
Loss at batch 90 : 0.015807490795850754
Loss at batch 100 : 0.016418742015957832
Loss at batch 110 : 0.014702491462230682
Loss at batch 120 : 0.018716420978307724
Loss at batch 130 : 0.01638047955930233
Loss at batch 140 : 0.009233786724507809
Loss at batch 150 : 0.01848084107041359
Loss at batch 160 : 0.010049933567643166
Loss at batch 170 : 0.015193410217761993
Loss at batch 180 : 0.012775305658578873
Loss at batch 190 : 0.012544069439172745
Loss at batch 200 : 0.016066359356045723
Loss at batch 210 : 0.02029292844235897
Loss at batch 220 : 0.019354751333594322
Loss at batch 230 : 0.017330538481473923
Loss at batch 240 : 0.014781159348785877
Loss at batch 250 : 0.015464738942682743
Loss at batch 260 : 0.009734092280268669
Loss at batch 270 : 0.01684478297829628
Loss at batch 280 : 0.017639894038438797
Loss at batch 290 : 0.018406936898827553
Loss at batch 300 : 0.014862477779388428
Loss at batch 310 : 0.01231620367616415
Loss at batch 320 : 0.009279257617890835
Loss at batch 330 : 0.01108249370008707
Loss at batch 340 : 0.015276703052222729
Loss at batch 350 : 0.014685459434986115
Loss at batch 360 : 0.007177254650741816
Loss at batch 370 : 0.00785211194306612
epoch123 finished!
Loss at batch 10 : 0.01230623945593834
Loss at batch 20 : 0.011372270993888378
Loss at batch 30 : 0.00970264058560133
Loss at batch 40 : 0.011495710350573063
Loss at batch 50 : 0.006714608054608107
Loss at batch 60 : 0.009602347388863564
Loss at batch 70 : 0.011558866128325462
Loss at batch 80 : 0.00810677744448185
Loss at batch 90 : 0.010875329375267029
Loss at batch 100 : 0.012612678110599518
Loss at batch 110 : 0.012640207074582577
Loss at batch 120 : 0.011584874242544174
Loss at batch 130 : 0.01655026525259018
Loss at batch 140 : 0.010771275497972965
Loss at batch 150 : 0.022607458755373955
Loss at batch 160 : 0.016379788517951965
Loss at batch 170 : 0.00879673007875681
Loss at batch 180 : 0.013440522365272045
Loss at batch 190 : 0.01350926049053669
Loss at batch 200 : 0.025514060631394386
Loss at batch 210 : 0.02937970496714115
Loss at batch 220 : 0.016534529626369476
Loss at batch 230 : 0.006943529937416315
Loss at batch 240 : 0.01899096556007862
Loss at batch 250 : 0.011140118353068829
Loss at batch 260 : 0.01569965109229088
Loss at batch 270 : 0.017423128709197044
Loss at batch 280 : 0.01091596856713295
Loss at batch 290 : 0.008883429691195488
Loss at batch 300 : 0.01647363044321537
Loss at batch 310 : 0.014970452524721622
Loss at batch 320 : 0.01768731139600277
Loss at batch 330 : 0.026854202151298523
Loss at batch 340 : 0.011690793558955193
Loss at batch 350 : 0.011204288341104984
Loss at batch 360 : 0.011513680219650269
Loss at batch 370 : 0.011138209141790867
epoch123 finished!
Loss at batch 10 : 0.016118202358484268
Loss at batch 20 : 0.018080096691846848
Loss at batch 30 : 0.011202017776668072
Loss at batch 40 : 0.026056014001369476
Loss at batch 50 : 0.018091557547450066
Loss at batch 60 : 0.01599663682281971
Loss at batch 70 : 0.014583134092390537
Loss at batch 80 : 0.021425452083349228
Loss at batch 90 : 0.012564213946461678
Loss at batch 100 : 0.01896939054131508
Loss at batch 110 : 0.008206198923289776
Loss at batch 120 : 0.010872652754187584
Loss at batch 130 : 0.009669923223555088
Loss at batch 140 : 0.007865901105105877
Loss at batch 150 : 0.00849040038883686
Loss at batch 160 : 0.01364805642515421
Loss at batch 170 : 0.017897330224514008
Loss at batch 180 : 0.0072943163104355335
Loss at batch 190 : 0.021700751036405563
Loss at batch 200 : 0.01066554244607687
Loss at batch 210 : 0.012381864711642265
Loss at batch 220 : 0.008341002278029919
Loss at batch 230 : 0.02047714777290821
Loss at batch 240 : 0.01784159243106842
Loss at batch 250 : 0.017019733786582947
Loss at batch 260 : 0.019402913749217987
Loss at batch 270 : 0.011281823739409447
Loss at batch 280 : 0.01087554544210434
Loss at batch 290 : 0.00849026720970869
Loss at batch 300 : 0.014000912196934223
Loss at batch 310 : 0.01584642007946968
Loss at batch 320 : 0.021140726283192635
Loss at batch 330 : 0.012371735647320747
Loss at batch 340 : 0.010437045246362686
Loss at batch 350 : 0.014375796541571617
Loss at batch 360 : 0.017454246059060097
Loss at batch 370 : 0.026292840018868446
epoch124 finished!
Loss at batch 10 : 0.009734033606946468
Loss at batch 20 : 0.011605998501181602
Loss at batch 30 : 0.01861971989274025
Loss at batch 40 : 0.01255414541810751
Loss at batch 50 : 0.01555612962692976
Loss at batch 60 : 0.014481380581855774
Loss at batch 70 : 0.009574498049914837
Loss at batch 80 : 0.012564916163682938
Loss at batch 90 : 0.01453693863004446
Loss at batch 100 : 0.020112695172429085
Loss at batch 110 : 0.007538890466094017
Loss at batch 120 : 0.00963406078517437
Loss at batch 130 : 0.008790883235633373
Loss at batch 140 : 0.017200546339154243
Loss at batch 150 : 0.021535322070121765
Loss at batch 160 : 0.009767877869307995
Loss at batch 170 : 0.01335076056420803
Loss at batch 180 : 0.011937594972550869
Loss at batch 190 : 0.008106990717351437
Loss at batch 200 : 0.016823841258883476
Loss at batch 210 : 0.01109568402171135
Loss at batch 220 : 0.011550238355994225
Loss at batch 230 : 0.014141757041215897
Loss at batch 240 : 0.012895804829895496
Loss at batch 250 : 0.012566830962896347
Loss at batch 260 : 0.011007859371602535
Loss at batch 270 : 0.015600034035742283
Loss at batch 280 : 0.008263004943728447
Loss at batch 290 : 0.011954274959862232
Loss at batch 300 : 0.017157962545752525
Loss at batch 310 : 0.012501958757638931
Loss at batch 320 : 0.019337715581059456
Loss at batch 330 : 0.013977369293570518
Loss at batch 340 : 0.017059920355677605
Loss at batch 350 : 0.015019251964986324
Loss at batch 360 : 0.024287579581141472
Loss at batch 370 : 0.011844978667795658
epoch124 finished!
Loss at batch 10 : 0.01603124476969242
Loss at batch 20 : 0.014464836567640305
Loss at batch 30 : 0.013509091921150684
Loss at batch 40 : 0.01657845266163349
Loss at batch 50 : 0.015335042029619217
Loss at batch 60 : 0.008402789011597633
Loss at batch 70 : 0.02075820043683052
Loss at batch 80 : 0.013679128140211105
Loss at batch 90 : 0.013889862224459648
Loss at batch 100 : 0.023093728348612785
Loss at batch 110 : 0.0101688327267766
Loss at batch 120 : 0.013095214031636715
Loss at batch 130 : 0.012458804994821548
Loss at batch 140 : 0.016057822853326797
Loss at batch 150 : 0.019645826891064644
Loss at batch 160 : 0.031174922361969948
Loss at batch 170 : 0.014504742808640003
Loss at batch 180 : 0.010609714314341545
Loss at batch 190 : 0.039410300552845
Loss at batch 200 : 0.00833609513938427
Loss at batch 210 : 0.00989505648612976
Loss at batch 220 : 0.016161762177944183
Loss at batch 230 : 0.010681175626814365
Loss at batch 240 : 0.015095560811460018
Loss at batch 250 : 0.01741679571568966
Loss at batch 260 : 0.016570892184972763
Loss at batch 270 : 0.009725350886583328
Loss at batch 280 : 0.00868922472000122
Loss at batch 290 : 0.02213473990559578
Loss at batch 300 : 0.0213478934019804
Loss at batch 310 : 0.013063759543001652
Loss at batch 320 : 0.011602160520851612
Loss at batch 330 : 0.009560742415487766
Loss at batch 340 : 0.021560776978731155
Loss at batch 350 : 0.011746488511562347
Loss at batch 360 : 0.01044134795665741
Loss at batch 370 : 0.015466530807316303
epoch125 finished!
Loss at batch 10 : 0.015349851921200752
Loss at batch 20 : 0.023363346233963966
Loss at batch 30 : 0.008755735121667385
Loss at batch 40 : 0.013492591679096222
Loss at batch 50 : 0.016960835084319115
Loss at batch 60 : 0.009489519521594048
Loss at batch 70 : 0.016588879749178886
Loss at batch 80 : 0.01770559698343277
Loss at batch 90 : 0.009382332675158978
Loss at batch 100 : 0.010002483613789082
Loss at batch 110 : 0.010324571281671524
Loss at batch 120 : 0.012200086377561092
Loss at batch 130 : 0.011394797824323177
Loss at batch 140 : 0.009840977378189564
Loss at batch 150 : 0.010964447632431984
Loss at batch 160 : 0.009061053395271301
Loss at batch 170 : 0.020292121917009354
Loss at batch 180 : 0.01987842097878456
Loss at batch 190 : 0.008488580584526062
Loss at batch 200 : 0.016689131036400795
Loss at batch 210 : 0.01111383643001318
Loss at batch 220 : 0.0080427136272192
Loss at batch 230 : 0.009108802303671837
Loss at batch 240 : 0.01778344251215458
Loss at batch 250 : 0.016532259061932564
Loss at batch 260 : 0.014769420027732849
Loss at batch 270 : 0.013124234043061733
Loss at batch 280 : 0.01673717051744461
Loss at batch 290 : 0.014845982193946838
Loss at batch 300 : 0.014684636145830154
Loss at batch 310 : 0.02208772674202919
Loss at batch 320 : 0.009780696593225002
Loss at batch 330 : 0.014418166130781174
Loss at batch 340 : 0.008647438138723373
Loss at batch 350 : 0.010976100340485573
Loss at batch 360 : 0.011442617513239384
Loss at batch 370 : 0.018690012395381927
epoch125 finished!
Loss at batch 10 : 0.008493640460073948
Loss at batch 20 : 0.022730598226189613
Loss at batch 30 : 0.010731784626841545
Loss at batch 40 : 0.015956249088048935
Loss at batch 50 : 0.018713459372520447
Loss at batch 60 : 0.010184532031416893
Loss at batch 70 : 0.012525090016424656
Loss at batch 80 : 0.01603657752275467
Loss at batch 90 : 0.02352089062333107
Loss at batch 100 : 0.012884330935776234
Loss at batch 110 : 0.014965186826884747
Loss at batch 120 : 0.01210756041109562
Loss at batch 130 : 0.012665622867643833
Loss at batch 140 : 0.015249225310981274
Loss at batch 150 : 0.013309299014508724
Loss at batch 160 : 0.011288647539913654
Loss at batch 170 : 0.00828491523861885
Loss at batch 180 : 0.017374863848090172
Loss at batch 190 : 0.015758607536554337
Loss at batch 200 : 0.014665700495243073
Loss at batch 210 : 0.02325606904923916
Loss at batch 220 : 0.012778135947883129
Loss at batch 230 : 0.013600821606814861
Loss at batch 240 : 0.01732856035232544
Loss at batch 250 : 0.0100067974999547
Loss at batch 260 : 0.00811432022601366
Loss at batch 270 : 0.01644689030945301
Loss at batch 280 : 0.013145898468792439
Loss at batch 290 : 0.008628623560070992
Loss at batch 300 : 0.01048370636999607
Loss at batch 310 : 0.009327634237706661
Loss at batch 320 : 0.013647879473865032
Loss at batch 330 : 0.016338955610990524
Loss at batch 340 : 0.01200296450406313
Loss at batch 350 : 0.013815892860293388
Loss at batch 360 : 0.020063739269971848
Loss at batch 370 : 0.016160840168595314
epoch126 finished!
Loss at batch 10 : 0.025934919714927673
Loss at batch 20 : 0.016252964735031128
Loss at batch 30 : 0.008590334095060825
Loss at batch 40 : 0.016878925263881683
Loss at batch 50 : 0.011456502601504326
Loss at batch 60 : 0.010528244078159332
Loss at batch 70 : 0.009389766491949558
Loss at batch 80 : 0.009436610154807568
Loss at batch 90 : 0.007211937569081783
Loss at batch 100 : 0.019389567896723747
Loss at batch 110 : 0.013640209101140499
Loss at batch 120 : 0.015310953371226788
Loss at batch 130 : 0.010726713575422764
Loss at batch 140 : 0.014340315014123917
Loss at batch 150 : 0.01083276979625225
Loss at batch 160 : 0.0135417515411973
Loss at batch 170 : 0.01381972897797823
Loss at batch 180 : 0.01375583279877901
Loss at batch 190 : 0.024255404248833656
Loss at batch 200 : 0.01370946690440178
Loss at batch 210 : 0.01796262152493
Loss at batch 220 : 0.01296662725508213
Loss at batch 230 : 0.011215290986001492
Loss at batch 240 : 0.011294882744550705
Loss at batch 250 : 0.0188277717679739
Loss at batch 260 : 0.009436037391424179
Loss at batch 270 : 0.03607821837067604
Loss at batch 280 : 0.009422263130545616
Loss at batch 290 : 0.01296155620366335
Loss at batch 300 : 0.006988338194787502
Loss at batch 310 : 0.01770247146487236
Loss at batch 320 : 0.012949788011610508
Loss at batch 330 : 0.015215503983199596
Loss at batch 340 : 0.012243879027664661
Loss at batch 350 : 0.00858333520591259
Loss at batch 360 : 0.009004570543766022
Loss at batch 370 : 0.028239700943231583
epoch126 finished!
Loss at batch 10 : 0.018884701654314995
Loss at batch 20 : 0.020929811522364616
Loss at batch 30 : 0.007600762415677309
Loss at batch 40 : 0.01664343848824501
Loss at batch 50 : 0.007095612585544586
Loss at batch 60 : 0.007697525434195995
Loss at batch 70 : 0.01665864698588848
Loss at batch 80 : 0.008871474303305149
Loss at batch 90 : 0.011995900422334671
Loss at batch 100 : 0.010007016360759735
Loss at batch 110 : 0.016922449693083763
Loss at batch 120 : 0.012169498950242996
Loss at batch 130 : 0.029737940058112144
Loss at batch 140 : 0.019523421302437782
Loss at batch 150 : 0.012753709219396114
Loss at batch 160 : 0.022752806544303894
Loss at batch 170 : 0.010053248144686222
Loss at batch 180 : 0.01716543175280094
Loss at batch 190 : 0.010023043490946293
Loss at batch 200 : 0.009285158477723598
Loss at batch 210 : 0.010893918573856354
Loss at batch 220 : 0.010786847211420536
Loss at batch 230 : 0.010778968222439289
Loss at batch 240 : 0.018861733376979828
Loss at batch 250 : 0.01116445567458868
Loss at batch 260 : 0.016060946509242058
Loss at batch 270 : 0.008754752576351166
Loss at batch 280 : 0.012639335356652737
Loss at batch 290 : 0.013768992386758327
Loss at batch 300 : 0.01825915090739727
Loss at batch 310 : 0.019955512136220932
Loss at batch 320 : 0.017665497958660126
Loss at batch 330 : 0.020732205361127853
Loss at batch 340 : 0.009319886565208435
Loss at batch 350 : 0.01566491834819317
Loss at batch 360 : 0.009923876263201237
Loss at batch 370 : 0.011070993728935719
epoch127 finished!
Loss at batch 10 : 0.011292114853858948
Loss at batch 20 : 0.018131257966160774
Loss at batch 30 : 0.008985072374343872
Loss at batch 40 : 0.012637916021049023
Loss at batch 50 : 0.024895168840885162
Loss at batch 60 : 0.024517979472875595
Loss at batch 70 : 0.009167906828224659
Loss at batch 80 : 0.009480929933488369
Loss at batch 90 : 0.0072134812362492085
Loss at batch 100 : 0.009143875911831856
Loss at batch 110 : 0.015251856297254562
Loss at batch 120 : 0.013256560079753399
Loss at batch 130 : 0.01681903749704361
Loss at batch 140 : 0.014697739854454994
Loss at batch 150 : 0.016863586381077766
Loss at batch 160 : 0.010470581240952015
Loss at batch 170 : 0.03810949623584747
Loss at batch 180 : 0.006951299495995045
Loss at batch 190 : 0.018851852044463158
Loss at batch 200 : 0.013519810512661934
Loss at batch 210 : 0.012060846202075481
Loss at batch 220 : 0.012251432053744793
Loss at batch 230 : 0.010714897885918617
Loss at batch 240 : 0.008484860882163048
Loss at batch 250 : 0.009623130783438683
Loss at batch 260 : 0.011623196303844452
Loss at batch 270 : 0.008128723129630089
Loss at batch 280 : 0.010312655940651894
Loss at batch 290 : 0.009622294455766678
Loss at batch 300 : 0.007688344921916723
Loss at batch 310 : 0.009279205463826656
Loss at batch 320 : 0.01026908028870821
Loss at batch 330 : 0.015478112734854221
Loss at batch 340 : 0.016268186271190643
Loss at batch 350 : 0.018647393211722374
Loss at batch 360 : 0.012433495372533798
Loss at batch 370 : 0.008627457544207573
epoch127 finished!
Loss at batch 10 : 0.017670398578047752
Loss at batch 20 : 0.024893328547477722
Loss at batch 30 : 0.015036324970424175
Loss at batch 40 : 0.010827301070094109
Loss at batch 50 : 0.016452213749289513
Loss at batch 60 : 0.011300528421998024
Loss at batch 70 : 0.01498276088386774
Loss at batch 80 : 0.01231347769498825
Loss at batch 90 : 0.019541019573807716
Loss at batch 100 : 0.018770862370729446
Loss at batch 110 : 0.018796714022755623
Loss at batch 120 : 0.008782904595136642
Loss at batch 130 : 0.015396472066640854
Loss at batch 140 : 0.00983724370598793
Loss at batch 150 : 0.02366168238222599
Loss at batch 160 : 0.014223862439393997
Loss at batch 170 : 0.013518223538994789
Loss at batch 180 : 0.015538850799202919
Loss at batch 190 : 0.01821051724255085
Loss at batch 200 : 0.01862342841923237
Loss at batch 210 : 0.023907748982310295
Loss at batch 220 : 0.014198307879269123
Loss at batch 230 : 0.012161130085587502
Loss at batch 240 : 0.01714860461652279
Loss at batch 250 : 0.012322294525802135
Loss at batch 260 : 0.009038961492478848
Loss at batch 270 : 0.010097327642142773
Loss at batch 280 : 0.010780438780784607
Loss at batch 290 : 0.008794465102255344
Loss at batch 300 : 0.01019352488219738
Loss at batch 310 : 0.014808996580541134
Loss at batch 320 : 0.016173221170902252
Loss at batch 330 : 0.019351281225681305
Loss at batch 340 : 0.015008844435214996
Loss at batch 350 : 0.014349925331771374
Loss at batch 360 : 0.020228419452905655
Loss at batch 370 : 0.012638899497687817
epoch128 finished!
Loss at batch 10 : 0.012859632261097431
Loss at batch 20 : 0.011541805230081081
Loss at batch 30 : 0.012883709743618965
Loss at batch 40 : 0.02112838812172413
Loss at batch 50 : 0.015752870589494705
Loss at batch 60 : 0.011954933404922485
Loss at batch 70 : 0.011045836843550205
Loss at batch 80 : 0.013925188221037388
Loss at batch 90 : 0.008747756481170654
Loss at batch 100 : 0.012848102487623692
Loss at batch 110 : 0.012048788368701935
Loss at batch 120 : 0.01590883359313011
Loss at batch 130 : 0.011808526702225208
Loss at batch 140 : 0.01470272522419691
Loss at batch 150 : 0.01298530399799347
Loss at batch 160 : 0.011070188134908676
Loss at batch 170 : 0.014626708813011646
Loss at batch 180 : 0.010438972152769566
Loss at batch 190 : 0.017863817512989044
Loss at batch 200 : 0.016699234023690224
Loss at batch 210 : 0.01706608012318611
Loss at batch 220 : 0.022209282964468002
Loss at batch 230 : 0.013740546070039272
Loss at batch 240 : 0.010746638290584087
Loss at batch 250 : 0.008982982486486435
Loss at batch 260 : 0.010327504947781563
Loss at batch 270 : 0.007572461385279894
Loss at batch 280 : 0.015429310500621796
Loss at batch 290 : 0.009347515180706978
Loss at batch 300 : 0.019238093867897987
Loss at batch 310 : 0.023344621062278748
Loss at batch 320 : 0.01710108108818531
Loss at batch 330 : 0.017446419224143028
Loss at batch 340 : 0.012801174074411392
Loss at batch 350 : 0.009796272963285446
Loss at batch 360 : 0.01471264660358429
Loss at batch 370 : 0.010760060511529446
epoch128 finished!
Loss at batch 10 : 0.013750370591878891
Loss at batch 20 : 0.023726193234324455
Loss at batch 30 : 0.011990023776888847
Loss at batch 40 : 0.009269415400922298
Loss at batch 50 : 0.020704515278339386
Loss at batch 60 : 0.013588217087090015
Loss at batch 70 : 0.015134681016206741
Loss at batch 80 : 0.014502091333270073
Loss at batch 90 : 0.015490506775677204
Loss at batch 100 : 0.006947705987840891
Loss at batch 110 : 0.007486244663596153
Loss at batch 120 : 0.009147429838776588
Loss at batch 130 : 0.013553709723055363
Loss at batch 140 : 0.022715967148542404
Loss at batch 150 : 0.009434985928237438
Loss at batch 160 : 0.0270543210208416
Loss at batch 170 : 0.01747237518429756
Loss at batch 180 : 0.012431991286575794
Loss at batch 190 : 0.015173685736954212
Loss at batch 200 : 0.010572330094873905
Loss at batch 210 : 0.018596380949020386
Loss at batch 220 : 0.017086584120988846
Loss at batch 230 : 0.01538359560072422
Loss at batch 240 : 0.011913083493709564
Loss at batch 250 : 0.013215862214565277
Loss at batch 260 : 0.012400871142745018
Loss at batch 270 : 0.013466904871165752
Loss at batch 280 : 0.01176486536860466
Loss at batch 290 : 0.0164767038077116
Loss at batch 300 : 0.007529356516897678
Loss at batch 310 : 0.02140124887228012
Loss at batch 320 : 0.020506687462329865
Loss at batch 330 : 0.010433503426611423
Loss at batch 340 : 0.010690939612686634
Loss at batch 350 : 0.019238997250795364
Loss at batch 360 : 0.01444370299577713
Loss at batch 370 : 0.04183726757764816
epoch129 finished!
Loss at batch 10 : 0.00918911024928093
Loss at batch 20 : 0.010236600413918495
Loss at batch 30 : 0.013145184144377708
Loss at batch 40 : 0.012581137008965015
Loss at batch 50 : 0.008626098744571209
Loss at batch 60 : 0.014429351314902306
Loss at batch 70 : 0.010547800920903683
Loss at batch 80 : 0.02021743543446064
Loss at batch 90 : 0.007451239973306656
Loss at batch 100 : 0.012460552155971527
Loss at batch 110 : 0.01384742558002472
Loss at batch 120 : 0.007491790223866701
Loss at batch 130 : 0.010845400393009186
Loss at batch 140 : 0.012359969317913055
Loss at batch 150 : 0.016970356926321983
Loss at batch 160 : 0.024369392544031143
Loss at batch 170 : 0.00985303521156311
Loss at batch 180 : 0.015019278042018414
Loss at batch 190 : 0.022966399788856506
Loss at batch 200 : 0.01789843663573265
Loss at batch 210 : 0.014429526403546333
Loss at batch 220 : 0.014876692555844784
Loss at batch 230 : 0.011049335822463036
Loss at batch 240 : 0.01738634705543518
Loss at batch 250 : 0.022562669590115547
Loss at batch 260 : 0.029151955619454384
Loss at batch 270 : 0.011229044757783413
Loss at batch 280 : 0.015321668237447739
Loss at batch 290 : 0.01543597225099802
Loss at batch 300 : 0.018769273534417152
Loss at batch 310 : 0.017620474100112915
Loss at batch 320 : 0.030526284128427505
Loss at batch 330 : 0.009836042299866676
Loss at batch 340 : 0.01819041185081005
Loss at batch 350 : 0.015548265539109707
Loss at batch 360 : 0.01083135511726141
Loss at batch 370 : 0.015061738900840282
epoch129 finished!
Loss at batch 10 : 0.013382550328969955
Loss at batch 20 : 0.017135126516222954
Loss at batch 30 : 0.019435279071331024
Loss at batch 40 : 0.015024568885564804
Loss at batch 50 : 0.016731729730963707
Loss at batch 60 : 0.013904702849686146
Loss at batch 70 : 0.013818161562085152
Loss at batch 80 : 0.020168619230389595
Loss at batch 90 : 0.009758650325238705
Loss at batch 100 : 0.007952654734253883
Loss at batch 110 : 0.022190988063812256
Loss at batch 120 : 0.01451948843896389
Loss at batch 130 : 0.007524191867560148
Loss at batch 140 : 0.014302843250334263
Loss at batch 150 : 0.013702151365578175
Loss at batch 160 : 0.009909425862133503
Loss at batch 170 : 0.01062017772346735
Loss at batch 180 : 0.01766645349562168
Loss at batch 190 : 0.007267578970640898
Loss at batch 200 : 0.009021751582622528
Loss at batch 210 : 0.013574169017374516
Loss at batch 220 : 0.01839914545416832
Loss at batch 230 : 0.015968259423971176
Loss at batch 240 : 0.020479081198573112
Loss at batch 250 : 0.025250859558582306
Loss at batch 260 : 0.022318417206406593
Loss at batch 270 : 0.010039781220257282
Loss at batch 280 : 0.010007846169173717
Loss at batch 290 : 0.02317836880683899
Loss at batch 300 : 0.01354127749800682
Loss at batch 310 : 0.011533013544976711
Loss at batch 320 : 0.01183435507118702
Loss at batch 330 : 0.01787339150905609
Loss at batch 340 : 0.015208132565021515
Loss at batch 350 : 0.011367306113243103
Loss at batch 360 : 0.023723352700471878
Loss at batch 370 : 0.010470407083630562
epoch130 finished!
Loss at batch 10 : 0.01504517812281847
Loss at batch 20 : 0.012501867488026619
Loss at batch 30 : 0.0192815363407135
Loss at batch 40 : 0.011245343834161758
Loss at batch 50 : 0.015328913927078247
Loss at batch 60 : 0.010150683112442493
Loss at batch 70 : 0.018162500113248825
Loss at batch 80 : 0.013491365127265453
Loss at batch 90 : 0.011969654820859432
Loss at batch 100 : 0.01664309948682785
Loss at batch 110 : 0.018780522048473358
Loss at batch 120 : 0.011810410767793655
Loss at batch 130 : 0.015728803351521492
Loss at batch 140 : 0.010669145733118057
Loss at batch 150 : 0.012244971469044685
Loss at batch 160 : 0.026588469743728638
Loss at batch 170 : 0.009995843283832073
Loss at batch 180 : 0.008508527651429176
Loss at batch 190 : 0.017953084781765938
Loss at batch 200 : 0.016938574612140656
Loss at batch 210 : 0.017956160008907318
Loss at batch 220 : 0.01495980005711317
Loss at batch 230 : 0.011879709549248219
Loss at batch 240 : 0.015254341997206211
Loss at batch 250 : 0.024724062532186508
Loss at batch 260 : 0.012482537887990475
Loss at batch 270 : 0.010320871137082577
Loss at batch 280 : 0.017159970477223396
Loss at batch 290 : 0.016989128664135933
Loss at batch 300 : 0.01305732037872076
Loss at batch 310 : 0.017022686079144478
Loss at batch 320 : 0.012276459485292435
Loss at batch 330 : 0.018721742555499077
Loss at batch 340 : 0.013670017942786217
Loss at batch 350 : 0.012067485600709915
Loss at batch 360 : 0.011747345328330994
Loss at batch 370 : 0.01066930964589119
epoch130 finished!
Loss at batch 10 : 0.012834005057811737
Loss at batch 20 : 0.01094450056552887
Loss at batch 30 : 0.016070961952209473
Loss at batch 40 : 0.012806721031665802
Loss at batch 50 : 0.007851028814911842
Loss at batch 60 : 0.01168501004576683
Loss at batch 70 : 0.01815064437687397
Loss at batch 80 : 0.017202872782945633
Loss at batch 90 : 0.008944195695221424
Loss at batch 100 : 0.023945923894643784
Loss at batch 110 : 0.015299261547625065
Loss at batch 120 : 0.008594685234129429
Loss at batch 130 : 0.01467975229024887
Loss at batch 140 : 0.02916700206696987
Loss at batch 150 : 0.009828402660787106
Loss at batch 160 : 0.009118442423641682
Loss at batch 170 : 0.013643879443407059
Loss at batch 180 : 0.021717602387070656
Loss at batch 190 : 0.019276702776551247
Loss at batch 200 : 0.016032597050070763
Loss at batch 210 : 0.01247237529605627
Loss at batch 220 : 0.01166327390819788
Loss at batch 230 : 0.01774519495666027
Loss at batch 240 : 0.011656026355922222
Loss at batch 250 : 0.016114164143800735
Loss at batch 260 : 0.007633327040821314
Loss at batch 270 : 0.005829479545354843
Loss at batch 280 : 0.013096863403916359
Loss at batch 290 : 0.020232029259204865
Loss at batch 300 : 0.021137556061148643
Loss at batch 310 : 0.016445593908429146
Loss at batch 320 : 0.010595173574984074
Loss at batch 330 : 0.011164688505232334
Loss at batch 340 : 0.01345596369355917
Loss at batch 350 : 0.008675698190927505
Loss at batch 360 : 0.0123249227181077
Loss at batch 370 : 0.023854829370975494
epoch131 finished!
Loss at batch 10 : 0.00964542105793953
Loss at batch 20 : 0.012765293009579182
Loss at batch 30 : 0.019930878654122353
Loss at batch 40 : 0.013443127274513245
Loss at batch 50 : 0.019536977633833885
Loss at batch 60 : 0.013804535381495953
Loss at batch 70 : 0.01696106046438217
Loss at batch 80 : 0.014177750796079636
Loss at batch 90 : 0.009421205148100853
Loss at batch 100 : 0.007692807819694281
Loss at batch 110 : 0.00931525882333517
Loss at batch 120 : 0.007742530200630426
Loss at batch 130 : 0.016441846266388893
Loss at batch 140 : 0.012545418925583363
Loss at batch 150 : 0.01410058606415987
Loss at batch 160 : 0.011714405380189419
Loss at batch 170 : 0.015694821253418922
Loss at batch 180 : 0.012634421698749065
Loss at batch 190 : 0.022881297394633293
Loss at batch 200 : 0.010010063648223877
Loss at batch 210 : 0.01509090419858694
Loss at batch 220 : 0.012787596322596073
Loss at batch 230 : 0.016031205654144287
Loss at batch 240 : 0.011287081055343151
Loss at batch 250 : 0.019330529496073723
Loss at batch 260 : 0.008604191243648529
Loss at batch 270 : 0.02178298495709896
Loss at batch 280 : 0.02149413526058197
Loss at batch 290 : 0.010066960006952286
Loss at batch 300 : 0.011524626985192299
Loss at batch 310 : 0.01031313557177782
Loss at batch 320 : 0.00750991515815258
Loss at batch 330 : 0.01039363257586956
Loss at batch 340 : 0.012290598824620247
Loss at batch 350 : 0.010726108215749264
Loss at batch 360 : 0.010040353052318096
Loss at batch 370 : 0.011864673346281052
epoch131 finished!
Loss at batch 10 : 0.010197795927524567
Loss at batch 20 : 0.02363501489162445
Loss at batch 30 : 0.019970741122961044
Loss at batch 40 : 0.01272704266011715
Loss at batch 50 : 0.01047898642718792
Loss at batch 60 : 0.015298047102987766
Loss at batch 70 : 0.01595885679125786
Loss at batch 80 : 0.012142699211835861
Loss at batch 90 : 0.017907539382576942
Loss at batch 100 : 0.011425601318478584
Loss at batch 110 : 0.03524944186210632
Loss at batch 120 : 0.02112368680536747
Loss at batch 130 : 0.01044623926281929
Loss at batch 140 : 0.011973085813224316
Loss at batch 150 : 0.006266293115913868
Loss at batch 160 : 0.012687773443758488
Loss at batch 170 : 0.015111478976905346
Loss at batch 180 : 0.010662568733096123
Loss at batch 190 : 0.015179861336946487
Loss at batch 200 : 0.011122485622763634
Loss at batch 210 : 0.010329985991120338
Loss at batch 220 : 0.022643905133008957
Loss at batch 230 : 0.010066219605505466
Loss at batch 240 : 0.009579719044268131
Loss at batch 250 : 0.014863678254187107
Loss at batch 260 : 0.005871565081179142
Loss at batch 270 : 0.00679111247882247
Loss at batch 280 : 0.008549923077225685
Loss at batch 290 : 0.00733560137450695
Loss at batch 300 : 0.02102397382259369
Loss at batch 310 : 0.013491525314748287
Loss at batch 320 : 0.012425046414136887
Loss at batch 330 : 0.014893608167767525
Loss at batch 340 : 0.008845625445246696
Loss at batch 350 : 0.009599215351045132
Loss at batch 360 : 0.005357912741601467
Loss at batch 370 : 0.010734445415437222
epoch132 finished!
Loss at batch 10 : 0.008799976669251919
Loss at batch 20 : 0.00785088911652565
Loss at batch 30 : 0.012934516184031963
Loss at batch 40 : 0.009635137394070625
Loss at batch 50 : 0.019611384719610214
Loss at batch 60 : 0.010512245818972588
Loss at batch 70 : 0.017010994255542755
Loss at batch 80 : 0.007485185284167528
Loss at batch 90 : 0.011485790833830833
Loss at batch 100 : 0.015856781974434853
Loss at batch 110 : 0.013636268675327301
Loss at batch 120 : 0.00791971106082201
Loss at batch 130 : 0.011067125014960766
Loss at batch 140 : 0.01396553311496973
Loss at batch 150 : 0.020319722592830658
Loss at batch 160 : 0.021160565316677094
Loss at batch 170 : 0.010767113417387009
Loss at batch 180 : 0.009586048312485218
Loss at batch 190 : 0.013030259869992733
Loss at batch 200 : 0.011937160976231098
Loss at batch 210 : 0.00679238373413682
Loss at batch 220 : 0.00962390098720789
Loss at batch 230 : 0.02239386737346649
Loss at batch 240 : 0.021795887500047684
Loss at batch 250 : 0.026887107640504837
Loss at batch 260 : 0.012809340842068195
Loss at batch 270 : 0.00858980230987072
Loss at batch 280 : 0.01921914331614971
Loss at batch 290 : 0.02132060006260872
Loss at batch 300 : 0.01028143148869276
Loss at batch 310 : 0.011943007819354534
Loss at batch 320 : 0.014956790022552013
Loss at batch 330 : 0.011410410515964031
Loss at batch 340 : 0.017057906836271286
Loss at batch 350 : 0.013242282904684544
Loss at batch 360 : 0.010578506626188755
Loss at batch 370 : 0.010943377390503883
epoch132 finished!
Loss at batch 10 : 0.015913503244519234
Loss at batch 20 : 0.013632680289447308
Loss at batch 30 : 0.011234268546104431
Loss at batch 40 : 0.021526990458369255
Loss at batch 50 : 0.014627340249717236
Loss at batch 60 : 0.02159915119409561
Loss at batch 70 : 0.014596553519368172
Loss at batch 80 : 0.008449074812233448
Loss at batch 90 : 0.012444410473108292
Loss at batch 100 : 0.011331062763929367
Loss at batch 110 : 0.009477711282670498
Loss at batch 120 : 0.0076849511824548244
Loss at batch 130 : 0.022843247279524803
Loss at batch 140 : 0.021346289664506912
Loss at batch 150 : 0.015482163988053799
Loss at batch 160 : 0.009794941172003746
Loss at batch 170 : 0.011761673726141453
Loss at batch 180 : 0.01323476992547512
Loss at batch 190 : 0.01057934295386076
Loss at batch 200 : 0.015744570642709732
Loss at batch 210 : 0.008203024975955486
Loss at batch 220 : 0.016007648780941963
Loss at batch 230 : 0.013044795952737331
Loss at batch 240 : 0.019268710166215897
Loss at batch 250 : 0.012709074653685093
Loss at batch 260 : 0.013898752629756927
Loss at batch 270 : 0.010059311054646969
Loss at batch 280 : 0.009276331402361393
Loss at batch 290 : 0.006442265119403601
Loss at batch 300 : 0.007110564038157463
Loss at batch 310 : 0.020755428820848465
Loss at batch 320 : 0.01178559847176075
Loss at batch 330 : 0.017691180109977722
Loss at batch 340 : 0.009576220065355301
Loss at batch 350 : 0.009679289534687996
Loss at batch 360 : 0.018473384901881218
Loss at batch 370 : 0.01729854755103588
epoch133 finished!
Loss at batch 10 : 0.0063128164038062096
Loss at batch 20 : 0.016081031411886215
Loss at batch 30 : 0.008751881308853626
Loss at batch 40 : 0.015377362258732319
Loss at batch 50 : 0.01477766688913107
Loss at batch 60 : 0.011945960111916065
Loss at batch 70 : 0.010088741779327393
Loss at batch 80 : 0.01156582497060299
Loss at batch 90 : 0.012007257901132107
Loss at batch 100 : 0.009659327566623688
Loss at batch 110 : 0.015237206593155861
Loss at batch 120 : 0.009135360829532146
Loss at batch 130 : 0.013143789954483509
Loss at batch 140 : 0.0090562105178833
Loss at batch 150 : 0.013087423518300056
Loss at batch 160 : 0.017154863104224205
Loss at batch 170 : 0.008686313405632973
Loss at batch 180 : 0.013440960086882114
Loss at batch 190 : 0.026412801817059517
Loss at batch 200 : 0.009826978668570518
Loss at batch 210 : 0.013782422058284283
Loss at batch 220 : 0.009114323183894157
Loss at batch 230 : 0.015000741928815842
Loss at batch 240 : 0.02212541550397873
Loss at batch 250 : 0.019868461415171623
Loss at batch 260 : 0.013608098030090332
Loss at batch 270 : 0.009456864558160305
Loss at batch 280 : 0.01261034607887268
Loss at batch 290 : 0.012958582490682602
Loss at batch 300 : 0.011543656699359417
Loss at batch 310 : 0.015510093420743942
Loss at batch 320 : 0.012662668712437153
Loss at batch 330 : 0.012752481736242771
Loss at batch 340 : 0.01588216982781887
Loss at batch 350 : 0.01464026514440775
Loss at batch 360 : 0.011623901315033436
Loss at batch 370 : 0.008773128502070904
epoch133 finished!
Loss at batch 10 : 0.017783690243959427
Loss at batch 20 : 0.013537495397031307
Loss at batch 30 : 0.014228612184524536
Loss at batch 40 : 0.01241610199213028
Loss at batch 50 : 0.010946308262646198
Loss at batch 60 : 0.010169094428420067
Loss at batch 70 : 0.009764179587364197
Loss at batch 80 : 0.02539181150496006
Loss at batch 90 : 0.01382925920188427
Loss at batch 100 : 0.015943842008709908
Loss at batch 110 : 0.013538859784603119
Loss at batch 120 : 0.010566428303718567
Loss at batch 130 : 0.007458923384547234
Loss at batch 140 : 0.01678279973566532
Loss at batch 150 : 0.020395293831825256
Loss at batch 160 : 0.01700802892446518
Loss at batch 170 : 0.01607758365571499
Loss at batch 180 : 0.010518854483962059
Loss at batch 190 : 0.01587291806936264
Loss at batch 200 : 0.022160347551107407
Loss at batch 210 : 0.007364740129560232
Loss at batch 220 : 0.019854385405778885
Loss at batch 230 : 0.01921955496072769
Loss at batch 240 : 0.010158385150134563
Loss at batch 250 : 0.023007143288850784
Loss at batch 260 : 0.009757978841662407
Loss at batch 270 : 0.017997534945607185
Loss at batch 280 : 0.021531999111175537
Loss at batch 290 : 0.014059903100132942
Loss at batch 300 : 0.011557876132428646
Loss at batch 310 : 0.008397297002375126
Loss at batch 320 : 0.013571450486779213
Loss at batch 330 : 0.02140447497367859
Loss at batch 340 : 0.020734015852212906
Loss at batch 350 : 0.013800954446196556
Loss at batch 360 : 0.01088740024715662
Loss at batch 370 : 0.00926945824176073
epoch134 finished!
Loss at batch 10 : 0.009088031016290188
Loss at batch 20 : 0.008258079178631306
Loss at batch 30 : 0.015044361352920532
Loss at batch 40 : 0.0133324284106493
Loss at batch 50 : 0.01453306619077921
Loss at batch 60 : 0.020568573847413063
Loss at batch 70 : 0.01323428750038147
Loss at batch 80 : 0.01077321171760559
Loss at batch 90 : 0.014034964144229889
Loss at batch 100 : 0.010394596494734287
Loss at batch 110 : 0.016380097717046738
Loss at batch 120 : 0.014294921420514584
Loss at batch 130 : 0.007667529862374067
Loss at batch 140 : 0.008183383382856846
Loss at batch 150 : 0.015011952258646488
Loss at batch 160 : 0.012986522167921066
Loss at batch 170 : 0.017675304785370827
Loss at batch 180 : 0.01619269698858261
Loss at batch 190 : 0.02305692434310913
Loss at batch 200 : 0.013039618730545044
Loss at batch 210 : 0.014184040017426014
Loss at batch 220 : 0.022985737770795822
Loss at batch 230 : 0.013288489542901516
Loss at batch 240 : 0.011050348170101643
Loss at batch 250 : 0.009934800677001476
Loss at batch 260 : 0.016131090000271797
Loss at batch 270 : 0.008162221871316433
Loss at batch 280 : 0.01390563789755106
Loss at batch 290 : 0.014119774103164673
Loss at batch 300 : 0.008998631499707699
Loss at batch 310 : 0.015340790152549744
Loss at batch 320 : 0.015564092434942722
Loss at batch 330 : 0.03264766186475754
Loss at batch 340 : 0.019731204956769943
Loss at batch 350 : 0.015305701643228531
Loss at batch 360 : 0.017707383260130882
Loss at batch 370 : 0.015463776886463165
epoch134 finished!
Loss at batch 10 : 0.01721814274787903
Loss at batch 20 : 0.011567367240786552
Loss at batch 30 : 0.010635784827172756
Loss at batch 40 : 0.00901756715029478
Loss at batch 50 : 0.013858392834663391
Loss at batch 60 : 0.007988126948475838
Loss at batch 70 : 0.020921504124999046
Loss at batch 80 : 0.02173413150012493
Loss at batch 90 : 0.01836966723203659
Loss at batch 100 : 0.009750421158969402
Loss at batch 110 : 0.01993742398917675
Loss at batch 120 : 0.016783609986305237
Loss at batch 130 : 0.01814483478665352
Loss at batch 140 : 0.009018090553581715
Loss at batch 150 : 0.009609422646462917
Loss at batch 160 : 0.01495396438986063
Loss at batch 170 : 0.02246156521141529
Loss at batch 180 : 0.022810092195868492
Loss at batch 190 : 0.013166455551981926
Loss at batch 200 : 0.00833650678396225
Loss at batch 210 : 0.010352141223847866
Loss at batch 220 : 0.010867788456380367
Loss at batch 230 : 0.009088743478059769
Loss at batch 240 : 0.012890687212347984
Loss at batch 250 : 0.0204413253813982
Loss at batch 260 : 0.01458527147769928
Loss at batch 270 : 0.012276338413357735
Loss at batch 280 : 0.016451619565486908
Loss at batch 290 : 0.014861617237329483
Loss at batch 300 : 0.019985530525445938
Loss at batch 310 : 0.008726629428565502
Loss at batch 320 : 0.01652531512081623
Loss at batch 330 : 0.017671899870038033
Loss at batch 340 : 0.015514831058681011
Loss at batch 350 : 0.02411198988556862
Loss at batch 360 : 0.00979659240692854
Loss at batch 370 : 0.011942404322326183
epoch135 finished!
Loss at batch 10 : 0.012869230471551418
Loss at batch 20 : 0.019428368657827377
Loss at batch 30 : 0.009311595000326633
Loss at batch 40 : 0.007608751766383648
Loss at batch 50 : 0.019310569390654564
Loss at batch 60 : 0.012266954407095909
Loss at batch 70 : 0.010733092203736305
Loss at batch 80 : 0.012999541126191616
Loss at batch 90 : 0.01083536446094513
Loss at batch 100 : 0.012102563865482807
Loss at batch 110 : 0.015592808835208416
Loss at batch 120 : 0.012386179529130459
Loss at batch 130 : 0.009661272168159485
Loss at batch 140 : 0.01254905667155981
Loss at batch 150 : 0.007399828173220158
Loss at batch 160 : 0.017419056966900826
Loss at batch 170 : 0.0137308519333601
Loss at batch 180 : 0.011397791095077991
Loss at batch 190 : 0.008037498220801353
Loss at batch 200 : 0.006020822562277317
Loss at batch 210 : 0.010569057427346706
Loss at batch 220 : 0.014398040249943733
Loss at batch 230 : 0.01369398832321167
Loss at batch 240 : 0.01556185632944107
Loss at batch 250 : 0.010173963382840157
Loss at batch 260 : 0.013471769168972969
Loss at batch 270 : 0.01000224705785513
Loss at batch 280 : 0.01734199933707714
Loss at batch 290 : 0.012254871428012848
Loss at batch 300 : 0.010389596223831177
Loss at batch 310 : 0.013070126064121723
Loss at batch 320 : 0.014519757591187954
Loss at batch 330 : 0.013198303058743477
Loss at batch 340 : 0.009184411726891994
Loss at batch 350 : 0.016064463183283806
Loss at batch 360 : 0.02174759842455387
Loss at batch 370 : 0.01672215387225151
epoch135 finished!
Loss at batch 10 : 0.014281252399086952
Loss at batch 20 : 0.014834623783826828
Loss at batch 30 : 0.01732144132256508
Loss at batch 40 : 0.014683852903544903
Loss at batch 50 : 0.010737963952124119
Loss at batch 60 : 0.009705201722681522
Loss at batch 70 : 0.00967052485793829
Loss at batch 80 : 0.014711113646626472
Loss at batch 90 : 0.011059812270104885
Loss at batch 100 : 0.0153883071616292
Loss at batch 110 : 0.019449224695563316
Loss at batch 120 : 0.02386370114982128
Loss at batch 130 : 0.012677928432822227
Loss at batch 140 : 0.019472606480121613
Loss at batch 150 : 0.009755858220160007
Loss at batch 160 : 0.010771531611680984
Loss at batch 170 : 0.022461097687482834
Loss at batch 180 : 0.010251861065626144
Loss at batch 190 : 0.017256291583180428
Loss at batch 200 : 0.023650670424103737
Loss at batch 210 : 0.013076361268758774
Loss at batch 220 : 0.006244214717298746
Loss at batch 230 : 0.018342409282922745
Loss at batch 240 : 0.011734198778867722
Loss at batch 250 : 0.016328396275639534
Loss at batch 260 : 0.017806224524974823
Loss at batch 270 : 0.025173211470246315
Loss at batch 280 : 0.019619498401880264
Loss at batch 290 : 0.007730754092335701
Loss at batch 300 : 0.013085325248539448
Loss at batch 310 : 0.010679980739951134
Loss at batch 320 : 0.015648793429136276
Loss at batch 330 : 0.0090542146936059
Loss at batch 340 : 0.008464468643069267
Loss at batch 350 : 0.022520825266838074
Loss at batch 360 : 0.007225331384688616
Loss at batch 370 : 0.017195342108607292
epoch136 finished!
Loss at batch 10 : 0.01851629465818405
Loss at batch 20 : 0.02155294641852379
Loss at batch 30 : 0.00782603956758976
Loss at batch 40 : 0.01271561998873949
Loss at batch 50 : 0.010453542694449425
Loss at batch 60 : 0.012548253871500492
Loss at batch 70 : 0.006620536558330059
Loss at batch 80 : 0.018732160329818726
Loss at batch 90 : 0.011395236477255821
Loss at batch 100 : 0.011321447789669037
Loss at batch 110 : 0.015369388274848461
Loss at batch 120 : 0.020750220865011215
Loss at batch 130 : 0.01213324349373579
Loss at batch 140 : 0.008329961448907852
Loss at batch 150 : 0.01387453731149435
Loss at batch 160 : 0.014291148632764816
Loss at batch 170 : 0.013104433193802834
Loss at batch 180 : 0.020971672609448433
Loss at batch 190 : 0.014751807786524296
Loss at batch 200 : 0.007120151538401842
Loss at batch 210 : 0.0229704137891531
Loss at batch 220 : 0.013655470684170723
Loss at batch 230 : 0.020441971719264984
Loss at batch 240 : 0.029568176716566086
Loss at batch 250 : 0.011555413715541363
Loss at batch 260 : 0.01381761860102415
Loss at batch 270 : 0.020048366859555244
Loss at batch 280 : 0.01713421754539013
Loss at batch 290 : 0.009966874495148659
Loss at batch 300 : 0.013267924077808857
Loss at batch 310 : 0.008282642811536789
Loss at batch 320 : 0.010801300406455994
Loss at batch 330 : 0.00876472145318985
Loss at batch 340 : 0.010526004247367382
Loss at batch 350 : 0.016178108751773834
Loss at batch 360 : 0.011819197796285152
Loss at batch 370 : 0.00865938700735569
epoch136 finished!
Loss at batch 10 : 0.01394535694271326
Loss at batch 20 : 0.01730986498296261
Loss at batch 30 : 0.010019809007644653
Loss at batch 40 : 0.012648824602365494
Loss at batch 50 : 0.015988828614354134
Loss at batch 60 : 0.014208846725523472
Loss at batch 70 : 0.01718861609697342
Loss at batch 80 : 0.02251681312918663
Loss at batch 90 : 0.014771489426493645
Loss at batch 100 : 0.013890023343265057
Loss at batch 110 : 0.010929574258625507
Loss at batch 120 : 0.015049096196889877
Loss at batch 130 : 0.0070325639098882675
Loss at batch 140 : 0.01259579136967659
Loss at batch 150 : 0.017463602125644684
Loss at batch 160 : 0.01830769143998623
Loss at batch 170 : 0.010609965771436691
Loss at batch 180 : 0.022735748440027237
Loss at batch 190 : 0.017536701634526253
Loss at batch 200 : 0.013822359032928944
Loss at batch 210 : 0.01040561031550169
Loss at batch 220 : 0.011051452718675137
Loss at batch 230 : 0.0171053409576416
Loss at batch 240 : 0.02121873013675213
Loss at batch 250 : 0.00959186814725399
Loss at batch 260 : 0.01849731057882309
Loss at batch 270 : 0.011203436180949211
Loss at batch 280 : 0.012219634838402271
Loss at batch 290 : 0.013244555331766605
Loss at batch 300 : 0.008459562435746193
Loss at batch 310 : 0.01811722107231617
Loss at batch 320 : 0.00783531367778778
Loss at batch 330 : 0.010286958888173103
Loss at batch 340 : 0.014337019994854927
Loss at batch 350 : 0.01678490824997425
Loss at batch 360 : 0.014573044143617153
Loss at batch 370 : 0.01367119885981083
epoch137 finished!
Loss at batch 10 : 0.008959022350609303
Loss at batch 20 : 0.0068569849245250225
Loss at batch 30 : 0.016716862097382545
Loss at batch 40 : 0.025777507573366165
Loss at batch 50 : 0.022992974147200584
Loss at batch 60 : 0.009276188910007477
Loss at batch 70 : 0.01036252174526453
Loss at batch 80 : 0.015272031538188457
Loss at batch 90 : 0.009580251760780811
Loss at batch 100 : 0.023891737684607506
Loss at batch 110 : 0.011433684267103672
Loss at batch 120 : 0.008133950643241405
Loss at batch 130 : 0.009426443837583065
Loss at batch 140 : 0.013447766192257404
Loss at batch 150 : 0.010935121215879917
Loss at batch 160 : 0.010090283118188381
Loss at batch 170 : 0.013233792036771774
Loss at batch 180 : 0.015038876794278622
Loss at batch 190 : 0.01872388646006584
Loss at batch 200 : 0.008922543376684189
Loss at batch 210 : 0.021575860679149628
Loss at batch 220 : 0.017856262624263763
Loss at batch 230 : 0.011516482569277287
Loss at batch 240 : 0.024369044229388237
Loss at batch 250 : 0.007557033095508814
Loss at batch 260 : 0.013263052329421043
Loss at batch 270 : 0.010454624891281128
Loss at batch 280 : 0.009387915022671223
Loss at batch 290 : 0.010464605875313282
Loss at batch 300 : 0.010051066055893898
Loss at batch 310 : 0.01915987767279148
Loss at batch 320 : 0.01941312663257122
Loss at batch 330 : 0.015366099774837494
Loss at batch 340 : 0.009102582931518555
Loss at batch 350 : 0.022288933396339417
Loss at batch 360 : 0.024482164531946182
Loss at batch 370 : 0.013762232847511768
epoch137 finished!
Loss at batch 10 : 0.018980514258146286
Loss at batch 20 : 0.01109230238944292
Loss at batch 30 : 0.021253740414977074
Loss at batch 40 : 0.017046280205249786
Loss at batch 50 : 0.018228309229016304
Loss at batch 60 : 0.018642786890268326
Loss at batch 70 : 0.014112276025116444
Loss at batch 80 : 0.01715676486492157
Loss at batch 90 : 0.019132308661937714
Loss at batch 100 : 0.016724171116948128
Loss at batch 110 : 0.013615538366138935
Loss at batch 120 : 0.008091970346868038
Loss at batch 130 : 0.026303553953766823
Loss at batch 140 : 0.01486064400523901
Loss at batch 150 : 0.011764000169932842
Loss at batch 160 : 0.014168908819556236
Loss at batch 170 : 0.014500100165605545
Loss at batch 180 : 0.016737591475248337
Loss at batch 190 : 0.01993151754140854
Loss at batch 200 : 0.010044046677649021
Loss at batch 210 : 0.016227999702095985
Loss at batch 220 : 0.014861511066555977
Loss at batch 230 : 0.015588660724461079
Loss at batch 240 : 0.010203558951616287
Loss at batch 250 : 0.013215648010373116
Loss at batch 260 : 0.011353565379977226
Loss at batch 270 : 0.014523646794259548
Loss at batch 280 : 0.009063602425158024
Loss at batch 290 : 0.013128935359418392
Loss at batch 300 : 0.012010379694402218
Loss at batch 310 : 0.00979571882635355
Loss at batch 320 : 0.008792635053396225
Loss at batch 330 : 0.017927175387740135
Loss at batch 340 : 0.008173801004886627
Loss at batch 350 : 0.014099986292421818
Loss at batch 360 : 0.024152519181370735
Loss at batch 370 : 0.009083771146833897
epoch138 finished!
Loss at batch 10 : 0.007738557644188404
Loss at batch 20 : 0.011961806565523148
Loss at batch 30 : 0.01453618798404932
Loss at batch 40 : 0.010116037912666798
Loss at batch 50 : 0.022199636325240135
Loss at batch 60 : 0.011662865057587624
Loss at batch 70 : 0.016364306211471558
Loss at batch 80 : 0.01814461685717106
Loss at batch 90 : 0.010918994434177876
Loss at batch 100 : 0.014656058512628078
Loss at batch 110 : 0.011958444491028786
Loss at batch 120 : 0.0164471622556448
Loss at batch 130 : 0.008943089284002781
Loss at batch 140 : 0.009359668008983135
Loss at batch 150 : 0.014716284349560738
Loss at batch 160 : 0.01712348684668541
Loss at batch 170 : 0.013658651150763035
Loss at batch 180 : 0.025551803410053253
Loss at batch 190 : 0.016522228717803955
Loss at batch 200 : 0.018514983355998993
Loss at batch 210 : 0.018102429807186127
Loss at batch 220 : 0.009954136796295643
Loss at batch 230 : 0.010303293354809284
Loss at batch 240 : 0.015282289125025272
Loss at batch 250 : 0.010156151838600636
Loss at batch 260 : 0.011807768605649471
Loss at batch 270 : 0.013953911140561104
Loss at batch 280 : 0.019001906737685204
Loss at batch 290 : 0.015028774738311768
Loss at batch 300 : 0.008513161912560463
Loss at batch 310 : 0.007867657579481602
Loss at batch 320 : 0.012408371083438396
Loss at batch 330 : 0.013144660741090775
Loss at batch 340 : 0.02050928771495819
Loss at batch 350 : 0.01666574738919735
Loss at batch 360 : 0.013239482417702675
Loss at batch 370 : 0.014016698114573956
epoch138 finished!
Loss at batch 10 : 0.016806017607450485
Loss at batch 20 : 0.016738630831241608
Loss at batch 30 : 0.006504399236291647
Loss at batch 40 : 0.011907574720680714
Loss at batch 50 : 0.009951350279152393
Loss at batch 60 : 0.01543075405061245
Loss at batch 70 : 0.011476877145469189
Loss at batch 80 : 0.010684605687856674
Loss at batch 90 : 0.008626085706055164
Loss at batch 100 : 0.01383813563734293
Loss at batch 110 : 0.01670638844370842
Loss at batch 120 : 0.02235688641667366
Loss at batch 130 : 0.010307066142559052
Loss at batch 140 : 0.017870670184493065
Loss at batch 150 : 0.008816512301564217
Loss at batch 160 : 0.021863432601094246
Loss at batch 170 : 0.011098193936049938
Loss at batch 180 : 0.01251725759357214
Loss at batch 190 : 0.012278042733669281
Loss at batch 200 : 0.02388147823512554
Loss at batch 210 : 0.019621243700385094
Loss at batch 220 : 0.01661420613527298
Loss at batch 230 : 0.007503046654164791
Loss at batch 240 : 0.019728131592273712
Loss at batch 250 : 0.01794857531785965
Loss at batch 260 : 0.0212697796523571
Loss at batch 270 : 0.016814211383461952
Loss at batch 280 : 0.014384405687451363
Loss at batch 290 : 0.01607653684914112
Loss at batch 300 : 0.01037675328552723
Loss at batch 310 : 0.022499021142721176
Loss at batch 320 : 0.010147972032427788
Loss at batch 330 : 0.009417686611413956
Loss at batch 340 : 0.010985568165779114
Loss at batch 350 : 0.012465410865843296
Loss at batch 360 : 0.01964586041867733
Loss at batch 370 : 0.020582793280482292
epoch139 finished!
Loss at batch 10 : 0.012048091739416122
Loss at batch 20 : 0.016901401802897453
Loss at batch 30 : 0.015221977606415749
Loss at batch 40 : 0.01682671532034874
Loss at batch 50 : 0.008101528510451317
Loss at batch 60 : 0.019785059615969658
Loss at batch 70 : 0.01596367545425892
Loss at batch 80 : 0.012225463055074215
Loss at batch 90 : 0.015334836207330227
Loss at batch 100 : 0.010421204380691051
Loss at batch 110 : 0.011401141062378883
Loss at batch 120 : 0.013865678571164608
Loss at batch 130 : 0.007912678644061089
Loss at batch 140 : 0.020564720034599304
Loss at batch 150 : 0.017773514613509178
Loss at batch 160 : 0.01362474262714386
Loss at batch 170 : 0.010448822751641273
Loss at batch 180 : 0.014537758193910122
Loss at batch 190 : 0.0052825696766376495
Loss at batch 200 : 0.007268797606229782
Loss at batch 210 : 0.010777812451124191
Loss at batch 220 : 0.01618138886988163
Loss at batch 230 : 0.010165300220251083
Loss at batch 240 : 0.020958036184310913
Loss at batch 250 : 0.015338967554271221
Loss at batch 260 : 0.009516906924545765
Loss at batch 270 : 0.014814194291830063
Loss at batch 280 : 0.014340616762638092
Loss at batch 290 : 0.005214957986027002
Loss at batch 300 : 0.011633375659584999
Loss at batch 310 : 0.016273824498057365
Loss at batch 320 : 0.017025496810674667
Loss at batch 330 : 0.02097751945257187
Loss at batch 340 : 0.009007011540234089
Loss at batch 350 : 0.010956685990095139
Loss at batch 360 : 0.020558472722768784
Loss at batch 370 : 0.021262405440211296
epoch139 finished!
Loss at batch 10 : 0.017332762479782104
Loss at batch 20 : 0.013914618641138077
Loss at batch 30 : 0.013253919780254364
Loss at batch 40 : 0.01076401025056839
Loss at batch 50 : 0.02007933519780636
Loss at batch 60 : 0.012456478551030159
Loss at batch 70 : 0.014043443836271763
Loss at batch 80 : 0.011129679158329964
Loss at batch 90 : 0.020712781697511673
Loss at batch 100 : 0.013355600647628307
Loss at batch 110 : 0.01924988254904747
Loss at batch 120 : 0.00978078506886959
Loss at batch 130 : 0.011738022789359093
Loss at batch 140 : 0.015005049295723438
Loss at batch 150 : 0.018114039674401283
Loss at batch 160 : 0.011650987900793552
Loss at batch 170 : 0.008328581228852272
Loss at batch 180 : 0.017033744603395462
Loss at batch 190 : 0.014892869628965855
Loss at batch 200 : 0.008909851312637329
Loss at batch 210 : 0.018172018229961395
Loss at batch 220 : 0.018837645649909973
Loss at batch 230 : 0.019008513540029526
Loss at batch 240 : 0.006816854700446129
Loss at batch 250 : 0.008393730036914349
Loss at batch 260 : 0.012429933995008469
Loss at batch 270 : 0.0127640962600708
Loss at batch 280 : 0.011893018148839474
Loss at batch 290 : 0.01327819935977459
Loss at batch 300 : 0.01242511160671711
Loss at batch 310 : 0.012963047251105309
Loss at batch 320 : 0.018473457545042038
Loss at batch 330 : 0.010361256077885628
Loss at batch 340 : 0.015242064371705055
Loss at batch 350 : 0.009553820826113224
Loss at batch 360 : 0.007445810828357935
Loss at batch 370 : 0.02181328646838665
epoch140 finished!
Loss at batch 10 : 0.020402822643518448
Loss at batch 20 : 0.00800418108701706
Loss at batch 30 : 0.019081106409430504
Loss at batch 40 : 0.01211612019687891
Loss at batch 50 : 0.017813289538025856
Loss at batch 60 : 0.014342721551656723
Loss at batch 70 : 0.007422406692057848
Loss at batch 80 : 0.01524161733686924
Loss at batch 90 : 0.01991134323179722
Loss at batch 100 : 0.015310239046812057
Loss at batch 110 : 0.011982347816228867
Loss at batch 120 : 0.009422525763511658
Loss at batch 130 : 0.013116664253175259
Loss at batch 140 : 0.00693690637126565
Loss at batch 150 : 0.01264937873929739
Loss at batch 160 : 0.020373400300741196
Loss at batch 170 : 0.022411279380321503
Loss at batch 180 : 0.01249148789793253
Loss at batch 190 : 0.020677050575613976
Loss at batch 200 : 0.007752351928502321
Loss at batch 210 : 0.012324022129178047
Loss at batch 220 : 0.018876302987337112
Loss at batch 230 : 0.018510060384869576
Loss at batch 240 : 0.015190632082521915
Loss at batch 250 : 0.012450838461518288
Loss at batch 260 : 0.020699307322502136
Loss at batch 270 : 0.025836046785116196
Loss at batch 280 : 0.013331348076462746
Loss at batch 290 : 0.016122102737426758
Loss at batch 300 : 0.01444176398217678
Loss at batch 310 : 0.010442370548844337
Loss at batch 320 : 0.009580753743648529
Loss at batch 330 : 0.006605119444429874
Loss at batch 340 : 0.009967532008886337
Loss at batch 350 : 0.017477838322520256
Loss at batch 360 : 0.011957335285842419
Loss at batch 370 : 0.010366899892687798
epoch140 finished!
Loss at batch 10 : 0.016036707907915115
Loss at batch 20 : 0.010194825008511543
Loss at batch 30 : 0.008570321835577488
Loss at batch 40 : 0.01645587384700775
Loss at batch 50 : 0.016789259389042854
Loss at batch 60 : 0.01879829913377762
Loss at batch 70 : 0.02001359313726425
Loss at batch 80 : 0.01235311571508646
Loss at batch 90 : 0.008865850046277046
Loss at batch 100 : 0.007660624571144581
Loss at batch 110 : 0.01831398531794548
Loss at batch 120 : 0.013555292971432209
Loss at batch 130 : 0.005810925737023354
Loss at batch 140 : 0.010626908391714096
Loss at batch 150 : 0.011025043204426765
Loss at batch 160 : 0.012300350703299046
Loss at batch 170 : 0.01143624633550644
Loss at batch 180 : 0.010860070586204529
Loss at batch 190 : 0.013369807042181492
Loss at batch 200 : 0.01764974184334278
Loss at batch 210 : 0.019417522475123405
Loss at batch 220 : 0.011367755010724068
Loss at batch 230 : 0.018222399055957794
Loss at batch 240 : 0.01922403648495674
Loss at batch 250 : 0.02323519065976143
Loss at batch 260 : 0.0154181569814682
Loss at batch 270 : 0.009392136707901955
Loss at batch 280 : 0.014761202037334442
Loss at batch 290 : 0.013894358649849892
Loss at batch 300 : 0.010654795914888382
Loss at batch 310 : 0.009016171097755432
Loss at batch 320 : 0.01381207536906004
Loss at batch 330 : 0.01149892807006836
Loss at batch 340 : 0.009105097502470016
Loss at batch 350 : 0.028158830478787422
Loss at batch 360 : 0.008031906560063362
Loss at batch 370 : 0.008986381813883781
epoch141 finished!
Loss at batch 10 : 0.011402171105146408
Loss at batch 20 : 0.016082217916846275
Loss at batch 30 : 0.01590115949511528
Loss at batch 40 : 0.012813343666493893
Loss at batch 50 : 0.01972939260303974
Loss at batch 60 : 0.01344365905970335
Loss at batch 70 : 0.014574943110346794
Loss at batch 80 : 0.015767954289913177
Loss at batch 90 : 0.012011881917715073
Loss at batch 100 : 0.020092502236366272
Loss at batch 110 : 0.006974587216973305
Loss at batch 120 : 0.009926930069923401
Loss at batch 130 : 0.01640813797712326
Loss at batch 140 : 0.023685039952397346
Loss at batch 150 : 0.008816479705274105
Loss at batch 160 : 0.011426861397922039
Loss at batch 170 : 0.01210697740316391
Loss at batch 180 : 0.01613297127187252
Loss at batch 190 : 0.013367822393774986
Loss at batch 200 : 0.01947825215756893
Loss at batch 210 : 0.0124629782512784
Loss at batch 220 : 0.018321383744478226
Loss at batch 230 : 0.010113471187651157
Loss at batch 240 : 0.008232159540057182
Loss at batch 250 : 0.014278422109782696
Loss at batch 260 : 0.009727374650537968
Loss at batch 270 : 0.009732058271765709
Loss at batch 280 : 0.020128078758716583
Loss at batch 290 : 0.010214881040155888
Loss at batch 300 : 0.008530502207577229
Loss at batch 310 : 0.017802471294999123
Loss at batch 320 : 0.010831940919160843
Loss at batch 330 : 0.010335392318665981
Loss at batch 340 : 0.012830649502575397
Loss at batch 350 : 0.017552588135004044
Loss at batch 360 : 0.02714918553829193
Loss at batch 370 : 0.027602538466453552
epoch141 finished!
Loss at batch 10 : 0.010799815878272057
Loss at batch 20 : 0.01889811083674431
Loss at batch 30 : 0.01184482779353857
Loss at batch 40 : 0.015646621584892273
Loss at batch 50 : 0.022908693179488182
Loss at batch 60 : 0.015211233869194984
Loss at batch 70 : 0.008598839864134789
Loss at batch 80 : 0.014100504107773304
Loss at batch 90 : 0.019006527960300446
Loss at batch 100 : 0.009181216359138489
Loss at batch 110 : 0.0069274501875042915
Loss at batch 120 : 0.016409367322921753
Loss at batch 130 : 0.012498441152274609
Loss at batch 140 : 0.020497344434261322
Loss at batch 150 : 0.007268496789038181
Loss at batch 160 : 0.010555137880146503
Loss at batch 170 : 0.012563038617372513
Loss at batch 180 : 0.02042197436094284
Loss at batch 190 : 0.014981922693550587
Loss at batch 200 : 0.013400690630078316
Loss at batch 210 : 0.012872942723333836
Loss at batch 220 : 0.011841933242976665
Loss at batch 230 : 0.012262732721865177
Loss at batch 240 : 0.03868740424513817
Loss at batch 250 : 0.015355769544839859
Loss at batch 260 : 0.011479898355901241
Loss at batch 270 : 0.021522853523492813
Loss at batch 280 : 0.025377536192536354
Loss at batch 290 : 0.011153395287692547
Loss at batch 300 : 0.010772992856800556
Loss at batch 310 : 0.009850040078163147
Loss at batch 320 : 0.01532268337905407
Loss at batch 330 : 0.012906479649245739
Loss at batch 340 : 0.018433058634400368
Loss at batch 350 : 0.022662239149212837
Loss at batch 360 : 0.010124526917934418
Loss at batch 370 : 0.013007547706365585
epoch142 finished!
Loss at batch 10 : 0.024104993790388107
Loss at batch 20 : 0.013456912711262703
Loss at batch 30 : 0.01212526485323906
Loss at batch 40 : 0.012888270430266857
Loss at batch 50 : 0.015203181654214859
Loss at batch 60 : 0.013058577664196491
Loss at batch 70 : 0.01010137889534235
Loss at batch 80 : 0.018933558836579323
Loss at batch 90 : 0.01725907437503338
Loss at batch 100 : 0.011707540601491928
Loss at batch 110 : 0.01201674621552229
Loss at batch 120 : 0.011658618226647377
Loss at batch 130 : 0.008659840561449528
Loss at batch 140 : 0.008051215671002865
Loss at batch 150 : 0.016357600688934326
Loss at batch 160 : 0.012951075099408627
Loss at batch 170 : 0.008317790925502777
Loss at batch 180 : 0.011220277287065983
Loss at batch 190 : 0.01623775251209736
Loss at batch 200 : 0.01390391867607832
Loss at batch 210 : 0.010153071023523808
Loss at batch 220 : 0.016962805762887
Loss at batch 230 : 0.029185732826590538
Loss at batch 240 : 0.009630425833165646
Loss at batch 250 : 0.019887229427695274
Loss at batch 260 : 0.01087120734155178
Loss at batch 270 : 0.015085984952747822
Loss at batch 280 : 0.015888255089521408
Loss at batch 290 : 0.014090795069932938
Loss at batch 300 : 0.012756271287798882
Loss at batch 310 : 0.012759460136294365
Loss at batch 320 : 0.024981046095490456
Loss at batch 330 : 0.013986933045089245
Loss at batch 340 : 0.016162503510713577
Loss at batch 350 : 0.01833559200167656
Loss at batch 360 : 0.02413821779191494
Loss at batch 370 : 0.011716548353433609
epoch142 finished!
Loss at batch 10 : 0.010194217786192894
Loss at batch 20 : 0.01222242135554552
Loss at batch 30 : 0.01138730626553297
Loss at batch 40 : 0.013348614796996117
Loss at batch 50 : 0.01714685745537281
Loss at batch 60 : 0.016430648043751717
Loss at batch 70 : 0.0176340714097023
Loss at batch 80 : 0.02224750630557537
Loss at batch 90 : 0.016958344727754593
Loss at batch 100 : 0.009944363497197628
Loss at batch 110 : 0.023614222183823586
Loss at batch 120 : 0.01632866822183132
Loss at batch 130 : 0.009060961194336414
Loss at batch 140 : 0.010511950589716434
Loss at batch 150 : 0.02381611429154873
Loss at batch 160 : 0.014507167972624302
Loss at batch 170 : 0.021372269839048386
Loss at batch 180 : 0.027291668578982353
Loss at batch 190 : 0.017766524106264114
Loss at batch 200 : 0.011725383810698986
Loss at batch 210 : 0.010962397791445255
Loss at batch 220 : 0.02788136713206768
Loss at batch 230 : 0.017027081921696663
Loss at batch 240 : 0.0076312655583024025
Loss at batch 250 : 0.006572931073606014
Loss at batch 260 : 0.009596498683094978
Loss at batch 270 : 0.012864549644291401
Loss at batch 280 : 0.03867097571492195
Loss at batch 290 : 0.0156557597219944
Loss at batch 300 : 0.011402030475437641
Loss at batch 310 : 0.01019560918211937
Loss at batch 320 : 0.020923584699630737
Loss at batch 330 : 0.011337907053530216
Loss at batch 340 : 0.016349636018276215
Loss at batch 350 : 0.011606882326304913
Loss at batch 360 : 0.0176093690097332
Loss at batch 370 : 0.012314509600400925
epoch143 finished!
Loss at batch 10 : 0.014189093373715878
Loss at batch 20 : 0.015297872945666313
Loss at batch 30 : 0.01019953191280365
Loss at batch 40 : 0.018721390515565872
Loss at batch 50 : 0.019768543541431427
Loss at batch 60 : 0.0202618595212698
Loss at batch 70 : 0.009612135589122772
Loss at batch 80 : 0.015148184262216091
Loss at batch 90 : 0.009866713546216488
Loss at batch 100 : 0.020432893186807632
Loss at batch 110 : 0.017879847437143326
Loss at batch 120 : 0.0058525982312858105
Loss at batch 130 : 0.006361411418765783
Loss at batch 140 : 0.01100651454180479
Loss at batch 150 : 0.011914179660379887
Loss at batch 160 : 0.01760394312441349
Loss at batch 170 : 0.008111969567835331
Loss at batch 180 : 0.012445902451872826
Loss at batch 190 : 0.015714609995484352
Loss at batch 200 : 0.010491502471268177
Loss at batch 210 : 0.011019730940461159
Loss at batch 220 : 0.008729997090995312
Loss at batch 230 : 0.00999720674008131
Loss at batch 240 : 0.018966149538755417
Loss at batch 250 : 0.011839502491056919
Loss at batch 260 : 0.019236883148550987
Loss at batch 270 : 0.022420719265937805
Loss at batch 280 : 0.010765835642814636
Loss at batch 290 : 0.030382022261619568
Loss at batch 300 : 0.017780113965272903
Loss at batch 310 : 0.00983175914734602
Loss at batch 320 : 0.01372910663485527
Loss at batch 330 : 0.007112998981028795
Loss at batch 340 : 0.009496007114648819
Loss at batch 350 : 0.010760461911559105
Loss at batch 360 : 0.010647378861904144
Loss at batch 370 : 0.021155379712581635
epoch143 finished!
Loss at batch 10 : 0.01280982606112957
Loss at batch 20 : 0.01104064378887415
Loss at batch 30 : 0.01842121034860611
Loss at batch 40 : 0.009379829280078411
Loss at batch 50 : 0.015814457088708878
Loss at batch 60 : 0.018491677939891815
Loss at batch 70 : 0.02800850197672844
Loss at batch 80 : 0.012968960218131542
Loss at batch 90 : 0.011120270937681198
Loss at batch 100 : 0.011282247491180897
Loss at batch 110 : 0.010683925822377205
Loss at batch 120 : 0.009654860943555832
Loss at batch 130 : 0.014238457195460796
Loss at batch 140 : 0.013170208781957626
Loss at batch 150 : 0.012065784074366093
Loss at batch 160 : 0.014019759371876717
Loss at batch 170 : 0.01882089488208294
Loss at batch 180 : 0.013376533053815365
Loss at batch 190 : 0.007885090075433254
Loss at batch 200 : 0.017011163756251335
Loss at batch 210 : 0.009366443380713463
Loss at batch 220 : 0.01584779843688011
Loss at batch 230 : 0.015622173435986042
Loss at batch 240 : 0.00677677895873785
Loss at batch 250 : 0.009638690389692783
Loss at batch 260 : 0.020779432728886604
Loss at batch 270 : 0.010273710824549198
Loss at batch 280 : 0.010453286580741405
Loss at batch 290 : 0.008708246983587742
Loss at batch 300 : 0.01037436630576849
Loss at batch 310 : 0.0070708515122532845
Loss at batch 320 : 0.011109909974038601
Loss at batch 330 : 0.01153980940580368
Loss at batch 340 : 0.014226297847926617
Loss at batch 350 : 0.010336440987884998
Loss at batch 360 : 0.009747014380991459
Loss at batch 370 : 0.013666734099388123
epoch144 finished!
Loss at batch 10 : 0.00856940820813179
Loss at batch 20 : 0.01062974613159895
Loss at batch 30 : 0.007471810560673475
Loss at batch 40 : 0.008630521595478058
Loss at batch 50 : 0.019429894164204597
Loss at batch 60 : 0.014467320404946804
Loss at batch 70 : 0.019042685627937317
Loss at batch 80 : 0.02033691480755806
Loss at batch 90 : 0.014007237739861012
Loss at batch 100 : 0.014339426532387733
Loss at batch 110 : 0.028267187997698784
Loss at batch 120 : 0.011434374377131462
Loss at batch 130 : 0.013174846768379211
Loss at batch 140 : 0.012730583548545837
Loss at batch 150 : 0.011870344169437885
Loss at batch 160 : 0.011965103447437286
Loss at batch 170 : 0.013526164926588535
Loss at batch 180 : 0.010108486749231815
Loss at batch 190 : 0.007553851697593927
Loss at batch 200 : 0.009835821576416492
Loss at batch 210 : 0.012951756827533245
Loss at batch 220 : 0.012850676663219929
Loss at batch 230 : 0.017643030732870102
Loss at batch 240 : 0.011479824781417847
Loss at batch 250 : 0.010609096847474575
Loss at batch 260 : 0.011458995752036572
Loss at batch 270 : 0.01796303130686283
Loss at batch 280 : 0.011336118914186954
Loss at batch 290 : 0.016497135162353516
Loss at batch 300 : 0.013243631459772587
Loss at batch 310 : 0.011334165930747986
Loss at batch 320 : 0.00957100372761488
Loss at batch 330 : 0.01621716469526291
Loss at batch 340 : 0.011793375015258789
Loss at batch 350 : 0.005977945402264595
Loss at batch 360 : 0.014959903433918953
Loss at batch 370 : 0.013875833712518215
epoch144 finished!
Loss at batch 10 : 0.015443308278918266
Loss at batch 20 : 0.013007000088691711
Loss at batch 30 : 0.018428755924105644
Loss at batch 40 : 0.016097433865070343
Loss at batch 50 : 0.011485614813864231
Loss at batch 60 : 0.029777202755212784
Loss at batch 70 : 0.02002432569861412
Loss at batch 80 : 0.009409209713339806
Loss at batch 90 : 0.011521206237375736
Loss at batch 100 : 0.026476575061678886
Loss at batch 110 : 0.013950619846582413
Loss at batch 120 : 0.015847232192754745
Loss at batch 130 : 0.012622361071407795
Loss at batch 140 : 0.023092541843652725
Loss at batch 150 : 0.010345774702727795
Loss at batch 160 : 0.011396567337214947
Loss at batch 170 : 0.013526164926588535
Loss at batch 180 : 0.010841259732842445
Loss at batch 190 : 0.014462089166045189
Loss at batch 200 : 0.01074562780559063
Loss at batch 210 : 0.01957213692367077
Loss at batch 220 : 0.007312303874641657
Loss at batch 230 : 0.00709060113877058
Loss at batch 240 : 0.01628919690847397
Loss at batch 250 : 0.014538440853357315
Loss at batch 260 : 0.008817111141979694
Loss at batch 270 : 0.02562114968895912
Loss at batch 280 : 0.008645639754831791
Loss at batch 290 : 0.01617329567670822
Loss at batch 300 : 0.010683354921638966
Loss at batch 310 : 0.01570376753807068
Loss at batch 320 : 0.01283338200300932
Loss at batch 330 : 0.006319011561572552
Loss at batch 340 : 0.010794486850500107
Loss at batch 350 : 0.009721646085381508
Loss at batch 360 : 0.014184380881488323
Loss at batch 370 : 0.010195661336183548
epoch145 finished!
Loss at batch 10 : 0.0187337938696146
Loss at batch 20 : 0.01547471433877945
Loss at batch 30 : 0.018249936401844025
Loss at batch 40 : 0.01544315554201603
Loss at batch 50 : 0.014334590174257755
Loss at batch 60 : 0.025155628100037575
Loss at batch 70 : 0.02185240387916565
Loss at batch 80 : 0.025737959891557693
Loss at batch 90 : 0.015036195516586304
Loss at batch 100 : 0.015670759603381157
Loss at batch 110 : 0.008825527504086494
Loss at batch 120 : 0.010788175277411938
Loss at batch 130 : 0.013855298981070518
Loss at batch 140 : 0.011791262775659561
Loss at batch 150 : 0.008146237581968307
Loss at batch 160 : 0.02268153429031372
Loss at batch 170 : 0.007276833988726139
Loss at batch 180 : 0.01009766012430191
Loss at batch 190 : 0.01126676145941019
Loss at batch 200 : 0.009048735722899437
Loss at batch 210 : 0.01672130636870861
Loss at batch 220 : 0.009264325723052025
Loss at batch 230 : 0.015548715367913246
Loss at batch 240 : 0.00630532018840313
Loss at batch 250 : 0.01135394535958767
Loss at batch 260 : 0.017912212759256363
Loss at batch 270 : 0.017014360055327415
Loss at batch 280 : 0.0070928242057561874
Loss at batch 290 : 0.00957426242530346
Loss at batch 300 : 0.015852540731430054
Loss at batch 310 : 0.008840428665280342
Loss at batch 320 : 0.011321027763187885
Loss at batch 330 : 0.013400967232882977
Loss at batch 340 : 0.009748267941176891
Loss at batch 350 : 0.017197586596012115
Loss at batch 360 : 0.01593496836721897
Loss at batch 370 : 0.0072417655028402805
epoch145 finished!
Loss at batch 10 : 0.021906115114688873
Loss at batch 20 : 0.009996556676924229
Loss at batch 30 : 0.009099002927541733
Loss at batch 40 : 0.01318869087845087
Loss at batch 50 : 0.02238032966852188
Loss at batch 60 : 0.016953647136688232
Loss at batch 70 : 0.019916865974664688
Loss at batch 80 : 0.018435930833220482
Loss at batch 90 : 0.018953578546643257
Loss at batch 100 : 0.012495284900069237
Loss at batch 110 : 0.013891609385609627
Loss at batch 120 : 0.007625694386661053
Loss at batch 130 : 0.009710812009871006
Loss at batch 140 : 0.008606976829469204
Loss at batch 150 : 0.014791826717555523
Loss at batch 160 : 0.01582568697631359
Loss at batch 170 : 0.011195647530257702
Loss at batch 180 : 0.016107987612485886
Loss at batch 190 : 0.011254747398197651
Loss at batch 200 : 0.014240454882383347
Loss at batch 210 : 0.026654958724975586
Loss at batch 220 : 0.012685117311775684
Loss at batch 230 : 0.007792090531438589
Loss at batch 240 : 0.015324866399168968
Loss at batch 250 : 0.007464281748980284
Loss at batch 260 : 0.008760016411542892
Loss at batch 270 : 0.012390482239425182
Loss at batch 280 : 0.01853036880493164
Loss at batch 290 : 0.015995098277926445
Loss at batch 300 : 0.012057527899742126
Loss at batch 310 : 0.01271755900233984
Loss at batch 320 : 0.0183529295027256
Loss at batch 330 : 0.014800368808209896
Loss at batch 340 : 0.035575851798057556
Loss at batch 350 : 0.00810784101486206
Loss at batch 360 : 0.0204169899225235
Loss at batch 370 : 0.01993924006819725
epoch146 finished!
Loss at batch 10 : 0.036442141979932785
Loss at batch 20 : 0.011822819709777832
Loss at batch 30 : 0.013907580636441708
Loss at batch 40 : 0.01798498071730137
Loss at batch 50 : 0.01229217741638422
Loss at batch 60 : 0.011828445829451084
Loss at batch 70 : 0.013204006478190422
Loss at batch 80 : 0.014928661286830902
Loss at batch 90 : 0.011211483739316463
Loss at batch 100 : 0.014838066883385181
Loss at batch 110 : 0.02361157350242138
Loss at batch 120 : 0.011925145983695984
Loss at batch 130 : 0.012800744734704494
Loss at batch 140 : 0.010402687825262547
Loss at batch 150 : 0.015959840267896652
Loss at batch 160 : 0.018399806693196297
Loss at batch 170 : 0.019411655142903328
Loss at batch 180 : 0.012678556144237518
Loss at batch 190 : 0.013375313021242619
Loss at batch 200 : 0.017679033800959587
Loss at batch 210 : 0.012014917097985744
Loss at batch 220 : 0.007666836492717266
Loss at batch 230 : 0.01116774883121252
Loss at batch 240 : 0.010151447728276253
Loss at batch 250 : 0.019172094762325287
Loss at batch 260 : 0.01948777213692665
Loss at batch 270 : 0.010325614362955093
Loss at batch 280 : 0.010268747806549072
Loss at batch 290 : 0.009337486699223518
Loss at batch 300 : 0.007939157076179981
Loss at batch 310 : 0.012443872168660164
Loss at batch 320 : 0.017847813665866852
Loss at batch 330 : 0.012352350167930126
Loss at batch 340 : 0.013390460051596165
Loss at batch 350 : 0.031579259783029556
Loss at batch 360 : 0.012018278241157532
Loss at batch 370 : 0.019142858684062958
epoch146 finished!
Loss at batch 10 : 0.014608578756451607
Loss at batch 20 : 0.021316735073924065
Loss at batch 30 : 0.011397406458854675
Loss at batch 40 : 0.016707779839634895
Loss at batch 50 : 0.007041288074105978
Loss at batch 60 : 0.014230219647288322
Loss at batch 70 : 0.024922871962189674
Loss at batch 80 : 0.01380772702395916
Loss at batch 90 : 0.010541558265686035
Loss at batch 100 : 0.01751958392560482
Loss at batch 110 : 0.011221082881093025
Loss at batch 120 : 0.011618956923484802
Loss at batch 130 : 0.017114611342549324
Loss at batch 140 : 0.01747787930071354
Loss at batch 150 : 0.01744024083018303
Loss at batch 160 : 0.020867809653282166
Loss at batch 170 : 0.027660299092531204
Loss at batch 180 : 0.016402199864387512
Loss at batch 190 : 0.010218648239970207
Loss at batch 200 : 0.027444204315543175
Loss at batch 210 : 0.011313721537590027
Loss at batch 220 : 0.015880828723311424
Loss at batch 230 : 0.012304814532399178
Loss at batch 240 : 0.013996715657413006
Loss at batch 250 : 0.012276636436581612
Loss at batch 260 : 0.014515535905957222
Loss at batch 270 : 0.013229419477283955
Loss at batch 280 : 0.019863082095980644
Loss at batch 290 : 0.016432994976639748
Loss at batch 300 : 0.017150921747088432
Loss at batch 310 : 0.010902333073318005
Loss at batch 320 : 0.01584899052977562
Loss at batch 330 : 0.010615779086947441
Loss at batch 340 : 0.013925419189035892
Loss at batch 350 : 0.01009354181587696
Loss at batch 360 : 0.014983479864895344
Loss at batch 370 : 0.022548727691173553
epoch147 finished!
Loss at batch 10 : 0.01232193410396576
Loss at batch 20 : 0.012000682763755322
Loss at batch 30 : 0.0062789893709123135
Loss at batch 40 : 0.007352034095674753
Loss at batch 50 : 0.01073141023516655
Loss at batch 60 : 0.024248309433460236
Loss at batch 70 : 0.02332606539130211
Loss at batch 80 : 0.014857103116810322
Loss at batch 90 : 0.013613158836960793
Loss at batch 100 : 0.013486884534358978
Loss at batch 110 : 0.013650830835103989
Loss at batch 120 : 0.012937922030687332
Loss at batch 130 : 0.012710429728031158
Loss at batch 140 : 0.017184915021061897
Loss at batch 150 : 0.01702423393726349
Loss at batch 160 : 0.013127680867910385
Loss at batch 170 : 0.012852804735302925
Loss at batch 180 : 0.01749761775135994
Loss at batch 190 : 0.009881664998829365
Loss at batch 200 : 0.008916117250919342
Loss at batch 210 : 0.014950951561331749
Loss at batch 220 : 0.007977600209414959
Loss at batch 230 : 0.045260731130838394
Loss at batch 240 : 0.010126780718564987
Loss at batch 250 : 0.014177032746374607
Loss at batch 260 : 0.015242227353155613
Loss at batch 270 : 0.013522563502192497
Loss at batch 280 : 0.007682401221245527
Loss at batch 290 : 0.01718555949628353
Loss at batch 300 : 0.01161627285182476
Loss at batch 310 : 0.019455915316939354
Loss at batch 320 : 0.014144743792712688
Loss at batch 330 : 0.013508410193026066
Loss at batch 340 : 0.010931233875453472
Loss at batch 350 : 0.01671595871448517
Loss at batch 360 : 0.011264908127486706
Loss at batch 370 : 0.01581202633678913
epoch147 finished!
Loss at batch 10 : 0.01552383229136467
Loss at batch 20 : 0.011827629990875721
Loss at batch 30 : 0.015527334995567799
Loss at batch 40 : 0.013439136557281017
Loss at batch 50 : 0.013068956322968006
Loss at batch 60 : 0.011374516412615776
Loss at batch 70 : 0.012913262471556664
Loss at batch 80 : 0.016510503366589546
Loss at batch 90 : 0.01673240400850773
Loss at batch 100 : 0.016147030517458916
Loss at batch 110 : 0.01185956597328186
Loss at batch 120 : 0.011901230551302433
Loss at batch 130 : 0.01209305040538311
Loss at batch 140 : 0.022172141820192337
Loss at batch 150 : 0.01177438534796238
Loss at batch 160 : 0.015988623723387718
Loss at batch 170 : 0.008339515887200832
Loss at batch 180 : 0.015283721499145031
Loss at batch 190 : 0.01345945242792368
Loss at batch 200 : 0.01746988110244274
Loss at batch 210 : 0.014245378784835339
Loss at batch 220 : 0.009654327295720577
Loss at batch 230 : 0.01431229617446661
Loss at batch 240 : 0.013307809829711914
Loss at batch 250 : 0.015216350555419922
Loss at batch 260 : 0.00579610001295805
Loss at batch 270 : 0.023832757025957108
Loss at batch 280 : 0.01221572794020176
Loss at batch 290 : 0.016693176701664925
Loss at batch 300 : 0.019006723538041115
Loss at batch 310 : 0.027377616614103317
Loss at batch 320 : 0.017016978934407234
Loss at batch 330 : 0.010591373778879642
Loss at batch 340 : 0.0177866630256176
Loss at batch 350 : 0.012004888616502285
Loss at batch 360 : 0.016990570351481438
Loss at batch 370 : 0.012692955322563648
epoch148 finished!
Loss at batch 10 : 0.013012788258492947
Loss at batch 20 : 0.0229471568018198
Loss at batch 30 : 0.007477583363652229
Loss at batch 40 : 0.011228987947106361
Loss at batch 50 : 0.02165338397026062
Loss at batch 60 : 0.015473875217139721
Loss at batch 70 : 0.012259604409337044
Loss at batch 80 : 0.010286524891853333
Loss at batch 90 : 0.010847173631191254
Loss at batch 100 : 0.021697061136364937
Loss at batch 110 : 0.011888631619513035
Loss at batch 120 : 0.019869040697813034
Loss at batch 130 : 0.024731308221817017
Loss at batch 140 : 0.011343914084136486
Loss at batch 150 : 0.010823720134794712
Loss at batch 160 : 0.013595318421721458
Loss at batch 170 : 0.016869384795427322
Loss at batch 180 : 0.015763305127620697
Loss at batch 190 : 0.01676342450082302
Loss at batch 200 : 0.014795597642660141
Loss at batch 210 : 0.014811267144978046
Loss at batch 220 : 0.007851693779230118
Loss at batch 230 : 0.018695788457989693
Loss at batch 240 : 0.014596006833016872
Loss at batch 250 : 0.019931703805923462
Loss at batch 260 : 0.015934202820062637
Loss at batch 270 : 0.016646768897771835
Loss at batch 280 : 0.01474854163825512
Loss at batch 290 : 0.012710736133158207
Loss at batch 300 : 0.007830563932657242
Loss at batch 310 : 0.009375340305268764
Loss at batch 320 : 0.015081573277711868
Loss at batch 330 : 0.008171027526259422
Loss at batch 340 : 0.015355314128100872
Loss at batch 350 : 0.009605287574231625
Loss at batch 360 : 0.016341447830200195
Loss at batch 370 : 0.010912838391959667
epoch148 finished!
Loss at batch 10 : 0.011434135027229786
Loss at batch 20 : 0.01397894136607647
Loss at batch 30 : 0.013880785554647446
Loss at batch 40 : 0.01914467290043831
Loss at batch 50 : 0.01820972189307213
Loss at batch 60 : 0.016483228653669357
Loss at batch 70 : 0.014041326940059662
Loss at batch 80 : 0.015460127033293247
Loss at batch 90 : 0.01758786477148533
Loss at batch 100 : 0.01691126823425293
Loss at batch 110 : 0.010736734606325626
Loss at batch 120 : 0.011276625096797943
Loss at batch 130 : 0.011829781346023083
Loss at batch 140 : 0.014214764349162579
Loss at batch 150 : 0.009762628935277462
Loss at batch 160 : 0.01555788703262806
Loss at batch 170 : 0.012755432166159153
Loss at batch 180 : 0.01048259437084198
Loss at batch 190 : 0.010870948433876038
Loss at batch 200 : 0.018512973561882973
Loss at batch 210 : 0.014035793021321297
Loss at batch 220 : 0.013306931592524052
Loss at batch 230 : 0.015713751316070557
Loss at batch 240 : 0.020972568541765213
Loss at batch 250 : 0.029115131124854088
Loss at batch 260 : 0.014358974061906338
Loss at batch 270 : 0.0163777656853199
Loss at batch 280 : 0.017891671508550644
Loss at batch 290 : 0.01241483073681593
Loss at batch 300 : 0.014290129765868187
Loss at batch 310 : 0.011224295943975449
Loss at batch 320 : 0.012108868919312954
Loss at batch 330 : 0.015980051830410957
Loss at batch 340 : 0.013519609346985817
Loss at batch 350 : 0.012279290705919266
Loss at batch 360 : 0.02899458445608616
Loss at batch 370 : 0.015130833722651005
epoch149 finished!
Loss at batch 10 : 0.015844007954001427
Loss at batch 20 : 0.013434124179184437
Loss at batch 30 : 0.017553862184286118
Loss at batch 40 : 0.010910498909652233
Loss at batch 50 : 0.011951916851103306
Loss at batch 60 : 0.017193449661135674
Loss at batch 70 : 0.011574534699320793
Loss at batch 80 : 0.018451431766152382
Loss at batch 90 : 0.020340487360954285
Loss at batch 100 : 0.011571930721402168
Loss at batch 110 : 0.014464215375483036
Loss at batch 120 : 0.012939348816871643
Loss at batch 130 : 0.014602874405682087
Loss at batch 140 : 0.009608523920178413
Loss at batch 150 : 0.01535545289516449
Loss at batch 160 : 0.013542978093028069
Loss at batch 170 : 0.018940094858407974
Loss at batch 180 : 0.015049570240080357
Loss at batch 190 : 0.02014159969985485
Loss at batch 200 : 0.0161184873431921
Loss at batch 210 : 0.007162592373788357
Loss at batch 220 : 0.012035919353365898
Loss at batch 230 : 0.008680400438606739
Loss at batch 240 : 0.0070702433586120605
Loss at batch 250 : 0.014287255704402924
Loss at batch 260 : 0.013570052571594715
Loss at batch 270 : 0.018261589109897614
Loss at batch 280 : 0.017909593880176544
Loss at batch 290 : 0.01834816485643387
Loss at batch 300 : 0.011598674580454826
Loss at batch 310 : 0.020590148866176605
Loss at batch 320 : 0.01351865567266941
Loss at batch 330 : 0.012200584635138512
Loss at batch 340 : 0.015786370262503624
Loss at batch 350 : 0.010121921077370644
Loss at batch 360 : 0.013757271692156792
Loss at batch 370 : 0.011277342215180397
epoch149 finished!
Loss at batch 10 : 0.012726117856800556
Loss at batch 20 : 0.010748375207185745
Loss at batch 30 : 0.009787503629922867
Loss at batch 40 : 0.012250429019331932
Loss at batch 50 : 0.007684048265218735
Loss at batch 60 : 0.022507110610604286
Loss at batch 70 : 0.008663834072649479
Loss at batch 80 : 0.01571297086775303
Loss at batch 90 : 0.018692683428525925
Loss at batch 100 : 0.022784419357776642
Loss at batch 110 : 0.01342586986720562
Loss at batch 120 : 0.014416154474020004
Loss at batch 130 : 0.012582448311150074
Loss at batch 140 : 0.02517944946885109
Loss at batch 150 : 0.008350493386387825
Loss at batch 160 : 0.007008064538240433
Loss at batch 170 : 0.01859690435230732
Loss at batch 180 : 0.009367055259644985
Loss at batch 190 : 0.016591880470514297
Loss at batch 200 : 0.01099148578941822
Loss at batch 210 : 0.009320992976427078
Loss at batch 220 : 0.021862538531422615
Loss at batch 230 : 0.009419246576726437
Loss at batch 240 : 0.015948286280035973
Loss at batch 250 : 0.0140316067263484
Loss at batch 260 : 0.01344978716224432
Loss at batch 270 : 0.011610535904765129
Loss at batch 280 : 0.014748363755643368
Loss at batch 290 : 0.013128446415066719
Loss at batch 300 : 0.019090894609689713
Loss at batch 310 : 0.017384622246026993
Loss at batch 320 : 0.011687884107232094
Loss at batch 330 : 0.016952911391854286
Loss at batch 340 : 0.011923382058739662
Loss at batch 350 : 0.017403610050678253
Loss at batch 360 : 0.012295312248170376
Loss at batch 370 : 0.009308096952736378
epoch150 finished!
Loss at batch 10 : 0.009872245602309704
Loss at batch 20 : 0.007909528911113739
Loss at batch 30 : 0.025125673040747643
Loss at batch 40 : 0.011204763315618038
Loss at batch 50 : 0.011422615498304367
Loss at batch 60 : 0.014791076071560383
Loss at batch 70 : 0.014471527189016342
Loss at batch 80 : 0.015293054282665253
Loss at batch 90 : 0.007176022045314312
Loss at batch 100 : 0.010369001887738705
Loss at batch 110 : 0.014622442424297333
Loss at batch 120 : 0.014597075991332531
Loss at batch 130 : 0.018549490720033646
Loss at batch 140 : 0.015106475912034512
Loss at batch 150 : 0.029799852520227432
Loss at batch 160 : 0.013871596194803715
Loss at batch 170 : 0.017957525327801704
Loss at batch 180 : 0.022293107584118843
Loss at batch 190 : 0.009652812965214252
Loss at batch 200 : 0.022051772102713585
Loss at batch 210 : 0.018149450421333313
Loss at batch 220 : 0.010427331551909447
Loss at batch 230 : 0.021382348611950874
Loss at batch 240 : 0.013821294531226158
Loss at batch 250 : 0.022416653111577034
Loss at batch 260 : 0.01134503073990345
Loss at batch 270 : 0.013416901230812073
Loss at batch 280 : 0.01118872594088316
Loss at batch 290 : 0.013321971520781517
Loss at batch 300 : 0.013144667260348797
Loss at batch 310 : 0.008123492822051048
Loss at batch 320 : 0.013102381490170956
Loss at batch 330 : 0.014887871220707893
Loss at batch 340 : 0.01724339835345745
Loss at batch 350 : 0.011832726188004017
Loss at batch 360 : 0.021917888894677162
Loss at batch 370 : 0.018611090257763863
epoch150 finished!
Loss at batch 10 : 0.012568756006658077
Loss at batch 20 : 0.013918992131948471
Loss at batch 30 : 0.010186501778662205
Loss at batch 40 : 0.022278765216469765
Loss at batch 50 : 0.012489749118685722
Loss at batch 60 : 0.013009252026677132
Loss at batch 70 : 0.015269977040588856
Loss at batch 80 : 0.01435497310012579
Loss at batch 90 : 0.017885224893689156
Loss at batch 100 : 0.01746409758925438
Loss at batch 110 : 0.020771095529198647
Loss at batch 120 : 0.01663726009428501
Loss at batch 130 : 0.013371842913329601
Loss at batch 140 : 0.015021538361907005
Loss at batch 150 : 0.013876087963581085
Loss at batch 160 : 0.02275029942393303
Loss at batch 170 : 0.009836976416409016
Loss at batch 180 : 0.010829243808984756
Loss at batch 190 : 0.012499542906880379
Loss at batch 200 : 0.017037926241755486
Loss at batch 210 : 0.010602070949971676
Loss at batch 220 : 0.009812721982598305
Loss at batch 230 : 0.026618104428052902
Loss at batch 240 : 0.013532064855098724
Loss at batch 250 : 0.008530277758836746
Loss at batch 260 : 0.02479117549955845
Loss at batch 270 : 0.02199283242225647
Loss at batch 280 : 0.01648583635687828
Loss at batch 290 : 0.012220127508044243
Loss at batch 300 : 0.01643490232527256
Loss at batch 310 : 0.01835661195218563
Loss at batch 320 : 0.009855683892965317
Loss at batch 330 : 0.008999684825539589
Loss at batch 340 : 0.00880859512835741
Loss at batch 350 : 0.016019731760025024
Loss at batch 360 : 0.01954641193151474
Loss at batch 370 : 0.009725197218358517
epoch151 finished!
Loss at batch 10 : 0.017963876947760582
Loss at batch 20 : 0.017337657511234283
Loss at batch 30 : 0.007656668778508902
Loss at batch 40 : 0.008175631053745747
Loss at batch 50 : 0.017740853130817413
Loss at batch 60 : 0.016426119953393936
Loss at batch 70 : 0.011826835572719574
Loss at batch 80 : 0.008502133190631866
Loss at batch 90 : 0.012534098699688911
Loss at batch 100 : 0.013195277191698551
Loss at batch 110 : 0.018489576876163483
Loss at batch 120 : 0.027550578117370605
Loss at batch 130 : 0.01724456064403057
Loss at batch 140 : 0.02826056256890297
Loss at batch 150 : 0.008004074916243553
Loss at batch 160 : 0.015046346001327038
Loss at batch 170 : 0.011562857776880264
Loss at batch 180 : 0.01898077502846718
Loss at batch 190 : 0.013197999447584152
Loss at batch 200 : 0.018517736345529556
Loss at batch 210 : 0.008824829943478107
Loss at batch 220 : 0.013894589617848396
Loss at batch 230 : 0.010315444320440292
Loss at batch 240 : 0.011021194979548454
Loss at batch 250 : 0.015592295676469803
Loss at batch 260 : 0.014746518805623055
Loss at batch 270 : 0.01076536811888218
Loss at batch 280 : 0.01027662493288517
Loss at batch 290 : 0.006832660175859928
Loss at batch 300 : 0.01014796830713749
Loss at batch 310 : 0.01461857557296753
Loss at batch 320 : 0.01127701997756958
Loss at batch 330 : 0.010952748358249664
Loss at batch 340 : 0.009116488508880138
Loss at batch 350 : 0.0075838807970285416
Loss at batch 360 : 0.015274490229785442
Loss at batch 370 : 0.01509400736540556
epoch151 finished!
Loss at batch 10 : 0.010150416754186153
Loss at batch 20 : 0.0074954405426979065
Loss at batch 30 : 0.009481471963226795
Loss at batch 40 : 0.014592480845749378
Loss at batch 50 : 0.010542254894971848
Loss at batch 60 : 0.008363055065274239
Loss at batch 70 : 0.01378041785210371
Loss at batch 80 : 0.020051177591085434
Loss at batch 90 : 0.006807307712733746
Loss at batch 100 : 0.010907096788287163
Loss at batch 110 : 0.015058796852827072
Loss at batch 120 : 0.0224445927888155
Loss at batch 130 : 0.01843966357409954
Loss at batch 140 : 0.025546710938215256
Loss at batch 150 : 0.011825725436210632
Loss at batch 160 : 0.013626344501972198
Loss at batch 170 : 0.02008722722530365
Loss at batch 180 : 0.016138100996613503
Loss at batch 190 : 0.013198919594287872
Loss at batch 200 : 0.015212856233119965
Loss at batch 210 : 0.016566133126616478
Loss at batch 220 : 0.012963477522134781
Loss at batch 230 : 0.014199714176356792
Loss at batch 240 : 0.0155417425557971
Loss at batch 250 : 0.01726902276277542
Loss at batch 260 : 0.00901899766176939
Loss at batch 270 : 0.00837243627756834
Loss at batch 280 : 0.008985981345176697
Loss at batch 290 : 0.008293156512081623
Loss at batch 300 : 0.011658825911581516
Loss at batch 310 : 0.011465807445347309
Loss at batch 320 : 0.017682285979390144
Loss at batch 330 : 0.008295636624097824
Loss at batch 340 : 0.009936799295246601
Loss at batch 350 : 0.010592406615614891
Loss at batch 360 : 0.009324297308921814
Loss at batch 370 : 0.01144916471093893
epoch152 finished!
Loss at batch 10 : 0.010103444568812847
Loss at batch 20 : 0.009296692907810211
Loss at batch 30 : 0.007869533263146877
Loss at batch 40 : 0.01572994329035282
Loss at batch 50 : 0.016076434403657913
Loss at batch 60 : 0.01937652938067913
Loss at batch 70 : 0.010405714623630047
Loss at batch 80 : 0.007527243345975876
Loss at batch 90 : 0.019640306010842323
Loss at batch 100 : 0.008560243062675
Loss at batch 110 : 0.011904370039701462
Loss at batch 120 : 0.010160164907574654
Loss at batch 130 : 0.011599081568419933
Loss at batch 140 : 0.0231514610350132
Loss at batch 150 : 0.015498769469559193
Loss at batch 160 : 0.021274656057357788
Loss at batch 170 : 0.018192406743764877
Loss at batch 180 : 0.01141281332820654
Loss at batch 190 : 0.009963911958038807
Loss at batch 200 : 0.014082021079957485
Loss at batch 210 : 0.018533160910010338
Loss at batch 220 : 0.012305463664233685
Loss at batch 230 : 0.01890312321484089
Loss at batch 240 : 0.015190476551651955
Loss at batch 250 : 0.012819161638617516
Loss at batch 260 : 0.025047888979315758
Loss at batch 270 : 0.015649249777197838
Loss at batch 280 : 0.008944565430283546
Loss at batch 290 : 0.017089923843741417
Loss at batch 300 : 0.0168360136449337
Loss at batch 310 : 0.011777239851653576
Loss at batch 320 : 0.015641890466213226
Loss at batch 330 : 0.013881050050258636
Loss at batch 340 : 0.014841838739812374
Loss at batch 350 : 0.0145264882594347
Loss at batch 360 : 0.012230363674461842
Loss at batch 370 : 0.01326232124119997
epoch152 finished!
Loss at batch 10 : 0.014451340772211552
Loss at batch 20 : 0.011360160075128078
Loss at batch 30 : 0.02208269014954567
Loss at batch 40 : 0.018511928617954254
Loss at batch 50 : 0.006780017167329788
Loss at batch 60 : 0.006134368013590574
Loss at batch 70 : 0.010759941302239895
Loss at batch 80 : 0.02199588343501091
Loss at batch 90 : 0.011028665117919445
Loss at batch 100 : 0.01831796206533909
Loss at batch 110 : 0.016786545515060425
Loss at batch 120 : 0.013019965030252934
Loss at batch 130 : 0.009488378651440144
Loss at batch 140 : 0.0106443976983428
Loss at batch 150 : 0.010818659327924252
Loss at batch 160 : 0.01294423546642065
Loss at batch 170 : 0.015944065526127815
Loss at batch 180 : 0.012356539256870747
Loss at batch 190 : 0.011821090243756771
Loss at batch 200 : 0.021458439528942108
Loss at batch 210 : 0.017484771087765694
Loss at batch 220 : 0.011342937126755714
Loss at batch 230 : 0.019893279299139977
Loss at batch 240 : 0.010064393281936646
Loss at batch 250 : 0.02149030938744545
Loss at batch 260 : 0.014528779312968254
Loss at batch 270 : 0.010363833047449589
Loss at batch 280 : 0.012486562132835388
Loss at batch 290 : 0.012876932509243488
Loss at batch 300 : 0.02451714128255844
Loss at batch 310 : 0.011296388693153858
Loss at batch 320 : 0.008805917575955391
Loss at batch 330 : 0.00896892137825489
Loss at batch 340 : 0.016419054940342903
Loss at batch 350 : 0.010131226852536201
Loss at batch 360 : 0.008591705933213234
Loss at batch 370 : 0.016813207417726517
epoch153 finished!
Loss at batch 10 : 0.007945191115140915
Loss at batch 20 : 0.013672295957803726
Loss at batch 30 : 0.01589093543589115
Loss at batch 40 : 0.014878422021865845
Loss at batch 50 : 0.02854633890092373
Loss at batch 60 : 0.017968961969017982
Loss at batch 70 : 0.01187449786812067
Loss at batch 80 : 0.014903571456670761
Loss at batch 90 : 0.012205630540847778
Loss at batch 100 : 0.009810090065002441
Loss at batch 110 : 0.013132074847817421
Loss at batch 120 : 0.011874930001795292
Loss at batch 130 : 0.018861692398786545
Loss at batch 140 : 0.005566369742155075
Loss at batch 150 : 0.011380255222320557
Loss at batch 160 : 0.015501496382057667
Loss at batch 170 : 0.012836436741054058
Loss at batch 180 : 0.018474504351615906
Loss at batch 190 : 0.012190524488687515
Loss at batch 200 : 0.013123809359967709
Loss at batch 210 : 0.014141379855573177
Loss at batch 220 : 0.015570306219160557
Loss at batch 230 : 0.0083228200674057
Loss at batch 240 : 0.02178509533405304
Loss at batch 250 : 0.011731870472431183
Loss at batch 260 : 0.007269404362887144
Loss at batch 270 : 0.013896622695028782
Loss at batch 280 : 0.015630165114998817
Loss at batch 290 : 0.014351611956954002
Loss at batch 300 : 0.011349623091518879
Loss at batch 310 : 0.013782203197479248
Loss at batch 320 : 0.01640373095870018
Loss at batch 330 : 0.019924364984035492
Loss at batch 340 : 0.02183620072901249
Loss at batch 350 : 0.010227147489786148
Loss at batch 360 : 0.010600865818560123
Loss at batch 370 : 0.009789814241230488
epoch153 finished!
Loss at batch 10 : 0.017581909894943237
Loss at batch 20 : 0.0076124100014567375
Loss at batch 30 : 0.012597634457051754
Loss at batch 40 : 0.01909632794559002
Loss at batch 50 : 0.00985852349549532
Loss at batch 60 : 0.016651488840579987
Loss at batch 70 : 0.015416853129863739
Loss at batch 80 : 0.01307663507759571
Loss at batch 90 : 0.011776398867368698
Loss at batch 100 : 0.017936421558260918
Loss at batch 110 : 0.009855004958808422
Loss at batch 120 : 0.01673555187880993
Loss at batch 130 : 0.009412449784576893
Loss at batch 140 : 0.016646169126033783
Loss at batch 150 : 0.01080538984388113
Loss at batch 160 : 0.011035392060875893
Loss at batch 170 : 0.01759188435971737
Loss at batch 180 : 0.011307298205792904
Loss at batch 190 : 0.011731820181012154
Loss at batch 200 : 0.008842308074235916
Loss at batch 210 : 0.011576665565371513
Loss at batch 220 : 0.009882464073598385
Loss at batch 230 : 0.024097295477986336
Loss at batch 240 : 0.011843685992062092
Loss at batch 250 : 0.021378450095653534
Loss at batch 260 : 0.0068980432115495205
Loss at batch 270 : 0.013309481553733349
Loss at batch 280 : 0.02716708369553089
Loss at batch 290 : 0.00987314060330391
Loss at batch 300 : 0.01466792169958353
Loss at batch 310 : 0.011210037395358086
Loss at batch 320 : 0.012150295078754425
Loss at batch 330 : 0.010197505354881287
Loss at batch 340 : 0.01417982392013073
Loss at batch 350 : 0.013349095359444618
Loss at batch 360 : 0.013144726864993572
Loss at batch 370 : 0.02043929323554039
epoch154 finished!
Loss at batch 10 : 0.009070126339793205
Loss at batch 20 : 0.019862426444888115
Loss at batch 30 : 0.012872873805463314
Loss at batch 40 : 0.01770779676735401
Loss at batch 50 : 0.0165119431912899
Loss at batch 60 : 0.010272507555782795
Loss at batch 70 : 0.015422587282955647
Loss at batch 80 : 0.013140159659087658
Loss at batch 90 : 0.012884913012385368
Loss at batch 100 : 0.018014954403042793
Loss at batch 110 : 0.012370885349810123
Loss at batch 120 : 0.014018402434885502
Loss at batch 130 : 0.0158837977796793
Loss at batch 140 : 0.013741649687290192
Loss at batch 150 : 0.009656648151576519
Loss at batch 160 : 0.008406906388700008
Loss at batch 170 : 0.017773959785699844
Loss at batch 180 : 0.009101303294301033
Loss at batch 190 : 0.01932770200073719
Loss at batch 200 : 0.016313817352056503
Loss at batch 210 : 0.018783900886774063
Loss at batch 220 : 0.024062205106019974
Loss at batch 230 : 0.023380810394883156
Loss at batch 240 : 0.008911529555916786
Loss at batch 250 : 0.01145304273813963
Loss at batch 260 : 0.012757460586726665
Loss at batch 270 : 0.020617811009287834
Loss at batch 280 : 0.010606426745653152
Loss at batch 290 : 0.02881600335240364
Loss at batch 300 : 0.014597679488360882
Loss at batch 310 : 0.015925902873277664
Loss at batch 320 : 0.02004716545343399
Loss at batch 330 : 0.011328371241688728
Loss at batch 340 : 0.009727044962346554
Loss at batch 350 : 0.024653032422065735
Loss at batch 360 : 0.014502241276204586
Loss at batch 370 : 0.006258974317461252
epoch154 finished!
Loss at batch 10 : 0.02113467827439308
Loss at batch 20 : 0.027553953230381012
Loss at batch 30 : 0.01846555806696415
Loss at batch 40 : 0.01043865829706192
Loss at batch 50 : 0.008726845495402813
Loss at batch 60 : 0.006910594645887613
Loss at batch 70 : 0.00846817810088396
Loss at batch 80 : 0.008349914103746414
Loss at batch 90 : 0.010435674339532852
Loss at batch 100 : 0.010034349747002125
Loss at batch 110 : 0.02157801389694214
Loss at batch 120 : 0.01647276245057583
Loss at batch 130 : 0.01455792784690857
Loss at batch 140 : 0.02385653182864189
Loss at batch 150 : 0.019443148747086525
Loss at batch 160 : 0.02081022597849369
Loss at batch 170 : 0.01011844165623188
Loss at batch 180 : 0.010917439125478268
Loss at batch 190 : 0.007166318595409393
Loss at batch 200 : 0.008945195935666561
Loss at batch 210 : 0.016095686703920364
Loss at batch 220 : 0.011546834371984005
Loss at batch 230 : 0.011328171007335186
Loss at batch 240 : 0.015321126207709312
Loss at batch 250 : 0.009057189337909222
Loss at batch 260 : 0.006754526402801275
Loss at batch 270 : 0.01692359521985054
Loss at batch 280 : 0.008541780523955822
Loss at batch 290 : 0.013632775284349918
Loss at batch 300 : 0.009500249288976192
Loss at batch 310 : 0.024554817005991936
Loss at batch 320 : 0.012827747501432896
Loss at batch 330 : 0.014098926447331905
Loss at batch 340 : 0.025401895865797997
Loss at batch 350 : 0.012978969141840935
Loss at batch 360 : 0.01920832321047783
Loss at batch 370 : 0.016253216192126274
epoch155 finished!
Loss at batch 10 : 0.015315559692680836
Loss at batch 20 : 0.02483373135328293
Loss at batch 30 : 0.009366623125970364
Loss at batch 40 : 0.008902858011424541
Loss at batch 50 : 0.00829765573143959
Loss at batch 60 : 0.010225573554635048
Loss at batch 70 : 0.009270388633012772
Loss at batch 80 : 0.019441816955804825
Loss at batch 90 : 0.02008119970560074
Loss at batch 100 : 0.010249951854348183
Loss at batch 110 : 0.012747007422149181
Loss at batch 120 : 0.012292983941733837
Loss at batch 130 : 0.009712109342217445
Loss at batch 140 : 0.014621538110077381
Loss at batch 150 : 0.021407632157206535
Loss at batch 160 : 0.012922681868076324
Loss at batch 170 : 0.015368688851594925
Loss at batch 180 : 0.0077811055816709995
Loss at batch 190 : 0.02356690727174282
Loss at batch 200 : 0.009176415391266346
Loss at batch 210 : 0.02029351517558098
Loss at batch 220 : 0.009021544829010963
Loss at batch 230 : 0.007394272834062576
Loss at batch 240 : 0.00859768595546484
Loss at batch 250 : 0.01441479567438364
Loss at batch 260 : 0.010442671366035938
Loss at batch 270 : 0.009796525351703167
Loss at batch 280 : 0.02138335257768631
Loss at batch 290 : 0.01076288241893053
Loss at batch 300 : 0.022365642711520195
Loss at batch 310 : 0.013434436172246933
Loss at batch 320 : 0.014797662384808064
Loss at batch 330 : 0.016099022701382637
Loss at batch 340 : 0.012363164685666561
Loss at batch 350 : 0.005162825342267752
Loss at batch 360 : 0.01521351095288992
Loss at batch 370 : 0.00986457522958517
epoch155 finished!
Loss at batch 10 : 0.01228741742670536
Loss at batch 20 : 0.010808819904923439
Loss at batch 30 : 0.008821994066238403
Loss at batch 40 : 0.016744127497076988
Loss at batch 50 : 0.008321581408381462
Loss at batch 60 : 0.02322315238416195
Loss at batch 70 : 0.015268925577402115
Loss at batch 80 : 0.011043431237339973
Loss at batch 90 : 0.010401275008916855
Loss at batch 100 : 0.007484088186174631
Loss at batch 110 : 0.009861929342150688
Loss at batch 120 : 0.02146407775580883
Loss at batch 130 : 0.014842121861875057
Loss at batch 140 : 0.024712160229682922
Loss at batch 150 : 0.01207314059138298
Loss at batch 160 : 0.01493972260504961
Loss at batch 170 : 0.009222260676324368
Loss at batch 180 : 0.021507611498236656
Loss at batch 190 : 0.012470207177102566
Loss at batch 200 : 0.010327945463359356
Loss at batch 210 : 0.017922911792993546
Loss at batch 220 : 0.010707668960094452
Loss at batch 230 : 0.015612071380019188
Loss at batch 240 : 0.012301742099225521
Loss at batch 250 : 0.01520212646573782
Loss at batch 260 : 0.012365879490971565
Loss at batch 270 : 0.014207009226083755
Loss at batch 280 : 0.011426321230828762
Loss at batch 290 : 0.010507789440453053
Loss at batch 300 : 0.011643470264971256
Loss at batch 310 : 0.0160945076495409
Loss at batch 320 : 0.017126498743891716
Loss at batch 330 : 0.010675985366106033
Loss at batch 340 : 0.022642772644758224
Loss at batch 350 : 0.01206269022077322
Loss at batch 360 : 0.01541492436081171
Loss at batch 370 : 0.008074764162302017
epoch156 finished!
Loss at batch 10 : 0.012911864556372166
Loss at batch 20 : 0.007207256276160479
Loss at batch 30 : 0.021626558154821396
Loss at batch 40 : 0.006749059073626995
Loss at batch 50 : 0.022170817479491234
Loss at batch 60 : 0.019831521436572075
Loss at batch 70 : 0.017850616946816444
Loss at batch 80 : 0.010441009886562824
Loss at batch 90 : 0.009194020181894302
Loss at batch 100 : 0.02526145987212658
Loss at batch 110 : 0.019502492621541023
Loss at batch 120 : 0.012940834276378155
Loss at batch 130 : 0.009608727879822254
Loss at batch 140 : 0.010150806978344917
Loss at batch 150 : 0.008394187316298485
Loss at batch 160 : 0.011905457824468613
Loss at batch 170 : 0.009218030609190464
Loss at batch 180 : 0.010242561809718609
Loss at batch 190 : 0.010290325619280338
Loss at batch 200 : 0.015645775943994522
Loss at batch 210 : 0.019509805366396904
Loss at batch 220 : 0.027926098555326462
Loss at batch 230 : 0.019369788467884064
Loss at batch 240 : 0.015601242892444134
Loss at batch 250 : 0.01186283491551876
Loss at batch 260 : 0.011366747319698334
Loss at batch 270 : 0.03770934417843819
Loss at batch 280 : 0.01101844385266304
Loss at batch 290 : 0.011099828407168388
Loss at batch 300 : 0.02476206049323082
Loss at batch 310 : 0.011672435328364372
Loss at batch 320 : 0.012043367139995098
Loss at batch 330 : 0.013854029588401318
Loss at batch 340 : 0.01661732792854309
Loss at batch 350 : 0.013197483494877815
Loss at batch 360 : 0.014610592275857925
Loss at batch 370 : 0.012307082302868366
epoch156 finished!
Loss at batch 10 : 0.014662411995232105
Loss at batch 20 : 0.015565508045256138
Loss at batch 30 : 0.015495243482291698
Loss at batch 40 : 0.013668932020664215
Loss at batch 50 : 0.010342089459300041
Loss at batch 60 : 0.007076004985719919
Loss at batch 70 : 0.013094198890030384
Loss at batch 80 : 0.01063776109367609
Loss at batch 90 : 0.016855256631970406
Loss at batch 100 : 0.02209787257015705
Loss at batch 110 : 0.00786548387259245
Loss at batch 120 : 0.008219415321946144
Loss at batch 130 : 0.012009688653051853
Loss at batch 140 : 0.018392091616988182
Loss at batch 150 : 0.023314230144023895
Loss at batch 160 : 0.009008511900901794
Loss at batch 170 : 0.015867697075009346
Loss at batch 180 : 0.02395026944577694
Loss at batch 190 : 0.02521807886660099
Loss at batch 200 : 0.013672721572220325
Loss at batch 210 : 0.011529471725225449
Loss at batch 220 : 0.013578534126281738
Loss at batch 230 : 0.018219605088233948
Loss at batch 240 : 0.012390119954943657
Loss at batch 250 : 0.008356072939932346
Loss at batch 260 : 0.01778508722782135
Loss at batch 270 : 0.016016732901334763
Loss at batch 280 : 0.00787784531712532
Loss at batch 290 : 0.01093329582363367
Loss at batch 300 : 0.009257274679839611
Loss at batch 310 : 0.013255385681986809
Loss at batch 320 : 0.014550834894180298
Loss at batch 330 : 0.02180122770369053
Loss at batch 340 : 0.0168803371489048
Loss at batch 350 : 0.011172055266797543
Loss at batch 360 : 0.017098920419812202
Loss at batch 370 : 0.00831135269254446
epoch157 finished!
Loss at batch 10 : 0.012534908950328827
Loss at batch 20 : 0.010085741989314556
Loss at batch 30 : 0.021024610847234726
Loss at batch 40 : 0.010697176679968834
Loss at batch 50 : 0.011234268546104431
Loss at batch 60 : 0.010716336779296398
Loss at batch 70 : 0.016536518931388855
Loss at batch 80 : 0.007308881264179945
Loss at batch 90 : 0.024118313565850258
Loss at batch 100 : 0.012493722140789032
Loss at batch 110 : 0.013344966806471348
Loss at batch 120 : 0.009397072717547417
Loss at batch 130 : 0.009028462693095207
Loss at batch 140 : 0.010814148001372814
Loss at batch 150 : 0.010703382082283497
Loss at batch 160 : 0.01666414923965931
Loss at batch 170 : 0.014267804101109505
Loss at batch 180 : 0.012947031296789646
Loss at batch 190 : 0.021099744364619255
Loss at batch 200 : 0.013199576176702976
Loss at batch 210 : 0.01708574779331684
Loss at batch 220 : 0.015783270820975304
Loss at batch 230 : 0.02649439498782158
Loss at batch 240 : 0.016331316903233528
Loss at batch 250 : 0.008535878732800484
Loss at batch 260 : 0.010100115090608597
Loss at batch 270 : 0.009768418036401272
Loss at batch 280 : 0.011990380473434925
Loss at batch 290 : 0.009170547127723694
Loss at batch 300 : 0.011463538743555546
Loss at batch 310 : 0.00655354605987668
Loss at batch 320 : 0.014154825359582901
Loss at batch 330 : 0.024258648976683617
Loss at batch 340 : 0.01765337586402893
Loss at batch 350 : 0.013471257872879505
Loss at batch 360 : 0.01401488110423088
Loss at batch 370 : 0.017004098743200302
epoch157 finished!
Loss at batch 10 : 0.010900432243943214
Loss at batch 20 : 0.014451307244598866
Loss at batch 30 : 0.007912185043096542
Loss at batch 40 : 0.014652595855295658
Loss at batch 50 : 0.01634279452264309
Loss at batch 60 : 0.010142648592591286
Loss at batch 70 : 0.008340897969901562
Loss at batch 80 : 0.017039237543940544
Loss at batch 90 : 0.010449854657053947
Loss at batch 100 : 0.012590392492711544
Loss at batch 110 : 0.00934522319585085
Loss at batch 120 : 0.008146190084517002
Loss at batch 130 : 0.012784408405423164
Loss at batch 140 : 0.021277915686368942
Loss at batch 150 : 0.019063670188188553
Loss at batch 160 : 0.015062904916703701
Loss at batch 170 : 0.018172580748796463
Loss at batch 180 : 0.014088301919400692
Loss at batch 190 : 0.007849611341953278
Loss at batch 200 : 0.01745886169373989
Loss at batch 210 : 0.012983670458197594
Loss at batch 220 : 0.015125448815524578
Loss at batch 230 : 0.013194819912314415
Loss at batch 240 : 0.011949598789215088
Loss at batch 250 : 0.012813818641006947
Loss at batch 260 : 0.006967146880924702
Loss at batch 270 : 0.010518171824514866
Loss at batch 280 : 0.017780203372240067
Loss at batch 290 : 0.011489152908325195
Loss at batch 300 : 0.014444726519286633
Loss at batch 310 : 0.014258910901844501
Loss at batch 320 : 0.014987305738031864
Loss at batch 330 : 0.021056853234767914
Loss at batch 340 : 0.018269149586558342
Loss at batch 350 : 0.022873833775520325
Loss at batch 360 : 0.01140589639544487
Loss at batch 370 : 0.010988825932145119
epoch158 finished!
Loss at batch 10 : 0.018768731504678726
Loss at batch 20 : 0.022734040394425392
Loss at batch 30 : 0.011869091540575027
Loss at batch 40 : 0.027128132060170174
Loss at batch 50 : 0.012526904232800007
Loss at batch 60 : 0.016072511672973633
Loss at batch 70 : 0.01973063126206398
Loss at batch 80 : 0.015736466273665428
Loss at batch 90 : 0.014596612192690372
Loss at batch 100 : 0.015117664821445942
Loss at batch 110 : 0.010077144019305706
Loss at batch 120 : 0.010549486614763737
Loss at batch 130 : 0.007941359654068947
Loss at batch 140 : 0.011398122645914555
Loss at batch 150 : 0.0139780817553401
Loss at batch 160 : 0.02081657201051712
Loss at batch 170 : 0.008699016645550728
Loss at batch 180 : 0.010305525735020638
Loss at batch 190 : 0.009789811447262764
Loss at batch 200 : 0.011187986470758915
Loss at batch 210 : 0.012422909960150719
Loss at batch 220 : 0.008810397237539291
Loss at batch 230 : 0.03259740024805069
Loss at batch 240 : 0.020453261211514473
Loss at batch 250 : 0.01460564136505127
Loss at batch 260 : 0.01689811423420906
Loss at batch 270 : 0.014992444775998592
Loss at batch 280 : 0.015326461754739285
Loss at batch 290 : 0.011622556485235691
Loss at batch 300 : 0.010186716914176941
Loss at batch 310 : 0.012082270346581936
Loss at batch 320 : 0.010268716141581535
Loss at batch 330 : 0.01104728877544403
Loss at batch 340 : 0.014092190191149712
Loss at batch 350 : 0.024905435740947723
Loss at batch 360 : 0.016070494428277016
Loss at batch 370 : 0.009803000837564468
epoch158 finished!
Loss at batch 10 : 0.018834535032510757
Loss at batch 20 : 0.020972099155187607
Loss at batch 30 : 0.013443788513541222
Loss at batch 40 : 0.017631394788622856
Loss at batch 50 : 0.01198268961161375
Loss at batch 60 : 0.021720895543694496
Loss at batch 70 : 0.012316754087805748
Loss at batch 80 : 0.016999779269099236
Loss at batch 90 : 0.013559026643633842
Loss at batch 100 : 0.006390861235558987
Loss at batch 110 : 0.012138324789702892
Loss at batch 120 : 0.018428698182106018
Loss at batch 130 : 0.007903208024799824
Loss at batch 140 : 0.009209022857248783
Loss at batch 150 : 0.029110489413142204
Loss at batch 160 : 0.01237728912383318
Loss at batch 170 : 0.017490364611148834
Loss at batch 180 : 0.013033704832196236
Loss at batch 190 : 0.011701525188982487
Loss at batch 200 : 0.008457649499177933
Loss at batch 210 : 0.016888173297047615
Loss at batch 220 : 0.012523962184786797
Loss at batch 230 : 0.01135390903800726
Loss at batch 240 : 0.014824377372860909
Loss at batch 250 : 0.01011219434440136
Loss at batch 260 : 0.012288777157664299
Loss at batch 270 : 0.010449843481183052
Loss at batch 280 : 0.011112634092569351
Loss at batch 290 : 0.00997114833444357
Loss at batch 300 : 0.005673927720636129
Loss at batch 310 : 0.01903071068227291
Loss at batch 320 : 0.008993232622742653
Loss at batch 330 : 0.01657455787062645
Loss at batch 340 : 0.008874299004673958
Loss at batch 350 : 0.01624835655093193
Loss at batch 360 : 0.01652546413242817
Loss at batch 370 : 0.013787168078124523
epoch159 finished!
Loss at batch 10 : 0.008653007447719574
Loss at batch 20 : 0.011728505603969097
Loss at batch 30 : 0.016651568934321404
Loss at batch 40 : 0.009509292431175709
Loss at batch 50 : 0.010630199685692787
Loss at batch 60 : 0.008003247901797295
Loss at batch 70 : 0.014376106671988964
Loss at batch 80 : 0.01782289333641529
Loss at batch 90 : 0.018504219129681587
Loss at batch 100 : 0.02181488461792469
Loss at batch 110 : 0.011025129817426205
Loss at batch 120 : 0.020431682467460632
Loss at batch 130 : 0.00936497189104557
Loss at batch 140 : 0.0126687902957201
Loss at batch 150 : 0.009551732800900936
Loss at batch 160 : 0.017206186428666115
Loss at batch 170 : 0.016030628234148026
Loss at batch 180 : 0.02185874991118908
Loss at batch 190 : 0.006759724114090204
Loss at batch 200 : 0.01669338159263134
Loss at batch 210 : 0.011655512265861034
Loss at batch 220 : 0.011330227367579937
Loss at batch 230 : 0.01193930022418499
Loss at batch 240 : 0.008397653698921204
Loss at batch 250 : 0.014086248353123665
Loss at batch 260 : 0.010320206172764301
Loss at batch 270 : 0.008432003669440746
Loss at batch 280 : 0.01050250418484211
Loss at batch 290 : 0.01639878749847412
Loss at batch 300 : 0.017828332260251045
Loss at batch 310 : 0.013507962226867676
Loss at batch 320 : 0.021789327263832092
Loss at batch 330 : 0.007863756269216537
Loss at batch 340 : 0.012995445169508457
Loss at batch 350 : 0.013502444140613079
Loss at batch 360 : 0.009157096967101097
Loss at batch 370 : 0.006913095712661743
epoch159 finished!
Loss at batch 10 : 0.01749315671622753
Loss at batch 20 : 0.008496545255184174
Loss at batch 30 : 0.010676564648747444
Loss at batch 40 : 0.019186563789844513
Loss at batch 50 : 0.012705041095614433
Loss at batch 60 : 0.017996136099100113
Loss at batch 70 : 0.020991727709770203
Loss at batch 80 : 0.011811519041657448
Loss at batch 90 : 0.016122035682201385
Loss at batch 100 : 0.01144312135875225
Loss at batch 110 : 0.014511235989630222
Loss at batch 120 : 0.014083808287978172
Loss at batch 130 : 0.015100950375199318
Loss at batch 140 : 0.010641931556165218
Loss at batch 150 : 0.02236401103436947
Loss at batch 160 : 0.01707535609602928
Loss at batch 170 : 0.017419664189219475
Loss at batch 180 : 0.0092290248721838
Loss at batch 190 : 0.010605460964143276
Loss at batch 200 : 0.007910221815109253
Loss at batch 210 : 0.012853115797042847
Loss at batch 220 : 0.014933491125702858
Loss at batch 230 : 0.01178559847176075
Loss at batch 240 : 0.015086548402905464
Loss at batch 250 : 0.011953388340771198
Loss at batch 260 : 0.017910419031977654
Loss at batch 270 : 0.009051153436303139
Loss at batch 280 : 0.007914292626082897
Loss at batch 290 : 0.010653581470251083
Loss at batch 300 : 0.013371450826525688
Loss at batch 310 : 0.01408714521676302
Loss at batch 320 : 0.007443454582244158
Loss at batch 330 : 0.009284723550081253
Loss at batch 340 : 0.010051708668470383
Loss at batch 350 : 0.007091023959219456
Loss at batch 360 : 0.01446407102048397
Loss at batch 370 : 0.016370335593819618
epoch160 finished!
Loss at batch 10 : 0.01815093867480755
Loss at batch 20 : 0.015367429703474045
Loss at batch 30 : 0.017307190224528313
Loss at batch 40 : 0.016809100285172462
Loss at batch 50 : 0.009839060716331005
Loss at batch 60 : 0.01077923271805048
Loss at batch 70 : 0.027515819296240807
Loss at batch 80 : 0.012524656020104885
Loss at batch 90 : 0.009705974720418453
Loss at batch 100 : 0.008807404898107052
Loss at batch 110 : 0.010803953744471073
Loss at batch 120 : 0.015452686697244644
Loss at batch 130 : 0.008096645586192608
Loss at batch 140 : 0.019524775445461273
Loss at batch 150 : 0.009624553844332695
Loss at batch 160 : 0.01859249174594879
Loss at batch 170 : 0.019637884572148323
Loss at batch 180 : 0.011397849768400192
Loss at batch 190 : 0.014399462379515171
Loss at batch 200 : 0.02634372003376484
Loss at batch 210 : 0.015227244235575199
Loss at batch 220 : 0.01821715384721756
Loss at batch 230 : 0.012975790537893772
Loss at batch 240 : 0.016543101519346237
Loss at batch 250 : 0.01313241571187973
Loss at batch 260 : 0.009439066052436829
Loss at batch 270 : 0.010317768901586533
Loss at batch 280 : 0.00815673265606165
Loss at batch 290 : 0.012304548174142838
Loss at batch 300 : 0.012734394520521164
Loss at batch 310 : 0.017502430826425552
Loss at batch 320 : 0.010957468301057816
Loss at batch 330 : 0.008438149467110634
Loss at batch 340 : 0.015150833874940872
Loss at batch 350 : 0.011134378612041473
Loss at batch 360 : 0.01792670413851738
Loss at batch 370 : 0.011344579979777336
epoch160 finished!
Loss at batch 10 : 0.011710481718182564
Loss at batch 20 : 0.019769970327615738
Loss at batch 30 : 0.011362530291080475
Loss at batch 40 : 0.018165787681937218
Loss at batch 50 : 0.015341280028223991
Loss at batch 60 : 0.014646227471530437
Loss at batch 70 : 0.014391104690730572
Loss at batch 80 : 0.013843618333339691
Loss at batch 90 : 0.0110559593886137
Loss at batch 100 : 0.011288122273981571
Loss at batch 110 : 0.017872106283903122
Loss at batch 120 : 0.014305252581834793
Loss at batch 130 : 0.012390145100653172
Loss at batch 140 : 0.018405558541417122
Loss at batch 150 : 0.006959369406104088
Loss at batch 160 : 0.02284621261060238
Loss at batch 170 : 0.010170427151024342
Loss at batch 180 : 0.02120334282517433
Loss at batch 190 : 0.013291792012751102
Loss at batch 200 : 0.01696319319307804
Loss at batch 210 : 0.009557489305734634
Loss at batch 220 : 0.00908065214753151
Loss at batch 230 : 0.011922527104616165
Loss at batch 240 : 0.009891141206026077
Loss at batch 250 : 0.015521429479122162
Loss at batch 260 : 0.016482725739479065
Loss at batch 270 : 0.009757960215210915
Loss at batch 280 : 0.010497738607227802
Loss at batch 290 : 0.010276000015437603
Loss at batch 300 : 0.009805133566260338
Loss at batch 310 : 0.011339596472680569
Loss at batch 320 : 0.01502617634832859
Loss at batch 330 : 0.009244110435247421
Loss at batch 340 : 0.009031420573592186
Loss at batch 350 : 0.022450534626841545
Loss at batch 360 : 0.010433588176965714
Loss at batch 370 : 0.011490635573863983
epoch161 finished!
Loss at batch 10 : 0.011993514373898506
Loss at batch 20 : 0.0121556231752038
Loss at batch 30 : 0.006482794880867004
Loss at batch 40 : 0.017379989847540855
Loss at batch 50 : 0.007643203716725111
Loss at batch 60 : 0.010181165300309658
Loss at batch 70 : 0.006845747586339712
Loss at batch 80 : 0.007621497381478548
Loss at batch 90 : 0.01299049612134695
Loss at batch 100 : 0.007819524966180325
Loss at batch 110 : 0.0085648437961936
Loss at batch 120 : 0.016655683517456055
Loss at batch 130 : 0.015804246068000793
Loss at batch 140 : 0.012327787466347218
Loss at batch 150 : 0.026387928053736687
Loss at batch 160 : 0.01600405015051365
Loss at batch 170 : 0.01542660966515541
Loss at batch 180 : 0.016712090000510216
Loss at batch 190 : 0.02062901109457016
Loss at batch 200 : 0.01466604508459568
Loss at batch 210 : 0.015551390126347542
Loss at batch 220 : 0.01435506995767355
Loss at batch 230 : 0.012138731777668
Loss at batch 240 : 0.015141156502068043
Loss at batch 250 : 0.009848223067820072
Loss at batch 260 : 0.018638283014297485
Loss at batch 270 : 0.010449574328958988
Loss at batch 280 : 0.012226373888552189
Loss at batch 290 : 0.009027184918522835
Loss at batch 300 : 0.023760801181197166
Loss at batch 310 : 0.014904782176017761
Loss at batch 320 : 0.012320341542363167
Loss at batch 330 : 0.004589298274368048
Loss at batch 340 : 0.02906443364918232
Loss at batch 350 : 0.010460716672241688
Loss at batch 360 : 0.010849910788238049
Loss at batch 370 : 0.010652465745806694
epoch161 finished!
Loss at batch 10 : 0.009616941213607788
Loss at batch 20 : 0.01753164269030094
Loss at batch 30 : 0.009895591996610165
Loss at batch 40 : 0.013090746477246284
Loss at batch 50 : 0.01287729199975729
Loss at batch 60 : 0.01625978760421276
Loss at batch 70 : 0.009423444047570229
Loss at batch 80 : 0.013528978452086449
Loss at batch 90 : 0.009720190428197384
Loss at batch 100 : 0.010761828161776066
Loss at batch 110 : 0.01483587920665741
Loss at batch 120 : 0.01605507917702198
Loss at batch 130 : 0.011475908569991589
Loss at batch 140 : 0.019126955419778824
Loss at batch 150 : 0.015242459252476692
Loss at batch 160 : 0.006244035437703133
Loss at batch 170 : 0.01955997571349144
Loss at batch 180 : 0.012598374858498573
Loss at batch 190 : 0.014164350926876068
Loss at batch 200 : 0.012105175293982029
Loss at batch 210 : 0.0153108024969697
Loss at batch 220 : 0.014707550406455994
Loss at batch 230 : 0.013603889383375645
Loss at batch 240 : 0.016628330573439598
Loss at batch 250 : 0.017907459288835526
Loss at batch 260 : 0.00984521210193634
Loss at batch 270 : 0.01076894998550415
Loss at batch 280 : 0.010849389247596264
Loss at batch 290 : 0.01217687875032425
Loss at batch 300 : 0.009738428518176079
Loss at batch 310 : 0.012915418483316898
Loss at batch 320 : 0.018480319529771805
Loss at batch 330 : 0.010146287269890308
Loss at batch 340 : 0.014813446439802647
Loss at batch 350 : 0.014998836442828178
Loss at batch 360 : 0.021552836522459984
Loss at batch 370 : 0.019928641617298126
epoch162 finished!
Loss at batch 10 : 0.013276884332299232
Loss at batch 20 : 0.0086711710318923
Loss at batch 30 : 0.015412388369441032
Loss at batch 40 : 0.018045857548713684
Loss at batch 50 : 0.018386386334896088
Loss at batch 60 : 0.006744073238223791
Loss at batch 70 : 0.013716944493353367
Loss at batch 80 : 0.013129199855029583
Loss at batch 90 : 0.01302872784435749
Loss at batch 100 : 0.013748942874372005
Loss at batch 110 : 0.01886124722659588
Loss at batch 120 : 0.027767742052674294
Loss at batch 130 : 0.012522346340119839
Loss at batch 140 : 0.020061606541275978
Loss at batch 150 : 0.01899050362408161
Loss at batch 160 : 0.009356064721941948
Loss at batch 170 : 0.01721053570508957
Loss at batch 180 : 0.015994613990187645
Loss at batch 190 : 0.01899179071187973
Loss at batch 200 : 0.009351445361971855
Loss at batch 210 : 0.011270913295447826
Loss at batch 220 : 0.011774862185120583
Loss at batch 230 : 0.01706107147037983
Loss at batch 240 : 0.018231438472867012
Loss at batch 250 : 0.011920448392629623
Loss at batch 260 : 0.021887432783842087
Loss at batch 270 : 0.011912568472325802
Loss at batch 280 : 0.006868419703096151
Loss at batch 290 : 0.018488584086298943
Loss at batch 300 : 0.011838792823255062
Loss at batch 310 : 0.020933998748660088
Loss at batch 320 : 0.013312643393874168
Loss at batch 330 : 0.007301175966858864
Loss at batch 340 : 0.0185137540102005
Loss at batch 350 : 0.01927325688302517
Loss at batch 360 : 0.011628027074038982
Loss at batch 370 : 0.013757195323705673
epoch162 finished!
Loss at batch 10 : 0.013915503397583961
Loss at batch 20 : 0.010495074093341827
Loss at batch 30 : 0.031431522220373154
Loss at batch 40 : 0.014395027421414852
Loss at batch 50 : 0.01677083782851696
Loss at batch 60 : 0.015787584707140923
Loss at batch 70 : 0.014744285494089127
Loss at batch 80 : 0.008931641466915607
Loss at batch 90 : 0.013555938377976418
Loss at batch 100 : 0.008128917776048183
Loss at batch 110 : 0.01349622756242752
Loss at batch 120 : 0.01114292535930872
Loss at batch 130 : 0.01139792799949646
Loss at batch 140 : 0.0256584994494915
Loss at batch 150 : 0.01292682159692049
Loss at batch 160 : 0.018740341067314148
Loss at batch 170 : 0.012354702688753605
Loss at batch 180 : 0.010018114931881428
Loss at batch 190 : 0.015782564878463745
Loss at batch 200 : 0.023984523490071297
Loss at batch 210 : 0.011456141248345375
Loss at batch 220 : 0.01975729502737522
Loss at batch 230 : 0.012510145083069801
Loss at batch 240 : 0.013046946376562119
Loss at batch 250 : 0.009517277590930462
Loss at batch 260 : 0.02559506706893444
Loss at batch 270 : 0.015155252069234848
Loss at batch 280 : 0.02463436871767044
Loss at batch 290 : 0.010326235555112362
Loss at batch 300 : 0.008391841314733028
Loss at batch 310 : 0.016308529302477837
Loss at batch 320 : 0.01809637062251568
Loss at batch 330 : 0.01403233502060175
Loss at batch 340 : 0.006283535156399012
Loss at batch 350 : 0.026111315935850143
Loss at batch 360 : 0.011754672974348068
Loss at batch 370 : 0.014251035638153553
epoch163 finished!
Loss at batch 10 : 0.01007323432713747
Loss at batch 20 : 0.01269827876240015
Loss at batch 30 : 0.021119533106684685
Loss at batch 40 : 0.012713504955172539
Loss at batch 50 : 0.01092248409986496
Loss at batch 60 : 0.01153674814850092
Loss at batch 70 : 0.01287375669926405
Loss at batch 80 : 0.03045842982828617
Loss at batch 90 : 0.013466555625200272
Loss at batch 100 : 0.015557980164885521
Loss at batch 110 : 0.015846405178308487
Loss at batch 120 : 0.012832516804337502
Loss at batch 130 : 0.00950061809271574
Loss at batch 140 : 0.007702634669840336
Loss at batch 150 : 0.008197839371860027
Loss at batch 160 : 0.014985005371272564
Loss at batch 170 : 0.010578861460089684
Loss at batch 180 : 0.00609695166349411
Loss at batch 190 : 0.012430347502231598
Loss at batch 200 : 0.007516990415751934
Loss at batch 210 : 0.016652602702379227
Loss at batch 220 : 0.017275290563702583
Loss at batch 230 : 0.019390374422073364
Loss at batch 240 : 0.010216640308499336
Loss at batch 250 : 0.010787731036543846
Loss at batch 260 : 0.009074327535927296
Loss at batch 270 : 0.014943304471671581
Loss at batch 280 : 0.014479201287031174
Loss at batch 290 : 0.01966826803982258
Loss at batch 300 : 0.008277815766632557
Loss at batch 310 : 0.00952827651053667
Loss at batch 320 : 0.010769401676952839
Loss at batch 330 : 0.01738709956407547
Loss at batch 340 : 0.02628472074866295
Loss at batch 350 : 0.01587633229792118
Loss at batch 360 : 0.009367349557578564
Loss at batch 370 : 0.01933104731142521
epoch163 finished!
Loss at batch 10 : 0.016959810629487038
Loss at batch 20 : 0.017130171880126
Loss at batch 30 : 0.017145024612545967
Loss at batch 40 : 0.00809093751013279
Loss at batch 50 : 0.012493970803916454
Loss at batch 60 : 0.018417157232761383
Loss at batch 70 : 0.028046270832419395
Loss at batch 80 : 0.014595333486795425
Loss at batch 90 : 0.019076278433203697
Loss at batch 100 : 0.016479598358273506
Loss at batch 110 : 0.016995813697576523
Loss at batch 120 : 0.010743199847638607
Loss at batch 130 : 0.015707004815340042
Loss at batch 140 : 0.0137240095064044
Loss at batch 150 : 0.012458186596632004
Loss at batch 160 : 0.015418341383337975
Loss at batch 170 : 0.0244853887706995
Loss at batch 180 : 0.01264573447406292
Loss at batch 190 : 0.01051334384828806
Loss at batch 200 : 0.02193479798734188
Loss at batch 210 : 0.03158685564994812
Loss at batch 220 : 0.01743575930595398
Loss at batch 230 : 0.022074174135923386
Loss at batch 240 : 0.016176270321011543
Loss at batch 250 : 0.017117397859692574
Loss at batch 260 : 0.009737646207213402
Loss at batch 270 : 0.03379194438457489
Loss at batch 280 : 0.022493872791528702
Loss at batch 290 : 0.0140993632376194
Loss at batch 300 : 0.022545993328094482
Loss at batch 310 : 0.009888722561299801
Loss at batch 320 : 0.012968284077942371
Loss at batch 330 : 0.014602464623749256
Loss at batch 340 : 0.01501797791570425
Loss at batch 350 : 0.01286444440484047
Loss at batch 360 : 0.01758950762450695
Loss at batch 370 : 0.016072634607553482
epoch164 finished!
Loss at batch 10 : 0.00933726318180561
Loss at batch 20 : 0.01159738190472126
Loss at batch 30 : 0.016133401542901993
Loss at batch 40 : 0.014957454055547714
Loss at batch 50 : 0.009213954210281372
Loss at batch 60 : 0.014911366626620293
Loss at batch 70 : 0.015722082927823067
Loss at batch 80 : 0.011843662708997726
Loss at batch 90 : 0.016010109335184097
Loss at batch 100 : 0.01430290937423706
Loss at batch 110 : 0.016355840489268303
Loss at batch 120 : 0.008114755153656006
Loss at batch 130 : 0.014009918086230755
Loss at batch 140 : 0.023752929642796516
Loss at batch 150 : 0.009693268686532974
Loss at batch 160 : 0.014457060024142265
Loss at batch 170 : 0.014193384908139706
Loss at batch 180 : 0.007970277220010757
Loss at batch 190 : 0.013694274239242077
Loss at batch 200 : 0.008029695600271225
Loss at batch 210 : 0.024481365457177162
Loss at batch 220 : 0.008142993785440922
Loss at batch 230 : 0.00772136589512229
Loss at batch 240 : 0.018169140443205833
Loss at batch 250 : 0.011031024158000946
Loss at batch 260 : 0.012553507462143898
Loss at batch 270 : 0.00968572311103344
Loss at batch 280 : 0.01153451669961214
Loss at batch 290 : 0.013514033518731594
Loss at batch 300 : 0.016357261687517166
Loss at batch 310 : 0.014636709354817867
Loss at batch 320 : 0.011783202178776264
Loss at batch 330 : 0.016735149547457695
Loss at batch 340 : 0.009999704547226429
Loss at batch 350 : 0.011978293769061565
Loss at batch 360 : 0.01292604859918356
Loss at batch 370 : 0.01603899523615837
epoch164 finished!
Loss at batch 10 : 0.012372041121125221
Loss at batch 20 : 0.01457593496888876
Loss at batch 30 : 0.020965920761227608
Loss at batch 40 : 0.00783722847700119
Loss at batch 50 : 0.012808071449398994
Loss at batch 60 : 0.012777111493051052
Loss at batch 70 : 0.014073401689529419
Loss at batch 80 : 0.015141417272388935
Loss at batch 90 : 0.0320541188120842
Loss at batch 100 : 0.005104167852550745
Loss at batch 110 : 0.014178604818880558
Loss at batch 120 : 0.01412724144756794
Loss at batch 130 : 0.007576741278171539
Loss at batch 140 : 0.013816490769386292
Loss at batch 150 : 0.01616801880300045
Loss at batch 160 : 0.01102690864354372
Loss at batch 170 : 0.017513683065772057
Loss at batch 180 : 0.02100977674126625
Loss at batch 190 : 0.01619994081556797
Loss at batch 200 : 0.01938919723033905
Loss at batch 210 : 0.009811248630285263
Loss at batch 220 : 0.012488163076341152
Loss at batch 230 : 0.01641407608985901
Loss at batch 240 : 0.01612904667854309
Loss at batch 250 : 0.012602141126990318
Loss at batch 260 : 0.013077604584395885
Loss at batch 270 : 0.010899310931563377
Loss at batch 280 : 0.01913842000067234
Loss at batch 290 : 0.015369291417300701
Loss at batch 300 : 0.016157472506165504
Loss at batch 310 : 0.020426316186785698
Loss at batch 320 : 0.015351363457739353
Loss at batch 330 : 0.011239718645811081
Loss at batch 340 : 0.010597280226647854
Loss at batch 350 : 0.012411200441420078
Loss at batch 360 : 0.014229961670935154
Loss at batch 370 : 0.01168392226099968
epoch165 finished!
Loss at batch 10 : 0.014126193709671497
Loss at batch 20 : 0.00973391905426979
Loss at batch 30 : 0.015546471811830997
Loss at batch 40 : 0.01773729920387268
Loss at batch 50 : 0.0120939826592803
Loss at batch 60 : 0.0129125090315938
Loss at batch 70 : 0.01192654948681593
Loss at batch 80 : 0.023167310282588005
Loss at batch 90 : 0.012644432485103607
Loss at batch 100 : 0.026206079870462418
Loss at batch 110 : 0.022533675655722618
Loss at batch 120 : 0.013525713235139847
Loss at batch 130 : 0.013200094923377037
Loss at batch 140 : 0.020364321768283844
Loss at batch 150 : 0.007433757651597261
Loss at batch 160 : 0.013307781890034676
Loss at batch 170 : 0.012572943232953548
Loss at batch 180 : 0.021265175193548203
Loss at batch 190 : 0.014685780741274357
Loss at batch 200 : 0.013887731358408928
Loss at batch 210 : 0.008211859501898289
Loss at batch 220 : 0.018402056768536568
Loss at batch 230 : 0.019180959090590477
Loss at batch 240 : 0.008825000375509262
Loss at batch 250 : 0.0074200378730893135
Loss at batch 260 : 0.006493864580988884
Loss at batch 270 : 0.019457079470157623
Loss at batch 280 : 0.01325052697211504
Loss at batch 290 : 0.020299186930060387
Loss at batch 300 : 0.012125146575272083
Loss at batch 310 : 0.009935407899320126
Loss at batch 320 : 0.012792371213436127
Loss at batch 330 : 0.019086159765720367
Loss at batch 340 : 0.024818632751703262
Loss at batch 350 : 0.020595649257302284
Loss at batch 360 : 0.01397857628762722
Loss at batch 370 : 0.01778431423008442
epoch165 finished!
Loss at batch 10 : 0.01645256020128727
Loss at batch 20 : 0.008954743854701519
Loss at batch 30 : 0.010066067799925804
Loss at batch 40 : 0.010014715604484081
Loss at batch 50 : 0.01657535508275032
Loss at batch 60 : 0.012554890476167202
Loss at batch 70 : 0.010831432417035103
Loss at batch 80 : 0.007453595288097858
Loss at batch 90 : 0.013745761476457119
Loss at batch 100 : 0.007085014134645462
Loss at batch 110 : 0.01674339361488819
Loss at batch 120 : 0.013817516155540943
Loss at batch 130 : 0.013170047663152218
Loss at batch 140 : 0.016298804432153702
Loss at batch 150 : 0.014549501240253448
Loss at batch 160 : 0.016887443140149117
Loss at batch 170 : 0.027369888499379158
Loss at batch 180 : 0.013090838678181171
Loss at batch 190 : 0.02714606001973152
Loss at batch 200 : 0.014395852573215961
Loss at batch 210 : 0.023879898712038994
Loss at batch 220 : 0.013441061601042747
Loss at batch 230 : 0.013925437815487385
Loss at batch 240 : 0.017206694930791855
Loss at batch 250 : 0.011096474714577198
Loss at batch 260 : 0.0183470007032156
Loss at batch 270 : 0.011456767097115517
Loss at batch 280 : 0.01086338423192501
Loss at batch 290 : 0.015071927569806576
Loss at batch 300 : 0.01308781374245882
Loss at batch 310 : 0.015103957615792751
Loss at batch 320 : 0.010282536037266254
Loss at batch 330 : 0.010235427878797054
Loss at batch 340 : 0.012056665495038033
Loss at batch 350 : 0.0062480103224515915
Loss at batch 360 : 0.014676935039460659
Loss at batch 370 : 0.008886760100722313
epoch166 finished!
Loss at batch 10 : 0.015358420088887215
Loss at batch 20 : 0.013622335158288479
Loss at batch 30 : 0.01429302804172039
Loss at batch 40 : 0.026743359863758087
Loss at batch 50 : 0.015020526014268398
Loss at batch 60 : 0.012681813910603523
Loss at batch 70 : 0.018748385831713676
Loss at batch 80 : 0.02414076030254364
Loss at batch 90 : 0.009990531019866467
Loss at batch 100 : 0.019205916672945023
Loss at batch 110 : 0.014882897958159447
Loss at batch 120 : 0.01763228327035904
Loss at batch 130 : 0.01708444394171238
Loss at batch 140 : 0.009539809077978134
Loss at batch 150 : 0.01990828663110733
Loss at batch 160 : 0.011756335385143757
Loss at batch 170 : 0.008833399042487144
Loss at batch 180 : 0.01870773360133171
Loss at batch 190 : 0.009340907447040081
Loss at batch 200 : 0.01766541413962841
Loss at batch 210 : 0.015075773000717163
Loss at batch 220 : 0.016060689464211464
Loss at batch 230 : 0.017552213743329048
Loss at batch 240 : 0.013247594237327576
Loss at batch 250 : 0.013316972181200981
Loss at batch 260 : 0.014590968377888203
Loss at batch 270 : 0.015795163810253143
Loss at batch 280 : 0.013008825480937958
Loss at batch 290 : 0.014379817061126232
Loss at batch 300 : 0.017663046717643738
Loss at batch 310 : 0.015014223754405975
Loss at batch 320 : 0.013224619440734386
Loss at batch 330 : 0.014140786603093147
Loss at batch 340 : 0.007703459355980158
Loss at batch 350 : 0.013842456042766571
Loss at batch 360 : 0.015210204757750034
Loss at batch 370 : 0.008239846676588058
epoch166 finished!
Loss at batch 10 : 0.014400554820895195
Loss at batch 20 : 0.013407494872808456
Loss at batch 30 : 0.009935644455254078
Loss at batch 40 : 0.019831733778119087
Loss at batch 50 : 0.008984196931123734
Loss at batch 60 : 0.011204632930457592
Loss at batch 70 : 0.014834875240921974
Loss at batch 80 : 0.0081357816234231
Loss at batch 90 : 0.013400550931692123
Loss at batch 100 : 0.025536490604281425
Loss at batch 110 : 0.007839697413146496
Loss at batch 120 : 0.01484458427876234
Loss at batch 130 : 0.019424574449658394
Loss at batch 140 : 0.012475326657295227
Loss at batch 150 : 0.011351956985890865
Loss at batch 160 : 0.01063132006675005
Loss at batch 170 : 0.018296387046575546
Loss at batch 180 : 0.020772090181708336
Loss at batch 190 : 0.017180103808641434
Loss at batch 200 : 0.00993541069328785
Loss at batch 210 : 0.012117286212742329
Loss at batch 220 : 0.017921555787324905
Loss at batch 230 : 0.013624255545437336
Loss at batch 240 : 0.017666153609752655
Loss at batch 250 : 0.010803371667861938
Loss at batch 260 : 0.009087876416742802
Loss at batch 270 : 0.007748897653073072
Loss at batch 280 : 0.01087146531790495
Loss at batch 290 : 0.009329111315310001
Loss at batch 300 : 0.009846598841249943
Loss at batch 310 : 0.010928916744887829
Loss at batch 320 : 0.012709235772490501
Loss at batch 330 : 0.007955209352076054
Loss at batch 340 : 0.011432590894401073
Loss at batch 350 : 0.02161994017660618
Loss at batch 360 : 0.019998913630843163
Loss at batch 370 : 0.009373716078698635
epoch167 finished!
Loss at batch 10 : 0.013837267644703388
Loss at batch 20 : 0.011911112815141678
Loss at batch 30 : 0.016132181510329247
Loss at batch 40 : 0.015984266996383667
Loss at batch 50 : 0.022443411871790886
Loss at batch 60 : 0.01476982794702053
Loss at batch 70 : 0.018836619332432747
Loss at batch 80 : 0.018694570288062096
Loss at batch 90 : 0.010992580093443394
Loss at batch 100 : 0.015326120890676975
Loss at batch 110 : 0.012247995473444462
Loss at batch 120 : 0.010504614561796188
Loss at batch 130 : 0.030235884711146355
Loss at batch 140 : 0.015263565815985203
Loss at batch 150 : 0.019780289381742477
Loss at batch 160 : 0.00935987289994955
Loss at batch 170 : 0.014004177413880825
Loss at batch 180 : 0.011812937445938587
Loss at batch 190 : 0.010413053445518017
Loss at batch 200 : 0.0416550375521183
Loss at batch 210 : 0.013349516317248344
Loss at batch 220 : 0.012452637776732445
Loss at batch 230 : 0.012371417135000229
Loss at batch 240 : 0.01286172866821289
Loss at batch 250 : 0.013425977900624275
Loss at batch 260 : 0.01367815863341093
Loss at batch 270 : 0.01138141006231308
Loss at batch 280 : 0.009537379257380962
Loss at batch 290 : 0.012904278934001923
Loss at batch 300 : 0.016495728865265846
Loss at batch 310 : 0.020923443138599396
Loss at batch 320 : 0.012339845299720764
Loss at batch 330 : 0.02199612185359001
Loss at batch 340 : 0.010214616544544697
Loss at batch 350 : 0.011503662914037704
Loss at batch 360 : 0.026773538440465927
Loss at batch 370 : 0.008135099895298481
epoch167 finished!
Loss at batch 10 : 0.013403365388512611
Loss at batch 20 : 0.013074043206870556
Loss at batch 30 : 0.019153278321027756
Loss at batch 40 : 0.023359600454568863
Loss at batch 50 : 0.013003502041101456
Loss at batch 60 : 0.010787809267640114
Loss at batch 70 : 0.010760752484202385
Loss at batch 80 : 0.012953984551131725
Loss at batch 90 : 0.008477815426886082
Loss at batch 100 : 0.0067361388355493546
Loss at batch 110 : 0.01271036732941866
Loss at batch 120 : 0.012259317561984062
Loss at batch 130 : 0.013724075630307198
Loss at batch 140 : 0.017100151628255844
Loss at batch 150 : 0.016360532492399216
Loss at batch 160 : 0.011284836567938328
Loss at batch 170 : 0.005850197281688452
Loss at batch 180 : 0.010837717913091183
Loss at batch 190 : 0.014795276336371899
Loss at batch 200 : 0.011724485084414482
Loss at batch 210 : 0.011201136745512486
Loss at batch 220 : 0.01681450940668583
Loss at batch 230 : 0.014198731631040573
Loss at batch 240 : 0.01786990649998188
Loss at batch 250 : 0.01390319038182497
Loss at batch 260 : 0.00819771271198988
Loss at batch 270 : 0.019855091348290443
Loss at batch 280 : 0.009049629792571068
Loss at batch 290 : 0.011546519584953785
Loss at batch 300 : 0.0197904035449028
Loss at batch 310 : 0.009643523953855038
Loss at batch 320 : 0.01763901673257351
Loss at batch 330 : 0.011911788955330849
Loss at batch 340 : 0.007525817025452852
Loss at batch 350 : 0.015547907911241055
Loss at batch 360 : 0.008594832383096218
Loss at batch 370 : 0.013611134141683578
epoch168 finished!
Loss at batch 10 : 0.009987873956561089
Loss at batch 20 : 0.020691148936748505
Loss at batch 30 : 0.011953795328736305
Loss at batch 40 : 0.019494574517011642
Loss at batch 50 : 0.012791290879249573
Loss at batch 60 : 0.015500023029744625
Loss at batch 70 : 0.015470911748707294
Loss at batch 80 : 0.013956761918962002
Loss at batch 90 : 0.016576703637838364
Loss at batch 100 : 0.011355491355061531
Loss at batch 110 : 0.014274735003709793
Loss at batch 120 : 0.013770614750683308
Loss at batch 130 : 0.014945397153496742
Loss at batch 140 : 0.010300117544829845
Loss at batch 150 : 0.010164698585867882
Loss at batch 160 : 0.02071956731379032
Loss at batch 170 : 0.007574998773634434
Loss at batch 180 : 0.008048835210502148
Loss at batch 190 : 0.010143519379198551
Loss at batch 200 : 0.008859746158123016
Loss at batch 210 : 0.0088541554287076
Loss at batch 220 : 0.014159321784973145
Loss at batch 230 : 0.01676558144390583
Loss at batch 240 : 0.01749052107334137
Loss at batch 250 : 0.006847429554909468
Loss at batch 260 : 0.019824014976620674
Loss at batch 270 : 0.021136000752449036
Loss at batch 280 : 0.021621454507112503
Loss at batch 290 : 0.013204318471252918
Loss at batch 300 : 0.018177533522248268
Loss at batch 310 : 0.01205225195735693
Loss at batch 320 : 0.025681478902697563
Loss at batch 330 : 0.012284567579627037
Loss at batch 340 : 0.015758126974105835
Loss at batch 350 : 0.011189019307494164
Loss at batch 360 : 0.011946727521717548
Loss at batch 370 : 0.01397966593503952
epoch168 finished!
Loss at batch 10 : 0.026179594919085503
Loss at batch 20 : 0.022732434794306755
Loss at batch 30 : 0.01824646070599556
Loss at batch 40 : 0.01560935191810131
Loss at batch 50 : 0.007790387608110905
Loss at batch 60 : 0.016861891373991966
Loss at batch 70 : 0.021058786660432816
Loss at batch 80 : 0.013342732563614845
Loss at batch 90 : 0.008740282617509365
Loss at batch 100 : 0.01437599677592516
Loss at batch 110 : 0.011436221189796925
Loss at batch 120 : 0.016122836619615555
Loss at batch 130 : 0.012561974115669727
Loss at batch 140 : 0.009628917090594769
Loss at batch 150 : 0.020496852695941925
Loss at batch 160 : 0.015300503931939602
Loss at batch 170 : 0.016743507236242294
Loss at batch 180 : 0.013830188661813736
Loss at batch 190 : 0.008401279337704182
Loss at batch 200 : 0.010126549750566483
Loss at batch 210 : 0.010931869968771935
Loss at batch 220 : 0.014958145096898079
Loss at batch 230 : 0.010399721562862396
Loss at batch 240 : 0.010371721349656582
Loss at batch 250 : 0.017168445512652397
Loss at batch 260 : 0.015784088522195816
Loss at batch 270 : 0.00794267188757658
Loss at batch 280 : 0.014847150072455406
Loss at batch 290 : 0.01029092539101839
Loss at batch 300 : 0.008902253583073616
Loss at batch 310 : 0.01621064729988575
Loss at batch 320 : 0.011361345648765564
Loss at batch 330 : 0.01433210726827383
Loss at batch 340 : 0.0178302563726902
Loss at batch 350 : 0.011659467592835426
Loss at batch 360 : 0.011994553729891777
Loss at batch 370 : 0.011290404014289379
epoch169 finished!
Loss at batch 10 : 0.007738890126347542
Loss at batch 20 : 0.0173361636698246
Loss at batch 30 : 0.015332033857703209
Loss at batch 40 : 0.01612308993935585
Loss at batch 50 : 0.01427947822958231
Loss at batch 60 : 0.015191733837127686
Loss at batch 70 : 0.012348701246082783
Loss at batch 80 : 0.009050368331372738
Loss at batch 90 : 0.016090884804725647
Loss at batch 100 : 0.00955911260098219
Loss at batch 110 : 0.015474949032068253
Loss at batch 120 : 0.0073776026256382465
Loss at batch 130 : 0.019917691126465797
Loss at batch 140 : 0.015625542029738426
Loss at batch 150 : 0.01732492633163929
Loss at batch 160 : 0.01038444135338068
Loss at batch 170 : 0.0076419515535235405
Loss at batch 180 : 0.007814821787178516
Loss at batch 190 : 0.017750507220625877
Loss at batch 200 : 0.011616191826760769
Loss at batch 210 : 0.011732127517461777
Loss at batch 220 : 0.008770919404923916
Loss at batch 230 : 0.026500144973397255
Loss at batch 240 : 0.008467408828437328
Loss at batch 250 : 0.009117435663938522
Loss at batch 260 : 0.01675870269536972
Loss at batch 270 : 0.018932664766907692
Loss at batch 280 : 0.009775590151548386
Loss at batch 290 : 0.01926993764936924
Loss at batch 300 : 0.0165927205234766
Loss at batch 310 : 0.014471438713371754
Loss at batch 320 : 0.023760078474879265
Loss at batch 330 : 0.008664753288030624
Loss at batch 340 : 0.015400299802422523
Loss at batch 350 : 0.017505479976534843
Loss at batch 360 : 0.01434286404401064
Loss at batch 370 : 0.021469084545969963
epoch169 finished!
Loss at batch 10 : 0.027957992628216743
Loss at batch 20 : 0.014275996014475822
Loss at batch 30 : 0.011073392815887928
Loss at batch 40 : 0.018197890371084213
Loss at batch 50 : 0.010307420045137405
Loss at batch 60 : 0.01860758475959301
Loss at batch 70 : 0.013241088949143887
Loss at batch 80 : 0.014231489039957523
Loss at batch 90 : 0.014359699562191963
Loss at batch 100 : 0.013559479266405106
Loss at batch 110 : 0.01073959656059742
Loss at batch 120 : 0.012406336143612862
Loss at batch 130 : 0.011089181527495384
Loss at batch 140 : 0.014668943360447884
Loss at batch 150 : 0.021228982135653496
Loss at batch 160 : 0.021091755479574203
Loss at batch 170 : 0.017189811915159225
Loss at batch 180 : 0.012642588466405869
Loss at batch 190 : 0.006274065934121609
Loss at batch 200 : 0.00933664757758379
Loss at batch 210 : 0.02133193612098694
Loss at batch 220 : 0.016585519537329674
Loss at batch 230 : 0.009732967242598534
Loss at batch 240 : 0.01295398361980915
Loss at batch 250 : 0.015867257490754128
Loss at batch 260 : 0.02221154421567917
Loss at batch 270 : 0.01812942512333393
Loss at batch 280 : 0.008833874017000198
Loss at batch 290 : 0.01181255467236042
Loss at batch 300 : 0.017687078565359116
Loss at batch 310 : 0.017167847603559494
Loss at batch 320 : 0.01649002730846405
Loss at batch 330 : 0.01443342212587595
Loss at batch 340 : 0.012834964320063591
Loss at batch 350 : 0.006457038689404726
Loss at batch 360 : 0.01474074088037014
Loss at batch 370 : 0.01355804968625307
epoch170 finished!
Loss at batch 10 : 0.007763172499835491
Loss at batch 20 : 0.006900703068822622
Loss at batch 30 : 0.012748613022267818
Loss at batch 40 : 0.01883559674024582
Loss at batch 50 : 0.010041839443147182
Loss at batch 60 : 0.020777324214577675
Loss at batch 70 : 0.017893152311444283
Loss at batch 80 : 0.00903392769396305
Loss at batch 90 : 0.006992577575147152
Loss at batch 100 : 0.009688667953014374
Loss at batch 110 : 0.01630123145878315
Loss at batch 120 : 0.021244769915938377
Loss at batch 130 : 0.017415834590792656
Loss at batch 140 : 0.00896467361599207
Loss at batch 150 : 0.014591297134757042
Loss at batch 160 : 0.015114420093595982
Loss at batch 170 : 0.0076156803406775
Loss at batch 180 : 0.007543403189629316
Loss at batch 190 : 0.0103798508644104
Loss at batch 200 : 0.02136361040174961
Loss at batch 210 : 0.02610069327056408
Loss at batch 220 : 0.010810714215040207
Loss at batch 230 : 0.011489098891615868
Loss at batch 240 : 0.012412868440151215
Loss at batch 250 : 0.016326405107975006
Loss at batch 260 : 0.01968676969408989
Loss at batch 270 : 0.017927784472703934
Loss at batch 280 : 0.012279451824724674
Loss at batch 290 : 0.015600519254803658
Loss at batch 300 : 0.011707044206559658
Loss at batch 310 : 0.015272494405508041
Loss at batch 320 : 0.012538352981209755
Loss at batch 330 : 0.009243297390639782
Loss at batch 340 : 0.020254159346222878
Loss at batch 350 : 0.019221507012844086
Loss at batch 360 : 0.015055160969495773
Loss at batch 370 : 0.014405611902475357
epoch170 finished!
Loss at batch 10 : 0.0093282051384449
Loss at batch 20 : 0.017211435362696648
Loss at batch 30 : 0.010142615996301174
Loss at batch 40 : 0.014629478566348553
Loss at batch 50 : 0.0085286321118474
Loss at batch 60 : 0.012722435407340527
Loss at batch 70 : 0.009028257802128792
Loss at batch 80 : 0.022990763187408447
Loss at batch 90 : 0.011403155513107777
Loss at batch 100 : 0.01677926816046238
Loss at batch 110 : 0.013014862313866615
Loss at batch 120 : 0.022237928584218025
Loss at batch 130 : 0.012159598059952259
Loss at batch 140 : 0.024758659303188324
Loss at batch 150 : 0.012969110161066055
Loss at batch 160 : 0.013863462023437023
Loss at batch 170 : 0.02029496058821678
Loss at batch 180 : 0.013139834627509117
Loss at batch 190 : 0.013860009610652924
Loss at batch 200 : 0.025223219767212868
Loss at batch 210 : 0.013020290993154049
Loss at batch 220 : 0.013929377309978008
Loss at batch 230 : 0.014420414343476295
Loss at batch 240 : 0.016551027074456215
Loss at batch 250 : 0.01973026618361473
Loss at batch 260 : 0.01107319351285696
Loss at batch 270 : 0.014308730140328407
Loss at batch 280 : 0.010633188299834728
Loss at batch 290 : 0.013994032517075539
Loss at batch 300 : 0.020266778767108917
Loss at batch 310 : 0.010052502155303955
Loss at batch 320 : 0.0162639282643795
Loss at batch 330 : 0.011079693213105202
Loss at batch 340 : 0.0187216866761446
Loss at batch 350 : 0.01763308234512806
Loss at batch 360 : 0.009706662967801094
Loss at batch 370 : 0.013898447155952454
epoch171 finished!
Loss at batch 10 : 0.027390701696276665
Loss at batch 20 : 0.010282243601977825
Loss at batch 30 : 0.011530112475156784
Loss at batch 40 : 0.01039806380867958
Loss at batch 50 : 0.017395898699760437
Loss at batch 60 : 0.007673745974898338
Loss at batch 70 : 0.01310522761195898
Loss at batch 80 : 0.018379755318164825
Loss at batch 90 : 0.013196559622883797
Loss at batch 100 : 0.01322631724178791
Loss at batch 110 : 0.015038109384477139
Loss at batch 120 : 0.016430040821433067
Loss at batch 130 : 0.018648317083716393
Loss at batch 140 : 0.008625849150121212
Loss at batch 150 : 0.014179819263517857
Loss at batch 160 : 0.009107492864131927
Loss at batch 170 : 0.013708760030567646
Loss at batch 180 : 0.009595466777682304
Loss at batch 190 : 0.008981217630207539
Loss at batch 200 : 0.012153899297118187
Loss at batch 210 : 0.009611088782548904
Loss at batch 220 : 0.009446240030229092
Loss at batch 230 : 0.011651339940726757
Loss at batch 240 : 0.010787298902869225
Loss at batch 250 : 0.01158454641699791
Loss at batch 260 : 0.012481220066547394
Loss at batch 270 : 0.009547642432153225
Loss at batch 280 : 0.018759427592158318
Loss at batch 290 : 0.007541502360254526
Loss at batch 300 : 0.012369118630886078
Loss at batch 310 : 0.01306785736232996
Loss at batch 320 : 0.012872587889432907
Loss at batch 330 : 0.011845081113278866
Loss at batch 340 : 0.0133458711206913
Loss at batch 350 : 0.00956629030406475
Loss at batch 360 : 0.00936826504766941
Loss at batch 370 : 0.008184372447431087
epoch171 finished!
Loss at batch 10 : 0.014104871079325676
Loss at batch 20 : 0.011175544932484627
Loss at batch 30 : 0.019335826858878136
Loss at batch 40 : 0.01283802930265665
Loss at batch 50 : 0.00988475326448679
Loss at batch 60 : 0.015339734964072704
Loss at batch 70 : 0.010770700871944427
Loss at batch 80 : 0.010367322713136673
Loss at batch 90 : 0.008649205788969994
Loss at batch 100 : 0.009676704183220863
Loss at batch 110 : 0.013150227256119251
Loss at batch 120 : 0.01719648577272892
Loss at batch 130 : 0.011297287419438362
Loss at batch 140 : 0.016821779310703278
Loss at batch 150 : 0.014805215410888195
Loss at batch 160 : 0.015807436779141426
Loss at batch 170 : 0.016253553330898285
Loss at batch 180 : 0.010322585701942444
Loss at batch 190 : 0.01069409679621458
Loss at batch 200 : 0.012746571563184261
Loss at batch 210 : 0.010656844824552536
Loss at batch 220 : 0.009254256263375282
Loss at batch 230 : 0.012698139064013958
Loss at batch 240 : 0.014444227330386639
Loss at batch 250 : 0.02722911536693573
Loss at batch 260 : 0.009581190533936024
Loss at batch 270 : 0.008262804709374905
Loss at batch 280 : 0.01253420114517212
Loss at batch 290 : 0.016036663204431534
Loss at batch 300 : 0.01499699056148529
Loss at batch 310 : 0.011203974485397339
Loss at batch 320 : 0.01787690445780754
Loss at batch 330 : 0.007500822655856609
Loss at batch 340 : 0.016700588166713715
Loss at batch 350 : 0.019151119515299797
Loss at batch 360 : 0.02185617759823799
Loss at batch 370 : 0.01668587140738964
epoch172 finished!
Loss at batch 10 : 0.01286614965647459
Loss at batch 20 : 0.013285581022500992
Loss at batch 30 : 0.007305285427719355
Loss at batch 40 : 0.009256964549422264
Loss at batch 50 : 0.02272564359009266
Loss at batch 60 : 0.013943038880825043
Loss at batch 70 : 0.011213116347789764
Loss at batch 80 : 0.010909591801464558
Loss at batch 90 : 0.013539185747504234
Loss at batch 100 : 0.01268631499260664
Loss at batch 110 : 0.01661611720919609
Loss at batch 120 : 0.02114223502576351
Loss at batch 130 : 0.021018318831920624
Loss at batch 140 : 0.014348401688039303
Loss at batch 150 : 0.009880470111966133
Loss at batch 160 : 0.013408607803285122
Loss at batch 170 : 0.013321389444172382
Loss at batch 180 : 0.020214904099702835
Loss at batch 190 : 0.015288425609469414
Loss at batch 200 : 0.015888800844550133
Loss at batch 210 : 0.012918845750391483
Loss at batch 220 : 0.0101424315944314
Loss at batch 230 : 0.013086511753499508
Loss at batch 240 : 0.02948620542883873
Loss at batch 250 : 0.0142470458522439
Loss at batch 260 : 0.0074622053653001785
Loss at batch 270 : 0.010500811971724033
Loss at batch 280 : 0.014396131969988346
Loss at batch 290 : 0.011731836013495922
Loss at batch 300 : 0.0074461838230490685
Loss at batch 310 : 0.01529955305159092
Loss at batch 320 : 0.016137609258294106
Loss at batch 330 : 0.02144668623805046
Loss at batch 340 : 0.018083492293953896
Loss at batch 350 : 0.019276289269328117
Loss at batch 360 : 0.018213948234915733
Loss at batch 370 : 0.013240263797342777
epoch172 finished!
Loss at batch 10 : 0.010929207317531109
Loss at batch 20 : 0.009538842365145683
Loss at batch 30 : 0.01160489208996296
Loss at batch 40 : 0.011719917878508568
Loss at batch 50 : 0.010830559767782688
Loss at batch 60 : 0.012727197259664536
Loss at batch 70 : 0.013846277259290218
Loss at batch 80 : 0.010663206689059734
Loss at batch 90 : 0.02238115854561329
Loss at batch 100 : 0.012883839197456837
Loss at batch 110 : 0.014090459793806076
Loss at batch 120 : 0.011346343904733658
Loss at batch 130 : 0.017659449949860573
Loss at batch 140 : 0.017056621611118317
Loss at batch 150 : 0.01952947862446308
Loss at batch 160 : 0.025005722418427467
Loss at batch 170 : 0.00975896418094635
Loss at batch 180 : 0.015367298386991024
Loss at batch 190 : 0.012364295311272144
Loss at batch 200 : 0.014189336448907852
Loss at batch 210 : 0.008784471079707146
Loss at batch 220 : 0.01205747202038765
Loss at batch 230 : 0.00854500662535429
Loss at batch 240 : 0.019032593816518784
Loss at batch 250 : 0.015615354292094707
Loss at batch 260 : 0.014295624569058418
Loss at batch 270 : 0.00844529364258051
Loss at batch 280 : 0.01729278266429901
Loss at batch 290 : 0.02393290214240551
Loss at batch 300 : 0.013472292572259903
Loss at batch 310 : 0.017495213076472282
Loss at batch 320 : 0.010961640626192093
Loss at batch 330 : 0.013957181014120579
Loss at batch 340 : 0.017042936757206917
Loss at batch 350 : 0.018157128244638443
Loss at batch 360 : 0.019463438540697098
Loss at batch 370 : 0.01659674197435379
epoch173 finished!
Loss at batch 10 : 0.011346293613314629
Loss at batch 20 : 0.011677873320877552
Loss at batch 30 : 0.0224755946546793
Loss at batch 40 : 0.022452453151345253
Loss at batch 50 : 0.01656302623450756
Loss at batch 60 : 0.010160860605537891
Loss at batch 70 : 0.015212577767670155
Loss at batch 80 : 0.014433509670197964
Loss at batch 90 : 0.013065075501799583
Loss at batch 100 : 0.020303303375840187
Loss at batch 110 : 0.013629250228404999
Loss at batch 120 : 0.017540954053401947
Loss at batch 130 : 0.016999220475554466
Loss at batch 140 : 0.025703594088554382
Loss at batch 150 : 0.009392594918608665
Loss at batch 160 : 0.01842362806200981
Loss at batch 170 : 0.01262233592569828
Loss at batch 180 : 0.024093076586723328
Loss at batch 190 : 0.010874367319047451
Loss at batch 200 : 0.01322536263614893
Loss at batch 210 : 0.025624942034482956
Loss at batch 220 : 0.0072493101470172405
Loss at batch 230 : 0.0240467581897974
Loss at batch 240 : 0.008831516839563847
Loss at batch 250 : 0.010714183561503887
Loss at batch 260 : 0.007141965441405773
Loss at batch 270 : 0.009675093926489353
Loss at batch 280 : 0.011741774156689644
Loss at batch 290 : 0.018027404323220253
Loss at batch 300 : 0.009329047985374928
Loss at batch 310 : 0.015129386447370052
Loss at batch 320 : 0.013674858026206493
Loss at batch 330 : 0.011362980119884014
Loss at batch 340 : 0.02230633981525898
Loss at batch 350 : 0.011791589669883251
Loss at batch 360 : 0.008020583540201187
Loss at batch 370 : 0.023281114175915718
epoch173 finished!
Loss at batch 10 : 0.01562103908509016
Loss at batch 20 : 0.008956964127719402
Loss at batch 30 : 0.019237888976931572
Loss at batch 40 : 0.009570474736392498
Loss at batch 50 : 0.012244881130754948
Loss at batch 60 : 0.012080277316272259
Loss at batch 70 : 0.016342654824256897
Loss at batch 80 : 0.0122868362814188
Loss at batch 90 : 0.014963626861572266
Loss at batch 100 : 0.006070238538086414
Loss at batch 110 : 0.012835808098316193
Loss at batch 120 : 0.01243001502007246
Loss at batch 130 : 0.019725359976291656
Loss at batch 140 : 0.009862172417342663
Loss at batch 150 : 0.011681286618113518
Loss at batch 160 : 0.016488822177052498
Loss at batch 170 : 0.0098393764346838
Loss at batch 180 : 0.013032890856266022
Loss at batch 190 : 0.010383290238678455
Loss at batch 200 : 0.012579131871461868
Loss at batch 210 : 0.012275060638785362
Loss at batch 220 : 0.017190847545862198
Loss at batch 230 : 0.010913115926086903
Loss at batch 240 : 0.008996360003948212
Loss at batch 250 : 0.009922078810632229
Loss at batch 260 : 0.008407778106629848
Loss at batch 270 : 0.01527539361268282
Loss at batch 280 : 0.015249348245561123
Loss at batch 290 : 0.01808931678533554
Loss at batch 300 : 0.016281068325042725
Loss at batch 310 : 0.012567257508635521
Loss at batch 320 : 0.02441527508199215
Loss at batch 330 : 0.009006601758301258
Loss at batch 340 : 0.01676160842180252
Loss at batch 350 : 0.017380880191922188
Loss at batch 360 : 0.008498464711010456
Loss at batch 370 : 0.006772330962121487
epoch174 finished!
Loss at batch 10 : 0.012039978988468647
Loss at batch 20 : 0.01255835872143507
Loss at batch 30 : 0.018633143976330757
Loss at batch 40 : 0.019869856536388397
Loss at batch 50 : 0.02017231099307537
Loss at batch 60 : 0.01347410213202238
Loss at batch 70 : 0.013009339570999146
Loss at batch 80 : 0.02110716886818409
Loss at batch 90 : 0.01626390777528286
Loss at batch 100 : 0.012331231497228146
Loss at batch 110 : 0.011541640385985374
Loss at batch 120 : 0.01690654829144478
Loss at batch 130 : 0.01424246933311224
Loss at batch 140 : 0.010692724026739597
Loss at batch 150 : 0.008996284566819668
Loss at batch 160 : 0.0072026243433356285
Loss at batch 170 : 0.01452215202152729
Loss at batch 180 : 0.024627096951007843
Loss at batch 190 : 0.008567895740270615
Loss at batch 200 : 0.013451875187456608
Loss at batch 210 : 0.01281029637902975
Loss at batch 220 : 0.011742163449525833
Loss at batch 230 : 0.012093196623027325
Loss at batch 240 : 0.008052706718444824
Loss at batch 250 : 0.011101551353931427
Loss at batch 260 : 0.010290074162185192
Loss at batch 270 : 0.013158834539353848
Loss at batch 280 : 0.011572375893592834
Loss at batch 290 : 0.024883795529603958
Loss at batch 300 : 0.015360554680228233
Loss at batch 310 : 0.021506860852241516
Loss at batch 320 : 0.017605924978852272
Loss at batch 330 : 0.010252624750137329
Loss at batch 340 : 0.008726628497242928
Loss at batch 350 : 0.016404693946242332
Loss at batch 360 : 0.017545003443956375
Loss at batch 370 : 0.010253630578517914
epoch174 finished!
Loss at batch 10 : 0.009065674617886543
Loss at batch 20 : 0.012412051670253277
Loss at batch 30 : 0.017647311091423035
Loss at batch 40 : 0.010791897773742676
Loss at batch 50 : 0.007999817840754986
Loss at batch 60 : 0.013331877999007702
Loss at batch 70 : 0.010927853174507618
Loss at batch 80 : 0.017299972474575043
Loss at batch 90 : 0.016866140067577362
Loss at batch 100 : 0.012666890397667885
Loss at batch 110 : 0.01312547829002142
Loss at batch 120 : 0.012607940472662449
Loss at batch 130 : 0.01323288306593895
Loss at batch 140 : 0.012391281314194202
Loss at batch 150 : 0.011969179846346378
Loss at batch 160 : 0.016976799815893173
Loss at batch 170 : 0.013947989791631699
Loss at batch 180 : 0.018466295674443245
Loss at batch 190 : 0.013459623791277409
Loss at batch 200 : 0.014733893796801567
Loss at batch 210 : 0.02089238353073597
Loss at batch 220 : 0.010125290602445602
Loss at batch 230 : 0.0075899697840213776
Loss at batch 240 : 0.006442378740757704
Loss at batch 250 : 0.016818508505821228
Loss at batch 260 : 0.00681630102917552
Loss at batch 270 : 0.011050434783101082
Loss at batch 280 : 0.014215794391930103
Loss at batch 290 : 0.01632494293153286
Loss at batch 300 : 0.014320719987154007
Loss at batch 310 : 0.014366799965500832
Loss at batch 320 : 0.01338406465947628
Loss at batch 330 : 0.008964214473962784
Loss at batch 340 : 0.011360791511833668
Loss at batch 350 : 0.007602033205330372
Loss at batch 360 : 0.010800762102007866
Loss at batch 370 : 0.009905682876706123
epoch175 finished!
Loss at batch 10 : 0.022391427308321
Loss at batch 20 : 0.010060632601380348
Loss at batch 30 : 0.016810670495033264
Loss at batch 40 : 0.011046439409255981
Loss at batch 50 : 0.009774206206202507
Loss at batch 60 : 0.017708754166960716
Loss at batch 70 : 0.009848315268754959
Loss at batch 80 : 0.01729997806251049
Loss at batch 90 : 0.007047278806567192
Loss at batch 100 : 0.0099647743627429
Loss at batch 110 : 0.010441773571074009
Loss at batch 120 : 0.011949628591537476
Loss at batch 130 : 0.00942468922585249
Loss at batch 140 : 0.012165567837655544
Loss at batch 150 : 0.016395198181271553
Loss at batch 160 : 0.012013341300189495
Loss at batch 170 : 0.009161034598946571
Loss at batch 180 : 0.011174101382493973
Loss at batch 190 : 0.015955643728375435
Loss at batch 200 : 0.014424223452806473
Loss at batch 210 : 0.007399951107800007
Loss at batch 220 : 0.007251522038131952
Loss at batch 230 : 0.010070893913507462
Loss at batch 240 : 0.01027591060847044
Loss at batch 250 : 0.011360117234289646
Loss at batch 260 : 0.017351645976305008
Loss at batch 270 : 0.0180619228631258
Loss at batch 280 : 0.014710045419633389
Loss at batch 290 : 0.014322672970592976
Loss at batch 300 : 0.009703299030661583
Loss at batch 310 : 0.007641403935849667
Loss at batch 320 : 0.015615989454090595
Loss at batch 330 : 0.015889137983322144
Loss at batch 340 : 0.016583707183599472
Loss at batch 350 : 0.020004495978355408
Loss at batch 360 : 0.018805118277668953
Loss at batch 370 : 0.009644370526075363
epoch175 finished!
Loss at batch 10 : 0.011214538477361202
Loss at batch 20 : 0.012383897788822651
Loss at batch 30 : 0.01523201260715723
Loss at batch 40 : 0.011814884841442108
Loss at batch 50 : 0.011852656491100788
Loss at batch 60 : 0.014293785206973553
Loss at batch 70 : 0.013879221864044666
Loss at batch 80 : 0.015707921236753464
Loss at batch 90 : 0.017203345894813538
Loss at batch 100 : 0.01895906776189804
Loss at batch 110 : 0.008501734584569931
Loss at batch 120 : 0.01392216607928276
Loss at batch 130 : 0.025852324441075325
Loss at batch 140 : 0.013981183059513569
Loss at batch 150 : 0.007489647716283798
Loss at batch 160 : 0.0196110587567091
Loss at batch 170 : 0.011433788575232029
Loss at batch 180 : 0.014237851835787296
Loss at batch 190 : 0.008040539920330048
Loss at batch 200 : 0.02665545791387558
Loss at batch 210 : 0.021104497835040092
Loss at batch 220 : 0.01293379720300436
Loss at batch 230 : 0.016897084191441536
Loss at batch 240 : 0.015522690489888191
Loss at batch 250 : 0.011730637401342392
Loss at batch 260 : 0.011586150154471397
Loss at batch 270 : 0.011621616780757904
Loss at batch 280 : 0.01602170802652836
Loss at batch 290 : 0.017221815884113312
Loss at batch 300 : 0.01178340706974268
Loss at batch 310 : 0.013127812184393406
Loss at batch 320 : 0.012570002116262913
Loss at batch 330 : 0.020693108439445496
Loss at batch 340 : 0.010192074812948704
Loss at batch 350 : 0.018122060224413872
Loss at batch 360 : 0.014654664322733879
Loss at batch 370 : 0.007946198806166649
epoch176 finished!
Loss at batch 10 : 0.012451454065740108
Loss at batch 20 : 0.012133268639445305
Loss at batch 30 : 0.014517481438815594
Loss at batch 40 : 0.00797131098806858
Loss at batch 50 : 0.013158755376935005
Loss at batch 60 : 0.008398370817303658
Loss at batch 70 : 0.009923680685460567
Loss at batch 80 : 0.01160858478397131
Loss at batch 90 : 0.019178377464413643
Loss at batch 100 : 0.016967210918664932
Loss at batch 110 : 0.013827862218022346
Loss at batch 120 : 0.006743439007550478
Loss at batch 130 : 0.012417804449796677
Loss at batch 140 : 0.01502309087663889
Loss at batch 150 : 0.010569083504378796
Loss at batch 160 : 0.009655809961259365
Loss at batch 170 : 0.00967293418943882
Loss at batch 180 : 0.012172657065093517
Loss at batch 190 : 0.019845696166157722
Loss at batch 200 : 0.018673591315746307
Loss at batch 210 : 0.015852758660912514
Loss at batch 220 : 0.014861115254461765
Loss at batch 230 : 0.01434682309627533
Loss at batch 240 : 0.010413261130452156
Loss at batch 250 : 0.030790112912654877
Loss at batch 260 : 0.01644519716501236
Loss at batch 270 : 0.006175438407808542
Loss at batch 280 : 0.012655068188905716
Loss at batch 290 : 0.009085767902433872
Loss at batch 300 : 0.017111817374825478
Loss at batch 310 : 0.013082354329526424
Loss at batch 320 : 0.014507575891911983
Loss at batch 330 : 0.011368470266461372
Loss at batch 340 : 0.011771798133850098
Loss at batch 350 : 0.005781114101409912
Loss at batch 360 : 0.011831171810626984
Loss at batch 370 : 0.010878371074795723
epoch176 finished!
Loss at batch 10 : 0.014182563871145248
Loss at batch 20 : 0.014193631708621979
Loss at batch 30 : 0.010822029784321785
Loss at batch 40 : 0.009848574176430702
Loss at batch 50 : 0.011387389153242111
Loss at batch 60 : 0.01201142743229866
Loss at batch 70 : 0.02096513658761978
Loss at batch 80 : 0.010982312262058258
Loss at batch 90 : 0.015769293531775475
Loss at batch 100 : 0.009304478764533997
Loss at batch 110 : 0.006566152907907963
Loss at batch 120 : 0.01651483215391636
Loss at batch 130 : 0.008507556281983852
Loss at batch 140 : 0.008213669061660767
Loss at batch 150 : 0.008920201100409031
Loss at batch 160 : 0.01698169857263565
Loss at batch 170 : 0.010318538174033165
Loss at batch 180 : 0.012620353139936924
Loss at batch 190 : 0.017804494127631187
Loss at batch 200 : 0.009312364272773266
Loss at batch 210 : 0.01139537338167429
Loss at batch 220 : 0.008324346505105495
Loss at batch 230 : 0.016320502385497093
Loss at batch 240 : 0.006654615048319101
Loss at batch 250 : 0.009759132750332355
Loss at batch 260 : 0.02087879739701748
Loss at batch 270 : 0.014920618385076523
Loss at batch 280 : 0.02088676579296589
Loss at batch 290 : 0.011231333948671818
Loss at batch 300 : 0.009126722812652588
Loss at batch 310 : 0.01960689201951027
Loss at batch 320 : 0.009881933219730854
Loss at batch 330 : 0.013220257125794888
Loss at batch 340 : 0.008121410384774208
Loss at batch 350 : 0.02113739401102066
Loss at batch 360 : 0.01751200668513775
Loss at batch 370 : 0.02759118191897869
epoch177 finished!
Loss at batch 10 : 0.012000440619885921
Loss at batch 20 : 0.013752528466284275
Loss at batch 30 : 0.017217054963111877
Loss at batch 40 : 0.011006399989128113
Loss at batch 50 : 0.014134125784039497
Loss at batch 60 : 0.01019864622503519
Loss at batch 70 : 0.01689435914158821
Loss at batch 80 : 0.008839773945510387
Loss at batch 90 : 0.00725493673235178
Loss at batch 100 : 0.012835546396672726
Loss at batch 110 : 0.025828523561358452
Loss at batch 120 : 0.018979979678988457
Loss at batch 130 : 0.011236049234867096
Loss at batch 140 : 0.02984759211540222
Loss at batch 150 : 0.017333313822746277
Loss at batch 160 : 0.011171233840286732
Loss at batch 170 : 0.020174577832221985
Loss at batch 180 : 0.011877119541168213
Loss at batch 190 : 0.015460358932614326
Loss at batch 200 : 0.016832908615469933
Loss at batch 210 : 0.008887192234396935
Loss at batch 220 : 0.014290476217865944
Loss at batch 230 : 0.011366955004632473
Loss at batch 240 : 0.007587373722344637
Loss at batch 250 : 0.012165012769401073
Loss at batch 260 : 0.013832696713507175
Loss at batch 270 : 0.011443100869655609
Loss at batch 280 : 0.017318768426775932
Loss at batch 290 : 0.017238330096006393
Loss at batch 300 : 0.014818628318607807
Loss at batch 310 : 0.006128521636128426
Loss at batch 320 : 0.010244688019156456
Loss at batch 330 : 0.007566116750240326
Loss at batch 340 : 0.013643186539411545
Loss at batch 350 : 0.018653349950909615
Loss at batch 360 : 0.018436945974826813
Loss at batch 370 : 0.010979097336530685
epoch177 finished!
Loss at batch 10 : 0.015219947323203087
Loss at batch 20 : 0.008740530349314213
Loss at batch 30 : 0.029742911458015442
Loss at batch 40 : 0.013329658657312393
Loss at batch 50 : 0.015173777006566525
Loss at batch 60 : 0.01624986343085766
Loss at batch 70 : 0.011712769977748394
Loss at batch 80 : 0.0088435597717762
Loss at batch 90 : 0.02659432403743267
Loss at batch 100 : 0.012851173058152199
Loss at batch 110 : 0.009862266480922699
Loss at batch 120 : 0.016187429428100586
Loss at batch 130 : 0.018112624064087868
Loss at batch 140 : 0.015563909895718098
Loss at batch 150 : 0.0219814982265234
Loss at batch 160 : 0.012510336004197598
Loss at batch 170 : 0.016737518832087517
Loss at batch 180 : 0.015894437208771706
Loss at batch 190 : 0.00975238811224699
Loss at batch 200 : 0.012537458911538124
Loss at batch 210 : 0.016468940302729607
Loss at batch 220 : 0.008985019288957119
Loss at batch 230 : 0.008353449404239655
Loss at batch 240 : 0.025148561224341393
Loss at batch 250 : 0.012526294216513634
Loss at batch 260 : 0.011708098463714123
Loss at batch 270 : 0.00855217780917883
Loss at batch 280 : 0.01274830847978592
Loss at batch 290 : 0.010080006904900074
Loss at batch 300 : 0.010267461650073528
Loss at batch 310 : 0.015997420996427536
Loss at batch 320 : 0.009861717000603676
Loss at batch 330 : 0.010490292683243752
Loss at batch 340 : 0.009882878512144089
Loss at batch 350 : 0.014755478128790855
Loss at batch 360 : 0.01318447757512331
Loss at batch 370 : 0.02936636656522751
epoch178 finished!
Loss at batch 10 : 0.010197486728429794
Loss at batch 20 : 0.017718195915222168
Loss at batch 30 : 0.015159934759140015
Loss at batch 40 : 0.012384219095110893
Loss at batch 50 : 0.007659080903977156
Loss at batch 60 : 0.008289742283523083
Loss at batch 70 : 0.0174630805850029
Loss at batch 80 : 0.021806636825203896
Loss at batch 90 : 0.007239635102450848
Loss at batch 100 : 0.008474111557006836
Loss at batch 110 : 0.016531920060515404
Loss at batch 120 : 0.017909923568367958
Loss at batch 130 : 0.0067084794864058495
Loss at batch 140 : 0.012777846306562424
Loss at batch 150 : 0.013627947308123112
Loss at batch 160 : 0.014369409531354904
Loss at batch 170 : 0.011914961040019989
Loss at batch 180 : 0.010987255722284317
Loss at batch 190 : 0.02257670648396015
Loss at batch 200 : 0.016780680045485497
Loss at batch 210 : 0.017720777541399002
Loss at batch 220 : 0.012077043764293194
Loss at batch 230 : 0.009503715671598911
Loss at batch 240 : 0.014894572086632252
Loss at batch 250 : 0.00792759656906128
Loss at batch 260 : 0.017599396407604218
Loss at batch 270 : 0.02830088697373867
Loss at batch 280 : 0.019362034276127815
Loss at batch 290 : 0.021030224859714508
Loss at batch 300 : 0.013502409681677818
Loss at batch 310 : 0.014793905429542065
Loss at batch 320 : 0.00804425124078989
Loss at batch 330 : 0.013012093491852283
Loss at batch 340 : 0.008271410129964352
Loss at batch 350 : 0.016419602558016777
Loss at batch 360 : 0.010817167349159718
Loss at batch 370 : 0.015990646556019783
epoch178 finished!
Loss at batch 10 : 0.013304976746439934
Loss at batch 20 : 0.02474488876760006
Loss at batch 30 : 0.011674226261675358
Loss at batch 40 : 0.010079034604132175
Loss at batch 50 : 0.010503338649868965
Loss at batch 60 : 0.01268544141203165
Loss at batch 70 : 0.011289279907941818
Loss at batch 80 : 0.008202336728572845
Loss at batch 90 : 0.017475448548793793
Loss at batch 100 : 0.015557232312858105
Loss at batch 110 : 0.023094438016414642
Loss at batch 120 : 0.01033529732376337
Loss at batch 130 : 0.011968511156737804
Loss at batch 140 : 0.025123154744505882
Loss at batch 150 : 0.029788514599204063
Loss at batch 160 : 0.009503047913312912
Loss at batch 170 : 0.008659105747938156
Loss at batch 180 : 0.012814094312489033
Loss at batch 190 : 0.014723408967256546
Loss at batch 200 : 0.00735033443197608
Loss at batch 210 : 0.013130955398082733
Loss at batch 220 : 0.0105608981102705
Loss at batch 230 : 0.021025683730840683
Loss at batch 240 : 0.018099023029208183
Loss at batch 250 : 0.011624104343354702
Loss at batch 260 : 0.028700798749923706
Loss at batch 270 : 0.0091222720220685
Loss at batch 280 : 0.011995784938335419
Loss at batch 290 : 0.0075261592864990234
Loss at batch 300 : 0.01936257816851139
Loss at batch 310 : 0.013753189705312252
Loss at batch 320 : 0.023156607523560524
Loss at batch 330 : 0.011051470413804054
Loss at batch 340 : 0.006535426713526249
Loss at batch 350 : 0.010010848753154278
Loss at batch 360 : 0.012482664547860622
Loss at batch 370 : 0.021717440336942673
epoch179 finished!
Loss at batch 10 : 0.015189784578979015
Loss at batch 20 : 0.014213643036782742
Loss at batch 30 : 0.013071149587631226
Loss at batch 40 : 0.012572606094181538
Loss at batch 50 : 0.010454753413796425
Loss at batch 60 : 0.008440538309514523
Loss at batch 70 : 0.009398212656378746
Loss at batch 80 : 0.018269307911396027
Loss at batch 90 : 0.013862677849829197
Loss at batch 100 : 0.007798659149557352
Loss at batch 110 : 0.013681107200682163
Loss at batch 120 : 0.012177852913737297
Loss at batch 130 : 0.015146038495004177
Loss at batch 140 : 0.015998780727386475
Loss at batch 150 : 0.013071204535663128
Loss at batch 160 : 0.020553017035126686
Loss at batch 170 : 0.010535992681980133
Loss at batch 180 : 0.02810630016028881
Loss at batch 190 : 0.008291388861835003
Loss at batch 200 : 0.011898992583155632
Loss at batch 210 : 0.009743094444274902
Loss at batch 220 : 0.010725606232881546
Loss at batch 230 : 0.014614804647862911
Loss at batch 240 : 0.011778661049902439
Loss at batch 250 : 0.011549055576324463
Loss at batch 260 : 0.015129475854337215
Loss at batch 270 : 0.02484976500272751
Loss at batch 280 : 0.013332925736904144
Loss at batch 290 : 0.015709152445197105
Loss at batch 300 : 0.012507684528827667
Loss at batch 310 : 0.01780240796506405
Loss at batch 320 : 0.023850571364164352
Loss at batch 330 : 0.007784591987729073
Loss at batch 340 : 0.010754876770079136
Loss at batch 350 : 0.013880924321711063
Loss at batch 360 : 0.01808418147265911
Loss at batch 370 : 0.007760259322822094
epoch179 finished!
Loss at batch 10 : 0.01647135429084301
Loss at batch 20 : 0.014179431833326817
Loss at batch 30 : 0.012114830315113068
Loss at batch 40 : 0.022208459675312042
Loss at batch 50 : 0.008485349826514721
Loss at batch 60 : 0.00907164253294468
Loss at batch 70 : 0.01153989601880312
Loss at batch 80 : 0.009337833151221275
Loss at batch 90 : 0.01215479988604784
Loss at batch 100 : 0.014336105436086655
Loss at batch 110 : 0.01870899461209774
Loss at batch 120 : 0.024976443499326706
Loss at batch 130 : 0.007599205244332552
Loss at batch 140 : 0.008469370193779469
Loss at batch 150 : 0.013013928197324276
Loss at batch 160 : 0.014343060553073883
Loss at batch 170 : 0.020499521866440773
Loss at batch 180 : 0.015936624258756638
Loss at batch 190 : 0.011113705113530159
Loss at batch 200 : 0.01670595072209835
Loss at batch 210 : 0.012442221865057945
Loss at batch 220 : 0.011816530488431454
Loss at batch 230 : 0.012810437940061092
Loss at batch 240 : 0.012646721675992012
Loss at batch 250 : 0.012365259230136871
Loss at batch 260 : 0.01588229462504387
Loss at batch 270 : 0.0077885729260742664
Loss at batch 280 : 0.01042213011533022
Loss at batch 290 : 0.017600921913981438
Loss at batch 300 : 0.016171526163816452
Loss at batch 310 : 0.01716398261487484
Loss at batch 320 : 0.011567662470042706
Loss at batch 330 : 0.013520917855203152
Loss at batch 340 : 0.012863170355558395
Loss at batch 350 : 0.010622022673487663
Loss at batch 360 : 0.00971250794827938
Loss at batch 370 : 0.012469703331589699
epoch180 finished!
Loss at batch 10 : 0.008412890136241913
Loss at batch 20 : 0.00911614578217268
Loss at batch 30 : 0.012087768875062466
Loss at batch 40 : 0.018343353644013405
Loss at batch 50 : 0.01620381698012352
Loss at batch 60 : 0.009484672918915749
Loss at batch 70 : 0.01844736561179161
Loss at batch 80 : 0.014763087965548038
Loss at batch 90 : 0.019381670281291008
Loss at batch 100 : 0.020811621099710464
Loss at batch 110 : 0.01634395681321621
Loss at batch 120 : 0.01329669076949358
Loss at batch 130 : 0.011613545008003712
Loss at batch 140 : 0.015477560460567474
Loss at batch 150 : 0.009177519008517265
Loss at batch 160 : 0.013987822458148003
Loss at batch 170 : 0.012748530134558678
Loss at batch 180 : 0.00786293763667345
Loss at batch 190 : 0.007118665147572756
Loss at batch 200 : 0.008906072936952114
Loss at batch 210 : 0.01458823960274458
Loss at batch 220 : 0.016546858474612236
Loss at batch 230 : 0.01633644290268421
Loss at batch 240 : 0.023419464007019997
Loss at batch 250 : 0.014499902725219727
Loss at batch 260 : 0.02301727421581745
Loss at batch 270 : 0.017996225506067276
Loss at batch 280 : 0.012318047694861889
Loss at batch 290 : 0.015787949785590172
Loss at batch 300 : 0.022122720256447792
Loss at batch 310 : 0.011903619393706322
Loss at batch 320 : 0.018052879720926285
Loss at batch 330 : 0.020612221211194992
Loss at batch 340 : 0.01923457346856594
Loss at batch 350 : 0.018336601555347443
Loss at batch 360 : 0.01388609316200018
Loss at batch 370 : 0.01023960579186678
epoch180 finished!
Loss at batch 10 : 0.013885854743421078
Loss at batch 20 : 0.013042635284364223
Loss at batch 30 : 0.016370434314012527
Loss at batch 40 : 0.019275814294815063
Loss at batch 50 : 0.01485538762062788
Loss at batch 60 : 0.015840409323573112
Loss at batch 70 : 0.01602344959974289
Loss at batch 80 : 0.010486569255590439
Loss at batch 90 : 0.012364002875983715
Loss at batch 100 : 0.014686600305140018
Loss at batch 110 : 0.011870676651597023
Loss at batch 120 : 0.020103098824620247
Loss at batch 130 : 0.01421363465487957
Loss at batch 140 : 0.00943288579583168
Loss at batch 150 : 0.0128064826130867
Loss at batch 160 : 0.024639029055833817
Loss at batch 170 : 0.014822076074779034
Loss at batch 180 : 0.010687942616641521
Loss at batch 190 : 0.015894316136837006
Loss at batch 200 : 0.009558632038533688
Loss at batch 210 : 0.012497713789343834
Loss at batch 220 : 0.010623598471283913
Loss at batch 230 : 0.014129157178103924
Loss at batch 240 : 0.01216419693082571
Loss at batch 250 : 0.008950104005634785
Loss at batch 260 : 0.00758125027641654
Loss at batch 270 : 0.02302492782473564
Loss at batch 280 : 0.012839999981224537
Loss at batch 290 : 0.022600973024964333
Loss at batch 300 : 0.008417905308306217
Loss at batch 310 : 0.011559275910258293
Loss at batch 320 : 0.012314065359532833
Loss at batch 330 : 0.010372363030910492
Loss at batch 340 : 0.012118159793317318
Loss at batch 350 : 0.016311295330524445
Loss at batch 360 : 0.011958703398704529
Loss at batch 370 : 0.0152427414432168
epoch181 finished!
Loss at batch 10 : 0.009962713345885277
Loss at batch 20 : 0.013562229461967945
Loss at batch 30 : 0.023037072271108627
Loss at batch 40 : 0.025528421625494957
Loss at batch 50 : 0.013650636188685894
Loss at batch 60 : 0.013721702620387077
Loss at batch 70 : 0.023176604881882668
Loss at batch 80 : 0.013477748259902
Loss at batch 90 : 0.007553021423518658
Loss at batch 100 : 0.022709492594003677
Loss at batch 110 : 0.012074790894985199
Loss at batch 120 : 0.008373161777853966
Loss at batch 130 : 0.015482472255825996
Loss at batch 140 : 0.013581217266619205
Loss at batch 150 : 0.015799077227711678
Loss at batch 160 : 0.014436841942369938
Loss at batch 170 : 0.020206492394208908
Loss at batch 180 : 0.008976052515208721
Loss at batch 190 : 0.01219863910228014
Loss at batch 200 : 0.01312233041971922
Loss at batch 210 : 0.010388056747615337
Loss at batch 220 : 0.015380127355456352
Loss at batch 230 : 0.010729060508310795
Loss at batch 240 : 0.016617493703961372
Loss at batch 250 : 0.015545648522675037
Loss at batch 260 : 0.022774022072553635
Loss at batch 270 : 0.009231294505298138
Loss at batch 280 : 0.015006380155682564
Loss at batch 290 : 0.009880042634904385
Loss at batch 300 : 0.012033861130475998
Loss at batch 310 : 0.015030311420559883
Loss at batch 320 : 0.019420361146330833
Loss at batch 330 : 0.014837267808616161
Loss at batch 340 : 0.015669137239456177
Loss at batch 350 : 0.014778455719351768
Loss at batch 360 : 0.010147307999432087
Loss at batch 370 : 0.012791640125215054
epoch181 finished!
Loss at batch 10 : 0.013812825083732605
Loss at batch 20 : 0.018669215962290764
Loss at batch 30 : 0.008149986155331135
Loss at batch 40 : 0.010837418958544731
Loss at batch 50 : 0.009279024787247181
Loss at batch 60 : 0.018496476113796234
Loss at batch 70 : 0.010302708484232426
Loss at batch 80 : 0.012445803731679916
Loss at batch 90 : 0.018578551709651947
Loss at batch 100 : 0.01922491192817688
Loss at batch 110 : 0.012845511548221111
Loss at batch 120 : 0.01699160970747471
Loss at batch 130 : 0.01102611143141985
Loss at batch 140 : 0.009855980984866619
Loss at batch 150 : 0.011073509231209755
Loss at batch 160 : 0.014059609733521938
Loss at batch 170 : 0.01637573167681694
Loss at batch 180 : 0.010099121369421482
Loss at batch 190 : 0.02027350850403309
Loss at batch 200 : 0.012474308721721172
Loss at batch 210 : 0.010097160935401917
Loss at batch 220 : 0.014889704063534737
Loss at batch 230 : 0.013459381647408009
Loss at batch 240 : 0.01033768616616726
Loss at batch 250 : 0.011309281922876835
Loss at batch 260 : 0.013799059204757214
Loss at batch 270 : 0.011504190973937511
Loss at batch 280 : 0.00610474543645978
Loss at batch 290 : 0.010398012585937977
Loss at batch 300 : 0.011952267028391361
Loss at batch 310 : 0.011754093691706657
Loss at batch 320 : 0.022668762132525444
Loss at batch 330 : 0.011708988808095455
Loss at batch 340 : 0.008855541236698627
Loss at batch 350 : 0.012647952884435654
Loss at batch 360 : 0.012409528717398643
Loss at batch 370 : 0.009761147201061249
epoch182 finished!
Loss at batch 10 : 0.010952833108603954
Loss at batch 20 : 0.017679153010249138
Loss at batch 30 : 0.01110012922435999
Loss at batch 40 : 0.01224285364151001
Loss at batch 50 : 0.016818180680274963
Loss at batch 60 : 0.012484016828238964
Loss at batch 70 : 0.01077759638428688
Loss at batch 80 : 0.010901576839387417
Loss at batch 90 : 0.015660351142287254
Loss at batch 100 : 0.00971162598580122
Loss at batch 110 : 0.019729789346456528
Loss at batch 120 : 0.008395696990191936
Loss at batch 130 : 0.017437657341361046
Loss at batch 140 : 0.01451842486858368
Loss at batch 150 : 0.01350703090429306
Loss at batch 160 : 0.008454103954136372
Loss at batch 170 : 0.007723315618932247
Loss at batch 180 : 0.018415672704577446
Loss at batch 190 : 0.012139265425503254
Loss at batch 200 : 0.016715310513973236
Loss at batch 210 : 0.011720948852598667
Loss at batch 220 : 0.025158558040857315
Loss at batch 230 : 0.015020398423075676
Loss at batch 240 : 0.01560389343649149
Loss at batch 250 : 0.016851693391799927
Loss at batch 260 : 0.015367697924375534
Loss at batch 270 : 0.013934402726590633
Loss at batch 280 : 0.011601048521697521
Loss at batch 290 : 0.013169731944799423
Loss at batch 300 : 0.017123274505138397
Loss at batch 310 : 0.011442593298852444
Loss at batch 320 : 0.02005944959819317
Loss at batch 330 : 0.015212591737508774
Loss at batch 340 : 0.016653353348374367
Loss at batch 350 : 0.01716558448970318
Loss at batch 360 : 0.022568872198462486
Loss at batch 370 : 0.01168468315154314
epoch182 finished!
Loss at batch 10 : 0.01381817925721407
Loss at batch 20 : 0.0071780988946557045
Loss at batch 30 : 0.013850703835487366
Loss at batch 40 : 0.012942339293658733
Loss at batch 50 : 0.010967420414090157
Loss at batch 60 : 0.0076402900740504265
Loss at batch 70 : 0.008067593909800053
Loss at batch 80 : 0.015467751771211624
Loss at batch 90 : 0.0119058508425951
Loss at batch 100 : 0.016575736925005913
Loss at batch 110 : 0.013693421147763729
Loss at batch 120 : 0.02471913769841194
Loss at batch 130 : 0.007988533936440945
Loss at batch 140 : 0.011824941262602806
Loss at batch 150 : 0.018236402422189713
Loss at batch 160 : 0.011136350221931934
Loss at batch 170 : 0.014425799250602722
Loss at batch 180 : 0.0073143355548381805
Loss at batch 190 : 0.02612636610865593
Loss at batch 200 : 0.015042547136545181
Loss at batch 210 : 0.012084653601050377
Loss at batch 220 : 0.017120512202382088
Loss at batch 230 : 0.010864635929465294
Loss at batch 240 : 0.010119660757482052
Loss at batch 250 : 0.014954671263694763
Loss at batch 260 : 0.024491915479302406
Loss at batch 270 : 0.013376995921134949
Loss at batch 280 : 0.010609769262373447
Loss at batch 290 : 0.016255294904112816
Loss at batch 300 : 0.01830524019896984
Loss at batch 310 : 0.019396375864744186
Loss at batch 320 : 0.012339415960013866
Loss at batch 330 : 0.009838881902396679
Loss at batch 340 : 0.00853483285754919
Loss at batch 350 : 0.0314277708530426
Loss at batch 360 : 0.016622323542833328
Loss at batch 370 : 0.01633862592279911
epoch183 finished!
Loss at batch 10 : 0.01048574224114418
Loss at batch 20 : 0.009240653365850449
Loss at batch 30 : 0.00923183374106884
Loss at batch 40 : 0.021502789109945297
Loss at batch 50 : 0.01909678801894188
Loss at batch 60 : 0.012143793515861034
Loss at batch 70 : 0.007864139974117279
Loss at batch 80 : 0.01747088134288788
Loss at batch 90 : 0.013849781826138496
Loss at batch 100 : 0.015147645026445389
Loss at batch 110 : 0.017634883522987366
Loss at batch 120 : 0.018964480608701706
Loss at batch 130 : 0.01847025193274021
Loss at batch 140 : 0.010259563103318214
Loss at batch 150 : 0.018678834661841393
Loss at batch 160 : 0.010171844623982906
Loss at batch 170 : 0.01749170385301113
Loss at batch 180 : 0.008867213502526283
Loss at batch 190 : 0.012311868369579315
Loss at batch 200 : 0.009047039784491062
Loss at batch 210 : 0.01218625158071518
Loss at batch 220 : 0.011959921568632126
Loss at batch 230 : 0.01337585411965847
Loss at batch 240 : 0.017963292077183723
Loss at batch 250 : 0.013438553549349308
Loss at batch 260 : 0.009434890933334827
Loss at batch 270 : 0.009511882439255714
Loss at batch 280 : 0.010577881708741188
Loss at batch 290 : 0.019192073494195938
Loss at batch 300 : 0.0174176637083292
Loss at batch 310 : 0.008913322351872921
Loss at batch 320 : 0.016102304682135582
Loss at batch 330 : 0.01563819870352745
Loss at batch 340 : 0.011237075552344322
Loss at batch 350 : 0.00938651617616415
Loss at batch 360 : 0.00876482855528593
Loss at batch 370 : 0.021162766963243484
epoch183 finished!
Loss at batch 10 : 0.019948972389101982
Loss at batch 20 : 0.01966876909136772
Loss at batch 30 : 0.009351780638098717
Loss at batch 40 : 0.011636977083981037
Loss at batch 50 : 0.019446589052677155
Loss at batch 60 : 0.00831765029579401
Loss at batch 70 : 0.017245838418602943
Loss at batch 80 : 0.00960703007876873
Loss at batch 90 : 0.013782020658254623
Loss at batch 100 : 0.008688931353390217
Loss at batch 110 : 0.014977197162806988
Loss at batch 120 : 0.013584166765213013
Loss at batch 130 : 0.01211259700357914
Loss at batch 140 : 0.014822466298937798
Loss at batch 150 : 0.012243911623954773
Loss at batch 160 : 0.011386781930923462
Loss at batch 170 : 0.015664948150515556
Loss at batch 180 : 0.011951745487749577
Loss at batch 190 : 0.0324772484600544
Loss at batch 200 : 0.023807916790246964
Loss at batch 210 : 0.00944600161164999
Loss at batch 220 : 0.02071552351117134
Loss at batch 230 : 0.01426640059798956
Loss at batch 240 : 0.012231067754328251
Loss at batch 250 : 0.009663062170147896
Loss at batch 260 : 0.01600201241672039
Loss at batch 270 : 0.022304004058241844
Loss at batch 280 : 0.009584720246493816
Loss at batch 290 : 0.012345897033810616
Loss at batch 300 : 0.018277764320373535
Loss at batch 310 : 0.022151697427034378
Loss at batch 320 : 0.020531494170427322
Loss at batch 330 : 0.018079856410622597
Loss at batch 340 : 0.01883055828511715
Loss at batch 350 : 0.012801329605281353
Loss at batch 360 : 0.009968763217329979
Loss at batch 370 : 0.011448673903942108
epoch184 finished!
Loss at batch 10 : 0.010365973226726055
Loss at batch 20 : 0.010370978154242039
Loss at batch 30 : 0.02755247987806797
Loss at batch 40 : 0.010762323625385761
Loss at batch 50 : 0.010122456587851048
Loss at batch 60 : 0.013609813526272774
Loss at batch 70 : 0.01455706637352705
Loss at batch 80 : 0.01142915990203619
Loss at batch 90 : 0.0064145480282604694
Loss at batch 100 : 0.016346968710422516
Loss at batch 110 : 0.011542846448719501
Loss at batch 120 : 0.008834685198962688
Loss at batch 130 : 0.007658693939447403
Loss at batch 140 : 0.008005413226783276
Loss at batch 150 : 0.011481952853500843
Loss at batch 160 : 0.008127660490572453
Loss at batch 170 : 0.023268112912774086
Loss at batch 180 : 0.009921135380864143
Loss at batch 190 : 0.02146400511264801
Loss at batch 200 : 0.01005110889673233
Loss at batch 210 : 0.015057770535349846
Loss at batch 220 : 0.024990465492010117
Loss at batch 230 : 0.020366597920656204
Loss at batch 240 : 0.013242734596133232
Loss at batch 250 : 0.013633926399052143
Loss at batch 260 : 0.00786528829485178
Loss at batch 270 : 0.011827410198748112
Loss at batch 280 : 0.017736105248332024
Loss at batch 290 : 0.012272888794541359
Loss at batch 300 : 0.013285189867019653
Loss at batch 310 : 0.015286944806575775
Loss at batch 320 : 0.013509390875697136
Loss at batch 330 : 0.015310794115066528
Loss at batch 340 : 0.00864892452955246
Loss at batch 350 : 0.018603600561618805
Loss at batch 360 : 0.01883670873939991
Loss at batch 370 : 0.015556911937892437
epoch184 finished!
Loss at batch 10 : 0.011140729300677776
Loss at batch 20 : 0.012587507255375385
Loss at batch 30 : 0.015867169946432114
Loss at batch 40 : 0.01881447434425354
Loss at batch 50 : 0.007388993166387081
Loss at batch 60 : 0.016344815492630005
Loss at batch 70 : 0.008079762570559978
Loss at batch 80 : 0.011783151887357235
Loss at batch 90 : 0.01248952466994524
Loss at batch 100 : 0.014460277743637562
Loss at batch 110 : 0.014752951450645924
Loss at batch 120 : 0.013425750657916069
Loss at batch 130 : 0.015634335577487946
Loss at batch 140 : 0.014521139673888683
Loss at batch 150 : 0.014610248617827892
Loss at batch 160 : 0.01324947364628315
Loss at batch 170 : 0.014886569231748581
Loss at batch 180 : 0.012334585189819336
Loss at batch 190 : 0.02095963805913925
Loss at batch 200 : 0.013249344192445278
Loss at batch 210 : 0.01227058656513691
Loss at batch 220 : 0.01534826960414648
Loss at batch 230 : 0.013362128287553787
Loss at batch 240 : 0.012432493269443512
Loss at batch 250 : 0.012710930779576302
Loss at batch 260 : 0.013326920568943024
Loss at batch 270 : 0.023229282349348068
Loss at batch 280 : 0.006446507293730974
Loss at batch 290 : 0.013689459301531315
Loss at batch 300 : 0.012997780926525593
Loss at batch 310 : 0.011098908260464668
Loss at batch 320 : 0.014152578078210354
Loss at batch 330 : 0.013799158856272697
Loss at batch 340 : 0.019346479326486588
Loss at batch 350 : 0.012067883275449276
Loss at batch 360 : 0.014058182947337627
Loss at batch 370 : 0.008912686258554459
epoch185 finished!
Loss at batch 10 : 0.010411255992949009
Loss at batch 20 : 0.011071708053350449
Loss at batch 30 : 0.011605699546635151
Loss at batch 40 : 0.01985420659184456
Loss at batch 50 : 0.03356264531612396
Loss at batch 60 : 0.010285190306603909
Loss at batch 70 : 0.01119198091328144
Loss at batch 80 : 0.012882084585726261
Loss at batch 90 : 0.00874753575772047
Loss at batch 100 : 0.010696092620491982
Loss at batch 110 : 0.013752827420830727
Loss at batch 120 : 0.02249853126704693
Loss at batch 130 : 0.01737620308995247
Loss at batch 140 : 0.012418185360729694
Loss at batch 150 : 0.014047429896891117
Loss at batch 160 : 0.009935805574059486
Loss at batch 170 : 0.013381462544202805
Loss at batch 180 : 0.018135512247681618
Loss at batch 190 : 0.012022629380226135
Loss at batch 200 : 0.015994589775800705
Loss at batch 210 : 0.011723634786903858
Loss at batch 220 : 0.009715876542031765
Loss at batch 230 : 0.006910521537065506
Loss at batch 240 : 0.008115768432617188
Loss at batch 250 : 0.015648089349269867
Loss at batch 260 : 0.01491466537117958
Loss at batch 270 : 0.014232161454856396
Loss at batch 280 : 0.026264358311891556
Loss at batch 290 : 0.012612135149538517
Loss at batch 300 : 0.017513437196612358
Loss at batch 310 : 0.010882104746997356
Loss at batch 320 : 0.012519058771431446
Loss at batch 330 : 0.008394114673137665
Loss at batch 340 : 0.01229887641966343
Loss at batch 350 : 0.01814492978155613
Loss at batch 360 : 0.017195438966155052
Loss at batch 370 : 0.01478104293346405
epoch185 finished!
Loss at batch 10 : 0.015468324534595013
Loss at batch 20 : 0.020778216421604156
Loss at batch 30 : 0.02370596118271351
Loss at batch 40 : 0.016024580225348473
Loss at batch 50 : 0.008225991390645504
Loss at batch 60 : 0.009129696525633335
Loss at batch 70 : 0.019879061728715897
Loss at batch 80 : 0.013742046430706978
Loss at batch 90 : 0.010750873014330864
Loss at batch 100 : 0.02001415565609932
Loss at batch 110 : 0.013650520704686642
Loss at batch 120 : 0.014310366474092007
Loss at batch 130 : 0.020133154466748238
Loss at batch 140 : 0.01580389402806759
Loss at batch 150 : 0.011008786968886852
Loss at batch 160 : 0.016124481335282326
Loss at batch 170 : 0.008411048911511898
Loss at batch 180 : 0.02341514267027378
Loss at batch 190 : 0.017337558791041374
Loss at batch 200 : 0.011700852774083614
Loss at batch 210 : 0.017218057066202164
Loss at batch 220 : 0.0065115951001644135
Loss at batch 230 : 0.01084936410188675
Loss at batch 240 : 0.011789494194090366
Loss at batch 250 : 0.014465400017797947
Loss at batch 260 : 0.012470860965549946
Loss at batch 270 : 0.014348629862070084
Loss at batch 280 : 0.00943199172616005
Loss at batch 290 : 0.011454625055193901
Loss at batch 300 : 0.021510738879442215
Loss at batch 310 : 0.013430015183985233
Loss at batch 320 : 0.010509657673537731
Loss at batch 330 : 0.01248431857675314
Loss at batch 340 : 0.014136644080281258
Loss at batch 350 : 0.015265977941453457
Loss at batch 360 : 0.02358662150800228
Loss at batch 370 : 0.014712072908878326
epoch186 finished!
Loss at batch 10 : 0.025886883959174156
Loss at batch 20 : 0.011668718419969082
Loss at batch 30 : 0.014170333743095398
Loss at batch 40 : 0.0063309939578175545
Loss at batch 50 : 0.01793340966105461
Loss at batch 60 : 0.009886824525892735
Loss at batch 70 : 0.006750562693923712
Loss at batch 80 : 0.012279193848371506
Loss at batch 90 : 0.009694390930235386
Loss at batch 100 : 0.01448726560920477
Loss at batch 110 : 0.013098891824483871
Loss at batch 120 : 0.01876867562532425
Loss at batch 130 : 0.011597668752074242
Loss at batch 140 : 0.02188732661306858
Loss at batch 150 : 0.010935569182038307
Loss at batch 160 : 0.007709916215389967
Loss at batch 170 : 0.011981198564171791
Loss at batch 180 : 0.014949080534279346
Loss at batch 190 : 0.010410899296402931
Loss at batch 200 : 0.012845253571867943
Loss at batch 210 : 0.012907490134239197
Loss at batch 220 : 0.01873241551220417
Loss at batch 230 : 0.021922718733549118
Loss at batch 240 : 0.012855950742959976
Loss at batch 250 : 0.015275099314749241
Loss at batch 260 : 0.009255404584109783
Loss at batch 270 : 0.015575356781482697
Loss at batch 280 : 0.014310495927929878
Loss at batch 290 : 0.016041461378335953
Loss at batch 300 : 0.012030440382659435
Loss at batch 310 : 0.012788807041943073
Loss at batch 320 : 0.01566477119922638
Loss at batch 330 : 0.01307159848511219
Loss at batch 340 : 0.011455739848315716
Loss at batch 350 : 0.018981222063302994
Loss at batch 360 : 0.011126242578029633
Loss at batch 370 : 0.01883186399936676
epoch186 finished!
Loss at batch 10 : 0.017455661669373512
Loss at batch 20 : 0.010845569893717766
Loss at batch 30 : 0.01986832544207573
Loss at batch 40 : 0.013702395372092724
Loss at batch 50 : 0.011386331170797348
Loss at batch 60 : 0.016724055632948875
Loss at batch 70 : 0.011247319169342518
Loss at batch 80 : 0.009721999987959862
Loss at batch 90 : 0.011179575696587563
Loss at batch 100 : 0.015221992507576942
Loss at batch 110 : 0.016086434945464134
Loss at batch 120 : 0.00973493978381157
Loss at batch 130 : 0.0070104473270475864
Loss at batch 140 : 0.012977471575140953
Loss at batch 150 : 0.012066222727298737
Loss at batch 160 : 0.012390071526169777
Loss at batch 170 : 0.009398079477250576
Loss at batch 180 : 0.00837747287005186
Loss at batch 190 : 0.014194563962519169
Loss at batch 200 : 0.021034423261880875
Loss at batch 210 : 0.015227251686155796
Loss at batch 220 : 0.017269106581807137
Loss at batch 230 : 0.019327284768223763
Loss at batch 240 : 0.009473239071667194
Loss at batch 250 : 0.01070338487625122
Loss at batch 260 : 0.01834646239876747
Loss at batch 270 : 0.012692236341536045
Loss at batch 280 : 0.014570025727152824
Loss at batch 290 : 0.011505965143442154
Loss at batch 300 : 0.012521570548415184
Loss at batch 310 : 0.01619551330804825
Loss at batch 320 : 0.01053953729569912
Loss at batch 330 : 0.009246144443750381
Loss at batch 340 : 0.009429429657757282
Loss at batch 350 : 0.010181150399148464
Loss at batch 360 : 0.014332350343465805
Loss at batch 370 : 0.015523800626397133
epoch187 finished!
Loss at batch 10 : 0.013032120652496815
Loss at batch 20 : 0.020497089251875877
Loss at batch 30 : 0.012007256038486958
Loss at batch 40 : 0.019390461966395378
Loss at batch 50 : 0.009488075971603394
Loss at batch 60 : 0.01677021011710167
Loss at batch 70 : 0.026127390563488007
Loss at batch 80 : 0.014115085825324059
Loss at batch 90 : 0.011331692337989807
Loss at batch 100 : 0.009319928474724293
Loss at batch 110 : 0.008637559600174427
Loss at batch 120 : 0.01500802394002676
Loss at batch 130 : 0.0228965375572443
Loss at batch 140 : 0.01340901106595993
Loss at batch 150 : 0.02374994568526745
Loss at batch 160 : 0.011703768745064735
Loss at batch 170 : 0.019930221140384674
Loss at batch 180 : 0.01570810377597809
Loss at batch 190 : 0.0143747478723526
Loss at batch 200 : 0.011033840477466583
Loss at batch 210 : 0.013870945200324059
Loss at batch 220 : 0.02348519116640091
Loss at batch 230 : 0.017969250679016113
Loss at batch 240 : 0.011063025332987309
Loss at batch 250 : 0.011436822824180126
Loss at batch 260 : 0.010991325601935387
Loss at batch 270 : 0.008404538966715336
Loss at batch 280 : 0.019974691793322563
Loss at batch 290 : 0.01186195109039545
Loss at batch 300 : 0.014978752471506596
Loss at batch 310 : 0.01074644923210144
Loss at batch 320 : 0.013782921247184277
Loss at batch 330 : 0.017218446359038353
Loss at batch 340 : 0.008105486631393433
Loss at batch 350 : 0.010279403068125248
Loss at batch 360 : 0.021170172840356827
Loss at batch 370 : 0.01700475998222828
epoch187 finished!
Loss at batch 10 : 0.009410866536200047
Loss at batch 20 : 0.01396244391798973
Loss at batch 30 : 0.013950221240520477
Loss at batch 40 : 0.02029303088784218
Loss at batch 50 : 0.02526196837425232
Loss at batch 60 : 0.008470525033771992
Loss at batch 70 : 0.017589086666703224
Loss at batch 80 : 0.011416343972086906
Loss at batch 90 : 0.007607008330523968
Loss at batch 100 : 0.005895503330975771
Loss at batch 110 : 0.010708190500736237
Loss at batch 120 : 0.011865024454891682
Loss at batch 130 : 0.009686105884611607
Loss at batch 140 : 0.014677217230200768
Loss at batch 150 : 0.022453704848885536
Loss at batch 160 : 0.00937184039503336
Loss at batch 170 : 0.014988293871283531
Loss at batch 180 : 0.0062956311739981174
Loss at batch 190 : 0.01848786510527134
Loss at batch 200 : 0.016440538689494133
Loss at batch 210 : 0.022563651204109192
Loss at batch 220 : 0.008223753422498703
Loss at batch 230 : 0.011892464943230152
Loss at batch 240 : 0.0155039606615901
Loss at batch 250 : 0.01757609099149704
Loss at batch 260 : 0.011644008569419384
Loss at batch 270 : 0.019574971869587898
Loss at batch 280 : 0.011313771829009056
Loss at batch 290 : 0.013866513967514038
Loss at batch 300 : 0.010385517962276936
Loss at batch 310 : 0.014641128480434418
Loss at batch 320 : 0.006183916702866554
Loss at batch 330 : 0.022651249542832375
Loss at batch 340 : 0.012780427001416683
Loss at batch 350 : 0.014739975333213806
Loss at batch 360 : 0.01949208416044712
Loss at batch 370 : 0.013039430603384972
epoch188 finished!
Loss at batch 10 : 0.013150220736861229
Loss at batch 20 : 0.011963470838963985
Loss at batch 30 : 0.009213038720190525
Loss at batch 40 : 0.012998848222196102
Loss at batch 50 : 0.005814375355839729
Loss at batch 60 : 0.01657749153673649
Loss at batch 70 : 0.008295535109937191
Loss at batch 80 : 0.007164980750530958
Loss at batch 90 : 0.017263557761907578
Loss at batch 100 : 0.01043668482452631
Loss at batch 110 : 0.02446586824953556
Loss at batch 120 : 0.012190629728138447
Loss at batch 130 : 0.019207356497645378
Loss at batch 140 : 0.021832015365362167
Loss at batch 150 : 0.012835931032896042
Loss at batch 160 : 0.010186916217207909
Loss at batch 170 : 0.015124301426112652
Loss at batch 180 : 0.020060503855347633
Loss at batch 190 : 0.011929236352443695
Loss at batch 200 : 0.013608324341475964
Loss at batch 210 : 0.01343030296266079
Loss at batch 220 : 0.023410044610500336
Loss at batch 230 : 0.013971736654639244
Loss at batch 240 : 0.018441082909703255
Loss at batch 250 : 0.013494216836988926
Loss at batch 260 : 0.023828545585274696
Loss at batch 270 : 0.02721717767417431
Loss at batch 280 : 0.01056277472525835
Loss at batch 290 : 0.016677025705575943
Loss at batch 300 : 0.009428019635379314
Loss at batch 310 : 0.0156010203063488
Loss at batch 320 : 0.012602372094988823
Loss at batch 330 : 0.012256236746907234
Loss at batch 340 : 0.011117133311927319
Loss at batch 350 : 0.007658388931304216
Loss at batch 360 : 0.006962208542972803
Loss at batch 370 : 0.012769641354680061
epoch188 finished!
Loss at batch 10 : 0.009885597042739391
Loss at batch 20 : 0.00899740681052208
Loss at batch 30 : 0.015822604298591614
Loss at batch 40 : 0.012002475559711456
Loss at batch 50 : 0.01992041803896427
Loss at batch 60 : 0.013176674023270607
Loss at batch 70 : 0.010170264169573784
Loss at batch 80 : 0.015880394726991653
Loss at batch 90 : 0.014608977362513542
Loss at batch 100 : 0.01266296673566103
Loss at batch 110 : 0.020320633426308632
Loss at batch 120 : 0.018072986975312233
Loss at batch 130 : 0.012358108535408974
Loss at batch 140 : 0.012802468612790108
Loss at batch 150 : 0.01653156243264675
Loss at batch 160 : 0.011254613287746906
Loss at batch 170 : 0.014279698953032494
Loss at batch 180 : 0.011796517297625542
Loss at batch 190 : 0.007986518554389477
Loss at batch 200 : 0.019667094573378563
Loss at batch 210 : 0.0071231890469789505
Loss at batch 220 : 0.014924874529242516
Loss at batch 230 : 0.008342294953763485
Loss at batch 240 : 0.0161797683686018
Loss at batch 250 : 0.011561228893697262
Loss at batch 260 : 0.008311698213219643
Loss at batch 270 : 0.01718510501086712
Loss at batch 280 : 0.014363745227456093
Loss at batch 290 : 0.01533547043800354
Loss at batch 300 : 0.016286492347717285
Loss at batch 310 : 0.013464538380503654
Loss at batch 320 : 0.013696878217160702
Loss at batch 330 : 0.011008558794856071
Loss at batch 340 : 0.011918152682483196
Loss at batch 350 : 0.019319895654916763
Loss at batch 360 : 0.01160388719290495
Loss at batch 370 : 0.010117118246853352
epoch189 finished!
Loss at batch 10 : 0.00798012875020504
Loss at batch 20 : 0.010407969355583191
Loss at batch 30 : 0.012083740904927254
Loss at batch 40 : 0.009270834736526012
Loss at batch 50 : 0.01224601175636053
Loss at batch 60 : 0.010842039249837399
Loss at batch 70 : 0.014657688327133656
Loss at batch 80 : 0.01697545312345028
Loss at batch 90 : 0.01209008414298296
Loss at batch 100 : 0.014442230574786663
Loss at batch 110 : 0.013263251632452011
Loss at batch 120 : 0.01416782010346651
Loss at batch 130 : 0.010211961343884468
Loss at batch 140 : 0.012307750061154366
Loss at batch 150 : 0.00999339297413826
Loss at batch 160 : 0.010133429430425167
Loss at batch 170 : 0.012809689156711102
Loss at batch 180 : 0.009119784459471703
Loss at batch 190 : 0.017988266423344612
Loss at batch 200 : 0.013586319051682949
Loss at batch 210 : 0.011889269575476646
Loss at batch 220 : 0.025600237771868706
Loss at batch 230 : 0.013446965254843235
Loss at batch 240 : 0.009624551050364971
Loss at batch 250 : 0.017099764198064804
Loss at batch 260 : 0.01389771606773138
Loss at batch 270 : 0.013061391189694405
Loss at batch 280 : 0.014918491244316101
Loss at batch 290 : 0.012531853280961514
Loss at batch 300 : 0.016834260895848274
Loss at batch 310 : 0.015989836305379868
Loss at batch 320 : 0.01420349720865488
Loss at batch 330 : 0.015354336239397526
Loss at batch 340 : 0.01121763326227665
Loss at batch 350 : 0.016416287049651146
Loss at batch 360 : 0.017679305747151375
Loss at batch 370 : 0.008978004567325115
epoch189 finished!
Loss at batch 10 : 0.01708759181201458
Loss at batch 20 : 0.013009940274059772
Loss at batch 30 : 0.01762971468269825
Loss at batch 40 : 0.015699494630098343
Loss at batch 50 : 0.00891551747918129
Loss at batch 60 : 0.01951083168387413
Loss at batch 70 : 0.014578346163034439
Loss at batch 80 : 0.011324148625135422
Loss at batch 90 : 0.014979008585214615
Loss at batch 100 : 0.01505634468048811
Loss at batch 110 : 0.009062034077942371
Loss at batch 120 : 0.010137206874787807
Loss at batch 130 : 0.013973541557788849
Loss at batch 140 : 0.01953498087823391
Loss at batch 150 : 0.020650038495659828
Loss at batch 160 : 0.016638407483696938
Loss at batch 170 : 0.015685053542256355
Loss at batch 180 : 0.017428699880838394
Loss at batch 190 : 0.01236648764461279
Loss at batch 200 : 0.015077531337738037
Loss at batch 210 : 0.01390568632632494
Loss at batch 220 : 0.012311266735196114
Loss at batch 230 : 0.016719913110136986
Loss at batch 240 : 0.014938341453671455
Loss at batch 250 : 0.01403170544654131
Loss at batch 260 : 0.010364430956542492
Loss at batch 270 : 0.012806707993149757
Loss at batch 280 : 0.01093948632478714
Loss at batch 290 : 0.013417769223451614
Loss at batch 300 : 0.013649046421051025
Loss at batch 310 : 0.015351323410868645
Loss at batch 320 : 0.011616882868111134
Loss at batch 330 : 0.01437798049300909
Loss at batch 340 : 0.011567211709916592
Loss at batch 350 : 0.0072075361385941505
Loss at batch 360 : 0.007617901545017958
Loss at batch 370 : 0.009148044511675835
epoch190 finished!
Loss at batch 10 : 0.016392773017287254
Loss at batch 20 : 0.005666634533554316
Loss at batch 30 : 0.006956854369491339
Loss at batch 40 : 0.01820474863052368
Loss at batch 50 : 0.00831415131688118
Loss at batch 60 : 0.010184419341385365
Loss at batch 70 : 0.00830539409071207
Loss at batch 80 : 0.016042128205299377
Loss at batch 90 : 0.011354178190231323
Loss at batch 100 : 0.011190559715032578
Loss at batch 110 : 0.0172659270465374
Loss at batch 120 : 0.020543590188026428
Loss at batch 130 : 0.015120481140911579
Loss at batch 140 : 0.009047036059200764
Loss at batch 150 : 0.014155788347125053
Loss at batch 160 : 0.01617482490837574
Loss at batch 170 : 0.020590055733919144
Loss at batch 180 : 0.014595805667340755
Loss at batch 190 : 0.010584475472569466
Loss at batch 200 : 0.009343483485281467
Loss at batch 210 : 0.017146605998277664
Loss at batch 220 : 0.009168953634798527
Loss at batch 230 : 0.02325216308236122
Loss at batch 240 : 0.01366996206343174
Loss at batch 250 : 0.00918679591268301
Loss at batch 260 : 0.01633218675851822
Loss at batch 270 : 0.012514608912169933
Loss at batch 280 : 0.013271015137434006
Loss at batch 290 : 0.019243570044636726
Loss at batch 300 : 0.01975913904607296
Loss at batch 310 : 0.006906988099217415
Loss at batch 320 : 0.013783876784145832
Loss at batch 330 : 0.01675521768629551
Loss at batch 340 : 0.01676906831562519
Loss at batch 350 : 0.013599857687950134
Loss at batch 360 : 0.012727960012853146
Loss at batch 370 : 0.009624948725104332
epoch190 finished!
Loss at batch 10 : 0.016020730137825012
Loss at batch 20 : 0.015561847016215324
Loss at batch 30 : 0.007789614610373974
Loss at batch 40 : 0.014278201386332512
Loss at batch 50 : 0.012380407191812992
Loss at batch 60 : 0.008570440113544464
Loss at batch 70 : 0.01145568024367094
Loss at batch 80 : 0.015038070268929005
Loss at batch 90 : 0.021157579496502876
Loss at batch 100 : 0.020240407437086105
Loss at batch 110 : 0.017807379364967346
Loss at batch 120 : 0.009140276350080967
Loss at batch 130 : 0.011803442612290382
Loss at batch 140 : 0.013757536187767982
Loss at batch 150 : 0.008978460915386677
Loss at batch 160 : 0.014560047537088394
Loss at batch 170 : 0.008418620564043522
Loss at batch 180 : 0.010653349570930004
Loss at batch 190 : 0.013493271544575691
Loss at batch 200 : 0.013232968747615814
Loss at batch 210 : 0.014241121709346771
Loss at batch 220 : 0.01571088470518589
Loss at batch 230 : 0.007605768274515867
Loss at batch 240 : 0.02033066749572754
Loss at batch 250 : 0.011381586082279682
Loss at batch 260 : 0.01188148558139801
Loss at batch 270 : 0.010633359663188457
Loss at batch 280 : 0.010289096273481846
Loss at batch 290 : 0.015237358398735523
Loss at batch 300 : 0.007882599718868732
Loss at batch 310 : 0.016299888491630554
Loss at batch 320 : 0.009046715684235096
Loss at batch 330 : 0.011436089873313904
Loss at batch 340 : 0.007576223462820053
Loss at batch 350 : 0.013026644475758076
Loss at batch 360 : 0.01198721956461668
Loss at batch 370 : 0.0136359091848135
epoch191 finished!
Loss at batch 10 : 0.016194477677345276
Loss at batch 20 : 0.01692252978682518
Loss at batch 30 : 0.01692667230963707
Loss at batch 40 : 0.01362196821719408
Loss at batch 50 : 0.01519968081265688
Loss at batch 60 : 0.016650473698973656
Loss at batch 70 : 0.015572883188724518
Loss at batch 80 : 0.015048588626086712
Loss at batch 90 : 0.020455559715628624
Loss at batch 100 : 0.018174318596720695
Loss at batch 110 : 0.02052677609026432
Loss at batch 120 : 0.0162100438028574
Loss at batch 130 : 0.010636236518621445
Loss at batch 140 : 0.011532174423336983
Loss at batch 150 : 0.014544791541993618
Loss at batch 160 : 0.012613517232239246
Loss at batch 170 : 0.008570145815610886
Loss at batch 180 : 0.009637231938540936
Loss at batch 190 : 0.008350293152034283
Loss at batch 200 : 0.01669088378548622
Loss at batch 210 : 0.012855283915996552
Loss at batch 220 : 0.019429204985499382
Loss at batch 230 : 0.014722599647939205
Loss at batch 240 : 0.00996002834290266
Loss at batch 250 : 0.02495102398097515
Loss at batch 260 : 0.029079865664243698
Loss at batch 270 : 0.011211353354156017
Loss at batch 280 : 0.019299905747175217
Loss at batch 290 : 0.013162174262106419
Loss at batch 300 : 0.011922385543584824
Loss at batch 310 : 0.01710711419582367
Loss at batch 320 : 0.02654970809817314
Loss at batch 330 : 0.010887069627642632
Loss at batch 340 : 0.013695036992430687
Loss at batch 350 : 0.014793516136705875
Loss at batch 360 : 0.01778477616608143
Loss at batch 370 : 0.012489672750234604
epoch191 finished!
Loss at batch 10 : 0.014203479513525963
Loss at batch 20 : 0.014363585971295834
Loss at batch 30 : 0.009937525726854801
Loss at batch 40 : 0.010808862745761871
Loss at batch 50 : 0.01229354739189148
Loss at batch 60 : 0.020120836794376373
Loss at batch 70 : 0.01502437423914671
Loss at batch 80 : 0.017222246155142784
Loss at batch 90 : 0.013536922633647919
Loss at batch 100 : 0.013708672486245632
Loss at batch 110 : 0.015471926890313625
Loss at batch 120 : 0.011956990696489811
Loss at batch 130 : 0.017417671158909798
Loss at batch 140 : 0.00663943774998188
Loss at batch 150 : 0.020623212680220604
Loss at batch 160 : 0.022713687270879745
Loss at batch 170 : 0.01627802662551403
Loss at batch 180 : 0.013955569826066494
Loss at batch 190 : 0.012626529671251774
Loss at batch 200 : 0.011849867179989815
Loss at batch 210 : 0.013201278634369373
Loss at batch 220 : 0.008493749424815178
Loss at batch 230 : 0.015438245609402657
Loss at batch 240 : 0.015012403018772602
Loss at batch 250 : 0.006883809342980385
Loss at batch 260 : 0.00801408477127552
Loss at batch 270 : 0.010269688442349434
Loss at batch 280 : 0.013302125036716461
Loss at batch 290 : 0.01454292144626379
Loss at batch 300 : 0.01397372130304575
Loss at batch 310 : 0.011944523081183434
Loss at batch 320 : 0.010419250465929508
Loss at batch 330 : 0.014052389189600945
Loss at batch 340 : 0.017795462161302567
Loss at batch 350 : 0.010489637963473797
Loss at batch 360 : 0.010549865663051605
Loss at batch 370 : 0.013109906576573849
epoch192 finished!
Loss at batch 10 : 0.01526532880961895
Loss at batch 20 : 0.012198341079056263
Loss at batch 30 : 0.013286887668073177
Loss at batch 40 : 0.01701406016945839
Loss at batch 50 : 0.02039959654211998
Loss at batch 60 : 0.008734467439353466
Loss at batch 70 : 0.018798615783452988
Loss at batch 80 : 0.02152188867330551
Loss at batch 90 : 0.018261155113577843
Loss at batch 100 : 0.016183121129870415
Loss at batch 110 : 0.01709829643368721
Loss at batch 120 : 0.01428919192403555
Loss at batch 130 : 0.013937356881797314
Loss at batch 140 : 0.0045175617560744286
Loss at batch 150 : 0.014547498896718025
Loss at batch 160 : 0.022541658952832222
Loss at batch 170 : 0.011641038581728935
Loss at batch 180 : 0.012675213627517223
Loss at batch 190 : 0.016373490914702415
Loss at batch 200 : 0.015568748116493225
Loss at batch 210 : 0.009764175862073898
Loss at batch 220 : 0.007845769636332989
Loss at batch 230 : 0.011118515394628048
Loss at batch 240 : 0.013073563575744629
Loss at batch 250 : 0.01270694937556982
Loss at batch 260 : 0.01548461988568306
Loss at batch 270 : 0.011069109663367271
Loss at batch 280 : 0.01699076034128666
Loss at batch 290 : 0.016410812735557556
Loss at batch 300 : 0.017367403954267502
Loss at batch 310 : 0.014394940808415413
Loss at batch 320 : 0.018244082108139992
Loss at batch 330 : 0.015928616747260094
Loss at batch 340 : 0.017019296064972878
Loss at batch 350 : 0.02056511864066124
Loss at batch 360 : 0.01089895237237215
Loss at batch 370 : 0.011215806007385254
epoch192 finished!
Loss at batch 10 : 0.01199033297598362
Loss at batch 20 : 0.009985269047319889
Loss at batch 30 : 0.007695347536355257
Loss at batch 40 : 0.007083171978592873
Loss at batch 50 : 0.013100345619022846
Loss at batch 60 : 0.012373284436762333
Loss at batch 70 : 0.013635936193168163
Loss at batch 80 : 0.013542916625738144
Loss at batch 90 : 0.014236003160476685
Loss at batch 100 : 0.024766800925135612
Loss at batch 110 : 0.020091481506824493
Loss at batch 120 : 0.017289387062191963
Loss at batch 130 : 0.009267479181289673
Loss at batch 140 : 0.010074354708194733
Loss at batch 150 : 0.012422557920217514
Loss at batch 160 : 0.01507390383630991
Loss at batch 170 : 0.015528854914009571
Loss at batch 180 : 0.015159456059336662
Loss at batch 190 : 0.015843456611037254
Loss at batch 200 : 0.007359284441918135
Loss at batch 210 : 0.008994956500828266
Loss at batch 220 : 0.01062817219644785
Loss at batch 230 : 0.010622700676321983
Loss at batch 240 : 0.0072992462664842606
Loss at batch 250 : 0.019355859607458115
Loss at batch 260 : 0.014452701434493065
Loss at batch 270 : 0.010095889680087566
Loss at batch 280 : 0.0165358055382967
Loss at batch 290 : 0.009506503120064735
Loss at batch 300 : 0.01589871756732464
Loss at batch 310 : 0.013894004747271538
Loss at batch 320 : 0.013346721418201923
Loss at batch 330 : 0.009981164708733559
Loss at batch 340 : 0.00944595132023096
Loss at batch 350 : 0.0093696853145957
Loss at batch 360 : 0.015554833225905895
Loss at batch 370 : 0.013753028586506844
epoch193 finished!
Loss at batch 10 : 0.019658084958791733
Loss at batch 20 : 0.010364356450736523
Loss at batch 30 : 0.01255734357982874
Loss at batch 40 : 0.013248586095869541
Loss at batch 50 : 0.010274051688611507
Loss at batch 60 : 0.013060931116342545
Loss at batch 70 : 0.0158856138586998
Loss at batch 80 : 0.013912688940763474
Loss at batch 90 : 0.013403068296611309
Loss at batch 100 : 0.020809948444366455
Loss at batch 110 : 0.011862880550324917
Loss at batch 120 : 0.014717317186295986
Loss at batch 130 : 0.015904970467090607
Loss at batch 140 : 0.013917111791670322
Loss at batch 150 : 0.01778447814285755
Loss at batch 160 : 0.031136183068156242
Loss at batch 170 : 0.024831246584653854
Loss at batch 180 : 0.016453400254249573
Loss at batch 190 : 0.010200109332799911
Loss at batch 200 : 0.008703348226845264
Loss at batch 210 : 0.00732546066865325
Loss at batch 220 : 0.018819542601704597
Loss at batch 230 : 0.027450012043118477
Loss at batch 240 : 0.013338061980903149
Loss at batch 250 : 0.01596038229763508
Loss at batch 260 : 0.010258018039166927
Loss at batch 270 : 0.014171581715345383
Loss at batch 280 : 0.011552014388144016
Loss at batch 290 : 0.01120064128190279
Loss at batch 300 : 0.016408322378993034
Loss at batch 310 : 0.025266407057642937
Loss at batch 320 : 0.017773238942027092
Loss at batch 330 : 0.018845735117793083
Loss at batch 340 : 0.015344907529652119
Loss at batch 350 : 0.011097223497927189
Loss at batch 360 : 0.02097816951572895
Loss at batch 370 : 0.02850383147597313
epoch193 finished!
Loss at batch 10 : 0.017270229756832123
Loss at batch 20 : 0.014666478149592876
Loss at batch 30 : 0.01755572110414505
Loss at batch 40 : 0.015012633055448532
Loss at batch 50 : 0.011022881604731083
Loss at batch 60 : 0.015824181959033012
Loss at batch 70 : 0.02594599686563015
Loss at batch 80 : 0.010513890534639359
Loss at batch 90 : 0.0135665163397789
Loss at batch 100 : 0.009870678186416626
Loss at batch 110 : 0.014358030632138252
Loss at batch 120 : 0.014738167636096478
Loss at batch 130 : 0.009636146016418934
Loss at batch 140 : 0.008134594187140465
Loss at batch 150 : 0.017787663266062737
Loss at batch 160 : 0.023092864081263542
Loss at batch 170 : 0.023611389100551605
Loss at batch 180 : 0.015536366030573845
Loss at batch 190 : 0.009498266503214836
Loss at batch 200 : 0.011282840743660927
Loss at batch 210 : 0.014601665548980236
Loss at batch 220 : 0.015127889811992645
Loss at batch 230 : 0.013943918980658054
Loss at batch 240 : 0.011667037382721901
Loss at batch 250 : 0.013863485306501389
Loss at batch 260 : 0.015838418155908585
Loss at batch 270 : 0.0183910820633173
Loss at batch 280 : 0.006294766906648874
Loss at batch 290 : 0.015895454213023186
Loss at batch 300 : 0.018929865211248398
Loss at batch 310 : 0.013338008895516396
Loss at batch 320 : 0.017375126481056213
Loss at batch 330 : 0.01098336186259985
Loss at batch 340 : 0.027382152155041695
Loss at batch 350 : 0.01700679026544094
Loss at batch 360 : 0.007896987721323967
Loss at batch 370 : 0.011069374158978462
epoch194 finished!
Loss at batch 10 : 0.01576320454478264
Loss at batch 20 : 0.010277122259140015
Loss at batch 30 : 0.008410780690610409
Loss at batch 40 : 0.0221088957041502
Loss at batch 50 : 0.012762466445565224
Loss at batch 60 : 0.024222081527113914
Loss at batch 70 : 0.011082102544605732
Loss at batch 80 : 0.016368193551898003
Loss at batch 90 : 0.012130452319979668
Loss at batch 100 : 0.013989671133458614
Loss at batch 110 : 0.009579803794622421
Loss at batch 120 : 0.013179506175220013
Loss at batch 130 : 0.009353749454021454
Loss at batch 140 : 0.016122417524456978
Loss at batch 150 : 0.010609885677695274
Loss at batch 160 : 0.01447860337793827
Loss at batch 170 : 0.019361605867743492
Loss at batch 180 : 0.015267487615346909
Loss at batch 190 : 0.020061014220118523
Loss at batch 200 : 0.012430812232196331
Loss at batch 210 : 0.011790506541728973
Loss at batch 220 : 0.015024777501821518
Loss at batch 230 : 0.008470098488032818
Loss at batch 240 : 0.011788268573582172
Loss at batch 250 : 0.010792306624352932
Loss at batch 260 : 0.00863582268357277
Loss at batch 270 : 0.01740245893597603
Loss at batch 280 : 0.019219771027565002
Loss at batch 290 : 0.023321611806750298
Loss at batch 300 : 0.013790677301585674
Loss at batch 310 : 0.0166502445936203
Loss at batch 320 : 0.013990458101034164
Loss at batch 330 : 0.012152680195868015
Loss at batch 340 : 0.019751518964767456
Loss at batch 350 : 0.012346120551228523
Loss at batch 360 : 0.01705191098153591
Loss at batch 370 : 0.01376282423734665
epoch194 finished!
Loss at batch 10 : 0.016991732642054558
Loss at batch 20 : 0.00687795877456665
Loss at batch 30 : 0.011410743929445744
Loss at batch 40 : 0.00685347244143486
Loss at batch 50 : 0.0087236063554883
Loss at batch 60 : 0.013386635109782219
Loss at batch 70 : 0.015746846795082092
Loss at batch 80 : 0.023033136501908302
Loss at batch 90 : 0.008059683255851269
Loss at batch 100 : 0.01876991055905819
Loss at batch 110 : 0.009058604948222637
Loss at batch 120 : 0.012519458308815956
Loss at batch 130 : 0.008608467876911163
Loss at batch 140 : 0.007896408438682556
Loss at batch 150 : 0.020440882071852684
Loss at batch 160 : 0.014234484173357487
Loss at batch 170 : 0.01234197337180376
Loss at batch 180 : 0.014370047487318516
Loss at batch 190 : 0.01384162437170744
Loss at batch 200 : 0.013666420243680477
Loss at batch 210 : 0.02144245058298111
Loss at batch 220 : 0.018547507002949715
Loss at batch 230 : 0.015345616266131401
Loss at batch 240 : 0.007425267249345779
Loss at batch 250 : 0.02534360997378826
Loss at batch 260 : 0.013435764238238335
Loss at batch 270 : 0.020576566457748413
Loss at batch 280 : 0.018298890441656113
Loss at batch 290 : 0.008979595266282558
Loss at batch 300 : 0.012912739999592304
Loss at batch 310 : 0.026158707216382027
Loss at batch 320 : 0.01590440608561039
Loss at batch 330 : 0.009237341582775116
Loss at batch 340 : 0.009588129818439484
Loss at batch 350 : 0.01604536361992359
Loss at batch 360 : 0.010596878826618195
Loss at batch 370 : 0.015614124946296215
epoch195 finished!
Loss at batch 10 : 0.01594582200050354
Loss at batch 20 : 0.012715968303382397
Loss at batch 30 : 0.00965159758925438
Loss at batch 40 : 0.010000295005738735
Loss at batch 50 : 0.008752429857850075
Loss at batch 60 : 0.011205069720745087
Loss at batch 70 : 0.02635764703154564
Loss at batch 80 : 0.013282038271427155
Loss at batch 90 : 0.022474806755781174
Loss at batch 100 : 0.011267263442277908
Loss at batch 110 : 0.017724623903632164
Loss at batch 120 : 0.01540074497461319
Loss at batch 130 : 0.010108263231813908
Loss at batch 140 : 0.015391498804092407
Loss at batch 150 : 0.01579180359840393
Loss at batch 160 : 0.018588434904813766
Loss at batch 170 : 0.017038697376847267
Loss at batch 180 : 0.02115596830844879
Loss at batch 190 : 0.011446092277765274
Loss at batch 200 : 0.01635022461414337
Loss at batch 210 : 0.009222392924129963
Loss at batch 220 : 0.007278661243617535
Loss at batch 230 : 0.011759914457798004
Loss at batch 240 : 0.011907573789358139
Loss at batch 250 : 0.009696098044514656
Loss at batch 260 : 0.01605577953159809
Loss at batch 270 : 0.023579813539981842
Loss at batch 280 : 0.011328323744237423
Loss at batch 290 : 0.029515322297811508
Loss at batch 300 : 0.01581234484910965
Loss at batch 310 : 0.017462432384490967
Loss at batch 320 : 0.010327866300940514
Loss at batch 330 : 0.01346578449010849
Loss at batch 340 : 0.010671288706362247
Loss at batch 350 : 0.00959409773349762
Loss at batch 360 : 0.012931527569890022
Loss at batch 370 : 0.014574017375707626
epoch195 finished!
Loss at batch 10 : 0.011065620929002762
Loss at batch 20 : 0.008831944316625595
Loss at batch 30 : 0.014185242354869843
Loss at batch 40 : 0.007083088159561157
Loss at batch 50 : 0.010410800576210022
Loss at batch 60 : 0.011422539129853249
Loss at batch 70 : 0.01450001448392868
Loss at batch 80 : 0.00888647697865963
Loss at batch 90 : 0.018206890672445297
Loss at batch 100 : 0.012411147356033325
Loss at batch 110 : 0.010127497836947441
Loss at batch 120 : 0.024009641259908676
Loss at batch 130 : 0.012544136494398117
Loss at batch 140 : 0.01573163829743862
Loss at batch 150 : 0.01979305036365986
Loss at batch 160 : 0.012049201875925064
Loss at batch 170 : 0.012282059527933598
Loss at batch 180 : 0.009508000686764717
Loss at batch 190 : 0.014025088399648666
Loss at batch 200 : 0.007880117744207382
Loss at batch 210 : 0.020473526790738106
Loss at batch 220 : 0.019236773252487183
Loss at batch 230 : 0.011662233620882034
Loss at batch 240 : 0.015527229756116867
Loss at batch 250 : 0.010775750502943993
Loss at batch 260 : 0.013095084577798843
Loss at batch 270 : 0.014608710072934628
Loss at batch 280 : 0.01271119061857462
Loss at batch 290 : 0.00825483351945877
Loss at batch 300 : 0.021775975823402405
Loss at batch 310 : 0.013102957978844643
Loss at batch 320 : 0.009773480705916882
Loss at batch 330 : 0.007750662975013256
Loss at batch 340 : 0.01393695268779993
Loss at batch 350 : 0.012150261551141739
Loss at batch 360 : 0.014380188658833504
Loss at batch 370 : 0.010919506661593914
epoch196 finished!
Loss at batch 10 : 0.008990516886115074
Loss at batch 20 : 0.015510980039834976
Loss at batch 30 : 0.020783143118023872
Loss at batch 40 : 0.01852750964462757
Loss at batch 50 : 0.0224233977496624
Loss at batch 60 : 0.014971521683037281
Loss at batch 70 : 0.007268726825714111
Loss at batch 80 : 0.01671767234802246
Loss at batch 90 : 0.012572168372571468
Loss at batch 100 : 0.02040654979646206
Loss at batch 110 : 0.022034551948308945
Loss at batch 120 : 0.011305390857160091
Loss at batch 130 : 0.008205442689359188
Loss at batch 140 : 0.007330664899200201
Loss at batch 150 : 0.012668702751398087
Loss at batch 160 : 0.011089573614299297
Loss at batch 170 : 0.014592958614230156
Loss at batch 180 : 0.01625436544418335
Loss at batch 190 : 0.008207211270928383
Loss at batch 200 : 0.02263868972659111
Loss at batch 210 : 0.03365635871887207
Loss at batch 220 : 0.01762871816754341
Loss at batch 230 : 0.009787998162209988
Loss at batch 240 : 0.007059475872665644
Loss at batch 250 : 0.009279782883822918
Loss at batch 260 : 0.019050903618335724
Loss at batch 270 : 0.01182820275425911
Loss at batch 280 : 0.012674673460423946
Loss at batch 290 : 0.015292289666831493
Loss at batch 300 : 0.009375411085784435
Loss at batch 310 : 0.006676844786852598
Loss at batch 320 : 0.010688303969800472
Loss at batch 330 : 0.00801529735326767
Loss at batch 340 : 0.0168711356818676
Loss at batch 350 : 0.01459071971476078
Loss at batch 360 : 0.021169040352106094
Loss at batch 370 : 0.012466304004192352
epoch196 finished!
Loss at batch 10 : 0.015379009768366814
Loss at batch 20 : 0.00784845370799303
Loss at batch 30 : 0.011356504634022713
Loss at batch 40 : 0.016432341188192368
Loss at batch 50 : 0.014937707222998142
Loss at batch 60 : 0.007560696452856064
Loss at batch 70 : 0.010666398331522942
Loss at batch 80 : 0.010714077390730381
Loss at batch 90 : 0.025500020012259483
Loss at batch 100 : 0.011021225713193417
Loss at batch 110 : 0.01380948070436716
Loss at batch 120 : 0.007762514986097813
Loss at batch 130 : 0.022619064897298813
Loss at batch 140 : 0.008304350078105927
Loss at batch 150 : 0.012265186756849289
Loss at batch 160 : 0.01239309087395668
Loss at batch 170 : 0.019409388303756714
Loss at batch 180 : 0.017039358615875244
Loss at batch 190 : 0.01833578385412693
Loss at batch 200 : 0.013838067650794983
Loss at batch 210 : 0.013894700445234776
Loss at batch 220 : 0.013060837052762508
Loss at batch 230 : 0.00899774394929409
Loss at batch 240 : 0.009984024800360203
Loss at batch 250 : 0.01625373400747776
Loss at batch 260 : 0.009561736136674881
Loss at batch 270 : 0.020732346922159195
Loss at batch 280 : 0.010430101305246353
Loss at batch 290 : 0.007512266747653484
Loss at batch 300 : 0.024088343605399132
Loss at batch 310 : 0.017324641346931458
Loss at batch 320 : 0.014344376511871815
Loss at batch 330 : 0.015221565030515194
Loss at batch 340 : 0.010851814411580563
Loss at batch 350 : 0.023543795570731163
Loss at batch 360 : 0.020000725984573364
Loss at batch 370 : 0.01336036529392004
epoch197 finished!
Loss at batch 10 : 0.015264507383108139
Loss at batch 20 : 0.008859405294060707
Loss at batch 30 : 0.014246822334825993
Loss at batch 40 : 0.01797240599989891
Loss at batch 50 : 0.00973651371896267
Loss at batch 60 : 0.008501945994794369
Loss at batch 70 : 0.007549667730927467
Loss at batch 80 : 0.011518293991684914
Loss at batch 90 : 0.009475963190197945
Loss at batch 100 : 0.01105128601193428
Loss at batch 110 : 0.018850117921829224
Loss at batch 120 : 0.011830709874629974
Loss at batch 130 : 0.014360814355313778
Loss at batch 140 : 0.00989743135869503
Loss at batch 150 : 0.006406685337424278
Loss at batch 160 : 0.01031222939491272
Loss at batch 170 : 0.01536252349615097
Loss at batch 180 : 0.01402475405484438
Loss at batch 190 : 0.03010457381606102
Loss at batch 200 : 0.007564597763121128
Loss at batch 210 : 0.009939631447196007
Loss at batch 220 : 0.019490964710712433
Loss at batch 230 : 0.009914026595652103
Loss at batch 240 : 0.009545601904392242
Loss at batch 250 : 0.010586157441139221
Loss at batch 260 : 0.013430453836917877
Loss at batch 270 : 0.007589232176542282
Loss at batch 280 : 0.013609746471047401
Loss at batch 290 : 0.011073742061853409
Loss at batch 300 : 0.014773706905543804
Loss at batch 310 : 0.015334537252783775
Loss at batch 320 : 0.013006359338760376
Loss at batch 330 : 0.01469569094479084
Loss at batch 340 : 0.008133058436214924
Loss at batch 350 : 0.012994442135095596
Loss at batch 360 : 0.016988560557365417
Loss at batch 370 : 0.009501602500677109
epoch197 finished!
Loss at batch 10 : 0.011601858772337437
Loss at batch 20 : 0.019791439175605774
Loss at batch 30 : 0.01589021272957325
Loss at batch 40 : 0.010263146832585335
Loss at batch 50 : 0.01423654891550541
Loss at batch 60 : 0.013901331461966038
Loss at batch 70 : 0.018175261095166206
Loss at batch 80 : 0.027518929913640022
Loss at batch 90 : 0.011041482910513878
Loss at batch 100 : 0.010743779130280018
Loss at batch 110 : 0.009641656652092934
Loss at batch 120 : 0.011445668525993824
Loss at batch 130 : 0.014720709063112736
Loss at batch 140 : 0.012315468862652779
Loss at batch 150 : 0.01368664763867855
Loss at batch 160 : 0.007739729713648558
Loss at batch 170 : 0.005675034131854773
Loss at batch 180 : 0.01771131157875061
Loss at batch 190 : 0.011607786640524864
Loss at batch 200 : 0.011664214543998241
Loss at batch 210 : 0.006831833627074957
Loss at batch 220 : 0.013080425560474396
Loss at batch 230 : 0.016023030504584312
Loss at batch 240 : 0.028648385778069496
Loss at batch 250 : 0.018688907846808434
Loss at batch 260 : 0.01165809202939272
Loss at batch 270 : 0.0076680490747094154
Loss at batch 280 : 0.018750792369246483
Loss at batch 290 : 0.008986592292785645
Loss at batch 300 : 0.01541068870574236
Loss at batch 310 : 0.030039487406611443
Loss at batch 320 : 0.01345817930996418
Loss at batch 330 : 0.009923300705850124
Loss at batch 340 : 0.013360879383981228
Loss at batch 350 : 0.0078094732016325
Loss at batch 360 : 0.01317199319601059
Loss at batch 370 : 0.011246654205024242
epoch198 finished!
Loss at batch 10 : 0.008147437125444412
Loss at batch 20 : 0.01160008367151022
Loss at batch 30 : 0.014414891600608826
Loss at batch 40 : 0.028576206415891647
Loss at batch 50 : 0.018594559282064438
Loss at batch 60 : 0.009310046210885048
Loss at batch 70 : 0.013378540053963661
Loss at batch 80 : 0.011519215069711208
Loss at batch 90 : 0.014247654005885124
Loss at batch 100 : 0.019927555695176125
Loss at batch 110 : 0.024232517927885056
Loss at batch 120 : 0.00998472049832344
Loss at batch 130 : 0.02437753975391388
Loss at batch 140 : 0.014939450658857822
Loss at batch 150 : 0.013585429638624191
Loss at batch 160 : 0.008673620410263538
Loss at batch 170 : 0.015439385548233986
Loss at batch 180 : 0.00880716647952795
Loss at batch 190 : 0.01852293685078621
Loss at batch 200 : 0.008256800472736359
Loss at batch 210 : 0.016829274594783783
Loss at batch 220 : 0.010248219594359398
Loss at batch 230 : 0.011680849827826023
Loss at batch 240 : 0.013105137273669243
Loss at batch 250 : 0.01974092796444893
Loss at batch 260 : 0.01570817269384861
Loss at batch 270 : 0.010774740017950535
Loss at batch 280 : 0.016861939802765846
Loss at batch 290 : 0.012470345944166183
Loss at batch 300 : 0.009100199677050114
Loss at batch 310 : 0.007569143548607826
Loss at batch 320 : 0.010696847923099995
Loss at batch 330 : 0.0115404287353158
Loss at batch 340 : 0.019572772085666656
Loss at batch 350 : 0.013451351784169674
Loss at batch 360 : 0.01628687232732773
Loss at batch 370 : 0.012689192779362202
epoch198 finished!
Loss at batch 10 : 0.011072803288698196
Loss at batch 20 : 0.018840759992599487
Loss at batch 30 : 0.011911381967365742
Loss at batch 40 : 0.023694202303886414
Loss at batch 50 : 0.025950033217668533
Loss at batch 60 : 0.015618662349879742
Loss at batch 70 : 0.01059543527662754
Loss at batch 80 : 0.01647663116455078
Loss at batch 90 : 0.013332671485841274
Loss at batch 100 : 0.011625978164374828
Loss at batch 110 : 0.012179400771856308
Loss at batch 120 : 0.014320861548185349
Loss at batch 130 : 0.011361200362443924
Loss at batch 140 : 0.017621316015720367
Loss at batch 150 : 0.006113497540354729
Loss at batch 160 : 0.007252545095980167
Loss at batch 170 : 0.008432022295892239
Loss at batch 180 : 0.01243489608168602
Loss at batch 190 : 0.012424874119460583
Loss at batch 200 : 0.021607929840683937
Loss at batch 210 : 0.014638803899288177
Loss at batch 220 : 0.012545200064778328
Loss at batch 230 : 0.01864485815167427
Loss at batch 240 : 0.010441653430461884
Loss at batch 250 : 0.013695194385945797
Loss at batch 260 : 0.01306725014001131
Loss at batch 270 : 0.010989310219883919
Loss at batch 280 : 0.016291165724396706
Loss at batch 290 : 0.010744048282504082
Loss at batch 300 : 0.009297166019678116
Loss at batch 310 : 0.013497089967131615
Loss at batch 320 : 0.013699712231755257
Loss at batch 330 : 0.021501172333955765
Loss at batch 340 : 0.018455645069479942
Loss at batch 350 : 0.018487730994820595
Loss at batch 360 : 0.01992625743150711
Loss at batch 370 : 0.01356197614222765
epoch199 finished!
Loss at batch 10 : 0.009244493208825588
Loss at batch 20 : 0.009003670886158943
Loss at batch 30 : 0.013001558370888233
Loss at batch 40 : 0.009699990972876549
Loss at batch 50 : 0.008723201230168343
Loss at batch 60 : 0.007316228002309799
Loss at batch 70 : 0.018267694860696793
Loss at batch 80 : 0.015883440151810646
Loss at batch 90 : 0.008594750426709652
Loss at batch 100 : 0.0223446823656559
Loss at batch 110 : 0.016790365800261497
Loss at batch 120 : 0.02636290341615677
Loss at batch 130 : 0.021106991916894913
Loss at batch 140 : 0.021811800077557564
Loss at batch 150 : 0.01461966522037983
Loss at batch 160 : 0.01179569587111473
Loss at batch 170 : 0.013753268867731094
Loss at batch 180 : 0.01444648765027523
Loss at batch 190 : 0.013568253256380558
Loss at batch 200 : 0.010372832417488098
Loss at batch 210 : 0.01383671723306179
Loss at batch 220 : 0.01294652558863163
Loss at batch 230 : 0.024782773107290268
Loss at batch 240 : 0.023126015439629555
Loss at batch 250 : 0.02062724344432354
Loss at batch 260 : 0.009983454830944538
Loss at batch 270 : 0.016758548095822334
Loss at batch 280 : 0.014653246849775314
Loss at batch 290 : 0.015588145703077316
Loss at batch 300 : 0.0200638547539711
Loss at batch 310 : 0.007846112363040447
Loss at batch 320 : 0.014160329475998878
Loss at batch 330 : 0.009623092599213123
Loss at batch 340 : 0.01621902734041214
Loss at batch 350 : 0.01798439584672451
Loss at batch 360 : 0.0066884709522128105
Loss at batch 370 : 0.036314647644758224
epoch199 finished!
